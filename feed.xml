<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>opus.stedden</title>
    <description>just your standard information identity spacetime field</description>
    <link>https://opus.stedden.org</link>
    <atom:link href="https://opus.stedden.org/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 19 Nov 2024 11:13:41 -0600</pubDate>
    <lastBuildDate>Tue, 19 Nov 2024 11:13:41 -0600</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <image>https://opus.stedden.orgassets/images/2024/PXL_20241027_165020295.jpg</image>
        <title>CITY MOTION: Transforming Cities One Game at a Time</title>
        <description>&lt;p&gt;&lt;em&gt;Update: The game was originally called Walkable, but was updated to the title CITY MOTION based on feedback from game testers. It has been updated below.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I don’t think I’ve ever worked on a project longer than the board game I’ve finally finished.  The idea was born while I was doing chores on a farm in the New Mexico desert, and now three painstaking years and more than 100 test games later, I’m extremely proud of all the work I’ve put into it. &lt;a href=&quot;https://kickstarter.com/projects/solarpunktravel/walkable&quot;&gt;And now, I’m ready to share it with the world.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I’m hoping that this game will delight the overlapping Venn diagram of board game / transit nerds that I know and love, and I hope that it’ll also work as an advocacy tool to help non-urbanists start to think about how their cities can work a little better for human life.&lt;/p&gt;

&lt;h2 id=&quot;a-game-about-sustainable-transportation&quot;&gt;A game about sustainable transportation&lt;/h2&gt;

&lt;p&gt;At its core, CITY MOTION is a board game designed for 2-9 players, where each turn players earn points by visiting various destinations on the board. The twist? As the game progresses it gets harder to get everywhere in time by car so players must also &lt;em&gt;invest&lt;/em&gt; their time in improving the existing urban environment around them.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;small_img&quot; title=&quot;Walkable Board&quot; src=&quot;/assets/images/2024/PXL_20241027_165020295.jpg&quot; alt=&quot;A game board with small city tiles on top of a gridded city board. In the bottom left there is an upside down board piece with the logo and a futuristic urban city with tram on it.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The game begins with a modular board representing a city on the grid. Each player starts by adding their home to the board-oldest first because that’s how real estate works naturally. On each turn, players can spend time to move their character to different locations to earn points or spend time improving the city by advocating for initiatives. Players advocate for adding bike lanes or public transit, increasing density, removing parking and a host of other options.  However, they can’t automatically pass initiatives on their own, and the odds of one passing get higher if they team up.&lt;/p&gt;

&lt;p&gt;The ultimate objective is to collect the most points by visiting the most places, but they can’t run up their score in later rounds unless they’ve planned ahead and worked together to reshape their city.&lt;/p&gt;

&lt;p&gt;A fitting analogy for real life change in local politics!&lt;/p&gt;

&lt;h2 id=&quot;leveling-up-our-cities-games-as-change-makers&quot;&gt;Leveling Up Our Cities: Games as Change-Makers&lt;/h2&gt;

&lt;p&gt;CITY MOTION isn’t just about scoring points; it’s about shifting perspectives on urban development. At every step in the design, I wanted to emphasize that players don’t just get to build the city perfectly from the top-down, but have to actively think about reforming the spaces that already exist around them. The game simulates the experience of being an engaged citizen, where time spent on improving the community may detract from the immediate rewards of getting out to visit the destinations around you.&lt;/p&gt;

&lt;p&gt;What was interesting was that while working on this game, I test played it with more than a dozen people, many of whom tried to steer the game towards a more top-down mechanic. It was quite hard to resist the urge because I had no desire to make a game that looked like a board game version of Sim City.  In the end, I think I was right and the game that I ended up with was the perfect blend of a city-building game and a “getaraound” game.&lt;/p&gt;

&lt;h2 id=&quot;seeds-of-inspiration-how-it-all-started&quot;&gt;Seeds of Inspiration: How It All Started&lt;/h2&gt;

&lt;p&gt;The seeds for CITY MOTION were sown during our transformative year biking the &lt;a href=&quot;2021/01/coop-trail-update/&quot;&gt;western and southwest US in 2021-2022&lt;/a&gt;. We’d seen such a variety of city designs from Portland’s bike utopia to LA’s grimy car-dependent misery, and we’d met so many people who were passionate about urban planning. I think I first started to want to do something during a particularly thought-provoking stay with an urban planner focused on the health impacts of car-dependence. Earlier that year, I’d built the online game &lt;a href=&quot;/2021/10/uprising-chess/&quot;&gt;Uprising Chess&lt;/a&gt; as a tool to advocate for worker cooperatives as an alternative economic model, and an urban planning board game felt like the perfect idea as an advocacy tool.&lt;/p&gt;

&lt;p&gt;It was shortly after that, while WWOOFing on a farm and having only to work 4 hours per day that I started to put together the concepts that would become the game. Claire and I began sketching out the game in the afternoons, and I designed the first prototype and biked into town to get it printed. It was a whirlwind of work and I finished in less than a week.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;small_img&quot; title=&quot;Original Prototype&quot; src=&quot;/assets/images/2024/PXL_20220422_022856769.jpg&quot; alt=&quot;A prototype game board on a camping mat.&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;text-align:center;margin-bottom:20px;margin-top:5px;&quot;&gt;Original prototype on our camping mat&lt;/div&gt;

&lt;p&gt;When we returned to visit our urban planner friend, we presented her with the first copy of the game—a heartfelt culmination of our experiences and shared visions. She was so amused, and her enthusiasm reaffirmed my belief in the power of games to inspire real change.&lt;/p&gt;

&lt;h2 id=&quot;join-the-adventure-my-first-kickstarter-journey&quot;&gt;Join the Adventure: My First Kickstarter Journey&lt;/h2&gt;

&lt;p&gt;As we prepare to launch CITY MOTION on &lt;a href=&quot;https://kickstarter.com/projects/solarpunktravel/walkable&quot;&gt;Kickstarter&lt;/a&gt;, I’m experiencing a mix of excitement and nerves. This is my first crowdfunding campaign, and it feels a bit strange to put my creation out there for others to support.&lt;/p&gt;

&lt;p&gt;With most of the projects on this site, I would normally just give away the plans and then call it a day.  But I’m hopeful that the process of putting it on Kickstarter, and promoting it around town and with online communities will actually help it to spread further than if I just put it up and moved on. And I believe it’s really important to share this game with a wider audience.&lt;/p&gt;

&lt;p&gt;In addition, I decided to use any surplus funds that might come from sales to kickstart my other urbanism related project: the &lt;a href=&quot;https://isthmuscarshare.com&quot;&gt;Isthmus Carshare Cooperative&lt;/a&gt;.  Isthmus Carshare is another huge project that I’ll be writing more about soon.  It’s an outgrowth of my &lt;a href=&quot;/2024/02/climatebase-carshare/&quot;&gt;earlier work&lt;/a&gt; with my team from the &lt;a href=&quot;https://climatebase.org/fellowship&quot;&gt;Climatebase Fellowship&lt;/a&gt; to vet a novel hyper-local system for carsharing. It’s operating on a much grander scale and is already requiring grants and Board meetings, but if we can make it happen it can really help reduce car dependency in Madison.  Overall I think it’ll be a perfect beneficiary of any success this game manages to have, and I’m extremely hopeful that we’ll be able to successfully launch our operations on the success of our efforts with CITY MOTION.&lt;/p&gt;

&lt;h2 id=&quot;wrap-up-lets-walk-the-talk-or-bike-or-bus&quot;&gt;Wrap-Up: Let’s Walk the Talk (or Bike or Bus)!&lt;/h2&gt;

&lt;p&gt;I really hope WITY MOTION can be more than just a fun board game; I want it to be an advocacy tool and a conversation starter for our aspirations toward healthier, more vibrant cities. And even though it’s just a game, building it has felt like some of the most important I’ve ever undertaken. The time really is upon us to fix our cities both for healthy urban living and fixing unsustainable car-dependency in a positive way.&lt;/p&gt;

&lt;p&gt;So whether you’re a board game enthusiast, a transit advocate, or just looking to have a good time with some friends, I invite you to join us in reimagining what it means to be an engaged citizen in a walkable world. Now go contribute to that &lt;a href=&quot;https://kickstarter.com/projects/solarpunktravel/walkable&quot;&gt;Kickstarter&lt;/a&gt; please :)&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Oct 2024 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2024/10/walkable-board-game/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2024/10/walkable-board-game/</guid>
        
        <category>games</category>
        
        <category>urban planning</category>
        
        <category>sustainability</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orgassets/images/2024/carshare_survey.png</image>
        <title>Climatebase Fellowship and Vetting a Carshare</title>
        <description>&lt;p&gt;I had the incredible opportunity to be part of &lt;strong&gt;Climatebase Fellowship Cohort 4&lt;/strong&gt;, and I’m excited to share my journey with you. Over the past few months, I’ve learned so much about climate tech, entrepreneurship, and the power of community-based solutions. The Fellowship not only deepened my understanding of how we can tackle the climate crisis through innovative technologies but also gave me the opportunity to pursue a project that I’m passionate about: &lt;strong&gt;Down the Block Carshare&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-problem-carshare-isnt-working-for-the-average-household&quot;&gt;The Problem: Carshare Isn’t Working for the Average Household&lt;/h2&gt;

&lt;p&gt;For a long time, I’ve been thinking about how cities are designed for cars, and how difficult it is for the average person to find affordable, flexible transportation options. Carshare programs like Zipcar or Turo offer a solution, but they tend to be more convenient for people who already live in car-centric areas. What about households in neighborhoods where a personal car is still necessary, even though it’s used less often?&lt;/p&gt;

&lt;p&gt;What if we could bring carshare directly into local communities and prep neighborhoods for the future of green, walkable cities?&lt;/p&gt;

&lt;p&gt;I pitched this idea to my fellow Fellows: &lt;strong&gt;Down the Block Carshare&lt;/strong&gt;, a &lt;strong&gt;local-first carshare model&lt;/strong&gt; designed to give people access to cars on their own block, reduce the number of cars on the road, and save money by cutting down on unnecessary car ownership. By reducing fleet size, we could save money that could go directly into purchasing electric vehicles (EVs) and e-bikes, creating a greener, more sustainable transportation system for everyone.&lt;/p&gt;

&lt;iframe src=&quot;https://docs.google.com/presentation/d/e/2PACX-1vT_jtN5GGaGZcDgrMAqNCSc2onL66YkOrIikrVmbcDpAILKJbs3gO0Z1jBxeSr7eNS1-eQNenj50yqW/embed?start=true&amp;amp;loop=true&amp;amp;delayms=3000&quot; frameborder=&quot;0&quot; width=&quot;960&quot; height=&quot;569&quot; allowfullscreen=&quot;true&quot; mozallowfullscreen=&quot;true&quot; webkitallowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;hr /&gt;

&lt;p&gt;After I pitched the &lt;strong&gt;Down the Block Carshare&lt;/strong&gt; idea to my fellow Fellows, I was blown away by the response. People were really engaged and eager to support the concept. In fact, the feedback I received was so positive that it quickly turned into something tangible. I ended up collaborating with two talented Fellows, &lt;a href=&quot;https://www.linkedin.com/in/chad-bustard-phd-20628090&quot;&gt;Chad Bustard&lt;/a&gt; and &lt;a href=&quot;https://app.midstay.com/profiles/carsten-roskes&quot;&gt;Carsten Röskes&lt;/a&gt;, who shared the vision and helped me turn this idea into a real project.&lt;/p&gt;

&lt;p&gt;With their help, we set out to test the idea by speaking directly to the people who would be most impacted: our local community.&lt;/p&gt;

&lt;h2 id=&quot;vetting-carshare-viability-in-madison&quot;&gt;Vetting Carshare Viability in Madison&lt;/h2&gt;

&lt;p&gt;While Chad and Carsten worked on geospatial and financial models, I kicked off by conducting &lt;strong&gt;10 in-person interviews&lt;/strong&gt; with people in our target neighborhood, the &lt;strong&gt;Tenney-Lapham&lt;/strong&gt; area. The feedback was invaluable. People loved the idea of local carshare options but had concerns about costs, access to vehicles, and reliability. From there, we put together an online &lt;strong&gt;survey&lt;/strong&gt; that received &lt;strong&gt;68 responses&lt;/strong&gt; from local residents. The survey results were even more encouraging: over &lt;strong&gt;20 people&lt;/strong&gt; were interested in signing up to learn more if and when the carshare launched!&lt;/p&gt;

&lt;p&gt;This research gave us a clearer picture of what people actually want in a carshare program and how we could make it work in our specific neighborhood.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;scrolly-telling-why-carshare&quot;&gt;“Scrolly-Telling” Why Carshare&lt;/h4&gt;

&lt;p&gt;One of the coolest parts of this project was building an interactive web app to showcase our idea and spread the word. We wanted to make the information engaging and easy to understand, so we created a &lt;strong&gt;“scrolly-telling”&lt;/strong&gt; experience that breaks down the benefits of carshare in a fun, interactive way.
It covered a cost-comparison of owning a car vs carshare, and included the responses from our survey.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;small_img&quot; title=&quot;Carshare Survey wordcloud&quot; src=&quot;/assets/images/2024/carshare_survey.png&quot; alt=&quot;A word cloud with car related words included, words like maintenance, guilt, climate.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And Chad also included a very cool app that allowed a direct cost comparison between Zipcar and our carshare’s pricing model for various locations around Madison, WI.&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;small_img&quot; title=&quot;Walkable Board&quot; src=&quot;/assets/images/2024/carshare_demo.png&quot; alt=&quot;A game board with small city tiles on top of a gridded city board. In the bottom left there is an upside down board piece with the logo and a futuristic urban city with tram on it.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can check it out here: &lt;a href=&quot;https://why.isthmuscarshare.com/&quot;&gt;&lt;strong&gt;Why Isthmus Carshare&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;final-project-summary-from-research-to-realization&quot;&gt;Final Project Summary: From Research to Realization&lt;/h3&gt;

&lt;p&gt;As part of the Fellowship, we gave a &lt;strong&gt;final project presentation&lt;/strong&gt; where we shared our survey results, the web app, and the financial model we worked out for the carshare initiative. This presentation was a culmination of months of research, design, and collaboration. We were able to show how our carshare could realistically be implemented and make a meaningful impact in the local community.&lt;/p&gt;

&lt;iframe src=&quot;https://docs.google.com/presentation/d/e/2PACX-1vQMghlZG6VtpGKFTX9eKQaTvXM6mTOfufPRUhHCBN9zxPOTh2hlBJMwzRQDxlqUrw/embed?start=true&amp;amp;loop=true&amp;amp;delayms=3000&quot; frameborder=&quot;0&quot; width=&quot;960&quot; height=&quot;569&quot; allowfullscreen=&quot;true&quot; mozallowfullscreen=&quot;true&quot; webkitallowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;whats-next&quot;&gt;What’s Next?&lt;/h3&gt;

&lt;p&gt;After the presentation, we realized that this project had a lot of potential, and it’s too important to let go. So, we’ve decided to &lt;strong&gt;keep pursuing Down the Block Carshare&lt;/strong&gt;. We’re taking the next step by forming a &lt;strong&gt;steering committee&lt;/strong&gt; to explore its viability further. We’ll be working to refine the business model, secure funding, and make sure we have a sustainable, community-centered carshare program in place for the long term.&lt;/p&gt;

&lt;p&gt;I’m so grateful for everything I learned during the &lt;strong&gt;Climatebase Fellowship&lt;/strong&gt; and for the amazing teammates who made this project possible. The experience was invaluable, and I can’t wait to see where &lt;strong&gt;Down the Block Carshare&lt;/strong&gt; goes next!&lt;/p&gt;

&lt;p&gt;If you’re in the Madison area and want to learn more or get involved, don’t hesitate to reach out. We’re excited to see how we can transform our city’s transportation system together.&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Feb 2024 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2024/02/climatebase-carshare/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2024/02/climatebase-carshare/</guid>
        
        <category>games</category>
        
        <category>urban planning</category>
        
        <category>sustainability</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2023/PXL_20230512_010033194.jpg</image>
        <title>A Bicycle Sailboat Trailer</title>
        <description>&lt;p&gt;
It has been such a fast-paced summer and fall this year that I've hardly had time to write in this blog of mine.  One of the things that's been taking up a lot of time has been sailing with my friends on beautiful Lake Mendota here in Madison.  And one thing that I've thought would be fun to document here was exactly how I get my sailboat to the water.
&lt;/p&gt;
&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2023/PXL_20230726_233745038.jpg&quot; alt=&quot;Claire sailing with the capitol in the background at the edge of a pretty blue lake&quot;/&gt;

&lt;p&gt;I &lt;a href=&quot;https://reddit.com/r/fuckcars&quot;&gt;don't like cars&lt;/a&gt;.  In my fiction writing, &lt;a href=&quot;&quot;&gt;the bad guys drive cars&lt;/a&gt;. I don't particularly want to own a car, and sometimes that causes me to need to get creative. In this case, I had to figure out how I was going to get my impulse-purchase sailboat to the water a mile away from my house!&lt;/p&gt;

&lt;p&gt;The solution (as is often the case in my life) was my ebike. &lt;/p&gt;

&lt;blockquote class=&quot;instagram-media&quot; data-instgrm-permalink=&quot;https://www.instagram.com/reel/CsJAiPatXeD/?utm_source=ig_embed&amp;amp;utm_campaign=loading&quot; data-instgrm-version=&quot;14&quot; style=&quot; background:#FFF; border:0; border-radius:3px; box-shadow:0 0 1px 0 rgba(0,0,0,0.5),0 1px 10px 0 rgba(0,0,0,0.15); margin: 1px; max-width:540px; min-width:326px; padding:0; width:99.375%; width:-webkit-calc(100% - 2px); width:calc(100% - 2px);&quot;&gt;&lt;div style=&quot;padding:16px;&quot;&gt; &lt;a href=&quot;https://www.instagram.com/reel/CsJAiPatXeD/?utm_source=ig_embed&amp;amp;utm_campaign=loading&quot; style=&quot; background:#FFFFFF; line-height:0; padding:0 0; text-align:center; text-decoration:none; width:100%;&quot; target=&quot;_blank&quot;&gt; &lt;div style=&quot; display: flex; flex-direction: row; align-items: center;&quot;&gt; &lt;div style=&quot;background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 40px; margin-right: 14px; width: 40px;&quot;&gt;&lt;/div&gt; &lt;div style=&quot;display: flex; flex-direction: column; flex-grow: 1; justify-content: center;&quot;&gt; &lt;div style=&quot; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 100px;&quot;&gt;&lt;/div&gt; &lt;div style=&quot; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 60px;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;padding: 19% 0;&quot;&gt;&lt;/div&gt; &lt;div style=&quot;display:block; height:50px; margin:0 auto 12px; width:50px;&quot;&gt;&lt;svg width=&quot;50px&quot; height=&quot;50px&quot; viewBox=&quot;0 0 60 60&quot; version=&quot;1.1&quot; xmlns=&quot;https://www.w3.org/2000/svg&quot; xmlns:xlink=&quot;https://www.w3.org/1999/xlink&quot;&gt;&lt;g stroke=&quot;none&quot; stroke-width=&quot;1&quot; fill=&quot;none&quot; fill-rule=&quot;evenodd&quot;&gt;&lt;g transform=&quot;translate(-511.000000, -20.000000)&quot; fill=&quot;#000000&quot;&gt;&lt;g&gt;&lt;path d=&quot;M556.869,30.41 C554.814,30.41 553.148,32.076 553.148,34.131 C553.148,36.186 554.814,37.852 556.869,37.852 C558.924,37.852 560.59,36.186 560.59,34.131 C560.59,32.076 558.924,30.41 556.869,30.41 M541,60.657 C535.114,60.657 530.342,55.887 530.342,50 C530.342,44.114 535.114,39.342 541,39.342 C546.887,39.342 551.658,44.114 551.658,50 C551.658,55.887 546.887,60.657 541,60.657 M541,33.886 C532.1,33.886 524.886,41.1 524.886,50 C524.886,58.899 532.1,66.113 541,66.113 C549.9,66.113 557.115,58.899 557.115,50 C557.115,41.1 549.9,33.886 541,33.886 M565.378,62.101 C565.244,65.022 564.756,66.606 564.346,67.663 C563.803,69.06 563.154,70.057 562.106,71.106 C561.058,72.155 560.06,72.803 558.662,73.347 C557.607,73.757 556.021,74.244 553.102,74.378 C549.944,74.521 548.997,74.552 541,74.552 C533.003,74.552 532.056,74.521 528.898,74.378 C525.979,74.244 524.393,73.757 523.338,73.347 C521.94,72.803 520.942,72.155 519.894,71.106 C518.846,70.057 518.197,69.06 517.654,67.663 C517.244,66.606 516.755,65.022 516.623,62.101 C516.479,58.943 516.448,57.996 516.448,50 C516.448,42.003 516.479,41.056 516.623,37.899 C516.755,34.978 517.244,33.391 517.654,32.338 C518.197,30.938 518.846,29.942 519.894,28.894 C520.942,27.846 521.94,27.196 523.338,26.654 C524.393,26.244 525.979,25.756 528.898,25.623 C532.057,25.479 533.004,25.448 541,25.448 C548.997,25.448 549.943,25.479 553.102,25.623 C556.021,25.756 557.607,26.244 558.662,26.654 C560.06,27.196 561.058,27.846 562.106,28.894 C563.154,29.942 563.803,30.938 564.346,32.338 C564.756,33.391 565.244,34.978 565.378,37.899 C565.522,41.056 565.552,42.003 565.552,50 C565.552,57.996 565.522,58.943 565.378,62.101 M570.82,37.631 C570.674,34.438 570.167,32.258 569.425,30.349 C568.659,28.377 567.633,26.702 565.965,25.035 C564.297,23.368 562.623,22.342 560.652,21.575 C558.743,20.834 556.562,20.326 553.369,20.18 C550.169,20.033 549.148,20 541,20 C532.853,20 531.831,20.033 528.631,20.18 C525.438,20.326 523.257,20.834 521.349,21.575 C519.376,22.342 517.703,23.368 516.035,25.035 C514.368,26.702 513.342,28.377 512.574,30.349 C511.834,32.258 511.326,34.438 511.181,37.631 C511.035,40.831 511,41.851 511,50 C511,58.147 511.035,59.17 511.181,62.369 C511.326,65.562 511.834,67.743 512.574,69.651 C513.342,71.625 514.368,73.296 516.035,74.965 C517.703,76.634 519.376,77.658 521.349,78.425 C523.257,79.167 525.438,79.673 528.631,79.82 C531.831,79.965 532.853,80.001 541,80.001 C549.148,80.001 550.169,79.965 553.369,79.82 C556.562,79.673 558.743,79.167 560.652,78.425 C562.623,77.658 564.297,76.634 565.965,74.965 C567.633,73.296 568.659,71.625 569.425,69.651 C570.167,67.743 570.674,65.562 570.82,62.369 C570.966,59.17 571,58.147 571,50 C571,41.851 570.966,40.831 570.82,37.631&quot;&gt;&lt;/path&gt;&lt;/g&gt;&lt;/g&gt;&lt;/g&gt;&lt;/svg&gt;&lt;/div&gt;&lt;div style=&quot;padding-top: 8px;&quot;&gt; &lt;div style=&quot; color:#3897f0; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:550; line-height:18px;&quot;&gt;View this post on Instagram&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;padding: 12.5% 0;&quot;&gt;&lt;/div&gt; &lt;div style=&quot;display: flex; flex-direction: row; margin-bottom: 14px; align-items: center;&quot;&gt;&lt;div&gt; &lt;div style=&quot;background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(0px) translateY(7px);&quot;&gt;&lt;/div&gt; &lt;div style=&quot;background-color: #F4F4F4; height: 12.5px; transform: rotate(-45deg) translateX(3px) translateY(1px); width: 12.5px; flex-grow: 0; margin-right: 14px; margin-left: 2px;&quot;&gt;&lt;/div&gt; &lt;div style=&quot;background-color: #F4F4F4; border-radius: 50%; height: 12.5px; width: 12.5px; transform: translateX(9px) translateY(-18px);&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: 8px;&quot;&gt; &lt;div style=&quot; background-color: #F4F4F4; border-radius: 50%; flex-grow: 0; height: 20px; width: 20px;&quot;&gt;&lt;/div&gt; &lt;div style=&quot; width: 0; height: 0; border-top: 2px solid transparent; border-left: 6px solid #f4f4f4; border-bottom: 2px solid transparent; transform: translateX(16px) translateY(-4px) rotate(30deg)&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;div style=&quot;margin-left: auto;&quot;&gt; &lt;div style=&quot; width: 0px; border-top: 8px solid #F4F4F4; border-right: 8px solid transparent; transform: translateY(16px);&quot;&gt;&lt;/div&gt; &lt;div style=&quot; background-color: #F4F4F4; flex-grow: 0; height: 12px; width: 16px; transform: translateY(-4px);&quot;&gt;&lt;/div&gt; &lt;div style=&quot; width: 0; height: 0; border-top: 8px solid #F4F4F4; border-left: 8px solid transparent; transform: translateY(-4px) translateX(8px);&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt; &lt;div style=&quot;display: flex; flex-direction: column; flex-grow: 1; justify-content: center; margin-bottom: 24px;&quot;&gt; &lt;div style=&quot; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; margin-bottom: 6px; width: 224px;&quot;&gt;&lt;/div&gt; &lt;div style=&quot; background-color: #F4F4F4; border-radius: 4px; flex-grow: 0; height: 14px; width: 144px;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;&lt;p style=&quot; color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; line-height:17px; margin-bottom:0; margin-top:8px; overflow:hidden; padding:8px 0 7px; text-align:center; text-overflow:ellipsis; white-space:nowrap;&quot;&gt;&lt;a href=&quot;https://www.instagram.com/reel/CsJAiPatXeD/?utm_source=ig_embed&amp;amp;utm_campaign=loading&quot; style=&quot; color:#c9c8cd; font-family:Arial,sans-serif; font-size:14px; font-style:normal; font-weight:normal; line-height:17px; text-decoration:none;&quot; target=&quot;_blank&quot;&gt;A post shared by Solarpunk Travel Cooperative (@solarpunktravel)&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/blockquote&gt; &lt;script async src=&quot;//www.instagram.com/embed.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;In case it isn't clear how I built this, I thought I'd share some pictures of just how magically the trailer fit together.&lt;/p&gt;

&lt;h4&gt;Trailer Build&lt;/h4&gt;

&lt;p&gt;Building this came as a bit of a stroke of luck.  Originally I was trying to use the trailer as it came, using a very long and very heavy (iron?) tongue to connect between the chassis and my bike. &lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2023/PXL_20230504_224020169_exported_1600.jpg&quot; alt=&quot;bicyle towing 12 ft sailboat&quot;/&gt;

&lt;p&gt; My attachment was tearing my rear rack apart and I knew that wouldn't be sustainable for the long-term. Fortunately, we had a leftover tow-behind trailer that I'd used to hold solar panels and gear on our &lt;a href=&quot;&quot;&gt;long ebike tour&lt;/a&gt; last year.  I've learned that tow-behind trailers do not work well at all for towing actual children, but they can still beused in creative ways.&lt;/p&gt;

&lt;p&gt;We got extremely lucky that the space where the original trailer tongue fit in was almost the exact same size as the tow-behind trailer's rear axel spacing.  This made it so that two bolts easily connected it together.&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2023/PXL_20230505_002526079.jpg&quot; alt=&quot;closeup on trailer tongue&quot; width=&quot;32%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2023/PXL_20230507_172020646.jpg&quot; alt=&quot;tow-behind trailer attached to trailer tongue&quot; width=&quot;32%&quot;/&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2023/PXL_20230511_224631531.jpg&quot; alt=&quot;trailer and bike attachment with boat in view&quot; width=&quot;32%&quot;/&gt;

&lt;/div&gt;

&lt;p&gt;The connection is temperamental at times and requires a little remedial wrenching, but for such a simple and effective hack job, it's really a small price to pay.  It's great getting the boat to the dock so easily, and I absolutely LOVE the look on the faces of my neighbors as I come down the bike path with my boat.  I hope it can inspire others that there are more sustainable and appropriate ways to accomplish things in our everyday life without cars.&lt;/p&gt;

&lt;img class=&quot;small_img&quot;  src=&quot;/assets/images/2023/PXL_20230512_010033194.jpg&quot; alt=&quot;me standing with bike trailer and boat in front of Lake Mendota&quot;/&gt;</description>
        <pubDate>Tue, 07 Nov 2023 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2023/11/ebike-boat-trailer/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2023/11/ebike-boat-trailer/</guid>
        
        <category>misc</category>
        
        <category>boatwork</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2023/vrail1.jpg</image>
        <title>VRAIL Chapters 1 &amp;amp; 2</title>
        <description>&lt;p&gt;
    This novel has been a long time coming, but I've finally finished my THIRD rewrite.  But I feel it's well worth it.  It finally fuses my love of psychological thriller, solarpunk sci-fi, and mystical fantasy all into one wild concoction.
&lt;/p&gt;
&lt;div&gt;&lt;iframe height=&quot;800px&quot; src=&quot;https://docs.google.com/document/d/e/2PACX-1vSWT7IvIAxr0vZ5YECJgMHAQthfuLC2T4QstmRT91EUdX13RkopT06xLOv2hpbnJtxcL4r2UFkusaGh/pub?embedded=true&quot; style=&quot;border:1px solid black; height: 800px&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
</description>
        <pubDate>Mon, 06 Nov 2023 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2023/11/vrail-1-2/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2023/11/vrail-1-2/</guid>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2023/fediwatch_2.png</image>
        <title>FEDI-WATCH demo</title>
        <description>&lt;p&gt;A few months back I worked on a very lightweight prototype for a decentralized moderation app for the fediverse.  I stalled out on the project when I couldn’t find collaborators who wanted to actually volunteer for moderation, but I had built a fairly interesting set of infrastructure to work on it.&lt;/p&gt;

&lt;h1 id=&quot;the-problem&quot;&gt;The Problem&lt;/h1&gt;

&lt;p&gt;After the recent migration from Twitter to &lt;a href=&quot;https://joinmastodon.org/&quot;&gt;Mastodon&lt;/a&gt;, with more people of color migrating to that platform there were &lt;a href=&quot;https://www.fastcompany.com/90817452/can-mastodon-be-a-twitter-refuge-for-marginalized-groups&quot;&gt;proven difficult&lt;/a&gt;.  Online harassment, spam and other generally harmful interactions have weren’t being dealt with properly. On the one hand, the issues on Mastodon have been described as reflecting general issues of its &lt;a href=&quot;https://techpolicy.press/the-whiteness-of-mastodon/&quot;&gt;inherent whiteness&lt;/a&gt; and not necessarily a technical problem.  On the other hand the specific nature of a decentralized service without a single accountable moderation team does present &lt;a href=&quot;https://www.webpurify.com/blog/moderating-mastodon-and-the-fediverse/&quot;&gt;unique technology challenges&lt;/a&gt; to that community that need to be overcome hand-in-hand with the work of &lt;a href=&quot;https://www.npr.org/2020/07/06/887646740/me-and-white-supremacy-helps-you-do-the-work-of-dismantling-racism&quot;&gt;dismantling internalized white supremacy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The nature of Mastodon (and the &lt;a href=&quot;https://www.lawfareblog.com/what-earth-fediverse&quot;&gt;fediverse&lt;/a&gt; in general) is that it is &lt;a href=&quot;https://www.theregister.com/2023/01/01/mastodon_activitypub/&quot;&gt;decentralized&lt;/a&gt;, which means that it isn’t just one monolithic website but actually entails a bunch of smaller web communities all speaking a common language so that content can be shared between them. This offers benefits and downsides. One downside is that some people can join “Mastodon,” but end up on specific servers where moderation is non-existent.  Because there isn’t a centralized reporting system to help those people, they can end up having a really harmful experience.&lt;/p&gt;

&lt;p&gt;There have been &lt;a href=&quot;https://www.fedi.watch/&quot;&gt;other&lt;/a&gt; &lt;a href=&quot;https://joinfediverse.wiki/FediBlock&quot;&gt;initiatives&lt;/a&gt; to start tackling this problem, and I’m honestly not sure whether there needed to be another approach.  But along with &lt;a href=&quot;https://github.com/umm-maybe&quot;&gt;umm-maybe&lt;/a&gt;, another AI interested mastodon user, I contemplated a specific solution that could scale out moderation to more people than just the local administration of one server.&lt;/p&gt;

&lt;h2 id=&quot;citizen-moderators&quot;&gt;Citizen Moderators&lt;/h2&gt;

&lt;p&gt;One idea that I’ve explored in &lt;a href=&quot;/2022/07/algorithmologists/&quot;&gt;my writing previously&lt;/a&gt; is that the information landscape could be moderator by a jury of impartial observers.  While we’re a long way off from a well-managed citizen’s assembly for disinformation and content moderation, I thought it would be interesting to explore this subject area beyond my hypothetical fictional musings and put it into a practical application.&lt;/p&gt;

&lt;p&gt;Specifically, I wanted to employ a user-centric approach that could allow a group of moderators to intervene and report toxic content as well as offer help moving instances or just generally supporting those who are being harassed online.  While this is possible with net-citizens just focusing,&lt;/p&gt;

&lt;p&gt;To make this form of moderation work in practice, Mastodon users sign up to allow us to perform API access on their behalf to their local server.  We then employ automated scripts to scout their local timelines and replies. We then pass that content through automated filters to search for offensive posts, and create a large centralized list of aggressive and caustic comments.  With that information we can then send moderators out to specific Mastodon servers help anyone who is being targeted for harassment.&lt;/p&gt;

&lt;p&gt;It’s a different approach, and one that I hadn’t seen mentioned anywhere else. I had trouble getting any feedback, positive or negative, about the idea, but I decided I’d try to flesh out a prototype to help others think through the concept.&lt;/p&gt;

&lt;h1 id=&quot;how-it-works&quot;&gt;How It Works&lt;/h1&gt;

&lt;p&gt;The general architecture of the decentralized moderation is that moderators login with their credentials to their own personal servers, which then allows for open polling of their server’s community feed.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;login screen for fediwatch&quot; src=&quot;/assets/images/2023/fediwatch_1.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;After picking up the community feed, I then poll each post for a period of time to watch if any replies are posted.  From that point, all of the replies are monitored in a centralized queue and they are prioritized for review using the detoxify algorithm for detecting offensive and toxic content.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Fediwatch reply cue showing results of detoxify algorithm&quot; src=&quot;/assets/images/2023/fediwatch_2.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;I built all of this on Google App Engine predominantly because I already had experience with the Mastodon OAuth flow from working with my friend &lt;a href=&quot;https://snarfed.org/&quot;&gt;Ryan&lt;/a&gt; on the &lt;a href=&quot;https://brid.gy/&quot;&gt;Bridgy&lt;/a&gt; open source project, which made it easier to get started. The UI is rudimentary at this point and really just spits out a long list of all the results that I’m picking up, along with their results from detoxify.  In a future release I could imagine sprucing up the UI somewhat, but it wasn’t as important as getting the algorithm running on the backend so I focused on that.&lt;/p&gt;

&lt;p&gt;The most interesting part of the project was getting UnitaryAI’s &lt;a href=&quot;https://github.com/unitaryai/detoxify&quot;&gt;detoxify&lt;/a&gt; up and running.  I hadn’t used it before, but it was a very easy package to get in place.  Under the hood, I believe it’s just a BERT classifier trained on a dataset of toxic content.  The output is just a probability score for each of the following classes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;toxicity&lt;/li&gt;
  &lt;li&gt;severe_toxicity&lt;/li&gt;
  &lt;li&gt;obscene&lt;/li&gt;
  &lt;li&gt;identity_attack&lt;/li&gt;
  &lt;li&gt;insult&lt;/li&gt;
  &lt;li&gt;threat&lt;/li&gt;
  &lt;li&gt;sexual_explicit&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can view the &lt;a href=&quot;https://github.com/unitaryai/detoxify&quot;&gt;detoxify repo&lt;/a&gt; for more information.&lt;/p&gt;

&lt;p&gt;For ops, I originally, used App Engine’s cron feature to call an endpoint that would load and run detoxify on the most recent batch and then do cleanup on old messages.  However, that turned out to be really really expensive so to reduce cost I rearchitected it with a cheap standalone Cloud Compute instance that would just continually run a script to process batches with a stored model.  Even with no usage this still costs me about $0.50/month, but that isn’t too much of an issue at the moment.&lt;/p&gt;

&lt;p&gt;As usual, all my code is &lt;a href=&quot;https://github.com/stedn/fedi-watch&quot;&gt;up on github&lt;/a&gt; in case someone else finds that they’d want to use this as a starting point for their own similar project.&lt;/p&gt;

</description>
        <pubDate>Fri, 19 May 2023 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2023/05/fedi-watch-demo/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2023/05/fedi-watch-demo/</guid>
        
        <category>web</category>
        
        <category>code</category>
        
        <category>data science</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/small_musk.png</image>
        <title>Myopic Centrism</title>
        <description>&lt;p&gt;There’s a meme I once saw that I think perfectly captures the attitude and logical justification of centrism.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Meme from Elon Musk depicting progresives moving farther left while he stays put on a worldview axis. Described more fully in the following paragraph.&quot; src=&quot;/assets/images/2022/elon_meme.jpeg&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;This meme is meant to portray an insight into how the woke progressives have moved into the realm of the extreme while the pragmatic centrists have remained steadfastly true to their origin.  In the meme we see a &lt;a href=&quot;https://x.com/elonmusk/status/1519735033950470144&quot;&gt;certain billionaire&lt;/a&gt; (depicted as “me”) and a conservative staying put in the same location on a political spectrum line from 2008 to 2021, while the liberal moves farther and farther to left.  The result of this is that in the year 2021, the centrist looks more right wing even though the progressive liberal was close to him 10 years prior. The subtext of the meme is that the centrist didn’t change, and the progressive got too “woke.”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.newsweek.com/problem-elon-musk-political-spectrum-meme-1702094&quot;&gt;Many pundits&lt;/a&gt; have pointed out that this idea doesn’t actually represent the facts of American political polarizations, but, nevertheless, the sentiment of the meme resonates with &lt;a href=&quot;https://clashdaily.com/2022/04/elon-musk-tweets-a-meme-about-how-far-the-left-has-moved-libs-freak-out/&quot;&gt;many&lt;/a&gt; &lt;a href=&quot;https://nypost.com/2022/04/29/elon-musks-right-the-left-has-gone-insane/&quot;&gt;many&lt;/a&gt; people who think they can see “the big picture.””&lt;/p&gt;

&lt;p&gt;But ultimately the meme and the thinking behind it, reveal the stalest and most unimaginative mindset imaginable.&lt;/p&gt;

&lt;h3 id=&quot;the-moral-arc-of-history&quot;&gt;The moral arc of history&lt;/h3&gt;

&lt;p&gt;About a decade ago, I considered myself aligned with the “independent, pragmatic centrist” moniker. I believed that the centrist approach offered an objectivity that allowed me to see &lt;em&gt;beyond&lt;/em&gt; the petty back and forth of the political tug-of-war.  But slowly over the past decade as I contemplated it more and scratched the facade on my own worldview, I saw how naive and myopic that mindset actually is.&lt;/p&gt;

&lt;p&gt;The problem with centrism is that it tacitly accepts that the center established during my youth is somehow objectively correct. Yet this entirely neglects humanity’s deep history of accepting norms that we ultimately recognize as fundamentally wrong.&lt;/p&gt;

&lt;p&gt;To illustrate my meaning, I expanded Musks’s meme to stretch back another 200 years.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Expansion of Musk's timeline meme to include political spectrum lines dating back to the 19th century, each line further to the right as time goes backwards.  On each line there is someone on the right end saying something that is obviously backwards and morally repugnant but was acceptable at that time.  On the left, there is someone walking leftward saying 'We can do better.' For 1990, the right-wing person is saying 'gays shouldn't marry.' 1950='blacks can't live here' 1910='women don't count',  1850='slavery is moral'&quot; src=&quot;/assets/images/2022/small_musk.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;Here we see the same meme, with the addition of a few ancestors of the current political divide.  However, when we look backwards, we can see the person on the right end of the spectrum holding on to a soon-to-be-outdated ideal, while those on the left end are constantly attempting to move toward the better end of the spectrum.&lt;/p&gt;

&lt;p&gt;When we do this, it becomes completely obvious what’s really going on.  There has been a march of progress that has always looked like people “moving to the left” in today’s parlance while others staunchly try to remain true to the “centrism” of backwards-looking ideals.  Some people work to make the world better, updating their ideals to reflect an improved morality.  But other people manage to convince themselves that they just happened to be born in a time where the default mindset was already perfectly justifiable.&lt;/p&gt;

&lt;p&gt;When put in this perspective, it’s easy to recognize just how silly it is for a centrist to not shift his beliefs at all for a decade.  That anyone could think of that epistemological hubris as a good thing is almost baffling.&lt;/p&gt;

&lt;h4 id=&quot;what-4d-chess-really-looks-like&quot;&gt;What 4D chess really looks like&lt;/h4&gt;

&lt;p&gt;I’ve realized that most billionaires aren’t as smart as I used to think, but I want to make it clear that the particular one who shared the meme above is not dumb.  He’s just normal.  Normal people see the world around them and react to it.  They want to win the games that have been put in place for them (fast cars, rocketships), rather than defining their own.&lt;/p&gt;

&lt;p&gt;True &lt;em&gt;imaginative genius&lt;/em&gt; (like the kind attributed to Musk) doesn’t just mean operating intelligently to execute on a worldview that exists in one’s own time.  It requires acting based on the worldview that &lt;em&gt;will exist&lt;/em&gt; decades or centuries after you are gone.  We’d all admit that the change from slavery and genocide to modern notions of equality are obvious improvements in our &lt;a href=&quot;https://www.moralunderstanding.com/research&quot;&gt;moral understanding&lt;/a&gt; of the universe.  And if progress was possible in the past, it’s most reasonable to assume that we are not yet living in the time when ethics and epistemology have already been solved.&lt;/p&gt;

&lt;p&gt;4D Chess means operating in a framework that transcends your own instantaneous existence and looks at the state of the universe as if everything is &lt;a href=&quot;https://quoteinvestigator.com/2019/07/06/time/&quot;&gt;happening at once&lt;/a&gt;.  It isn’t easy to optimize your decision-making over a probabalistic space of potential moral frameworks that might be discovered in the future.  But to me, it seems obvious that aligning with &lt;a href=&quot;https://www.rollingstone.com/politics/politics-news/elon-musk-twitter-reinstates-neo-nazi-andrew-anglin-account-1234640390/&quot;&gt;neo-Nazis&lt;/a&gt; and &lt;a href=&quot;https://www.cnn.com/2022/12/15/media/twitter-musk-journalists-hnk-intl/index.html&quot;&gt;banning journalists&lt;/a&gt; would exist in a low probability space for things that will be considered acceptable 200 years from now. Not to mention the long lists of &lt;a href=&quot;https://www.flyingpenguin.com/?p=38763&quot;&gt;racist&lt;/a&gt; and generally &lt;a href=&quot;https://aiguana.motoretta.ca/news/2022/04/elon-musk-twitter-terrible-things-hes-said-and-done&quot;&gt;messed up&lt;/a&gt; things he’s done publicly.&lt;/p&gt;

&lt;p&gt;The most interesting thing about this billionaire is that he has the clout to actually effect this kind of world-altering change.  He could redirect the discourse of millions of people off of the backwards-looking track they are stuck on.  I personally hope that he is playing a kind of 4D moral chess that will allow him to sway minds in the direction of progress.  Sadly, the evidence thus far suggests he doesn’t yet understand his place in any dimension.&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Dec 2022 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2022/12/myopic-centrism/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/12/myopic-centrism/</guid>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/own-it.png</image>
        <title>Socialism as Radical Entrepreneurialism</title>
        <description>&lt;p&gt;If there weren’t hundreds of years of propaganda in our collective psyche, we’d be able to recognize that the goals of  free market entrepreneurialism and democratic market socialism are the same: empowerment for every working person and every entrepreneur. It just so happens that neither side realizes, those are the same people.&lt;/p&gt;

&lt;figure&gt;
  &lt;img width=&quot;50%&quot; alt=&quot;OWN IT written in comic book letters&quot; src=&quot;/assets/images/2022/own-it.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;I can still see the words written floor to ceiling across the wall of my company’s office.&lt;/p&gt;

&lt;p&gt;The CEO and founder of the company had asked for his personal motto, “OWN IT,” to be emblazoned on the wall as a reminder for the employees to show their hard work and dedication. I’ll admit that at that time in my career, that was the kind of sentiment I believed in whole-heartedly.&lt;/p&gt;

&lt;p&gt;But even to a young “rise-and-grind” tech kid like me, seeing it written out like that was &lt;em&gt;weird&lt;/em&gt;, and yet it wasn’t until years later that I realized what rang so false about the motto:&lt;/p&gt;

&lt;h5 id=&quot;the-employees-of-that-company-did-not-own-it&quot;&gt;the employees of that company did NOT “own it.”&lt;/h5&gt;

&lt;p&gt;But now I wonder, what if the workers at that company had owned our business? What would have been different?&lt;/p&gt;

&lt;p&gt;Instead of having to stamp corny motivational posters onto the wall, every worker would have the very sincere motivation that their work was crucial to the enterprise that they own. Every person in every part of the business would be incentivized to innovate and automate and streamline.&lt;/p&gt;

&lt;p&gt;Many &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_contributors_to_Marxist_theory&quot;&gt;people&lt;/a&gt; have addressed the fact that separating workers and owners leads to bad results for the workers, and there’s generally been two diametrically opposed schools of thought about how to handle this problem:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Get yourself to the top of the system by becoming an entrepreneur&lt;/li&gt;
  &lt;li&gt;Dismantle the system and replace it with socialism&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;However, it turns out that the distinction between the entrepreneurial solution and the socialist solution might actually be two ways of approaching the same end result.&lt;/p&gt;

&lt;h3 id=&quot;the-radical-entrepreneur&quot;&gt;The Radical Entrepreneur&lt;/h3&gt;

&lt;p&gt;Let’s take the entrepreneurial approach on face value. It suggests that you can overcome the shittiness inherent to working one of our society’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Bullshit_job&quot;&gt;bullshit jobs&lt;/a&gt; by starting your own business. You create it. You own it.&lt;/p&gt;

&lt;p&gt;Unfortunately, in most cases this approach requires you to then tell other workers what to do, perpetuating the cycle.&lt;/p&gt;

&lt;p&gt;The obvious problem with this approach is that it only works for one person at a time, and it fundamentally relies on some people remaining in the shitty position of working without ownership.&lt;/p&gt;

&lt;p&gt;But what if we radically reimagine entrepreneurialism to picture that everyone in your firm shared the same entrepreneurial spirit? What if we could provide the same empowerment to every worker in the company? If we take that thought experiment to its limit, we’d see a whole new type of firm come into being, where the distinction between worker and entrepreneur disappears.&lt;/p&gt;

&lt;p&gt;The amazing part is that radically entrepreneurial business becomes the modern incarnation of socialist economics: the worker cooperative.&lt;/p&gt;

&lt;h3 id=&quot;socialism-and-economic-democracy&quot;&gt;Socialism and Economic Democracy&lt;/h3&gt;

&lt;p&gt;At its heart, socialism is about saying that our society should collectively get to decide how the economy runs. This general premise has many specific incarnations. One that many people are familiar with is a centrally planned government control of everything, like in the USSR. However, a universal central planning system has some drawbacks that make it pretty bad at solving a lot of problems&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;A more refined and modern approach to socialism is embodied in &lt;a href=&quot;https://www.britannica.com/topic/democratic-socialism&quot;&gt;democratic market socialism&lt;/a&gt;, where we utilize a political democracy to set up a government that decides how our market economy is going to work. This system has a lot of positive qualities and generally aligns with the &lt;a href=&quot;https://progressive.org/latest/sanders-success-democratic-socialism-goes-mainstream/&quot;&gt;direction&lt;/a&gt; that our modern liberal democracies are progressing towards.&lt;/p&gt;

&lt;p&gt;The important point about this system is that it gives ultimate control of the economy to our democratic society as a whole, rather than being under the control of those who happen to have the most wealth accumulated. Currently things like which businesses get funded are largely decided by corporations or individual investors who have accumulated a lot of personal wealth, but under a democratic socialist economy every citizen would have a lot more influence in deciding which things were worth applying our collective effort towards.&lt;/p&gt;

&lt;p&gt;One of the democratic market socialist systems that I’m personally a fan of would be called &lt;a href=&quot;https://www.liquisearch.com/david_schweickart/economic_democracy&quot;&gt;Economic Democracy&lt;/a&gt;, which I’ve written about &lt;a href=&quot;/2021/10/market-socialism-1/&quot;&gt;before&lt;/a&gt;. Economic Democracy proposes to heavily incentivize all businesses to be run as worker cooperatives. This means that on the level of the individual firm, businesses would need to be run as democratic systems. Now, this doesn’t mean that everybody gets paid the same or everybody does the same work. What it means is that every worker has an equal ownership stake in the company.&lt;/p&gt;

&lt;h3 id=&quot;when-the-workers-literally-own-it&quot;&gt;When the workers literally “own it.”&lt;/h3&gt;

&lt;p&gt;The amazing thing is that socialism in its modern conception shouldn’t be a scary thing. If more working people understood it for the common sense approach that it really is, we’d be able to make a lot more progress. The fact is we already operate in a mixed economy, where capitalist approaches and socialist approaches commingle. But there were achievements that capitalism brought 100 years ago that it isn’t capable of sustaining without introducing socialist methods.&lt;/p&gt;

&lt;p&gt;The beauty of democratic market socialism is that it has the capacity to bridge between our capitalist free market system and a smarter way of running the economy. Businesses still succeed or fail based on their own merits and the efforts of their workers in a marketplace, but everyone in the company shares in that success or failure. In a worker cooperative, every worker shares a stake in the business, effectively becoming an entrepreneur angling for their own collective success.&lt;/p&gt;

&lt;p&gt;So in the end, the goal of free market entrepreneurialists ends up being directly aligned with that of the socialists. If there wasn’t 100 years of rhetoric (and a heavy amount of propaganda), we’d be able to recognize that both sides want empowerment for every working person and every entrepreneur. It just so happens that by the end, those are the same people.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;While there may be a place for some role of central planning in large-scale economic decision making, there are notable &lt;a href=&quot;https://connectusfund.org/6-advantages-and-disadvantages-of-centrally-planned-economy&quot;&gt;disadvantages of a centrally planned economy&lt;/a&gt;. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 01 Dec 2022 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2022/12/radical-entrepreneurialism/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/12/radical-entrepreneurialism/</guid>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/algo_warship.png</image>
        <title>The Algorithmologists</title>
        <description>&lt;h3 id=&quot;the-city-at-dawn&quot;&gt;The city at dawn&lt;/h3&gt;

&lt;p&gt;Leo Rolé and eleven other Algorithmologists were drinking coffee or dragging on their vapor pipes under the dim amber lights of their city’s Algoritorium. Through the window looking out over the city, only a few apartments’ lights were starting to twinkle awake. In the distance, Leo could just see his own house’s kitchen window light up.  His husband would be out there pouring his cup of coffee that moment.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;futuristic city at dawn&quot; src=&quot;/assets/images/2022/algo_city.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;As more people woke up and logged on, the monitors at the front of the room started to update. A tangle of lines splayed across the screen started to twitch and undulate. It’s connections flickered different colors as news of the events of the morning started to spread.&lt;/p&gt;

&lt;p&gt;Leo returned to his seat at the round table in the center of the room as he and the Algorithmologists eased into their work. As information threats went, this one seemed like it would be less urgent. This was the kind of thing that had a well-established pattern, and it happened at a time of night that meant not everyone would hear the news at once. All the information diagnostics were looking normal as Leo scanned the neighborhood message boards.&lt;/p&gt;

&lt;p&gt;Next to him, Ione Proudfoot was monitoring the coverage from the global media sources. The news was about an attack on Refugio, one of the first and largest refugee outpost in the International Zone of Antarctica. Small bands of the paramilitary group EcoFascist Seed had been frequenting the waters of the South Sea where patrols by the peacekeepers were harder to maintain. Sometimes in search of food they’d come ashore on the lush green banks of Antarctica, and when they felt it was safe, they’d often try to attack the most vulnerable climate refugee cities established there. Now, news sources were starting to release their coverage of the attacks.&lt;/p&gt;

&lt;p&gt;“Looks like straight reporting for now,” Ione said, “no bullshit.”&lt;/p&gt;

&lt;p&gt;“Great,” Leo replied, his eyes glancing around his screen as he flipped between message boards, “there’s still not much locally, but what I do see looks pretty benign.”&lt;/p&gt;

&lt;p&gt;“Hopefully it’s a lighter day,” Ione said. She stood up and arched her back to stretch. “I could hardly get to sleep after putting out last night’s fire.”&lt;/p&gt;

&lt;p&gt;Ione started pacing up and down behind her desk. Leo nodded approvingly. The previous night, an international conference in their city had been interrupted by protesters. Ione had been put in charge of making sure the personal details of the protesters weren’t being shared.&lt;/p&gt;

&lt;p&gt;The Algorithmologists were each selected for a one month term analyzing media sources to help monitor public spaces online and make sure there wasn’t undo influence from nefarious parties. They worked a bit like a jury, acting under guidance of the Department of Information Health, to make sure the public was getting legitimate and balanced news. They didn’t censor information, just monitor and counteract the force of algorithms and the “influencers-for-hire” when they started to over-amplify certain narratives.&lt;/p&gt;

&lt;p&gt;The society-wide media systems had become too unwieldy and had failed to deter misinformation and dangerous conspiracies too many times. To deal with this, the Algorithmologists were established across cities around the world to help guide the conversation online. They prevented the power of money and vested interests from having too much influence on people’s minds.&lt;/p&gt;

&lt;p&gt;Leo was more than 3 weeks in. He’d only need to get to next Sunday. Ione was only on her 3rd day. Leo certainly didn’t envy her. The learning curve was steep in those first few days, and the pressure to prevent another gate level controversy was intense.&lt;/p&gt;

&lt;p&gt;Fortunately, today’s headline grabbing news of the attack on Refugio didn’t seem like it would be too much trouble.&lt;/p&gt;

&lt;h3 id=&quot;red-letter-day&quot;&gt;Red letter day&lt;/h3&gt;

&lt;figure&gt;
  &lt;img width=&quot;50%&quot; alt=&quot;warship in front of antartcia&quot; src=&quot;/assets/images/2022/algo_laptop.png&quot; /&gt;
  &lt;figcaption&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;From the corner of his eye, Leo saw a few red letters flash across Ione’s screen. He felt a sudden wave of nervous nausea in his stomach. Ione froze in the middle of a side stretch she’d been doing behind her seat.&lt;/p&gt;

&lt;p&gt;“You’ve got to be kidding me,” she mumbled. The red letters kept popping up. A moment later, red letters were flashing on Leo’s screen too.&lt;/p&gt;

&lt;p&gt;“Well shit,” Leo said, “something’s happening.”&lt;/p&gt;

&lt;p&gt;“Alright folks,” Ione yelled loud enough for everyone to hear, “looks like we have a botnet on this one.”&lt;/p&gt;

&lt;p&gt;The tangle of lines on the screen at the front of the room started to pulse in synchrony. A flurry of fingers began drumming the keyboards around the room. A few staccato voices punctuated the hum of the IMUNE System servers firing up.&lt;/p&gt;

&lt;p&gt;“Looks like it’s targeting Spanish speakers.”&lt;/p&gt;

&lt;p&gt;“Origin appears to be South America.”&lt;/p&gt;

&lt;p&gt;“The accounts in the net are all up to 1 year old.”&lt;/p&gt;

&lt;p&gt;“This seems like conspiracy type 1, subtype a.”&lt;/p&gt;

&lt;p&gt;“Somebody wake up a judge, we’re gonna need help on this.”&lt;/p&gt;

&lt;h3 id=&quot;marbleseed&quot;&gt;Marbleseed&lt;/h3&gt;

&lt;p&gt;“I’d like everyone to welcome Dr. Marbleseed,” one of the Chief Algorithmologists opened the door as the rest of the team rose from their seats.&lt;/p&gt;

&lt;p&gt;A thin-framed older woman inched her way into the room, holding her cane and shaking her head with amusement. “Don’t stand up on my account,” she said, “you’ve all got work to do.”&lt;/p&gt;

&lt;p&gt;Everyone in the room sheepishly returned to their seats. Dr Josephine Marbleseed was one of the most prolific scientists of Algorithmology—and not just in their city or the country, but on the whole planet. She’d been in the first generation helping found the craft almost 70 years prior. The science was intractible back then. Without a baseline, the misinformation and distrust on the internet had proven impossible to regulate. Politics, opinion, science, propaganda all stirred together in a deafening chaos, while any attempt to rein in the beast was filtered through the same polarizing lenses. It would have been impossible if the solar flare hadn’t taken it all down for a few months.  That was the only thing that allowed people to get a grip on themselves and pick up the pieces of their tattered society. The Algorithmologists were developed to prevent that from happening again when the internet came back online.&lt;/p&gt;

&lt;p&gt;“I saw the story on the tram,” Marbleseed continued, “looks like the IMUNE System already took down the botnet. So what do you need me for?”&lt;/p&gt;

&lt;p&gt;The 3 Chief Algorithmologists were all looking down at the floor letting the awkward silence hang in the room.&lt;/p&gt;

&lt;p&gt;Ione cleared her throat. “It appears that story is already organically spreading now,” she said, meaning that the story was spreading amongst real accounts, “we’re looking to shut down the accounts that are spreading the false story.”&lt;/p&gt;

&lt;p&gt;Dr Marbleseed raised her eyebrow. “Oh really,” she said, “and what exactly is the false story?”&lt;/p&gt;

&lt;h3 id=&quot;front-matter&quot;&gt;Front matter&lt;/h3&gt;

&lt;p&gt;Leo was standing next to the projected map at the front of the room.&lt;/p&gt;

&lt;p&gt;“You can see that this same story started being told across all of these global news sources all within 5 minutes.”&lt;/p&gt;

&lt;p&gt;Dr Marbleseed stared silently without allowing even an ounce of her opinion to show through. Leo tried to speak again, but found himself unable to continue.&lt;/p&gt;

&lt;p&gt;“The story is,” Ione jumped in, “that the attacks were not from EcoFascist Seed, but were a coordinated campaign from the South Sea Peacekeepers in the area.”&lt;/p&gt;

&lt;figure&gt;
  &lt;img width=&quot;75%&quot; alt=&quot;warship in front of a glacier&quot; src=&quot;/assets/images/2022/algo_warship.png&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;“So,” Marbleseed continued, “they’re trying to get us to believe that the International Protective Force has turned on those whom it’s meant to protect.”&lt;/p&gt;

&lt;p&gt;Serious nods of agreement swept across the room.&lt;/p&gt;

&lt;p&gt;“And how do we know that’s not true?”&lt;/p&gt;

&lt;h3 id=&quot;deliberation&quot;&gt;Deliberation&lt;/h3&gt;

&lt;p&gt;“The story has already been shut down in 72% of cities in our region,” said a voice from behind Leo.&lt;/p&gt;

&lt;p&gt;“Inadmissible,” Dr Marbleseed responded. She was now standing at the front of the room. Leo and the others had turned their seats to face her, lobbing questions at her.&lt;/p&gt;
&lt;figure&gt;
  &lt;img width=&quot;75%&quot; alt=&quot;futuristic network diagram at front of room&quot; src=&quot;/assets/images/2022/algo_class.png&quot; /&gt;
  &lt;figcaption&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;There had been misteps and overreach in the early days. Marbleseed had lived though it. Even the best and most necessary technology has the potential for corruption, and in the early days of Algorithmology, Marbleseed was there when her work became a tool of oppression.&lt;/p&gt;

&lt;p&gt;Marbleseed asked her own questions carefully. “Look at the timing of the verified bot network’s posts,” she said, pointing to a graph in the wall behind her, “were they the first accounts of the events?”&lt;/p&gt;

&lt;p&gt;Leo was beginning to understand. It was possible that the stories were true, and the attacks on Refugio really were the peacekeepers. There were conflicting accounts, and no one knew what was true on the ground. He leaned over to Ione.&lt;/p&gt;

&lt;p&gt;“When you think about it, “ Leo said, “the Protective Force would have a huge advantage here.”&lt;/p&gt;

&lt;p&gt;Ione looked puzzled.&lt;/p&gt;

&lt;p&gt;“They know exactly how the IMUNE System would respond in this scenario.”&lt;/p&gt;

&lt;p&gt;The IMUNE System stood for Information Management Under Nefarious Engagement and worked as an automated software toolkit to detect and filter posts. It’d been in use for decades now, detecting botnets, dark advertisements, and other sources of targeted misinformation. The IMUNE System was a conservative system, operating as a first pass before the Algorithmologists got to it.&lt;/p&gt;

&lt;p&gt;“So you actually believe that the peacekeepers have gone rogue?” Ione asked.&lt;/p&gt;

&lt;p&gt;“Not necessarily,” Leo said, “but Dr Marbleseed’s point is just that we don’t really know.”&lt;/p&gt;

&lt;p&gt;Ione wrinkled her brow and turned back to face the front.&lt;/p&gt;

&lt;p&gt;“The ultimate decision is up to you,” Dr Marbleseed said solemnly, “there’s nothing more I can offer than advice.”&lt;/p&gt;

&lt;h3 id=&quot;fragility&quot;&gt;Fragility&lt;/h3&gt;

&lt;p&gt;Within two days it was clear what was happening. The peacekeepers had undertaken a military coup to cut off the antarctic continent. Their goal had been to set up their own authoritarian slave state away from the democratic principles that governed the rest of the world. At first it had been difficult to believe, but as more and more evidence piled up, the truth became obvious.&lt;/p&gt;

&lt;p&gt;Their plan directly relied on the IMUNE System falsely detecting the conspiracy as misinformation. And had their botnet come online just a few minutes earlier, they probably would have pulled it off.&lt;/p&gt;

&lt;p&gt;At their worst point, 94% of Algorithmologosts were suppressing the true account, but a few held out.&lt;/p&gt;

&lt;p&gt;On the balcony outside their apartment Leo and his husband each had a glass in hand, with a half empty bottle of scotch on the table between them.&lt;/p&gt;

&lt;figure&gt;
  &lt;img width=&quot;50%&quot; alt=&quot;view from the balcony&quot; src=&quot;/assets/images/2022/algo_fin.png&quot; /&gt;
  &lt;figcaption&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;“I honestly don’t know what would have happened without Dr Marbleseed there,” Leo said, “we were so close to pulling the plug.”&lt;/p&gt;

&lt;p&gt;Leo’s husband took a drink and stared over the balcony, looking shocked at the story his had husband just told him.&lt;/p&gt;

&lt;p&gt;“It’s all so fragile.”&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;artwork generated by &lt;a href=&quot;https://nightcafe.studio/&quot;&gt;nightcafe.studio&lt;/a&gt; and &lt;a href=&quot;https://hotpot.ai/art-maker&quot;&gt;hotpot.ai&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 02 Jul 2022 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2022/07/algorithmologists/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/07/algorithmologists/</guid>
        
        <category>fiction</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/20220511_083546_0000.png</image>
        <title>Double Crux Station</title>
        <description>&lt;figure&gt;
  &lt;img width=&quot;50%&quot; alt=&quot;two Ys crossing on insignia&quot; src=&quot;/assets/images/2022/20220511_123642_0000.png&quot; /&gt;
  &lt;figcaption&gt;
    Insignia of the Double Crux Assembly
  &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Welcome to Double Crux Station! We are the Philosopher’s Governing Assembly, and we’re so excited that you’ll be joining us to represent your village or neighborhood at the world’s first philosophically principled government body.&lt;/p&gt;

&lt;p&gt;This welcome packet will help orient you to our humble Station, and delineate the expectations set for you by all the Double Cruxers who came before you. We’re grateful that you have decided to participate in the preeminent decision-making institution on the planet, and hope you are proud to be among the most reasoned, compassionate, forward thinking minds of your generation as we attempt to preserve the peace and prosperity of the solarpunk era.&lt;/p&gt;

&lt;figure&gt;
  &lt;img width=&quot;75%&quot; alt=&quot;aerial view of circular building in a forest.&quot; src=&quot;/assets/images/2022/20220511_083546_0000.png&quot; /&gt;
  &lt;figcaption&gt;
    View from above the Station
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h3 id=&quot;accomodations&quot;&gt;Accomodations&lt;/h3&gt;
&lt;p&gt;We’re sure you’re anxious to learn more about your living accomodations during your time at Double Crux Station. After all, it’s hard to make good decisions if you don’t know where you’ll be sleeping at night or how you’re going to eat.&lt;/p&gt;

&lt;p&gt;The survey of your governing district has been completed. And the results are available for your analysis.&lt;/p&gt;

&lt;p&gt;To summarize, 5% of your jurisdiction is currently living below poverty and their median caloric intake is at only 95% the healthy level.  While we absolutely understand that this outcome is not your fault, Double Crux has always honored the rule of living like your community. Therefore, for at least 5% of your time here, you will be required to live in a calorie restricted diet that matches the median person in your jurisdiction.&lt;/p&gt;

&lt;p&gt;Fortunately, you’re region has no unsheltered homelessness so you will be eligible for full time shelter in any of the housing options available.&lt;/p&gt;

&lt;p&gt;Remember that these surveys do reoccur on a 2 month cycle, so your housing and food situation may be updated if and when conditions in your jurisdiction change.&lt;/p&gt;

&lt;h3 id=&quot;assembly-participation&quot;&gt;Assembly Participation&lt;/h3&gt;

&lt;p&gt;You are required during your time here to participate in all Governance Assembly deliberations. And we ask that you retain a sense of reverence toward the work we do here.&lt;/p&gt;

&lt;p&gt;At Double Crux, many forms of debate and decision-making are possible, but we’d like to make sure you’re aware of our most cherished methodology and our namesake: the Double Crux. Double Cruxing is a method of short-circuiting unproductive arguments and helping Philosopher-Assembly members from becoming entrenched in ideological battles. The method works by asking two participants in a debate to identify the central Crux of each of their beliefs. The Crux should be any assumption that is crucial to their belief such that if they were to learn that the assumption is untrue, they guarantee that they would update their belief.  This procedure may then be repeated until such time as someone involved finds a Crux that turns out to be probably false, at which point they can rest assured that they should update their belief.  No one’s feelings need to be hurt in this activity because it is simply an issue of having been informed of some incorrect information.&lt;/p&gt;

&lt;p&gt;Using the Double Crux is a time honored tradition, and has brought much success in unlocking precisely the points of disagreement among the majority of humanity in the solarpunk era.  But remember that anything about the Assembly rules or operation is possible to change through careful deliberation, good faith argument, and compassionate persuasion.  So even the usage of the Double Crux will always remain open to debate.&lt;/p&gt;

&lt;p&gt;At our first meeting tomorrow, you will be provided with the most up-to-date information on Assembly procedures and schedules.&lt;/p&gt;

&lt;p&gt;Again, we wish to thank you for embarking on this challenging but monumentally important task of philosopher governance.  We hope that your work here can aid your constituents, and, in concert with the political, economic, academic, and spiritual bodies of government, can help to retain our prosperity and joyful living throughout the solarpunk era.&lt;/p&gt;
</description>
        <pubDate>Wed, 11 May 2022 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2022/05/double-crux-station/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/05/double-crux-station/</guid>
        
        <category>fiction</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/dystopia.png</image>
        <title>What separates utopia and dystopia?</title>
        <description>&lt;p&gt;Take a moment to think about all the possible futures you’ve ever seen presented in any of the various forms of science fiction media you’ve come across. Although many details may differ between the mutlitude of different worlds that artists and authors have depicted, when you boil them all down to their most fundamental core, there are only two possible future scenarios for humanity: &lt;a href=&quot;https://en.wikipedia.org/wiki/Utopian_and_dystopian_fiction&quot;&gt;a dystopian future or a utopian future&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But what is the fundamental feature that makes the difference between a dystopian and a utopian world.? You might think it’s an abundance of resources in a utopia, or something about the technological development of society, but our answer is actually much deeper, more subtle, and ultimately simpler&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;h3 id=&quot;default-scenario-the-dystopian-path&quot;&gt;Default Scenario: The Dystopian Path&lt;/h3&gt;

&lt;figure&gt;
  &lt;img width=&quot;75%&quot; alt=&quot;5 panel image. center: woman reclining on couch with VR goggles. top left: factory workers in bunny suits. top right: lithium mine workers. bottom left: soldiers firing weapons. bottom right: a crowd behind locked gates. &quot; src=&quot;/assets/images/2022/dystopia.png&quot; /&gt;
  &lt;figcaption&gt;
    Snapshots of dystopia
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;One future looks like the Malthusian fight for survival on a planet with &lt;a href=&quot;https://fortune.com/2022/03/01/resource-scarcity-new-report-bank-of-america&quot;&gt;dwindling resources&lt;/a&gt;.  That’s the trajectory that we’re on using the default capitalist system that we live under now.  If we fast forward 30 years, we basically know that the drive for greater and greater competition over resources is going to spread to more and more parts of the world.  And this is &lt;a href=&quot;https://www.weforum.org/agenda/2016/02/does-capitalism-have-to-be-bad-for-the-environment&quot;&gt;certain&lt;/a&gt; to eventually exhaust the ability of our planet to support everyone on it.  Even if we can figure out enough renewable-derived energy to satisfy all the energy needs of the world today, if we wanted everyone to live like Americans do today it’s estimated we’d need &lt;a href=&quot;https://www.overshootday.org/how-many-earths-or-countries-do-we-need&quot;&gt;5 planets worth of resources&lt;/a&gt;.&lt;/p&gt;

&lt;h5 id=&quot;just-as-a-reminder-we-only-get-1&quot;&gt;Just as a reminder, we only get 1.&lt;/h5&gt;

&lt;p&gt;So in the scenario where we compete until we’re past the point of ecological sustainability, there’s going to be &lt;a href=&quot;https:www.wfp.org/stories/act-now-climate-crisis-or-millions-more-will-be-pushed-hunger-and-famine&quot;&gt;famine and disaster that hurts a lot of people&lt;/a&gt;.  And there are going to be others who take advantage, expand their empires, and start wars for resources.  And the worst part is that the arms race to defend our scarce natural resources will end up consuming all of the good beautiful enjoyable parts of life that we have now.  We’ll continue to concentrate power into fewer and fewer hands. There will be automation of the machines of war, which will take energy that could go to human life.  And to secure this power a few people will have to build an iron tight grip on a state that even in the best scenarios will slip ever closer to totalitarianism.&lt;/p&gt;

&lt;p&gt;Again, all of that follows logically from a survival of the fittest, competition-centric model of society. That’s what we have today, and that’s for the most part what a lot of our growth-oriented leaders seem to think is the best solution for our own survival.&lt;/p&gt;

&lt;p&gt;Anyone who tells you that capitalism will solve all these future problems hasn’t thought it all the way through&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.  After all, even if you are one of the lucky few who do manage to survive the first 10 years. What happens when one half of the planet decides to go to war with the other half for the rest of the resources? Will you survive that? And so on? Would you want to live that way? Literally nothing but fighting over scraps until we’ve lost all our culture, our art, and any science that didn’t relate directly to war. &lt;/p&gt;

&lt;p&gt;To my mind, there is no healthy and morally sane way to move forward as we approach the limits of the environmental capacity of the planet without a drastic change to our social structure and what it means to be successful in our society.&lt;/p&gt;

&lt;h3 id=&quot;scenario-2-the-utopian-option&quot;&gt;Scenario 2: The Utopian Option&lt;/h3&gt;

&lt;p&gt;But there is an alternative scenario for humanity’s future.&lt;/p&gt;

&lt;figure&gt;
  &lt;img width=&quot;75%&quot; alt=&quot;5 panel image. center: woman reclining on tree holding violin. top left: a crowd at a festival. top right: scientist/worker in front of greenhouse shelf full of plants. bottom left: community planting a garden. bottom right: town square in a walkable city. &quot; src=&quot;/assets/images/2022/utopia.png&quot; /&gt;
  &lt;figcaption&gt;
    Snapshots of utopia
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;A utopian future would look very different.  Everyone on the planet would be certain that their basic needs would be met, and that future generations of their children would have a similar safety and security.  Technological advances would be distributed more equitably, allowing even more people to share in the abundance and contribute to society.&lt;/p&gt;

&lt;p&gt;However, this alternative relies on humanity reaching a consensus on a truce—a global truce between every person not to overconsume their share.  How do we define the rules of “a fair share?” Honestly that is probably the most difficult question of our time.  It’s one that terrifies the powerful who in their hubris are convinced that they’ll maintain power forever.  It’s one that confuses regular working people who have been so propagandized to this cult of individualism and competition that they literally can’t imagine anything better.&lt;/p&gt;

&lt;p&gt;I can’t tell you how to answer the question of how we decide what is enough because I can’t possibly be the one to decide. Is it everyone getting the same? I doubt it. Is it a basic income and then crafts, art, games and sport deciding who gets a little extra? Probably not. I have my own ideas, which I’ll elaborate on in other writings, but my point here is &lt;em&gt;you&lt;/em&gt; have to start thinking about it now.  And you have to ask your friends. And you have to be prepared to answer that question in your life. And you have to start working towards the world where your answer comes to life as soon as you can.&lt;/p&gt;

&lt;p&gt;If we can’t come to a consensus, and figure out some way to regulate ourselves and each other, the default is to spiral back into the overconsumption arms race. &lt;/p&gt;

&lt;p&gt;I believe we’re better than that.  In all this universe there’s no one I believe in more to solve this problem. We have thousands of years and hundreds of cultures who have practiced these ways of living within their means.  That form of cooperation is literally imprinted in our blood.  But we’ve been fooled by a few bad philosophers who cooked up a bullshit ideology to justify slavery and colonization.  We can undo this.  We just need to work on it.  It needs to be an idea we study with more attention than anything else we’ve ever learned.  But I believe every human being is capable of having this conversation.&lt;/p&gt;

&lt;p&gt;And even though we’re talking about something that feels so distant it’s almost like science fiction, this conversation needs to happen now. The default path may be dystopia, but if we act, utopia is possible.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Simple, but almost certainly not easy. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;If someone out there thinks they have thought a captialist utopia through, and you believe there’s a reason a utopia based on fairness isn’t the best possibility, I challenge you to join our &lt;a href=&quot;https://discord.gg/MP5vJAQ2XM&quot;&gt;discord&lt;/a&gt; and debate the subject.  Or if there’s any other points you’d like to make, please don’t hesitate to join the community and have a discussion. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 04 May 2022 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2022/05/dystopia-or-utopia/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/05/dystopia-or-utopia/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/new_shade.jpg</image>
        <title>Why a different shade of solarpunk</title>
        <description>&lt;p&gt;Solarpunk is in my opinion &lt;em&gt;the&lt;/em&gt; movement for a better future. It embraces and amplifies the best parts of humanity: innovation, compassion resilience, freedom, and justice, and focuses our imagination into making those qualities the underpinning of our future society.
I’ve become a solarpunk because I think this optimism is essential. In fact, I think the &lt;a href=&quot;https://www.history.com/news/american-labor-unions-decline-1920s&quot;&gt;decline of optimism
&lt;/a&gt; and the &lt;a href=&quot;https://en.m.wikipedia.org/wiki/Theory_of_International_Politics&quot;&gt;rise of “realism”&lt;/a&gt; in the 20th century, is the one thing that has stagnated humanity. &lt;/p&gt;

&lt;figure&gt;
  &lt;img width=&quot;50%&quot; alt=&quot;graph of word usage from Google N-gram for optimist and realist&quot; src=&quot;/assets/images/2022/realism_optimism.jpg&quot; /&gt;
  &lt;figcaption&gt;
    Word usage of &quot;optimist&quot; peaked in the 1920s, while usage of &quot;realist&quot; continued to increase and accelerated in the 1980s.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Essentially, I believe nay-sayers interrupting and redirecting our imagination towards less-and-less ideal solutions is what prevented us from reaching a utopian future in the wake of the brilliant technical innovations of the last 100 years.  We need to revive the idealism that radically transformed societies for the better before the fear of being labeled “unrealistic” took hold.&lt;/p&gt;

&lt;p&gt;But if solarpunk is the way forward, solarpunk is inherently green, right?&lt;/p&gt;

&lt;h4 id=&quot;why-talk-about-a-solarpunk-blue&quot;&gt;Why talk about a solarpunk blue? &lt;/h4&gt;

&lt;p&gt;Solarpunk thrives on diversity, and a monoculture can be unhealthy even if it’s green. In my experience, green is used to mean a lot of different things, but in the context of solarpunk, I feel it represents the active forms of change.  Green is literally the color of the transformation of energy and regeneration.  After all, it’s the green photosynthesizing leaves and algae that are converting the bulk of the planet’s abundant solar energy into the material sustenance for all life.&lt;/p&gt;

&lt;p&gt;But energy and matter are just a part of what makes up our reality.  And we need more shades of solarpunk because there’s more than just material concerns when it comes to imagining our future.  To start, there is the entire world of the mind: ideas, emotions, social structures.  This informational space that we exist in, beyond just atoms and photons, is just as essential to contemplate.&lt;/p&gt;

&lt;p&gt;To me, the space for that contemplation is &lt;strong&gt;blue&lt;/strong&gt;—either a dark blue of a deep ocean, or the airy blue of a clear sky.  So Solarpunk Blue is a space to ponder on how the experience of humankind will have to change internally for this new and better world we create.&lt;/p&gt;

&lt;p&gt;I aim to make this a more contemplative space than my previous efforts, and this should be a site to come to when needing to grapple with some of the stickier questions about the future.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Will it feel human to move beyond the quest for endless expansion?&lt;/li&gt;
  &lt;li&gt;Can sustainability exist without equity?&lt;/li&gt;
  &lt;li&gt;How can we find motivation in a world where competition is recognized as destructive?&lt;/li&gt;
  &lt;li&gt;What will count as life when artificial intelligence occupies just as essential a niche in our ecosystems?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As solarpunk is a form of speculative design, the aim is always to imagine solutions in an engaging and creative way that allows ideas to spread. That’s why we’ll have essays, art, fiction, games, and activism to contemplate and to motivate, here.
Hopefully, as this picture of our future gets filled in, we can help to color in a little shade of blue.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Satellite image of Earth from above the Pacific Ocean&quot; src=&quot;/assets/images/2022/new_shade.jpg&quot; /&gt;
&lt;/figure&gt;
</description>
        <pubDate>Mon, 25 Apr 2022 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2022/04/different-shade-of-solarpunk/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/04/different-shade-of-solarpunk/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/stool_pretty_2.jpg</image>
        <title>Scrap Wood Stool on a New Mexico Farm</title>
        <description>&lt;p&gt;
I haven't had much time to myself for projects during my &lt;a href=&quot;https://solarpunktravel.org/tour/&quot;&gt;year-long bicycle tour&lt;/a&gt;, but while &lt;a href=&quot;https://wwoof.net/wwoofers-testimonials/all-about-wwoof-how-it-works-and-what-you-need-to-know/&quot;&gt;WWOOFing&lt;/a&gt; here on the Sheridan Project Farm in New Mexico this season, I've had a bit more free time to relax and get up to some hobbies.  I've also had access to a lot of raw materials in the form of construction scrap, which got me thinking about what I could do to spruce up my partner's and my living accomodations.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2022/stool_1.jpg&quot; alt=&quot;a single roomed green cabin with a small front porch&quot;/&gt;

&lt;p&gt;It's a small space, but in the lovely weather this spring, it's just what we need.  However, we realized it'd be nice to have a little space on the front porch to have breakfast in the morning sun. My partner came up with the idea to build a high table along the railing, but we realized it'd be even better if someone had a stool to sit at while we're there.&lt;/p&gt;

&lt;h4&gt;Trash to Treasure&lt;/h4&gt;

&lt;p&gt;I personally don't ever like buying new materials for hobby projects.* The way I see it, there's already so much trash in perfectly good condition trash out there, it's almost criminal to buy new. So it makes me really happy when I come to a space with a stack of leftover materials that are just waiting to be put to good use. &lt;/p&gt;

&lt;img class=&quot;small_img&quot;  src=&quot;/assets/images/2022/stool_2.jpg&quot; alt=&quot;a stack of unevenly cut 4x4 inch boards&quot;/&gt;

&lt;p&gt;This looks like some grade A material to me, but you might notice that those 4x4 boards are all cut to very inconsistent lengths.  In practice, that would mean that there wasn't enough material to get a full height barstool out of any single cut, but by carefully choosing the lengths, I could retain the longest pieces possible.  This still left the problem of how to connect them, but with a little brainstorming we cam up with something that we figured would both look at least semi-intentional and not fall apart.&lt;/p&gt;


&lt;img class=&quot;small_img&quot;  src=&quot;/assets/images/2022/stool_3.jpg&quot; alt=&quot;a sketch of a stool design with multiple tiers of legs&quot;/&gt;


&lt;h4&gt;The Stool Build&lt;/h4&gt;

&lt;p&gt;The technique for the build was to take three 4x4s cut at a very slight angle on the ends so they would lean inward.  This gives the feet stability and makes it less likely to tip over.  For the seat I used a scrap of very nice wood that had been used for benches elsewhere on the property, and then I spent an inordinate amount of time trying (and failing) to get the symmetry of a triangle of rectangles right on the seat.  After sawing and sanding, I just brushed the wood with some tung oil to treat it.&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2022/stool_4.jpg&quot; alt=&quot;standing the boards up&quot; width=&quot;32%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2022/stool_5.jpg&quot; alt=&quot;many drawn attempts at symmetry on a wooden piece&quot; width=&quot;32%&quot;/&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2022/stool_6.jpg&quot; alt=&quot;wood with tung oil can next to it&quot; width=&quot;32%&quot;/&gt;

&lt;/div&gt;

&lt;p&gt;Finally, the most interesting part was how to connect the different layers, while also giving the legs in/outward stability. To do this. I sandwiched some particle board from a dempolished RV on site between the 4x4 layers.  My favorit part was that I was able to figure out a way to do it that hid all of the screws either between pieces of wood or on the underside of the stool.&lt;/p&gt;

&lt;img class=&quot;small_img&quot;  src=&quot;/assets/images/2022/stool_7.jpg&quot; alt=&quot;screwing pieces of wood into an upside down stool&quot;/&gt;

&lt;p&gt;My cuts weren't anywhere near perfect, and my alignment was more than a little off in places, but that gives it the homemade look.  And despite the aesthetic mishaps, it was still very sturdy. It was also extremely heavy, which is actually a good thing as the winds here in New Mexico get quite fierce this time of year.&lt;/p&gt;

&lt;img class=&quot;small_img&quot;  src=&quot;/assets/images/2022/stool_finished.jpg&quot; alt=&quot;finished stool&quot;/&gt;

&lt;p&gt;Now the only question was how does it look in place?&lt;/p&gt;

&lt;h4&gt;A front porch fit for a New Mexican Sunrise&lt;/h4&gt;

&lt;p&gt;&lt;/p&gt;After much head scratching, my partner eventually came up with this super beautiful design for the porch countertop. And as a bonus, it even matched the design of the stool!&lt;/p&gt;

&lt;img class=&quot;small_img&quot;  src=&quot;/assets/images/2022/stool_pretty_1.jpg&quot; alt=&quot;stool in place with counter&quot;/&gt;

&lt;p&gt;This little nook is now the perfect place to eat breakfast and let the sunrise warm us up.  We're happy with how it turned out and grateful to be able to gift these to Sandy and Dan for their tiny house at the Sheridan Farm Project.  I hope this front porch brings many WWOOFers a happy moments in the years to come.&lt;/p&gt;

&lt;img class=&quot;small_img&quot;  src=&quot;/assets/images/2022/stool_pretty_2.jpg&quot; alt=&quot;stool in place with counter&quot;/&gt;</description>
        <pubDate>Tue, 22 Feb 2022 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2022/02/scrap-wood-stool/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/02/scrap-wood-stool/</guid>
        
        <category>woodwork</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2022/google_sheet.png</image>
        <title>Building a website on Google Sheets</title>
        <description>&lt;p&gt;
I haven't been writing on here lately as I've been very busy he;ping to build a &lt;a href=&quot;https://solarpunktravel.org&quot;&gt;cooperative bicycle touring platform&lt;/a&gt; that I'm helping to start.  But I thought I would write down a quick tutorial since I've basically built the whole database to run for free on top of Google Sheets.
&lt;/p&gt;

&lt;p&gt;Now the only really good reason to do this is that (1) it is free and (2) it can be edited very easily by non-developers. And I already know that if this platform takes off there will need to be a lot of reworking to make it scalable.  But for now, this is working great and I just wanted to show how it's done.&lt;/p&gt;

&lt;h4&gt;How is that even possible?&lt;/h4&gt;
&lt;p&gt;If you're thinking running a whole website off of Google Sheets is impossible, you'd be right.  The website itself is built using Jekyll to serve a static website, which is hosted (for free of course) on Github Pages.  This has become a pretty standard way to host a free website for tech savvy (and less tech savvy) people in recent years.&lt;/p&gt;

&lt;p&gt;But the website I'm building doesn't want to just be a static site that we update by adding commits to a git repo!  Our site is designed to be a place to upload routes, cycling resources, and travel logs for people to find ways to bike tour in the local area around their home.  And we hope someday for people to be able to even add private resources, like property that can be used for camping and things like that.&lt;/p&gt;

&lt;p&gt;Typically if you want people to submit their own content to a website, you will have to build your own backend database.  But this means that as a developer I would need to build all the tooling for posting content to a DB. And importantly, most ways of doing this require some operating costs for storage and data transactions with the database.  &lt;/p&gt;

&lt;p&gt;So as a scrappy startup we decided we'd like to short cut all that. And based on a &lt;a href=&quot;2020/05/timeline-streamgraph-google-sheet/&quot;&gt;previous project&lt;/a&gt; where I pulled some data from a Google Sheet, I thought, why not try hosting the content in an editable Google Sheet and running the whole site from there?&lt;/p&gt;

&lt;p&gt;What could go wrong?&lt;/p&gt;

&lt;h4&gt;It's all in the javascript&lt;/h4&gt;
&lt;p&gt;The entirety of this relies on a few trick of javascript.  Basically, all that needs to happen is for me to make the Google Sheet public so that anyone can view it.  Then in the frontend of the webpage, I just run a little bit of javascript that downloads the contents of the spreadsheet, scans through it, builds the appropriate html, and adds it to the webpage.&lt;/p&gt;

&lt;pre&gt;
    fetch(&quot;&quot;)
    .then(res =&gt; res.text())
    .then(text =&gt; {
        meta_result = JSON.parse(text.substr(47).slice(0, -2))
&lt;/pre&gt;

&lt;p&gt;That's the magic line right there.  I don't know exactly why that works, but I copied it from this &lt;a href=&quot;https://stackoverflow.com/questions/68854198/did-google-sheets-stop-allowing-json-access&quot;&gt;stack overflow&lt;/a&gt; and nothing lit on fire.&lt;/p&gt;

&lt;p&gt;At this point, I have a data structure with each row and column. I access the &lt;i&gt;ith&lt;/i&gt; row and &lt;i&gt;jth&lt;/i&gt; column with the following.&lt;/p&gt;

&lt;pre&gt;meta_result.table.rows[i].c[j]&lt;/pre&gt;

&lt;p&gt;At this point it becomes very project specific.  For me, I just iterate through the rows and generate the custom HTML based on that content.  You can see how it works in all it's glory detail on the &lt;a href=&quot;https://github.com/stedn/cooptrail/blob/04f50ddb6b3dc30cfa73aad229b8e42ec9158b3b/_layouts/hub.html#L66&quot;&gt;Github repo&lt;/a&gt; for the site, though at the moment it is very very messy.&lt;/p&gt;

&lt;h4&gt;So what about user input?&lt;/h4&gt;

&lt;p&gt;So we're now displaying data from a google sheet, but we still need to manually input that data into the spreadsheet.  This is great for us since we know how the sheet is set up, but it would totally not work for a random person who wants to submit material to our site.&lt;/p&gt;

&lt;p&gt;So to get around this we used another simple hack that I've applied to &lt;a href=&quot;https://artificechicago.org&quot;&gt;multiple&lt;/a&gt; &lt;a href=&quot;https://opus.stedden.org&quot;&gt;previous&lt;/a&gt; &lt;a href=&quot;https://solarpunktravel.org&quot;&gt;websites&lt;/a&gt;, which is just making a custom form that submits to a Google Form.  I've covered how this works in a previous &lt;a href=&quot;/2018/12/rtifice-website-revamp/&quot;&gt;blog post&lt;/a&gt; so I won't rehash it here.&lt;/p&gt;

&lt;p&gt;Now we haven't fully closed the loop by having our form submit directly to the sheet that hosts our content. We thought about it, but based on the amount of random spam that comes through your average form, we figured it'd be best to have a manual check process to copy and paste content over.  &lt;/p&gt;

&lt;p&gt;That said, I'm thinking about making a little script that copies from one spreadsheet to another.  All in all, I'm really happy with the system and am looking forward to launching the project and getting more people biking in their area.&lt;/p&gt;

</description>
        <pubDate>Tue, 22 Feb 2022 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2022/02/google-sheet-hosted-website/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/02/google-sheet-hosted-website/</guid>
        
        <category>web</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/main/solarpunk_blue_logo.jpeg</image>
        <title>Solarpunk 2050</title>
        <description>&lt;p&gt;I recently read Bill Gates’ book &lt;a href=&quot;https://www.theguardian.com/books/2021/feb/17/how-to-avoid-a-climate-disaster-by-bill-gates-review-why-science-isnt-enough&quot;&gt;How to Avoid a Climate Disaster&lt;/a&gt;. While I have a huge problem with the book’s philosophy&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, I have taken one thing away from it in this blog’s approach to advocating for a socialist revolution: work backwards from a goal and a long-term horizon.&lt;/p&gt;

&lt;p&gt;I know many people want a socialist revolution &lt;strong&gt;now&lt;/strong&gt;, and they are working toward that goal either through political process or through yelling at other people on twitter.  Sadly, I am one small person with limited ability to effect massive changes, and realizing that, I’ve decided to take a different approach.&lt;/p&gt;

&lt;p&gt;I’m issuing the #solarpunk2050 challenge.  A call to specifically articulate your best case scenario for an ecosocialist utopia by the year 2050&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, to invision the systemic changes that will need to take place for that outcome, and to prioritizing taking the smartest actions today to maximize the likelihood of that happening.  Some would call it incrementalist, but I, personally, see it as revolutionary—just over a longer timescale.&lt;/p&gt;

&lt;h3 id=&quot;the-case-for-working-backwards&quot;&gt;The case for working backwards&lt;/h3&gt;

&lt;p&gt;Gates’ emphasized an interesting point when discussing how to evalutate different strategies for reaching net-zero carbon emissions by 2050. On the one hand, you can pursue a set of policies that can bring the largest drops in carbon emissions by 2030, but which might jeopardize the ability to get larger reductions by 2050.  Or on the other hand, you can pursue a set of policies that are much more likely to bring even greater reductions by 2050, but which may rely on delaying implementation after 2030 to avoid implementing something that sets back the long-term goal.&lt;/p&gt;

&lt;p&gt;In an even more extreme example, you might consider how can I reduce carbon emissions as much as possible this year, but this might actually have a backfire effect over the longterm.   In the specific case of climate change, reducing emissions a little bit over the short term isn’t helpful if it messes up with reaching net-zero over the long term.  Therefore, you wouldn’t want to pursue a strategy that emphasizes short term gain.&lt;/p&gt;

&lt;p&gt;We can look at a lot of things in this same light.  And in particular, I want to approach the construction of a sustainable, human-centered society in this way.  To do this, I’m going to work backwards from where I imagine the world could be, and give myself a suitable time-horizon to make it happen.&lt;/p&gt;

&lt;p&gt;The challenge is to break a solarpunk revolution down into 3 parts:&lt;/p&gt;

&lt;p&gt;1) what would define success,&lt;/p&gt;

&lt;p&gt;2) what big systemic changes need to take place to allow that success to happen, and&lt;/p&gt;

&lt;p&gt;3) what do I do today and every day, for the next year, and 28 years from now to make that change happen.&lt;/p&gt;

&lt;h3 id=&quot;what-would-define-a-solarpunk-revolution&quot;&gt;What would define a solarpunk revolution&lt;/h3&gt;

&lt;p&gt;For climate change, Gates’ easily identifiable goal was carbon neutrality.  For an equitable and sustainable world, the endpoint is harder to identify.  There are competing issues that need to be rectified, and, honestly, it isn’t up solely to me to identify what those are.&lt;/p&gt;

&lt;p&gt;Nevertheless, for articulating my own plan of action, I need to pick some endpoint that I think matches with the ideals that I think satisfy my fundamental principles of equity and sustainability. My four points to define a successful solarpunk revolution are as follows.&lt;/p&gt;

&lt;p&gt;1) No one consuming more than a sustainable share of Earth’s natural resources, and society collectively preserving the ecological abundance of our planet&lt;/p&gt;

&lt;p&gt;2) Increased standard of living so everyone on Earth is living with stability and dignity (at least $30/day in 2022 dollars)&lt;/p&gt;

&lt;p&gt;3) Acknowledgement of a fundamental right to an equal share in both political and economic decision making&lt;/p&gt;

&lt;p&gt;4) That the above be both objectively true and perceived as true by almost all of the population&lt;/p&gt;

&lt;h3 id=&quot;socialism-in-28-years-broken-down&quot;&gt;Socialism in 28 years, broken down&lt;/h3&gt;

&lt;p&gt;So what are the big society wide shifts that would have&lt;/p&gt;

&lt;p&gt;I think it comes on three fronts: culture shift, economic shift, and electoral politics shift.&lt;/p&gt;

&lt;h4 id=&quot;culture-shift&quot;&gt;Culture shift&lt;/h4&gt;

&lt;p&gt;I think the absolute most necessary change for creating a socialist society is the ongoing cultural shift towards collectivist morals.  Ultimately, I don’t believe there can be any change without a shift in people’s values underneath.  In fact, I think that the backlash to change is even more pronounced when someone tries to make change prior to the underlying cultural shift.&lt;/p&gt;

&lt;p&gt;But how do you take action for a culture shift?  It seems like culture shifts are assumed to be organic changes, but I believe there is a way to impact culture even if it’s slow moving.  There are two core parts to this: change the focus of conversation to shift the Overton window, and shift social status from capitalist values to egalitarian ones.&lt;/p&gt;

&lt;h5 id=&quot;shift-the-conversation&quot;&gt;Shift the conversation&lt;/h5&gt;

&lt;p&gt;There’s an idea of what is “acceptable” to talk about in polite society called the Overton window. The idea is that certain things are considered very mainstream, certain things are on the edges of the mainstream but still “normal,” and certain ideas fall outside in the “fringe.” Shifting the Overton window means shifting what falls directly inside the mainstream and bringing things that are fringe into the edge of the mainstream.  The most important thing about this theory is that it assumes since we are highly social that what falls within that window is directly set by how often we encounter certain ideas in our life.  In other words, if we see certain ideas repeated from 10 sources it becomes defined as mainstream, while something we only hear from 1 person is assumed to be fringe.&lt;/p&gt;

&lt;p&gt;It can be really troubling to think about ideas and beliefs as being so strongly tied to social convention, especially when we come from a place where we think that all of our ideas are strictly based in fact.  The way I think about this is recognizing that people living in the distant past had no way of knowing how &lt;em&gt;wrong&lt;/em&gt; their ideas were based on modern standards.  It would have been completely outside their imagination to discuss whether the king really had any right to their taxes.  In the same way, it’s probably impossible for me to imagine what society will accept as truly moral in 100 years.  All I can do is try to shift the conversation in the little interactions I have day-to-day.&lt;/p&gt;

&lt;p&gt;Now I believe that everyone wants to know the truth and is looking for the right information.  Therefore, I think the big barrier to shifting the conversation is that people just don’t have the free time and energy to become informed. This is why I think that we have to make spreading information and ideas a much more enjoyable part of our lives.  It should be possible to tie this kind of information sharing to our recreation activities.&lt;/p&gt;

&lt;p&gt;I’m calling this people-powered education and information citizenship.  In this situation, everyone is responsible for promoting factual and truthful education, and we all treat our own education and discussion of ideas as a hobby.  I already see this taking place on TikTok and social media, regular people are speaking about what they know and what they think they know.  But for this to really take off, I think we’ll have to move past individual moments of activism to a place where our regular lives are about sharing ideas and promoting conversations.&lt;/p&gt;

&lt;p&gt;I think this will have to grow and become a standard of our social interaction.  When you meet a new person, you’ll still have some small-talk standards like today, but it’ll have to become much more common to discuss a new piece of information, your sources, or to riff on imaginative ideas we have about how the future should look.&lt;/p&gt;

&lt;h5 id=&quot;shift-values&quot;&gt;Shift values&lt;/h5&gt;

&lt;p&gt;A second huge part of a culture shift will be shifting the definition of what brings us social status.  The key is going to become very very vigilant about only holding people in high regard who embody the principles you want to see.  For a socialist culture shift, you have to want to be friends with the people who share their resources equitably instead of using them to get richer and people who do real work instead of leeching off of others just because they can.  I think the most important part of that is having ideas of solidarity be completely central for giving people elevated social status in our life.  Making morality cool again, and enunciating the imperative for a moral life to be just to those who have been disadvantaged by the state of the world.&lt;/p&gt;

&lt;p&gt;I think most people are inherently good and &lt;em&gt;want&lt;/em&gt; to go along with this values shift, but everybody is scared to take the step alone for fear that they’ll be thought of as a “weird” person &lt;strong&gt;and&lt;/strong&gt; miss out on the material advantages of our greed-centric culture. This is why I’m willing to stick my neck out and try to push for this shift: because I want to pave the way for more people to follow as it becomes more normal.&lt;/p&gt;

&lt;p&gt;The biggest problem is trust.  Getting people bought into this new culture can only happen as fast as you can convince a friend to make this same change with you.  Imaginging that I just start with myself, and assuming I can convince 1 friend per year, and every person can convince 1 person per year, then it would take 28 years to pass 200 million people bought in.  Of course, that isn’t really how culture changes, but the idea is that if on average every person can bring one person over to the good side each year, then by 2050 we’ll have the majority of the US subscribing to a equitable and sustainable culture.  And fortunately, there are already millions of people who believe in a better future today.&lt;/p&gt;

&lt;h4 id=&quot;material-mutual-aid-and-the-solidarity-economy&quot;&gt;Material: Mutual aid and the solidarity economy&lt;/h4&gt;

&lt;p&gt;The truth is no amount of idealism can really change what we need to survive.  Even if we only like people with good values, if we still need people who are cutthroat in order to keep our economy running, then they will continue to hold all the power. So the second part is helping everyone shift their consumption to a new economy based on mutual aid, reciprocity, and solidarity with the people that do the work.&lt;/p&gt;

&lt;p&gt;There’s never been a better time to do this.  Technology-wise it is super easy to make our economy completely transparent.  And there’s never been an easier time to let regular people connect with each other and share things that agree with their values.  So creating a parralel economy that avoids exploitation seems to be possible for the first time.&lt;/p&gt;

&lt;p&gt;But it’ll still be next to impossible to move the big, monopolistic juggernauts that dominate our economy.  Wall Street, Hollywood, Silicon Valley, the military industrial complex, Big Ag, Big Pharma, and all the other “Big” players make it very hard to do large scale things.  So I see this rolling out in two phases.&lt;/p&gt;

&lt;p&gt;First, we’ll have 10 years developing more and more solidarity economic solutions for the most fundamental features of our life.  Farming, childcare, eldercare, food service, and housing will need a transition to just and community-oriented businesses.  But this will be hard, because price is the biggest decision maker in our standard economy. We’ll have to find a way to keep the prices low in the cooperative economy, while driving prices up in the exploitative economy through stricter labor laws and good union support.&lt;/p&gt;

&lt;p&gt;Second, there is going to be a big shift happening at the same time as this across the US towards automation. Automation is fundamentally good, but it comes with the big downside that the people who benefit will always be the owners at the expense of the workers.  Consumers don’t see much change, as they still pay close to the same amount, but owners start taking more profit and firing their employees.  So as this shift to a solidarity economy occurs, we’re going to need to stand in solidarity with each other and reduce our total work and total pay rather than overproduce.  Because if we overproduce we’ll devalue what we make.  The only other way I can see this to work out is if we keep working the same amount but some people have to relocate to other parts of the world to share their knowledge there.&lt;/p&gt;

&lt;p&gt;I also think it’s important to think about financial transparency and how much &lt;em&gt;actual&lt;/em&gt; work we all do.  Making income, expenses and hours of work public information might seem scary because it leaves us open to judgement from others.  But wouldn’t it be better if we could check our standing and make sure that our neighbors and colleagues aren’t trying to put one over on us.  I also think it’s important to create metrics to distinguish what is our essential work that keeps us all living just and dignified lives and what work is just superficial that we’ve invented to ensure that some people look busy.&lt;/p&gt;

&lt;p&gt;No matter what, it’s going to be a challenge, but without a backup economy, I don’t see a way to shift power away from small groups back to all citizens.&lt;/p&gt;

&lt;h4 id=&quot;politics-elections-are-crucial&quot;&gt;Politics: Elections are crucial&lt;/h4&gt;

&lt;p&gt;Even though sometimes it feels like electoral politics is a dead end, the truth is it’s only ended up this way because we hevent’ kept up the focused time and energy needed for shaping the way politics works.  We need to get started putting things back right.&lt;/p&gt;

&lt;p&gt;There are major issues that aren’t really solvable through cultural shift or meeting material needs. By my estimate, the following are the important issues that must be solved at the political level in the near term:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;regulating environmental impact and enforcing polluters to pay the cost of their damage.&lt;/li&gt;
  &lt;li&gt;keeping the social safety net intact.&lt;/li&gt;
  &lt;li&gt;outlawing intentional disinformation (should be curtailed just like defamation), this will lead to the ability to legally hold news outlets accountable and ratchet down on political lying.&lt;/li&gt;
  &lt;li&gt;better education and literacy standards, allowing people to continue education until they reach a threshold for informed citizenry.&lt;/li&gt;
  &lt;li&gt;regulation of paid advertising (aka capital sponsored mind control) especially in the political arena.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll need to put a lot of work into the political arena, especially given how broken our representation works.  There are so many good alternatives to the gerrymandered 2-party oligarchy that we’ve developed.  We’ll almost certainly need to implement better systems for representation, but fortunately other countries have developed extremely fucntional ones already, like ranked-choice voting or proportional representation.  Sadly, these kinds of changes will probably have to come from grassroots efforts as the 2-party system in the US has reached a point where it’s power has become self-reinforcing.  I belive we’ll need to organize constitutional amendments on how elections are run in the purple states to break this gridlock.  At least for the executive branch, there’s already a plna afoot to transition to the national popular vote.
https://www.nationalpopularvote.com/written-explanation&lt;/p&gt;

&lt;p&gt;Finally, I personally believe that we’ll need to dismantle economic authoritarianism in the way our businesses run, meaning we can’t have a small group of utlra-wealthy owners and corporations making all the decisions for our economy operates.  At first, this will come through co-ops and strong unions side-by-side with capitalist-owned companies, but I expect that by 2050 we’ll need to have laws that make workplace democracy mandatory.  It’ll be quite a challenge to figure out how that will be regulated, but absolutely imperative for making lasting change.&lt;/p&gt;

&lt;p&gt;In short, the political/legal world isn’t going away, and it’s absolutely important to think strategically about how to navigate from the politics we have to the kinds we want.&lt;/p&gt;

&lt;h3 id=&quot;my-personal-action&quot;&gt;My personal action&lt;/h3&gt;

&lt;p&gt;The final step is connecting the big social changes to my own everyday actions.&lt;/p&gt;

&lt;h4 id=&quot;culture&quot;&gt;culture&lt;/h4&gt;

&lt;p&gt;The theme of my culture change actions is about staying active in people-powered education and honoring those in my life who embody humanist values.&lt;/p&gt;

&lt;p&gt;For people-powered education, each week I plan to create at least one informative work on leftism, cooperative businesses, or sustainable travel, and I will switch all of my fiction writing to being positive and utopian.  For honoring humanists, I will be intentional about directing my respect to those who embody humanist principles, and preferentially sharing my time and energy with those who work for others.  Another really important part is continuing to educate myself and promote the voices of the amazing people I have learned so much from on this journey already.&lt;/p&gt;

&lt;p&gt;Another key factor is living my values in a public way and promoting others to do the same. I have switched to veganism, and while this is a good step on its own, individual action does nothing.  It might seemhard at first, but I believe that making my decisions public can help others see that taking moral actions in this time is a normal (and dare-I-say even popular) step to take in these times.&lt;/p&gt;

&lt;p&gt;The last part of the culture shift is spending my energy on helping others have the space and energy themselves to promote their ideas on collectivist.  I already support a number of educators, but I plan to provide more material support in the next year, which brings me to the next section.&lt;/p&gt;

&lt;h4 id=&quot;economics&quot;&gt;economics&lt;/h4&gt;

&lt;p&gt;Our economy makes its decisions by where the money flows. I’m going to remember this in my economic decision making this year.  For environmental causes, I will continue another year of car-free and airplane-free life, and in addition, I will be converting my diet to be fully vegan.  And while these individual actions do have an economic impact exactly equal to the scale of my consumption, I know that alone, they accomplish only little.  I need to take my economic “votes” to a better solution for our environment and people.&lt;/p&gt;

&lt;p&gt;The solidarity economy needs support.  I’m pledging to use every opportunity I have to donate to mutual aid and patronize businesses that function in this economy.&lt;/p&gt;

&lt;p&gt;In addition, I’m continuing to work on my own member cooperative effort to built the Trail Cooperative, a network of travelers supporting sustainable travel in the solidarity economy.  While working on this venture I will also be volunteering to work on local farms and infrastructure projects as I travel by bicycle.&lt;/p&gt;

&lt;h4 id=&quot;politics&quot;&gt;politics&lt;/h4&gt;

&lt;p&gt;Politics is hard, and something I’ve never particularly liked.  Still, I know I must be politically engaged and be intentional about how I do so.  I still believe that nonpartisan grassroots has the potential to reshape our country and I will involve myself with those groups this year.&lt;/p&gt;

&lt;p&gt;I am already in the Democractic Socialists of America and I will become more active with the Madison chapter in the next year.  I don’t know the best path forward, but the only one that I think I see is saddling up to the democratic socialists and making incremental shifts to the Democratic party.  This will need to occur on multiple fronts, but hopefullyt the demographic changes, and the rising education levels of younger generations should help.  I think the biggest leverage point is getting leftists into positions of power in state legislatures.  I think progressive and socialist candidates are already set up for local government positions, but statewide legislatures have been historically dominated by the right wing party. And of course, the fight has to continue in the US federal branch as well.  All levels are important, and I’m certainly not in a position to suggest that we cede anything.&lt;/p&gt;

&lt;p&gt;For myself personally, I’m going to continue campaigning with the lesser of two evils when I have to, and always advocating for the most left leaning candidate anywhere.&lt;/p&gt;

&lt;p&gt;Even though these long-term shifts need to be worked on now, there are still pressing needs that need to be addressed much more quickly.  For that, I plan to involve myself more deeply with the &lt;a href=&quot;https://citizensclimatelobby.org/&quot;&gt;Citizen’s Climate Lobby&lt;/a&gt; to try to get a carbon tax and universal dividend passed.  This group is working on the closest bills to providing a serious mechanism to curb carbon emissions.  I’ve researched them before, but never done campaigning work.  This year I will start.&lt;/p&gt;

&lt;h3 id=&quot;the-long-game-is-just-a-series-of-short-games&quot;&gt;The long game is just a series of short games&lt;/h3&gt;

&lt;p&gt;The most important thing to remember is that just because the endpoint is 28 years out, the work is going to be carried out in a million little battles along the way.&lt;/p&gt;

&lt;p&gt;To recap I will be&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;not traveling by car or airplane, and eating a purely plant-based diet&lt;/li&gt;
  &lt;li&gt;making 1 educational video per week all year&lt;/li&gt;
  &lt;li&gt;write at least 2 solarpunk stories&lt;/li&gt;
  &lt;li&gt;sharing my time and energy with people who embody humanist ideals&lt;/li&gt;
  &lt;li&gt;tracking and increasing my inputs into the solidarity economy&lt;/li&gt;
  &lt;li&gt;building the Trail Cooperative&lt;/li&gt;
  &lt;li&gt;increasing my activity with the DSA&lt;/li&gt;
  &lt;li&gt;doing campaign work for the Citizen’s Climate Lobby&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This might seem like a lot, but the truth is I’m mostly just helping with people who have spent way more effort making these things a possibility. Fortunately, the whole philosophy of leftism reinforces that it shouldn’t be the undertaking of one heroic person anyway, but the collective small efforts of everyone together that should shape the world.  So I hope you can join me.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Briefly, Gates’ thesis is that only an unpredictable scientific breakthrough will save us, that politics is impossible, and we can’t even talk about reducing consumption.  I think there’s a lot more on the table if rich people in power like Gates would simply start changing their attitudes, but that is what I’m working towards here anyway. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Why 2050?  None of my reasons for picking this year are particularly scientific.  First, I think it’s good to mirror the climate rhetoric around 2050 because, ultimately, an egalitarian society is part of making a world that is both sustainable.  Second, I think that it is good to have an endpoint that is still within the productive lifetime of my generation.  It would be too depressing to have the generation most harmed by capitalism to have to suffer under its yoke just long enough to free future generations but not to enjoy the benefits themselves.  Third, although it’s morbid, I think that between now and 2050 many people who are just not amenable to change will die off. And finally, I think that 28 years is enough time to spread the message and make change.  I have a broad based plan written below, and I think that 28 years is just enough time to see it happen. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 01 Jan 2022 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2022/01/solarpunk-2050/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2022/01/solarpunk-2050/</guid>
        
        <category>fiction</category>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/socialism_poll.png</image>
        <title>How Market Socialism Could Work</title>
        <description>&lt;p&gt;In 2018, Gallup conducted &lt;a href=&quot;https://news.gallup.com/opinion/polling-matters/243362/meaning-socialism-americans-today.aspx&quot;&gt;a poll&lt;/a&gt; to learn what most people in the US think of when they hear the word “socialism.”  The poll compared responses in 2018 and 1949, and pointed out a big change in perception over the seven decades since the beginning of the Cold War.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Gallup Poll on Socialism&quot; src=&quot;/assets/images/2021/socialism_poll.png&quot; /&gt;
  &lt;figcaption&gt;
    Gallup Poll on US understanding of the term &quot;socialism&quot;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;One of the most interesting findings is that over that time there has been a shift away from considering socialism to mean “state control of business” to meaning “equality” and “benefits and services.” The old perception (despite being incorrect, see below) made a lot of sense in relation to the main model of socialism that existed in the world at that time—the centrally planned, government-run economies of Russia and China. The new perception is much better aligned with the current understanding of socialism in Western European and South American democracies—of a country where everyone in society gets equal access to the kinds of benefits and services that increase the well-being of society as a whole.&lt;/p&gt;

&lt;p&gt;I largely agree with the perception of socialism as a more fair distribution of the goods of society, but it wasn’t until just a few years ago that I learned the actual definition of socialism. And while the perception is measurably changing&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, I’ve encountered many people (particularly &lt;a href=&quot;https://reddit.com/r/Capitalism&quot;&gt;online&lt;/a&gt;) who, just as I used to do, incorrectly identify socialism in terms of a centrally-planned bureaucratic government that tries to control everyone’s lives and thoughts.&lt;/p&gt;

&lt;p&gt;As it turns out there is a school of thought specifically dedicated to describing how socialism would work hand-in-hand with competitive markets. So to better explain what socialism is, I’d like to describe some of the main principles of the socio-economic philosophy called &lt;em&gt;market socialism&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;market-socialism-in-a-nutshell&quot;&gt;Market Socialism in a Nutshell&lt;/h3&gt;

&lt;p&gt;Market socialism preserves the market society that we’ve come to rely on— one where people trade goods and services using money, but it changes one crucial detail.  Ultimately the difference between the two systems is only a question of framing our relationship to ownership of businesses, natural resources, and investments. Under capitalism the ownership of our economy belongs to those with great wealth, and they generally hire (poorer) working people to do work and manage the resources they own. By contrast, under market socialism, ownership is transfered to society as a whole, with different institutions set up as the stewarding bodies of that ownership.&lt;/p&gt;

&lt;p&gt;I’ll get into more detail about how this has taken shape before and how it could in the future because there are myriad different ways that this takes place.   But no matter how this takes place there is always only one fundamental change in the economy, which is who owns it.  To understand what this change in fundamental ownership means, we need to break down ownership into its two core pieces: &lt;em&gt;control&lt;/em&gt; and the &lt;em&gt;right to profit&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&quot;control&quot;&gt;Control&lt;/h4&gt;

&lt;p&gt;Having ownership over a business or resource implies that one has &lt;em&gt;control&lt;/em&gt; over how it gets used.  Owners get to decide ultimately what is done with their property.  This control is already regulated by society in ways that prevent owners from doing things that would be massively detrimental, like polluting or creating destructive weapons, but market socialism would take the degree of societal control further.&lt;/p&gt;

&lt;p&gt;Under a market socialist system, the ultimate ownership of natural resources or business would belong to society as a whole.  However, since this isn’t very practical for everyone to be constantly controlling everything, the idea would be to establish management rights for resources or businesses in a form of a contract with the public.  This would allow the public much more ability to step in and stop businesses that were doing things that were outright harmful to society, like underpaying their workers to the point of starvation, or exploiting a natural resource that could be more effectively be put to a different use.&lt;/p&gt;

&lt;p&gt;This might sound radical, but it isn’t entirely too different from the way the natural resources on our public lands work today. For example, on a parcel of BLM grazing land, a ranching company will petition the government for the right to put cattle on the land; a public process will follow that allows the ranchers to make use of the land, and if there are any issues that go against the public good (e.g. the land is already overgrazed, or the methane released will increase global warming), representatives of the community can come forward to block access to the resource.&lt;/p&gt;

&lt;p&gt;This is in contrast to a conventional capitalist relationship when a rancher owns their own land.  Under a pure capitalist framework, the rancher would have the ability to do whatever they want with their livestock and land even when it’s detrimental to the public good.  For example, they could overgraze a hillside to the point that it causes erosion, or they could treat their livestock with potentially harmful chemicals.&lt;/p&gt;

&lt;p&gt;This is the change in framing of control between capitalism and socialism.  In capitalism, the owner gets the final say, while in socialism, society gets the final say.  In this sense, we already live in what’s called a “mixed economy,” where society has some capacity to regulate, but the rights of owners are also central to decision-making.  To move in the direction of market socialism is just to negotiate where that fine line is between how much any individual should be allowed to control vs how much say society should have.&lt;/p&gt;

&lt;h4 id=&quot;rights-to-profit&quot;&gt;Rights to Profit&lt;/h4&gt;

&lt;p&gt;The second big thing about a market economy is the idea of profit. Individual companies make their decisions about production with the hope that they can sell their products for more money than it took to create them, pocketing the difference.  This motive for profit would still be an important factor that would allow a socialist market to function.  However, since the ownership of the company would ultimately be society as a whole, the profit distribution would no longer be to individual shareholders. Instead society would need to decide how to distribute the returns.&lt;/p&gt;

&lt;p&gt;Now again, it would be quite difficult for all of society to decide where each dollar of profit goes, but it would be possible to set up rules for redistribution—to workers, customers, other businesses, and even directly back to the public-at-large.&lt;/p&gt;

&lt;p&gt;Again, this may sound like a radical idea, but this has been carried out in several places (Norway, UAE, and Alaska), where profits from oil revenues have been nationalized and redistributed to all citizens.  And in another form, described more carefully in the next section we’ll see how two specific proposals could manage this question.&lt;/p&gt;

&lt;h3 id=&quot;a-specific-implementation-economic-democracy&quot;&gt;A Specific Implementation: Economic Democracy&lt;/h3&gt;

&lt;p&gt;A particularly inspiring proposal for a form of market socialism is a system called Economic Democracy. There are several versions of this system, but I’m most familiar with the version proposed by Loyola University professor David Schweickart in his book &lt;a href=&quot;https://books.google.co.za/books?id=KWy9JbWvjywC&amp;amp;printsec=frontcover&amp;amp;source=gbs_atb#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;After Capitalism&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=pDGYSXMHJQE&quot;&gt;elaborated on&lt;/a&gt; and &lt;a href=&quot;https://www.youtube.com/watch?v=ui7c4MoeXsw&quot;&gt;summarized&lt;/a&gt; afterwards. I suggest reading his whole book for a more complete picture, but I’ll explain the 3 main components briefly.&lt;/p&gt;

&lt;h4 id=&quot;regulated-market&quot;&gt;Regulated Market&lt;/h4&gt;

&lt;p&gt;The first element is actually very intuitive because it matches exactly with the system we already have, a regulated market for consumer goods and services.  Basically, we all still go to the store or shop online for what we need to buy.  The only difference would be the degree to which the government would attempt to regulate negative externalities either via price controls like a carbon tax or direct administration, like stronger laws for intentional disinformation.  Overall this pillar of the current capitalist market would remain largely unchanged.&lt;/p&gt;

&lt;h4 id=&quot;democratic-workplaces&quot;&gt;Democratic Workplaces&lt;/h4&gt;

&lt;p&gt;A much bigger change would be the establishment of democratic workplaces to deal with the control of businesses.  As Schweickart describes it:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;An enterprise should no longer be thought of as a thing to be bought and sold; an enterprise is a community.  When you join the community, you get to vote.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The idea is that the workers at the company should have the best incentive to negotiate the pros and cons of business decisions since they will impact them the most.  So instead of major business decisions being made by shareholders, based on share of capital investment, the major decision making would come from democratic vote by workers.  This notion of economic empowerment for workers is a powerful idea that is most often encountered presently in the form of worker co-ops, though theoretically other institutions could operate with this same basic premise.&lt;/p&gt;

&lt;h4 id=&quot;public-control-of-investment&quot;&gt;Public Control of Investment&lt;/h4&gt;

&lt;p&gt;This one might be a little less familiar to people who aren’t aware of how businesses raise investments today.  Briefly, the way this works now, is people with significant savings will distribute their money to companies through any of a number of avenues, such as bank loans or public stocks or private equity firms.  Under the Schweickart model, this system would be replaced with a system of only public banks offering grants to worker-owned businesses.&lt;/p&gt;

&lt;p&gt;Personally, I find this last part a little too limiting&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.  I would think that there ought to be some form of heavily taxed semi-private equity that could be managed by people who have previously shown investment acumen.  But I’ll hold off on elaborating on socialist venture capital for another post.&lt;/p&gt;

&lt;h3 id=&quot;socialism-and-capitalism-are-ideas&quot;&gt;Socialism and Capitalism are Ideas&lt;/h3&gt;

&lt;p&gt;This article covered a lot and dove way into the details of a specific socialist implementation, but I want to make sure to step back and remind the reader that socialism, like capitalism, is just an idea.  It never was a specific policy, but rather diverse set of philosophical concepts that come together to describe a coherent worldview for how to structure policy decisions.  So thinking about how the world could work under socialism should always be an exercise that starts from understanding the broad principles before zooming into the minute details.&lt;/p&gt;

&lt;p&gt;Remember that socialism has always been centered on society as a whole owning the economy, instead of leaving it to those with large reserves of capital. If you agree that its better for our economy to be controlled by everyone, rather than just those with a lot of money, you probably mostly agree with socialist ideas.  And from there, it’s just a matter of figuring how we can achieve that goal in a practical way.&lt;/p&gt;

&lt;p&gt;I believe that the conditions are in place for a migration toward market socialism, and if incremental steps to a market socialist economy are practical, it’s time we take them.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Not surprisingly there was a partisan bias, with Republicans still more likely to consider socialism to mean the government controls everything. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;To be fair, Schweickart &lt;a href=&quot;https://youtu.be/7KRUj2lcj64?t=100&quot;&gt;also talks&lt;/a&gt; about an entrepreneurial capitalist in market socialism too. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 27 Oct 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/10/market-socialism-1/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/10/market-socialism-1/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        <category>economics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/board_fist.png</image>
        <title>Uprising Chess</title>
        <description>&lt;p&gt;What do you see when you look at a chessboard?  Two rows of expendable pawns march into battle to protect the interests of the nobility, convinced to fight solely because they happen to be a different color. Sacrificing their lives to protect a bumbling and ineffectual king.  The game itself is a blueprint for the kind of society the rulers wanted back when it was invented.  All of us regular people convinced to fight each other for the comfort of a few.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Uprising Chess Board&quot; src=&quot;/assets/images/2021/chess_king_match_symbolism.jpg&quot; /&gt;
  &lt;figcaption&gt;
    the chessboard is a perfect metaphor for our society
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;And sadly, that’s more or less the way our world works to this day, except instead of fighting with swords, we sacrifice our time and our sanity to toil away for our masters.&lt;/p&gt;

&lt;p&gt;Well not anymore. It’s about time for the pawns to unite and take on our real oppressors: the capitalist owners.&lt;/p&gt;

&lt;p&gt;I wrote new rules for a chess game called Uprising Chess that pits the pawns against the noble pieces. And just like in life, in this game the nobles only maintain their special moves if they can keep the pawns in their place. You can play the game with a friend online at &lt;a href=&quot;https://uprisingchess.web.app.org&quot;&gt;uprisingchess.web.app&lt;/a&gt; or join our &lt;a href=&quot;https://discord.gg/MP5vJAQ2XM&quot;&gt;discord&lt;/a&gt; to find other comrades to play with. Read on to learn more about the rules and philosophy behind the game.&lt;/p&gt;

&lt;h3 id=&quot;the-rules-of-the-game&quot;&gt;The Rules of the Game&lt;/h3&gt;

&lt;p&gt;The rules of Uprising Chess are derived from standard chess, with some notable exceptions. The pieces move in largely the same way, but now the pawns are all one team and nobility pieces (rook, knight, bishop, queen, and king) are all the other.  &lt;/p&gt;

&lt;h4 id=&quot;initial-setup&quot;&gt;Initial Setup&lt;/h4&gt;

&lt;p&gt;The game is played on a standard chess board except the pieces are rearranged, with a row of Worker pieces (pawns) along each outside edge (rows 1 and 8) and the Capitalist pieces (non-pawns) in two rows down the center (rows 4 and 5). When set up there will be 4 of each rook, knight and bishop, 2 queens, and a single king&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Uprising Chess Board&quot; src=&quot;/assets/images/2021/chess_board.png&quot; /&gt;
  &lt;figcaption&gt;
    Uprising Chess Initial Game Setup
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;h4 id=&quot;objective&quot;&gt;Objective&lt;/h4&gt;

&lt;p&gt;The main objective for the Worker is to take the Capitalist king (AKA ending capitalism itself). The objective for the Capitalist team is to force the worker team to a forfeit (AKA “get back to work”).&lt;/p&gt;

&lt;p&gt;But really, the meta-objective of this game is to get the word out about taking back some control of working people’s lives by a real-life general uprising.&lt;/p&gt;

&lt;h4 id=&quot;moves&quot;&gt;Moves&lt;/h4&gt;

&lt;p&gt;For the most part the pieces move the same as in regular chess, but there are important differences that make this game very different.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Capitalist pieces (non-pawns), move like they do in regular chess, and Worker pieces (pawns) move like regular pawns. At first glance it would seem like the Capitalist pieces have a huge advantage, but there is a catch! In each column, if the outside two squares aren’t both filled, then any capitalist piece in that column converts to moving just like a pawn. We call the outside two squares of each column the “factories.” So if a single pawn has moved out of its factory then the capitalist pieces in that column move like pawns. One important thing to note is that the factory squares don’t have to be occupied by a worker piece for them to be “running.” Even a Capitalist piece could move into the factory squares and cause the other Capitalist pieces in that column to operate normally again.
&lt;img style=&quot;max-width:300px;&quot; alt=&quot;Uprising Chess Nobles Convert to Pawns&quot; src=&quot;/assets/images/2021/chess_noble.gif&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Worker pieces (red pawns) mostly move like regular pawns (move 1 space, attack on the diagonal) from the outside inward.  However, once a pawn reaches the middle two rows (rows 4 and 5) they switch from moving like pawns to moving like a king (move or attack in any direction). If the pawn in the center rows then moves back out to either of the outside 3 rows (1-3 or 6-8), it goes back to acting like a pawn on that side again.  (Note that when a Capitalist piece is converted to a pawn it doesn’t move like a king in the center rows.)
&lt;img style=&quot;max-width:300px;&quot; alt=&quot;Uprising Chess Pawn Motion&quot; src=&quot;/assets/images/2021/chess_pawn.gif&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Importantly, when Capitalist pieces “take” Worker pawns, the pawns aren’t necessarily removed from the board. If the pawn is taken in a column with an unoccupied factory, then the pawn is immediately returned to that factory (if both factories are unoccupied it is returned to row 1 by default).  However, if the pawn is taken in a column where the factories are already both occupied, then the pawn IS removed from the game.  When Worker pieces take Capitalist pieces, the Capitalist piece is removed from the game.
&lt;img style=&quot;max-width:300px;&quot; alt=&quot;Uprising Chess Taking a Pawn&quot; src=&quot;/assets/images/2021/chess_take_pawn.gif&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Finally, the king is not affected by the factories, and always continues to move as a standard king. However, the king is not allowed to move outside of the middle two rows of the gameboard (rows 4 and 5).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;scoring&quot;&gt;Scoring&lt;/h4&gt;

&lt;p&gt;As the game is played, a score is tallied by counting how many factories are running at the end of each turn.  For each column with both factories occupied the Capitalists get 1 point, and for each with at least 1 unoccupied, the Workers get a point.  Often 2 games will be played, exchanging who is Capitalist and who is Worker.  If the Workers defeat Capitalism both times, then the player with the higher score as Capitalist is the overall winner.&lt;/p&gt;

&lt;h4 id=&quot;example-games&quot;&gt;Example Games&lt;/h4&gt;

&lt;p&gt;Those are all the basic rules of gameplay.  Here’s an example game:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/DRAcs98p1aA&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;If you’re ready to play, you can go to &lt;a href=&quot;https://uprisingchess.web.app&quot;&gt;uprisingchess.web.app&lt;/a&gt; and start a game, either against the AI or with a friend. Read on to learn more about the meaning behind the game.&lt;/p&gt;

&lt;h3 id=&quot;the-philosophy-of-uprising-chess&quot;&gt;The Philosophy of Uprising Chess&lt;/h3&gt;

&lt;p&gt;This game illustrates two important lessons about how the economy and political power is so messed up in the United States and how workers can do something to stop it.&lt;/p&gt;

&lt;p&gt;The first lesson is that the special abilities that we seem to ascribe to our rulers are only possible because of the work that the rest of us do for them. Successful business persons, entertainers, politicians, and even scientists are often only successful because they have a team of people who are having their efforts extracted from them for less than they are worth. That’s why in the game, the moment the worker walks away from their “factory square,” the owners’ special power disintegrates and they become just another regular pawn. In that sense, the major challenge of this game and of our collective struggle is to coordinate our resistance to overcome the owners’ systems of oppression.  In the strategy of this game, it’s the workers across factories stepping up and protecting each other.&lt;/p&gt;

&lt;p&gt;The second lesson that I wanted to show was the focus on artificial political ties. In regular chess, pawns fight for the king of the same color, which is the same way our real-life social and political tribalism works. These distinctions mask the great similarity between working people around the world. A working class person in the US is way more similar to a working class person in China than either are to the people who rule over them, but political divisions are drawn so that we don’t see our universal humanity. Similarly the divisions between working class Republicans and Democrats also mask our shared struggle to overcome our exploitation.&lt;/p&gt;

&lt;h3 id=&quot;onward-comrades&quot;&gt;Onward Comrades!&lt;/h3&gt;

&lt;p&gt;Although the game is new&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; and we don’t fully understand all its nuances, we hope to start to build more strategy around it. I also really hope that this game can help inspire more people to get involved with organizing to rise up and start to fight back against the pressures that the ruling class put on our lives.  Capitalism is a tired old system, and it’s time for all people to work together to self-govern our economy.&lt;/p&gt;

&lt;p&gt;So enjoy the game and lets do this!&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Fun Names for Pieces: Because it can get confusing to explain, I described the game using the standard chess piece names. But really it’s much more fun to rename the nobility pieces.  The names I came up with are: the rook = the landlord, the knight = the cop, the bishop = the influencer, the queens = CEOs, and the king = the owner.  Hopefully that makes the game as fun for you as it does for me. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Uprising Chess is an update of a previous version I had online called General Strike Chess. You can check out the old rules &lt;a href=&quot;/commentary/2021/05/13/chess-v1.html&quot;&gt;here&lt;/a&gt;. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 09 Oct 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/10/uprising-chess/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/10/uprising-chess/</guid>
        
        <category>games</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>Carbon Fragility</title>
        <description>&lt;p&gt;Our climate is changing, possibly irreversibly. When asked in &lt;a href=&quot;https://www.pewresearch.org/fact-tank/2020/04/21/how-americans-see-climate-change-and-the-environment-in-7-charts/&quot;&gt;polls&lt;/a&gt;, most everyone understands this. We even know how to stop it and yet in our day-to-day public interactions, very few people seem to be willing to talk about any of this.&lt;/p&gt;

&lt;p&gt;I’ve developed a theory to explain this, and I’ve termed it Carbon Fragility, an environmental correlate to the phenomenon known as &lt;a href=&quot;https://en.wikipedia.org/wiki/White_defensiveness&quot;&gt;white fragility&lt;/a&gt;.  In white fragility, white people build defense mechanisms to avoid directly confronting their implicit role in upholding white supremacy.  In carbon fragility, people build defense mechanisms that help them to avoid thinking about the environmental damage that they implicitly take part in every day through their carbon footprint.&lt;/p&gt;

&lt;p&gt;Just as in white fragility, the way carbon fragility manifests can take many forms, from frozen silence to outbursts of rage. And also just like with white fragility, the fragility response is perhaps the most dangerous roadblock to changing harmful behavior. But fortunately, thanks to the incredible work done by social justice advocates toward unpacking and answering how white fragility can be overcome, I think this framing could help us approach a way forward for changing minds about our role in reducing environmental harm.&lt;/p&gt;

&lt;h4 id=&quot;personal-experience&quot;&gt;Personal Experience&lt;/h4&gt;

&lt;p&gt;The inspiration for carbon fragility came from my personal experience trying to communicate to others how I’ve changed my lifestyle to be more environmentally conscientious.  I’m currently on a bicycle tour around the United States, and during this trip I’ve met and talked with many many people who are interested in my travels.  During these conversations, I’ve noticed a very specific pattern.  If I only talk about the adventure or the cost effectiveness of bike touring, I get great engagement from the people I’m talking to, and we can have a several minute conversation about bike touring.&lt;/p&gt;

&lt;p&gt;But if at any point I mention that part of the reason to bike tour is because it is better for the planet, or that cycling is important because it has a lower carbon footprint than driving, the conversation immediately ends.  In every case, the person I’ve been talking to has frozen up, changed the subject, and switched their body language to move on.  At first, I thought it was my messaging so I worked on saying this in the most positive way I could with absolutely no hint that I’m blaming them for their behavior.  I’ve gone out of my way to make sure they know it’s just my personal choice.&lt;/p&gt;

&lt;p&gt;But no matter what, the reaction is the same.  People just find it incredibly uncomfortable to think about the implication that driving cars is a social ill.&lt;/p&gt;

&lt;p&gt;In another manifestation of carbon fragility, I’ve experienced bursts of irrational outrage from white men in pickup trucks blasting black fumes of diesel exhaust out of their truck onto me as I bicycle (aka &lt;a href=&quot;https://en.wikipedia.org/wiki/Rolling_coal&quot;&gt;rolling coal&lt;/a&gt;). This rage seems completely out of place, and the only reason for doing this seems to be simply because we are bicycles and we have a solar panel visible on our trailer.  We’re often not even in the road.&lt;/p&gt;

&lt;p&gt;Both of these extreme reactions to simple behavior changes reminded me of the reactions I observed during the antiracism discussions I had during 2020, between incoherent rage, accusations of reverse racism, or simple silence from family members.&lt;/p&gt;

&lt;h4 id=&quot;fragility-and-harm&quot;&gt;Fragility and Harm&lt;/h4&gt;

&lt;p&gt;Although there are clear parallels between defensiveness in the context of white supremacy and defensiveness in the context of environmental harm, I also recognize the serious differences between the two.  First off, the implication that someone is racist is already universally acknowledged as wrong, while many people still don’t necessarily consider carbon pollution to be a real problem.  Also the harm of white supremacy is direct and observable by its victims while carbon pollution’s harm is easy to dismiss because it is so diffuse.&lt;/p&gt;

&lt;p&gt;However, I personally believe that the harm from carbon emissions are actually real and every person either contributes to the problem or contributes to the solution.  In this way there are still parallels to the harm done via racism and the harm done via carbon pollution, with the victims being the future generations, especially those in developing countries.  Indeed, many people have already elaborated on the idea that environmental and social justice activism are &lt;a href=&quot;https://blog.pachamama.org/how-social-justice-and-environmental-justice-are-intrinsically-interconnected&quot;&gt;inextricably linked&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In short, I believe that people are beginning to instinctively acknowledge the harm from carbon pollution even if they can still intellectually downplay it. And I believe it is this instinctive understanding of the harm that is causing them to manifest these characteristics of fragility. In that way, we actually have an advantage in that we can leverage our already considerable understanding of how to effectively deal with white fragility in our approach to carbon fragility.&lt;/p&gt;

&lt;h4 id=&quot;a-way-forward&quot;&gt;A Way Forward&lt;/h4&gt;

&lt;p&gt;From my brief time engaging in antiracism work, it has become clear that no amount of shaming from a stranger can change people’s minds.  The only thing that works is building a personal connection with the issue. And from those connections you can motivate people to investigate the problem for themselves.  If someone can reach the point where someone recognizes that they are personally a part of the problem and  they are able to pursue the solution on their own terms, then it becomes possible to address the behavior.&lt;/p&gt;

&lt;p&gt;So how to move forward on breaking down carbon fragility?&lt;/p&gt;

&lt;p&gt;The first step is educate people sympathetic to the cause that the behavior change works the same way as antiracism work. A huge and difficult part of this step is recognizing that even if you consider yourself “an environmentalist” you probably still cause considerable harm through your own lifestyle. In other words, the most important first step is recognizing that even if I consider myself “one of the good ones,” I still have a lot of work to do to understand all the ways that I am still part of the system that is a problem.  The second is outreach at a personal level to family and friends to let them know about the issue and how WE ARE ALL a part of this system and that we can only change it together. It’s important to have already ackowledged my own own shortcomings at this stage so that I can build empathy and let others know that I am doing the work for myself, making mistakes and muddling through it. And finally, the third step is to provide resources that can make it easier for friends to do internal work to recognize their place in this system. Everyone contributes to varying degrees and unless we are anti-carbon pollution we are pro-carbon pollution.&lt;/p&gt;

&lt;p&gt;I’ve only just begun thinking about this process and its implications. As always, I’m very curious how others feel about this idea, where you find strengths to the argument and weaknesses.  In my limited research I wasn’t able to find a good summary of this idea, but if you believe there is already an existing term that describes this behavior, please reach out. Or if you think you’ve observed carbon fragility and find the concept useful, drop me a line on Twitter or TikTok. &lt;/p&gt;
</description>
        <pubDate>Mon, 27 Sep 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/09/carbon-fragility/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/09/carbon-fragility/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        <category>environment</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/last_highway.jpg</image>
        <title>The Last Highway</title>
        <description>&lt;p&gt;Their packs were light. The next research station was only a short ride over the crest, and the valley on the other side had a well-stocked food forest.&lt;/p&gt;

&lt;p&gt;“The ride up is steep,” Teris said, “ take it easy on the throttle, we don’t want to use up our battery too early.”&lt;/p&gt;

&lt;p&gt;“Why not?” Casim said, “we’ve got plenty of sun to recharge up there.” They hit the pedal and the electric motor whirred as they accelerated up the incline. “See you at the top!”&lt;/p&gt;

&lt;p&gt;Casim banked hard as they hit the first turn, blazing up the narrow trail.&lt;/p&gt;

&lt;p&gt;Teris shook their graying head and tightened down their pack. They sped up behind, not as fast as Casim, but still faster than they would have liked.&lt;/p&gt;

&lt;p&gt;The pair of them, friends from their time in the Green Reserves, were on a six month vacation riding the Redwood Trails of the lands formerly called Northern California, volunteering to track wildlife repopulation and forest health in the renewing old growth forests. For Teris that meant taking things slow, but Casim was eager to complete two tours through the forest before they were done.&lt;/p&gt;

&lt;p&gt;Casim weaved and darted along the switchbacks up the canyon wall. The pavement was shattered and worn down from decades of coastal winds and winter thunderstorms. Casim slammed the brakes and skidded past a wide tan oak in the road. “Watch out for that old timer,” they yelled over their shoulder, but Teris barely heard over their own heavy breathing as they pedaled hard to conserve battery.&lt;/p&gt;

&lt;p&gt;“The young people don’t appreciate how much punch these batteries pack,” Teris said to themself.  They were nearly 50 and had lived through “The Trough,” the period of 20 years when the fossil fuel collapse and the climate weirding changed everyone’s lives. Life was hard in those years as society restructured. Teris weaved through the woods to keep their mind from drifting back to those days of war and mass migrations.  Suddenly Casim appeared in front of them, stopped on the trail. Teris slammed the brakes and skidded to an abrupt stop.&lt;/p&gt;

&lt;p&gt;“What the…!”&lt;/p&gt;

&lt;p&gt;“Just wanted to keep you from hitting those,” Casim said, gesturing toward huge boulders strewn across the road, “rubble from a rock slide.”&lt;/p&gt;

&lt;p&gt;Teris gazed across the rocks, puzzled. Something didn’t seem quite right. The canyon wall was solid rock and the pitch wasn’t so steep that it should have slid.&lt;/p&gt;

&lt;p&gt;“This isn’t a rockslide. You can see the dynamite holes,” Teris said.&lt;/p&gt;

&lt;p&gt;“You mean these rocks were blasted? By who?”&lt;/p&gt;

&lt;p&gt;“My best guess would be lumber poachers.”&lt;/p&gt;

&lt;p&gt;“You’re kidding!?”&lt;/p&gt;

&lt;p&gt;Teris’s look turned to their semi-serious smirk that told everyone, “I am serious, but life doesn’t care how serious we are.”&lt;/p&gt;

&lt;p&gt;“They warned us.”&lt;/p&gt;

&lt;p&gt;“It’s been 10 years. I didn’t take it seriously.”&lt;/p&gt;

&lt;p&gt;“10 years since anyone’s discovered them.  They’ve been out there, just not getting caught.  It’ll take a while for these folks to catch up. Destruction’s a part of their culture and that’s hard to change.”&lt;/p&gt;

&lt;p&gt;“So what do we do now?”&lt;/p&gt;

&lt;p&gt;Teris looked ahead down the road. “We report what we’ve seen, but I suspect we won’t get any signal til we’re higher up.”&lt;/p&gt;

&lt;p&gt;“But this is impassable.”&lt;/p&gt;

&lt;p&gt;“Maybe for you kid,” Teris dropped down on the throttle and shot up onto the bank the boulders had been blasted from. It was steep but Teris rode up and down like riding the curl of a wave.&lt;/p&gt;

&lt;p&gt;“I guess that’s one way to do it,” Casim yelled, hopping on their bike and starting a less aggressive angle. After a hundred meters, Teris’ wheels glided past the last obstructing boulder back into the normal trail.&lt;/p&gt;

&lt;p&gt;“The trail is different now,” Teris noticed. It took them too long to realize that the road had been cleared and graded. The lumber poachers weren’t just blocking access to this area, they were using it as their route. A petroleum fueled logging truck shot past Teris, clipping the front of their bike and kicking them to the edge of the road. Teris’s stomach churned as they stabilized the bike just in time to turn their body past an oncoming tree. Still, their turn wasn’t tight enough and the tail of the bike slammed into the tree, flinging them off their bike.&lt;/p&gt;

&lt;p&gt;Their body airbag deployed, blunting the impact with the road. They tumbled for what seemed like a minute trying to slow themself as they skidded. When they finally stopped spinning, they felt their body taking ages to stand up. The truck had stopped, and it’s doors were open. Teris scanned the woods on each side of the road. These loggers had probably been in the war. They’d have training, and probably guns. Teris needed to move but didn’t know where to go. Their thoughts stretched on forever, immobilizing them.&lt;/p&gt;

&lt;p&gt;Then piercing through their shock, Casim’s bike swished past and stopped.&lt;/p&gt;

&lt;p&gt;“Get on!” their glare broke through to Teris.&lt;/p&gt;

&lt;p&gt;Casim torqued the pedals and hit the accelerator as hard as they could, thrusting off the road and straight down the canyon wall. They must have been airborne for three whole seconds before they crashed back to ground. The bike trampled through ferns but somehow snaked through the trees. By some miracle, they eventually leveled out along a tight trail. The bike slowed and both of them slumped onto the ground to let their nerves catch-up.&lt;/p&gt;

&lt;p&gt;“Um, thank you,” Teris said.&lt;/p&gt;

&lt;p&gt;“No problem. Honestly, I didn’t think I had that in me.”&lt;/p&gt;

&lt;p&gt;An instant later, the sound of the logging truck echoed above them.&lt;/p&gt;

&lt;p&gt;“Seeing as our radio is about a half a mile up, next to those poachers, our best bet is to head down this river gorge toward the ocean. We can try to pass on the last highway.”&lt;/p&gt;

&lt;p&gt;“The what?”&lt;/p&gt;

&lt;p&gt;“It’s the furthest west passable route, used to be called highway 1. Though most of it has since fallen into the ocean.”&lt;/p&gt;

&lt;p&gt;“That doesn’t sound too hopeful.”&lt;/p&gt;

&lt;p&gt;Casim slowly rode the path that undulated downward along the canyon wall.  The trail was tight and overgrown. The two didn’t speak except for the occasional whisper to discuss the route. After a few hours, their surroundings transitioned from ferns and trees to denser brush.  Teris stepped off the bike to chop through the thicket.&lt;/p&gt;

&lt;p&gt;“We’re getting closer to the ocean.”&lt;/p&gt;

&lt;p&gt;Soon the trail dropped off to a nearly sheer switchback and they climbed down to a landing just below.&lt;/p&gt;

&lt;p&gt;“It’s clear just around this bend.”&lt;/p&gt;

&lt;p&gt;As Casim followed around the bend, they were struck with awe.  The cliff that they were standing on was a sheer slab of rock that rose for thousands of feet and continued for miles. Across there was no other side to the gorge, instead just piercing blue ocean that stretched out to meet the lighter sky.  At first Casim was too taken aback to notice, but below were massive swirling eddies of waves breaking against the exposed rock.&lt;/p&gt;

&lt;p&gt;Casim continued to stare in a stunned shock as Teris clammered along the side of the cliff.&lt;/p&gt;

&lt;p&gt;“Do I leave the bike?” Casim called over the thunder of the waves below.&lt;/p&gt;

&lt;p&gt;“No, push it along.”&lt;/p&gt;

&lt;p&gt;Casim’s gut knotted up.  But Teris was right.  Before long the trail dropped down to the ocean and widened out into fields that sat between the mountain and a shorter cliff. They got back on the bike and continued to ride south.&lt;/p&gt;

&lt;p&gt;They rode for another hour before, off in the distance, they noticed an oddly regular brown line crossing the whole plain in front of them.  Teris gestured left, toward the treeline at the base of the mountain. Perched behind the tree cover, Teris pulled out their binoculars.&lt;/p&gt;

&lt;p&gt;It was a wall.  Huge poles of redwood were driven into the ground and on top of one pole was a flag that they could barely recognize from history books.  Next to the flag was a sign that read: Fort Bragg.&lt;/p&gt;

&lt;p&gt;“Interesting,” Teris said, “they stopped calling it that when I was a kid. Just before The Trough began.” It took a moment to dawn on them, a flag and a name from before the Green Era, enormous trees that were felled and built into a fortress wall. Clearly this was bigger than just sneaking some lumber for the underground markets. The lumber poachers were trying to colonize this land again.&lt;/p&gt;

&lt;p&gt;“Looks like we’ll need to head north instead.”&lt;/p&gt;

&lt;p&gt;Teris and Casim retraced their route, but before their path turned back up along the cliffside, they found a turnoff that led down to the rocky shore.&lt;/p&gt;

&lt;p&gt;The tide had gone out and where the waves had buffeted the bluff before, now there stood a long beach of large stones.&lt;/p&gt;

&lt;p&gt;“We’ll need to make it to the next river before the tide comes,” Teris said.&lt;/p&gt;

&lt;p&gt;“You mean before we’re swept out to the ocean?” Casim said.&lt;/p&gt;

&lt;p&gt;“Yep, so let’s stop yapping and get riding.”&lt;/p&gt;

&lt;p&gt;The road over the boulders jolted the bike this way and that, almost bucking Teris from the rear.  At first, the waves crashed far away, but after an hour, they were crashing closer and closer, without a single break in the rock face.&lt;/p&gt;

&lt;p&gt;“Don’t worry,” Teris said, “We should see the mouth of a river coming up soon, and we can spend the night there.”&lt;/p&gt;

&lt;p&gt;The highest waves were already submerging the bottom of the wheels when the river finally came into view. At the river’s sight, Casim felt themself relax for the first time that day.&lt;/p&gt;

&lt;p&gt;They hadn’t brought camping supplies, and only had a bit of food, but Casim finally had time to study their map.  “Tomorrow we should get to Shelter Cove. We can warn them. And there should be a solar drone station or at least a boat that we can get out on.”&lt;/p&gt;

&lt;p&gt;The two slept surprisingly well to the sound of waves crashing. In the morning, the tide had subsided and the wind was nearly still.  They lay in their sleeping bags, trying to convince themselves that they were wrong about what they were hearing from the north.&lt;/p&gt;

&lt;p&gt;The sound was unmistakable: chainsaws.  The indigenous people who ran sustainable logging in the area never used chainsaws.  They harvested timber that fell naturally.  Shelter Cover must have fallen to the loggers too.&lt;/p&gt;

&lt;p&gt;The trails up into the cliffs here were sparse to the point of being non-existent. Their only choice was to ride the beach as far as they could, until the sound of chainsaws grew loud enough to be just around the bend.  From there, they continued on foot, hugging the inside of the bluff to keep out of view of the forest above. This slowed them down tremendously. After another hour of hard scrambling, they caught a glimpse of Shelter Cove. The buildings looked like they dated from a century prior, small cottages along the seawall, each with a chimney that smoke rose out of. Teris hadn’t seen that since The Trough.  This undoubtedly loggers. They would need to keep out of sight. The only choice was to wait for night.  Teris and Casim sat close together inside a hollowed out cave in the bluff.&lt;/p&gt;

&lt;p&gt;At dusk, the tide was already lapping at their feet. They left in the twilight, and walked along the nearest edge of the sandbar that led around the harbor just below the houses.  By the time they were halfway past, the high waves were already at their waists..&lt;/p&gt;

&lt;p&gt;Teris started to slow their pace, turning to Casim every so often.  Casim recognized the growing look of desperation.&lt;/p&gt;

&lt;p&gt;“Push on, fast!” Casim said, “we’ve only got one way to go now.”&lt;/p&gt;

&lt;p&gt;Teris tramped on, their body heavier from the salt water their clothes had absorbed. The din of the waves punctuated their pace.  Step, step, step, splash, the water would come in and move Teris’s feet under them.&lt;/p&gt;

&lt;p&gt;“Stay on the big rocks now, they don’t move when the waves hit.”&lt;/p&gt;

&lt;p&gt;Casim reached the first of the tall rocks a moment later.  The waves swirled around, but they were dry on top.  A row of tall rocks stretched around the next turn, each just far enough that they could reach.&lt;/p&gt;

&lt;p&gt;Teris turned around and saw the spot they’d passed 10 minutes prior. If they were still there, they’d be in over their heads. When Teris turned back, Casim was gone.&lt;/p&gt;

&lt;p&gt;Teris’s eyes darted around. If Casim was already underwater, no one could help them now.&lt;/p&gt;

&lt;p&gt;Teris leapt to the next rock, and the next.  As they rounded the bend they saw Casim, clinging to a crack in the boulder, their body half submerged.  Teris scrambled along and grasped Casim by their shoulders.  The pair pulled together as the wave crested and Casim’s body flopped up onto the rock, splayed and cringing in pain.  As the wave fell off, Teris hoisted Casim to their feet, and edged them forward toward the next leap.&lt;/p&gt;

&lt;p&gt;“Go now,” Teris said, “Jump.”&lt;/p&gt;

&lt;p&gt;Casim jumped across the gap, almost toppling, but keeping their balance.  They both pushed on, just a few more rocks until they found a narrow path carved into the rock face above them.  Teris boosted Casim up onto the path as another big wave came in behind.  Teris felt their body crushed against the wall of the bluff then lifted up, against their will. They were sure the waves had taken them, but a moment later, they recognized Casim’s now familiar grip, pulling them up.&lt;/p&gt;

&lt;p&gt;They were now far past the houses of Shelter Cove, but they continued, bodies soggy and tired, into the night. They hiked through the day before they found a river and collapsed.&lt;/p&gt;

&lt;p&gt;The next morning they gathered up strands of seaweed to eat. The walk felt unending as they realized there were no settlements mapped for a hundred miles.  And they couldn’t be sure that those lands hadn’t fallen to the loggers.&lt;/p&gt;

&lt;p&gt;They turned up the first river they could find, unable to bear walking along the coast. They wandered for half a day until the woods along the river opened up into a wide valley full of organized permaculture farms.&lt;/p&gt;

&lt;p&gt;Teris and Casim checked their maps, confused.  The river was called the Mattole, but these farms weren’t mapped.&lt;/p&gt;

&lt;p&gt;Shortly, Teris and Casim reached the center of the cooperative farming village nestled into a picturesque valley. The village still had radio communication, and it was only a few hours before a solar drone flew into town to whisk Teris and Casim back north to Wiyot territory.&lt;/p&gt;

&lt;p&gt;As they took off, they saw police drones begin their patrol to the south. The loggers wouldn’t outlast an embargo that cut off their supplies. After a few years of monitoring, some of them would go back to extraction society, but most would probably settle into new lives with the rest of the free people.&lt;/p&gt;

&lt;p&gt;As for Teris and Casim, their next sabbatical would be someplace safer, like the rehabilitated reefs in the southern sea. After all, there hadn’t been a sighting of an oil pirate in decades…&lt;/p&gt;

</description>
        <pubDate>Thu, 01 Jul 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/07/the-last-highway/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/07/the-last-highway/</guid>
        
        <category>fiction</category>
        
        <category>environment</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>What is involution</title>
        <description>&lt;p&gt;Last week a friend of mine from China introduced me to a new word that popped up in Chinese culture last year to describe the point where competition switches from being productive to destructive. It’s called &lt;strong&gt;involution&lt;/strong&gt; and if you haven’t heard of it yet, you’re missing out on an important concept that helps explain the greatest paradox of our time:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Why does everything keep feeling worse the harder we work to make things better?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;While the term was originally invented by anthropologists to describe a particular kind of &lt;a href=&quot;https://www.britannica.com/topic/social-change/Patterns-of-social-change#ref748348&quot;&gt;agricultural society&lt;/a&gt; where competition in food production causes standard of living to stagnate, the term has broadened in definition recently to describe the futility of the modern &lt;a href=&quot;https://en.wikipedia.org/wiki/996_working_hour_system&quot;&gt;996&lt;/a&gt; rat race.&lt;/p&gt;

&lt;p&gt;To get an understanding of the concept my friend introduced me to a simple example story.&lt;/p&gt;

&lt;h4 id=&quot;the-town-of-involution&quot;&gt;The town of Involution&lt;/h4&gt;
&lt;p&gt;Imagine there was a town that was totally self-sufficient. The citizens of the town were farmers who made the food, factory workers who made the clothes, and construction workers who built the houses for everyone. Because the town has been established for a while there is a good balance of each kind of worker so everyone works an 8 hour day and makes enough money to earn all the things they need to survive in town.&lt;/p&gt;

&lt;p&gt;Now imagine there are two people who make all the shoes for the town, but one day one worker who makes shoes decides that they are going to start working 16 hours instead of 8. They suddenly start producing enough shoes for both workers. At first everyone is happy because now they have more shoes to choose from, but eventually they notice a problem.&lt;/p&gt;

&lt;p&gt;The townspeople can’t afford to pay any more overall for their shoes so now the hyper-productive shoemaker makes 66% of the shoe related income, while the less productive shoemaker takes in 33%&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. In order to earn enough to live with the same standard of living as before, the less productive shoemaker will have to respond by doubling their working hours as well. Now, both shoemakers are working twice as much as before, but they are both earning the same amount of money as when they started. The townspeople now have twice as many shoes to choose from, but they don’t actually need any more shoes so half of the shoes made in town are just wasted anyway.&lt;/p&gt;

&lt;p&gt;Now instead of this extreme example, imagine instead just one person in every industry in town starts working just slightly harder than their neighbor. Ultimately the same thing will happen to everyone, there will be no choice but to work more and more for no substantial material gain until literally everyone is pushed to their breaking point.&lt;/p&gt;

&lt;h4 id=&quot;the-obvious-oversimplification&quot;&gt;The obvious oversimplification&lt;/h4&gt;

&lt;p&gt;The oversimplified story presented in the town of Involution misses that displaced workers can go on to do other new things that make people’s lives better in unforeseen ways. Throughout much of the globe in the 20th century, there were still massive improvements in quality of life that were possible by getting everyone to work harder, and creating new industries with the displaced workers.&lt;/p&gt;

&lt;p&gt;But at some point, unlimited expansion and material improvement stops being possible. It can happen for various reasons, like reaching the limit of natural resources (in the basence of some technological invention) or satisfying nearly all the material needs our minds can imagine. But whenever that point is reached, society undergoes a kind of cultural &lt;a href=&quot;https://en.wikipedia.org/wiki/Phase_transition&quot;&gt;phase transition&lt;/a&gt;, from growth to involution, where we switch from competition being useful to being counterproductive for our own happiness.&lt;/p&gt;

&lt;p&gt;To me it seems fairly apparent&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; that there was a point at some time in the past 100 years where the global economy transitioned from a point where the material needs of all humans were unsatisfiable to a point where we could satisfy all material needs. And now, we are living with the consequences of failing to recognize this major structural change.&lt;/p&gt;

&lt;h4 id=&quot;this-outcome-is-not-inevitable&quot;&gt;This outcome is not inevitable&lt;/h4&gt;

&lt;p&gt;If this was the end of the story, there’d be no point in discussing it. The reason this concept is really valuable is that organizaing society this way is not inevitable.&lt;/p&gt;

&lt;p&gt;While reading about this, I came across &lt;a href=&quot;https://www.sixthtone.com/news/1006391/how-one-obscure-word-captures-urban-chinas-unhappiness&quot;&gt;an article&lt;/a&gt; where anthropologist Xiang Biao was describing why involution is a cultural &lt;strong&gt;choice&lt;/strong&gt;. In it, Biao points out that the problem is that we are holding up competition for the sake of competition and focusing our competition too narrowly on arbitrarily constrained resources. He describes how modern society has inextricably linked the means of material substistence with the mechanism of social good standing. He contrasts this with more primitive society where prestige was measured separate from wealth.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;People’s lives [were] often made up of two parts: the sphere of prestige and the sphere of subsistence. Subsistence refers to hunting and farming, in which people usually cooperate rather than compete so that everyone can be fed. However, competition still exists in this kind of society […] What are they competing for? Prestige. &lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To me this really sits at the heart of our society’s involution problem. For 90% of people in developed economies, their social standing is directly connected to their ability to succeed in an ever dwindling set of high-paying careers. This is why we have to keep working ever harder, and why we have to keep concentrating wealth more and more tightly.&lt;/p&gt;

&lt;p&gt;I personally think that migrating to a socialist society in both material conditions and mental framework is necessary for overcoming the death spiral of involution. For material conditions this is obvious. We have the ability to cooperatively satisfy all the needs of our society, but we choose not to because we use the hoarding of these tokens as measures of social status, which in turn are concentrated away from those who need them.&lt;/p&gt;

&lt;p&gt;For mental framework, it can be harder to see why socialism is so important. By my reckoning, we need to move away from &lt;em&gt;any&lt;/em&gt; single measure of value (like money) as advocated in our current capitalist mental framework. Right now, it doesn’t matter what role you fill in society as long as that role makes as much money as possible. In other words, vast amounts of social contributions are effectively invalidated, and this is why there becomes such intense competition for a few high paying jobs.&lt;/p&gt;

&lt;p&gt;In the article, Biao suggested that we can redefine our social value system based on a diversity of goals, which would make it easier for people to show their value in a diversity of ways without creating artificial competition. The only trick: we have to do it together as a society or we risk leaving more people trapped even further behind.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;We’ll ignore the additional problem that they also are both producing 50% more shoes than they can sell, and that they could start to drop prices to sell more and undercut their competition. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;but I’d love a citation for this :) &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://www.sixthtone.com/news/1006391/how-one-obscure-word-captures-urban-chinas-unhappiness &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 30 Jun 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/06/involution/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/06/involution/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        <category>economics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/chess1.png</image>
        <title>Class Warfare Chess Prototype</title>
        <description>&lt;h5 id=&quot;this-post-is-out-of-date-there-is-a-newer-better-version-of-class-warfare-chess-described-in-this-post&quot;&gt;This post is out of date. There is a newer, better version of Class Warfare Chess described in &lt;a href=&quot;/2021/10/09/uprising-chess.html&quot;&gt;this post&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;The narrative embedded in the classic chess board is obvious. Two rows of unskilled and expendable pawns face off to protect the interests of the more talented nobility. All sacrificing everything to protect a bumbling ineffectual king.&lt;/p&gt;

&lt;p&gt;Well not anymore. It’s time to flip the tables.&lt;/p&gt;

&lt;p&gt;I wrote new rules for chess that pits the pawns against the nobles. But in this game, the nobles only maintain their special moves if they can keep the pawns in their place. You can play the game online with a friend here. Read on to learn more about the rules.&lt;/p&gt;

&lt;h4 id=&quot;the-rules-of-the-game&quot;&gt;The Rules of the Game&lt;/h4&gt;

&lt;p&gt;Here are the rules we’ve come up with for the first edition.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The game is played on only one half of the board (8x4), with one row of proletariat pieces (pawns) on one side and the opposite color’s bourgeoisie pieces (non-pawns) on the other side.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess1.png&quot; /&gt;
  &lt;figcaption&gt;
    Class Warfare Chess Initial Game Setup
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Proletariat pieces (pawns) move like regular pawns.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For bourgeoisie pieces (non-pawns), we refer to the squares opposite to their type’s starting position as that type’s “factory squares.” As an example, here are the factory squares for the rooks.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess2.png&quot; /&gt;
  &lt;figcaption&gt;
    Factory Squares for Rooks
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;When both of the factory squares for a given type are occupied, then those bourgeoisie pieces move as in normal chess. However, if either factory square is empty, then the corresponding type moves just like a regular pawn. For example, both rooks can move like rooks only if the squares opposite to both rooks (the rooks’ factories) are occupied.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess3.png&quot; /&gt;
  &lt;figcaption&gt;
    Allowed moves for rook when both factory squares occupied
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;However, if either of those two positions are not occupied, then the rook operates like pawn. Here, the far away pawn moved out of the factory so now the rook can only move forward one space.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess4.png&quot; /&gt;
  &lt;figcaption&gt;
    Rook moves as a pawn because bottom left factory square is empty
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;The queen’s factory squares are the ones across from her and the king. The king has no factory and always moves like the king.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess5.png&quot; /&gt;
  &lt;figcaption&gt;
    Two central squares are the factory squares for queen
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;If a proletariat piece is captured in a column with an unoccupied factory square, then the proletariat will not be removed from the board. Instead it will just be returned to the factory square.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess6.gif&quot; /&gt;
  &lt;figcaption&gt;
    Proletariat captured in column without occupied factory is returned to factory rather than removed from play.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;However, if the column’s factory square is already occupied, then the proletariat is removed from play when captured.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess7.gif&quot; /&gt;
  &lt;figcaption&gt;
    Proletariat captured in colun with occupied factory removed from play.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ol&gt;
  &lt;li&gt;Finally, if a proletariat piece reaches the farthest row then it can move side-to-side along the back one square at a time for both capturing or moving. However, it cannot move off the back row.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess8.gif&quot; /&gt;
  &lt;figcaption&gt;
    Proletariat along furthest edge goes side-to-side, moving or attacking.
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Those are all the basic rules of gameplay in this version. If you just want to play the game you can play &lt;a href=&quot;/chess.html&quot;&gt;Class Warfare Chess&lt;/a&gt;. Read on to learn more about the meaning behind the game.&lt;/p&gt;

&lt;h4 id=&quot;the-philosophy-of-class-warfare-chess&quot;&gt;The Philosophy of Class Warfare Chess&lt;/h4&gt;

&lt;p&gt;We developed this game to teach two specific lessons about class consciousness.&lt;/p&gt;

&lt;p&gt;The first lesson is that the special abilities that we seem to ascribe to our rulers are only possible because of the work that we do for them. Successful business persons and politicians are often only successful because they have a team of people who are having their efforts extracted from them for less than they are worth. That’s why in the game, the moment the worker walks away from their “factory squares,” the owners’ special power disintegrates and they become just a regular pawn. In that sense, the major challenge of this game and of our collective struggle is to coordinate our resistance to overcome the owner’s systems of oppression.&lt;/p&gt;

&lt;p&gt;The second lesson that I wanted to show was the focus on artificial political ties in standard chess. In regular chess, pawns fight for the king of the same color, which is the same way our real-life social and political tribalism works. These distinctions mask the great similarity between working people around the world. A working class person in the US is way more similar to a working class person in China than either are to the people who rule over them, but political divisions are drawn so that we don’t see our universal humanity. Similarly the divisions between working class Republican and Democratic also mask our shared struggle to overcome our exploitation.&lt;/p&gt;

&lt;p&gt;This lesson becomes even more clear in the advanced version of the game. In the advanced version, you actually play with the whole board, but the black and white pieces don’t fight anymore: it’s all the pawns vs all the masters.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Class Warfare Chess Board&quot; src=&quot;/assets/images/2021/chess9.jpeg&quot; /&gt;
  &lt;figcaption&gt;
    Full Board
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;I haven’t yet built an online version with that format, but if you have your own chessboard, you can play it using the same rules defined above. The only modification is that any of the bourgeoisie pieces can move to either side while the proletariat can’t pass the central line. The implication in this version is that the proletariat from all corners of the world need to come together to bring down the ruling class.&lt;/p&gt;

&lt;h3 id=&quot;onward-comrades&quot;&gt;Onward Comrades!&lt;/h3&gt;

&lt;p&gt;We just invented this game and, as such, we don’t fully understand all its nuances. We expect over time we’ll modify the rules to optimize play. Make sure to let us know how it goes for you.&lt;/p&gt;
</description>
        <pubDate>Thu, 13 May 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/05/chess-v1/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/05/chess-v1/</guid>
        
        <category>games</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>A mixture of identifields</title>
        <description>&lt;p&gt;
What are two totally different sides of your personality that kind of &lt;a href=&quot;/2020/05/what-is-an-identifield/&quot;&gt;came together&lt;/a&gt; to form who you are today?
&lt;/p&gt;
&lt;p&gt;
I've always had a love of nature that kind of gave me a sense of awe and spirituality even though I've never been comfortable talking about it.  At the same time, I've also always been into science fiction of the space and time travel variety. These stories gave me kind of an intellectual sense of imagination about how limited our current social values might be compared to all the possibilities that could exist throughout all of time and space.
&lt;/p&gt;
&lt;p&gt;
Today, I realize that those two sides of me really fused to give me an intuition that there might be some values that cosmic and timeless rather than just socially constructed in our present moment.  I believe this is the source of my beliefs that things like justice, equality, and fairness could be ideas that are fundamentally embedded in the fabric of reality, just waiting for our silly little human social understanding to really grasp.
&lt;/p&gt;
&lt;p&gt;
As much as I want to move toward equality using the discourse we have on hand, I still feel like our very conceptions of those ideas are still childishly rudimentary.  I wonder how they'll look to some extraterrestrial species that has no sense of time.  Maybe they can help us understand those things that it could take the span of a whole universe to figure out for sure.&lt;/p&gt;</description>
        <pubDate>Fri, 07 May 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/05/identifield-mixture/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/05/identifield-mixture/</guid>
        
        <category>philosophy</category>
        
        <category>identifield</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/traingle.png</image>
        <title>Three parts to changing the world</title>
        <description>&lt;p&gt;The process of changing the world has 3 interrelated parts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Acknowledge where we are&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Define where we want to be&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Take steps to move in the right direction&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In this essay I want to go into why it’s important to remember that all 3 parts have a place and not to let 1 part dominate the others.&lt;/p&gt;

&lt;h4 id=&quot;criticism-acknowledging-where-we-are&quot;&gt;Criticism: acknowledging where we are&lt;/h4&gt;

&lt;p&gt;Some academics and activists will focus themselves particularly on the first point, drawing much needed attention to the dire consequences of the existing racist, exploitative systems that we deal with every day. Without this type of criticism, we could never hope to understand our world well enough to change it for the better.&lt;/p&gt;

&lt;p&gt;But what happens if criticism is all we have. Then when would we ever find ways to actually fix things?&lt;/p&gt;

&lt;h4 id=&quot;dreaming-defining-where-we-want-to-be&quot;&gt;Dreaming: defining where we want to be&lt;/h4&gt;

&lt;p&gt;Beautifully imaginative stories about our possible futures are so important. This can take the form of utopian visions of a collective society (eg solarpunk) or novel democratic or economic models from academics (eg UBI).&lt;/p&gt;

&lt;p&gt;But it can also be a problem to have too much utopian theorizing in the absence of our current lived reality.&lt;/p&gt;

&lt;h4 id=&quot;action-taking-steps-to-move-in-the-right-direction&quot;&gt;Action: taking steps to move in the right direction&lt;/h4&gt;

&lt;p&gt;To change the world, we have to take the tangible steps to ameliorate our current condition and actualize our ambitious goals. This can take the form of small-scale personal habits or directly spearheading major policy changes. Although many actions will fail, collectively following through to make those changes is what results in substantive changes in the way our world functions.&lt;/p&gt;

&lt;p&gt;But this is still just one equally important part of the process. It’s important to not get too fixated on tangible steps because sometimes this process-focus can cause changes that &lt;em&gt;feel&lt;/em&gt; useful to morph into a spinning hamster wheel that can actually be counterproductive and burn us out.&lt;/p&gt;

&lt;h3 id=&quot;goal-find-balance&quot;&gt;Goal: find balance&lt;/h3&gt;

&lt;p&gt;This post is an attempt to warn members of the leftist movement that they can sometimes seem focusing too much on one part of the process at the detriment of others. As one example, I sometimes see leftists get so addicted to hot takes that they forget to mention any solutions to the problems they see. Other times, I might see someone spending a lot of time articulating imagined perfect utopias without acknowledging the gap between those suggestions and .&lt;/p&gt;

&lt;p&gt;This isn’t to suggest that those things should all be avoided, but just to keep in mind not to take any one of them too seriously on its own all the time.&lt;/p&gt;

&lt;h4 id=&quot;practicing-balance&quot;&gt;Practicing Balance&lt;/h4&gt;
&lt;p&gt;Thus far in this essay, I’ve only focused on criticizing the way I see the left acting (how ironic!). To heed my own advice I’m going to make a suggestion for incremental actions that we can all take to keep this balance. And during this next week, I’ll actively put these into practice to try to develop these habits.&lt;/p&gt;

&lt;h6 id=&quot;1-assess-which-parts-you-favor&quot;&gt;1. Assess which parts you favor&lt;/h6&gt;
&lt;p&gt;While we’re thinking about it, lets take a personal inventory.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Do you often find yourself myself on social media writing posts trashing billionaires?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do you spend a lot of time reading econ experiments tested in the lab and extrapolated to hypothetical global economic systems?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Do you spend all of your time signing petitions, canvassing for politicians, or researching which non-profit to donate to&amp;gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many ways to focus on criticism, dreams, or actions. Take stock of where you think you’d fall on this diagram.&lt;/p&gt;

&lt;figure&gt;
  &lt;img alt=&quot;Triangle with the words action, criticism, and dreams in each corner&quot; src=&quot;/assets/images/2021/traingle.png&quot; /&gt;
  &lt;figcaption&gt;
    Three Parts to Changing the World Diagram
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Is this the right balance you intend to have?&lt;/p&gt;

&lt;h6 id=&quot;2-measure-and-shift&quot;&gt;2. Measure and shift&lt;/h6&gt;
&lt;p&gt;Over the next few days, lets take special note of which activities we’re engaging in most. And if you feel yourself drawn to engage in something you automatically favor, try to redirect that time to something you normally avoid. Some examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If you normally spend 1 hour reading Marxist criticism, try spending 30 minutes researching collectivist economic theories like those of Elinor Ostrom as well.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you spend every weekend taking direct action, try spending one evening watching some #leftist TikToks.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the end of the week compare how you spent your time on the diagram above. Were you closer to the balance you think is ideal for you?&lt;/p&gt;

&lt;h6 id=&quot;3-relate-to-friends&quot;&gt;3. Relate to friends&lt;/h6&gt;
&lt;p&gt;Finally, try relating your understanding of your own balance to others in your social circles. Try to take the approach where you are not criticizing them, but just trying to help them achieve their goals. Some examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If you have a friend who is always hard at work campaigning, encourage them to imagine their ideal world and see if they can map out how their actions are taking them in that direction.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you see an influencer repeatedly slamming corporations, send them a message asking what actions are they taking in their daily life to fight corporate power.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Remember to be polite and come from a place of respect and helpfulness. Respect everyone’s hard work and try to bring joy and positive reflection with this effort.&lt;/p&gt;

&lt;p&gt;Feel free to share this article if it inspires you to reassess your balance in advocating for a more equitable world. And never be afraid to learn more and change approach to meet your goals. That’s what leftwardism is all about.&lt;/p&gt;
</description>
        <pubDate>Wed, 05 May 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/05/three-parts/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/05/three-parts/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/20210416_095853.jpg</image>
        <title>More equal rights, more equal power</title>
        <description>&lt;p&gt;On tiktok and twitter, I’m seeing the hashtag #leftist trending for the first time in my life. People are coming out of the woodwork showing off their leftist pride. So what does it mean to be a leftist? Do you want to know if you might be a leftist?&lt;/p&gt;

&lt;p&gt;Sometimes people try to overcomplicate this question, but I’m a simple guy when it comes these ideas. So in this post I want to describe what it means to be a leftist in simple general terms. There are lots of nuanced ways to be a leftist, but they are all united by a single big idea: equality.&lt;/p&gt;

&lt;p&gt;To start, lets break down the first sentence of the wikipedia article on leftism (aka left-wing politics).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Left-wing politics supports social equality and egalitarianism, often in critique of social hierarchy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The first part of this sentence says that leftists support social equality and egalitarianism. These are two words that both mean that all people are fundamentally equal in our social worth. This can take a lot of forms, but normally it means that all people in a society should have equal rights and equal access to the most important things in society, like a right to vote, a right to clean water, a right to fair employment, and the right to be served by businesses regardless of your race, religion, gender identity or anything else.&lt;/p&gt;

&lt;p&gt;The ideas of leftism stand in contrast to more traditional notions of a natural social hierarchy. To be a leftist means you oppose rigid social structures that preclude certain people from having access to certain basic rights.&lt;/p&gt;

&lt;p&gt;When stated this way, most people tend to agree that leftist principles are really good for society. So why isn’t everybody a leftist? There are generally two reasons that some people offer to oppose leftist ideas:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;They believe that a certain amount of hierarchy is good for society.&lt;/li&gt;
  &lt;li&gt;They believe that we have already achieved the proper level of equality.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, I can’t tell you whether you should believe either of those ideas, but I can tell you that for me, believing some people deserve more than others feels fundamentally wrong. This is a personal intution I have that tells me that no one should have to suffer more than anyone else, and no one should have access to a lot more than anybody else. Looking at our society, I feel that we are still far away from a fair amount of equality, particularly when we look at the &lt;strong&gt;distribution of power&lt;/strong&gt; in our society.&lt;/p&gt;

&lt;h4 id=&quot;what-is-equality-without-equal-power&quot;&gt;What is equality without equal power?&lt;/h4&gt;

&lt;p&gt;One of the most complicated challenges of leftism is to try to explain what it means for people to be treated equally. Many people wonder just how “equal” the world would be under leftism. As an individual, you will need to define for yourself just how much equality you want to see in the world. But for me, I think that equality is only meaningful once everyone has equal decision-making power.&lt;/p&gt;

&lt;p&gt;What do I mean by equal decision making power? One might think that living in a democracy automatically satisfies equal decision-making power, but there are a few reasons why that isn’t quite enough. For starters, in a representative democracy like the United States, the way local, state and federal regulations tie together, along with the discrepancy in representation due to the electoral college means that the value of a vote is not equal depending on who you are. Also, many people who live in our country are not allowed to participate in our democracy for many arbitrary reasons.&lt;/p&gt;

&lt;p&gt;But even if those legal details of representative governance were fixed, we know that in practice, the systems in our country are fundamentally opposed to equal power for all those in our society. For starters, we’ve all learned this past year that certain groups in our society, like African-Americans and Hispanic-Americans, still don’t have truly equal worth in the eyes of our criminal justice system. And our healthcare and employement systems still exhibit these unfair distributions of power that disadvantage women and gender non-conforming people too. Part of being a leftist is acknowledging that social hierarchies that allow these injustices are still imposed by our systems in this country, and that it is imperative to combat racism, sexism, and all kinds of discrimination everywhere we see them.&lt;/p&gt;

&lt;p&gt;Finally, our economic system is another a major part of our lives where power is very unequally distributed. This is one of the big problem that leftism seeks to address today: that people with outsized economic assets (aka lots of money) have uneven power in our society. You can see this in a number of ways if you pay attention. As a small scale example, if you live in an apartment, who decides how many windows are in your building or whether your building is properly insulated or the color of the outside? Not you, the person living there, but the person or organization with enough money to buy the apartment building. For another example, even though electric cars have existed since the 19th century, you and I probably couldn’t buy one until recently simply because for a long time very, wealthy investors decided to invest in conventional cars instead of electric. Or for one more example, many people would love to start careers that restore the environment and protect people, but because they don’t have the means to finance their own work, they must work for a wealthy individual or corporation who is looking for employees, often at large companies like Amazon, Uber, or Walmart.&lt;/p&gt;

&lt;p&gt;In other words, some people have very wide choices about what they can do, while others are only allowed to choose from a very narrow list of options. This is a highly corrosive form of inequality, that leftists today are trying to figure out how to dismantle.&lt;/p&gt;

&lt;h4 id=&quot;so-where-to-go-from-here&quot;&gt;So where to go from here?&lt;/h4&gt;

&lt;p&gt;If you think that imbalances in power should be alleviated, you might want to consider yourself a leftist. If so, that’s great! And if you’re not there, that is cool too. Part of leftism is acknowledging your autonomy to make these kinds of decisions for yourself as an informed member of society. Importantly, even if you think full out leftism is too much, just remember that here at The Leftwardist, just by thinking that the world should become even any one little bit more equal, you can always consider yourself a leftwardist.&lt;/p&gt;

&lt;p&gt;:)&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Apr 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/04/equal/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/04/equal/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/20210416_095853.jpg</image>
        <title>An introduction to directional radicalism</title>
        <description>&lt;p&gt;You might be like me. I’m a millennial living in the US, worried about being a good person and surviving. I was raised to think that politics was mostly just a mess that should be ignored, and that being “into politics” meant you were always pushing your own agenda. I thought politics was working right when Obama was in the White House and I could ignore it. I didn’t like the results in 2016, but, at the time, I thought the US was still a fundamentally fair and decent country.&lt;/p&gt;

&lt;p&gt;In 2020 though, I started to realize how fundamental messed up the United States and its history really is. I started studying racial and class politics and history. I knew that I wanted the world to be more equitable, more fair, but I couldn’t understand why that had been so hard to get to. Where were all these greedy people that I’d never met? Then, I started to realize that a lot of lowkey, normal things that were a part of my life were at least partially contributing to how unjust the world was. When I thought about them carefully, a lot of things that I’d believed in my whole life were just fundamentally at odds with the kind of just world I want to live in.&lt;/p&gt;

&lt;p&gt;Eventually, I arrived at &lt;em&gt;the left&lt;/em&gt;. Not the nice cozy centrist-liberalism that I’d grown into in my 20s, but like the “get rid of capitalism” lefty left. Some of the leftist ideas make a lot of sense to me, and some of them will still take time for me to understand. But as I’ve explored, I’ve already seen a big problem with the way people on the left deal with people who are just in the “little bit leftward of center” region of the political spectrum.&lt;/p&gt;

&lt;p&gt;And I’m starting to suspect that this problem is at least part of the reason that the world seems to keep getting &lt;em&gt;less&lt;/em&gt; equitable over time.&lt;/p&gt;

&lt;p&gt;I’ll set the scene. It’s Friday night, I have some free time, and I want to learn more and get better acquianted with a new idea. I browse a leftist subreddit or drop into a Twitter thread. I read an article that makes me think. Then, when I’m done with the article, I scroll down and read the comments. Twitter, reddit, personal blogs, the comments all look about the same.&lt;/p&gt;

&lt;p&gt;“Yes, I agree with you, BUT have you instead considered my particular form of idiosyncratic means to reach a similar but perhaps slightly different end.”&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;“That isn’t real progressivism though.”&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;“Lets just eat the rich instead.”&lt;/p&gt;

&lt;p&gt;And then there’s the comments on those comments, deriding someone for misreading something. Everyone telling everyone else that they are arguing in bad faith. The ones between Democrats and Republicans are understandable since there’s longstanding partisanship there. But the strange part is when I see a Green Party person arguing with a Bernie bro.&lt;/p&gt;

&lt;p&gt;Now debate is no problem. After all, liberals and leftists in general likes complex ideas and have some attitude, so we’re always going to want to debate things. But why the rancor between people who basically agree in the grand scheme of things?&lt;/p&gt;

&lt;p&gt;I think the discourse is emotionally pitting people against each other who are really pretty much aligned. I think part of this is that we’ve all been trained by algorithms to beef with each other because that garners attention, but that is a subject for another article. Whatever the cause, nowadays every momentary interaction leaves you with your defenses up at all times. And this diminishes the solidarity and connectedness of humans that is the whole point of being a leftist in the first place.&lt;/p&gt;

&lt;p&gt;And there’s a reason this is a big problem. A lot of people (like me) don’t think we know exactly which heterodox economic policy is going to &lt;em&gt;solve everything&lt;/em&gt;. We just know that what we have now is bad and that we should add more things that just &lt;strong&gt;give more to people who have less&lt;/strong&gt;. So a silent population that could be more active stays in the dark because we are uncomfortable trying to advocate for things when we are constantly being berated from both sides on everything.&lt;/p&gt;

&lt;p&gt;Now, I’m not proposing to diminish all the nuances in any way. At some point, we may need to make some distinctions between different brands of leftist and liberal politics. But for a lot of the really radical ideas, we are a long way from reaching them. And people need changes in the right direction today. So I’m trying to advocate for directional radicalism. It’s a common sense stance that doesn’t try to look ahead to distant ideals about the way society should function. Instead, it just suggests that you move, even in small ways, in the same direction as others who are looking for a radical transformation toward equality.&lt;/p&gt;

&lt;p&gt;To help with this, I’m trying to create a broadly defined political label: leftwardist. A leftwardist is a person who works in solidarity with other people to move the world greater equality compared with where it is today. I’m going to be exploring what it means to be a leftwardist in this newsletter, but it starts with a recognition that being a leftwardist doesn’t have to conflict with more particular beliefs as long as you agree that the world has too much inequity today. This means you can call your self a leftwardist without diminishing your allegiance to any of the myriad other socio-economic-political ideologies out there. The label just suggests that you are open to accepting the commonalities that run all the way from full blown communism to just left of center liberalism.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The fundamental question is this. Do you think that the world should be any little tiny bit more equitable in any way than it is now?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Should one more poor person be able to afford healthcare? Should Jeff Bezos have to give one more dollar in taxes to help pay for the public roads that his company benefits from? Should one more person get the right to vote in the democracy that governs them?&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If so, you might be a leftwardist.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Apr 2021 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2021/04/intro/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/04/intro/</guid>
        
        <category>philosophy</category>
        
        <category>politics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/postpec_def.gif</image>
        <title>On the emergence of post-speculative fiction</title>
        <description>&lt;p&gt;I just ran a work of &lt;a href=&quot;/attention&quot;&gt;speculative fiction&lt;/a&gt; through a piece of &lt;a href=&quot;https://github.com/lots-of-things/Story2Hallucination/&quot;&gt;artificial intelligence software&lt;/a&gt; that once would have been called speculative. I'm realizing that we very well might be reaching a new era of science fiction and art.&lt;/p&gt;

&lt;p&gt;I'm wondering if we should call this era &lt;em&gt;post-speculative&lt;/em&gt;.&lt;/p&gt;

&lt;h4&gt;To Be Post-speculative&lt;/h4&gt;

&lt;p&gt;Speculative fiction generally works within a world where some things (eg technologies, magic, historical governments) can work in ways where the reader has no way of foreseeing the ultimate impact of these things. This is in contrast to forms of fiction that are strictly reality-based, meaning characters make choices inside the world where all the rules are already completely familiar to the reader.  &lt;/p&gt;

&lt;p&gt;For a work to become post-speculative the world in the story would need to be approximately as unpredictable or speculative as the tools used to create it. &lt;/p&gt;

&lt;img title=&quot;create a work of fiction where the world in the story is approximately as unpredictable or speculative as the tools used to create it. Post-speculative fiction is the realization of the 'medium is the message' in the case where message and medium are still not yet fully understood.&quot; alt=&quot;AI rendering of: create a work of fiction where the world in the story is approximately as unpredictable or speculative as the tools used to create it. Post-speculative fiction is the realization of the medium is the message in the case where message and medium are still not yet fully understood.&quot; src=&quot;/assets/images/2021/postpec_def.gif&quot;/&gt;

&lt;p&gt;I think that this genre would be characterized by three things that we see coming together now.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the narrative takes seriously the implications for humanity&lt;/li&gt;
&lt;li&gt;the medium involves significant interaction with technology that itself would fit into a speculative world&lt;/li&gt;
&lt;li&gt;the theme of the story rejects a default optimististic view of the future&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
In the next sections, I'll explain where these features fit in.
&lt;/p&gt;


&lt;h4&gt;Explanation by example&lt;/h4&gt;&gt;

&lt;p&gt;To compare and contrast what would or wouldn't be post-speculative, we might analyze  Black Mirror episode Bandersnatch. I think that Bandersnatch was a really entertaining piece of speculative fiction, and I definitely rewatched many times to follow all the paths. And part of the reason that I rewatched was because I was hoping for something that (although I hadn't named it at the time) would have been post-speculative. &lt;/p&gt;

&lt;p&gt;I had really wanted Bandersnatch to reach a point in the loop where it starts to blur the lines between the choose-your-own-adventureness and the free will of the audience member.  To reach the level of post-speculativeness, the movie would have needed to utilize some technology that made the viewer question whether what they were saying was really taking place in a different world from their own.  &lt;/p&gt;

&lt;p&gt;For example, if Netflix offered the option to play with the viewer's own image integrated into Bandersnatch to personalize it, and in the story, the game designer would have passed that image down into his game with the purpose of tracking and storing more data about the user, we would have crossed into the post-speculative realm.  Such a plot device would place the audience directly into the position of honestly considering themselves just the characters in a story for an audience in a world external to their own. Although the narrative suggests something like this (while also suggesting it is madness to consider it), nothing about the medium itself conveyed that.&lt;/p&gt;

&lt;p&gt;Another way to make it post-speculative, would have been to ackowledge that the viewer is in another kind of game.  In this case, the game would be Netflix using the choices that you made in Bandersnatch to figure out what you the user would choose next. Again, the technology that we are building will be used for this kind of prediction in the near future. Post-speculative is when we acknowledge that it is happening, and construct the medium to emphasize that it's happening even though we don't really understand how it works yet.&lt;/p&gt;


&lt;h4&gt;Deconstructing speculation&lt;/h4&gt;

&lt;p&gt;Another way to describe this, would be as deconstructing a culture of speculation using themes and technology that look speculative themselves.  This is not unlike postmodernism, where the tools of a society built by modernist thought were re-reflected back onto that world to critique it. This led to skepticism with the assumptions of everything that modernism felt so vindicated in creating.  There are more parallels with between scpeculative fiction and modernism too. I particularly like this passage I copy-pasted from &lt;a href=&quot;https://en.wikipedia.org/wiki/Postmodernity&quot;&gt;wikipedia&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
[Postmodernism was] a rejection of the modernist &quot;Utopian gesture&quot; of the transformation through art of misery into beauty whereas in the postmodernism movement the object world has ... &quot;now become a set of texts or simulacra&quot;. Whereas modernist art sought to redeem and sacralize the world, to give life to world, postmodernist art bestows upon the world a &quot;deathly quality… whose glacéd X-ray elegance mortifies the reified eye of the viewer&quot;
&lt;/blockquote&gt;

&lt;p&gt;I think the urge to create speculative fiction, particularly during and after the &quot;Golden Age&quot; of scifi, was a very utopian vision, similar to the grand ideals of modernism. The speculative writer aimed to point our minds at a distant horizon, and help us to tease apart just what we want our future world to look like.  I even might think that the fundamental morality of scifi and fantasy was an organic counterinsurgency against the cynical navel gazing of postmodern entertainment.  Even in the later cyberpunk/post-apocalypse/&quot;they're all Cylons&quot; era, the narratives still normally had a fairly idealistic moral core.  The evil tech conglomerate and/or the zombies were bad, and the people using super badass technology to win were good. The modernist glorified the rise of industrial technology powered by modernizing, we glorified the rise of information technology powered by speculation.&lt;/p&gt;

&lt;p&gt;Similar to the postmodernist rebuttal of modernism, the post-speculativist accepts a narrower view of the speculative future: that someday when we live in an era with new technology, our condition will still be fundamentally the same.&lt;/p&gt;

&lt;p&gt;But now, maybe the era of speculation is coming to a close, and just like the postmodernist, we're getting to the point where we have to fully acknowledge the aftermath of the idealism we neglected to inspect before we let it happen. And if we define a movement of deconstructing our fetishization of speculation, maybe we'll be able to dismantle it before it's too late. &lt;/p&gt;


&lt;h4&gt;Are you sure we should do that this way?&lt;/h4&gt;

&lt;p&gt;This does raise the question whether we need to make art that works like a proof of concept for the dystopian at all? It might be possible to critique without actually manifesting the art, but thus far, speculative fiction itself hasn't curbed our &quot;progress&quot; yet. Even the darkest of the speculative works still kept us thinking about those as issues to be dealt with by anti-heroes of the future. And based on my experience in this industry, I would say that if concerned people don't implement it out in the open, it'll just take a little more time before the opportunistic implement it behind-the-scenes. &lt;/p&gt;

&lt;p&gt;That said, there may be a bigger problem, and one that may disqualify me from speaking on this matter.  In a very real way, I'm one of many who are fully enthralled with speculative narratives of mind-machine interfaces, planet wide algorithms, and artificial metaconsciousnesses. Honestly, to see them come to life would be thrilling.  Even if I expect the ending.&lt;/p&gt;</description>
        <pubDate>Tue, 26 Jan 2021 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2021/01/post-speculative-fiction/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/01/post-speculative-fiction/</guid>
        
        <category>philosophy</category>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/columbia_gorge.jpg</image>
        <title>One month into the Co-op Trail</title>
        <description>&lt;p&gt;
I've been away from my computer for the most part this past month because I've been doing the hardest thing I've ever done before. In mid-june my partner and I quit our jobs and started touring on the tandem ebike we built last winter.  Our route has thus far been darting around the Pacific Northwest as we aim to connect the dots between beautiful scenic attractions, cooperative businesses, and regenerative farms.
&lt;/p&gt;
&lt;p&gt;
For anyone who has tried it, you already know cycle touring isn't easy, but it feels especially intense coming away from a year of near-isolation and minimal .
&lt;/p&gt;
&lt;p&gt;
It has been difficult, but it has also been tremendously interesting, moreso than almost any other project I've ever undertaken.  You can check out our website &lt;a href=&quot;https://cooptrail.org&quot;&gt;cooptrail.org&lt;/a&gt; for the cycle touring map if you want to see how the tour is going, but for this post, I wanted to point out all the interesting details of we are learning to survive this crazy journey.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2021/stealth.jpg&quot; alt=&quot;a camp in the woods&quot;/&gt;
&lt;h3&gt;camping, often stealthily&lt;/h3&gt;
&lt;p&gt;
    One of the most insanely frustrating parts of this trip is learning how impossible society has made it just to exist on the surface of this planet.  When bicycling, you learn about fundamental limits of distance that can be traversed in a day, and you learn about how expensive it is to stop part-way through a journey to rest for a night.
&lt;/p&gt;

&lt;p&gt;
    The cruelest irony is that you spend the far greatest amount of time cycling through rural areas where there is almost nothing but free, unoccupied, vacant, priceless space.  And yet, in this country, the vast majority of that unused space is technically &lt;strong&gt;owned&lt;/strong&gt; by someone, and those owners despise the idea of someone momentarily alighting their heads on the ground in a tent for a few hours.
&lt;/p&gt;

&lt;p&gt;
    In the evening hours, after another day being forced off the road by white dudes in trucks flying flags (see below), you have the added insult that you can't legally exist for the few hours that you aren't on the road.  In a car, you always have the option of pulling over and hopping into the back seat for a cramped nap, but on the bicycle, pulling out the tent makes you a blatant target.
&lt;/p&gt;

&lt;p&gt;
    I adore the website &lt;a href=&quot;https://www.warmshowers.org&quot;&gt;Warmshowers&lt;/a&gt;, which offers a way to connect with fellow cycling enthusiasts to find places to stay, but I also find it sad that we need that site. It would be a far better world if you could simply pitch a tent for 10 hours on any property in the world to get some rest, provided you leave it just exactly as you found it.  Because in reality, only that &lt;em&gt;should&lt;/em&gt; be the crime: disturbing land that belongs to someone else, not simply existing on it.
&lt;/p&gt;
&lt;h3&gt;Talking to strangers&lt;/h3&gt;
&lt;p&gt;
    On a more positive note, when you talk to people outside of their cars, they are pretty decent.  You really realize on a trip like this, that there are like an infinite number of people in the world.  It would take a long time to talk to all of them, but you'd probably learn something.
&lt;/p&gt;
&lt;h3&gt;Outside of the bubble&lt;/h3&gt;
&lt;p&gt;
    People are also really way more diverse in what they've been paying attention to over the past year. I started this trip thinking a lot more people had their eyes opened to how the world needs to change, but I've somewhat sadly realized a bunch of people either don't care or somehow believe in conspiracy theories that are huge distractions from real solutions.
&lt;/p&gt;
&lt;p&gt;
This relates strongly to the next point that my partner has realized.
&lt;/p&gt;
&lt;h3&gt;Community is an ideal&lt;/h3&gt;
&lt;p&gt;
    We wanted to go on this trip to see where we fit into a community of like-minded people. But one thing we're noticing is that a lot of people who espouse communitarian beliefs are really adamant about doing things in a narrowly defined window around their own beliefs. This is sad to me, because I am really hoping that reengaging the civic/social muscles will start to reconnect people with each other and the planet. But I have to admit these are also my own ideals, and I need to remain flexible with them to embrace the full gamut of cooperation instead of enforcing my views in the traditional competitive landscape. It's a total change and one that I'm always worried is bound to fail in a society of unbridled competition.
&lt;p&gt;
&lt;img src=&quot;/assets/images/2021/willantics.jpg&quot; alt=&quot;will standing tanedm bike on end&quot;/&gt;
&lt;h3&gt;Don't have a well-defined plan, but keep your butt moving&lt;/h3&gt;
&lt;p&gt;
    This is the first time since I was 12 years old that I've had more than 2 weeks away from an externally imposed structure like school or work. I've been working or in a school program, and never had any time to truly define what I wanted to do. So for two weeks it was possible to keep up a &quot;plan&quot; that tried to keep us moving along a specific trajectory over a specific timeframe. But after that 2 week period lapsed, it's become increasingly necessary to keep our plans at 3-4 days maximum.  Honestly, at this point it's often day to day how we decide where to go. This has been a suddenly amazing experience. We now get to talk to people without a firm plan and see what they think we should do, we'll meet people half way because we finally have the space to think.
&lt;/p&gt;
&lt;p&gt;
    Buuuuut, we also don't have too much space because we know we still have a few things we have to do. We scheduled a few hikes and we set up some farm workstays that are just far enough apart to keep us moving each day. Because if we don't get a little distance, we know we'll just stop and never make it all the way.  So this is a great balance of having a direction and a few dates we have to hit, with tons of space to figure it out along the way.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2021/dirtyclaire.jpg&quot; alt=&quot;claire looking a little scruffy&quot;/&gt;
&lt;h3&gt;It's ok to be dirty&lt;/h3&gt;
&lt;p&gt;
    I'm careful to say only that it's OK to be dirty here. It isn't great, but it isn't awful. I've been dirty a lot in my life. My first job was walking through dirty wet corn fields in the heat of the Midwest summer, so I'm comfortable with dirty for myself, what I mean is that it's ok to be dirty around other people.
&lt;/p&gt;
&lt;p&gt;
    During this trip we are frequently biking in the heat for multiple days, then backpacking, and then biking back into a town for food. We would be a different level of gross except that we always assiduously rinse our bodies in beautiful chilly rivers and streams along the way. This normally takes off the layers of sweat, bike grease, and mud.
&lt;/p&gt;
&lt;p&gt;
    Having the natural and healthy layers of grime will definitely cause some people to assume you're a *problem*, but most of the people who seem like they are worth talking to don't seem to care. Maybe it helps that were in the earthy-crunchy pacific northwest right now, but being a wild dirty person in the right way actually seems a little enticing here. So overall, I'd say being dirty is something I worry about less than I thought I would. (except when we're working on the farms, but then we get ourselves cleaned up!)
&lt;/p&gt;

&lt;h3&gt;Cars are the personification of evil&lt;/h3&gt;
&lt;p&gt;
    I've disliked cars since I began commuting by bicycle, but the anger and indignation I've felt has always been of a practical, dare I say pedestrian, variety due to cars being more-or-less a few feet away from killing me every day.  During this trip, my personal vitriol has finally given way to a new understanding of the profound evil that the car embodies.
&lt;/p&gt;
&lt;p&gt;
    The evils of the car follows from two principle things: first, the seemingly benign ubiquity of the damn machines, and second the false psychological connectedness between the machine and the owner.
&lt;/p&gt;

&lt;p&gt;
    From the ubiquity of the car, we get two major problems, the normalization of every incompetent imbecile grinding along in a death machine that commands more power than 500 humans can produce, and the godawful waste of space and resources.  I firmly believe that regular people shouldn't just be assumed to deserve the ability to move multiple tons of machinery faster than any land animal has ever moved. It's not just that it's unnatural, it's that they have shown they shouldn't be trusted with that.  They just start moving things around for no reason, going to places they didn't even want to go. People should have to think for a minute before they decide they can drive an entire home over a mountain! They should have to put forth a little more effort than swiping a credit card at a gas station and flexing their Achilles tendon by 3/4ths of an inch!
&lt;/p&gt;
&lt;p&gt;
    Which leads to the second point, giving people that power has caused us to restructure our entire society around its worship. Have you ever thought about how much of your life is devoted to the space that cars take up?  Compared to the pedestrian and the bicycle, the car takes up 10 to 40 times as much space, and it sits unoccupied on the street most of the day (and that's assuming you didn't build a goddam house for the thing.)  Riding the bicycle, you realize that every city could shrink itself by 20-30% or fill itself with 20-30% more greenspace if cars just weren't allowed.  And on the long highway, we'd need a fraction of the asphalt and econsystem damage if we at least drove single file (much love to motorcycles).
&lt;/p&gt;
&lt;p&gt;
    But the real evil is the psychological connection that human has to car.  This I cannot understand, someone pays money for a truck, and somehow they internalize the feeling of raw energy coarsing through their veins.  You didn't build the thing! You aren't strong!  You are just another underacheiving jackass who feels good when your butt vibrates that certain way as carbon dioxide spits out from under you.
&lt;/p&gt;
&lt;p&gt;
    This is the issue: everyone feels invicible power in their car, and I think that's part of the reason we see such toxicity in every aspect of our lives. The problem with humanity today is that they think they are cars.  And cars are evil.
&lt;/p&gt;


&lt;h3&gt;Conclusion: Keep On Going&lt;/h3&gt;
&lt;p&gt;Between the downsides and the upsides we've learned about, we still think that this is an interesting and worthwhile experiment.  We're going to keep it up at least through the end of the year, continuing our story onward through California and into Arizona.  From there, we don't know where the road will lead, but stay tuned to find out.&lt;/p&gt;</description>
        <pubDate>Fri, 22 Jan 2021 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2021/01/coop-trail-update/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/01/coop-trail-update/</guid>
        
        <category>philosophy</category>
        
        <category>bikes</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/ebike_trailer_demo1.jpg</image>
        <title>Solar Wagon: tandem ebike and solar charging trailer</title>
        <description>&lt;p&gt;My partner and I have dreamt of #VanLife for years, but I always worried about the awful carbon footprint of living on the move. A dream incubated in my head for a long while to make that lifestyle work in a downsized, ecologically conscious way.  This past winter, I finally put together the pieces on this most ambitious project of my life thus far: a tandem electric bike with a solar charging trailer filled with all the essentials for life on the road.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2021/ebike_trailer_demo1.jpg&quot; alt=&quot;claire and me riding the solar wagon&quot;/&gt;

&lt;p&gt;The goal of the solar charging trailer was to be able to carry all of the amenities that would make a bikepacking life viable long term. In this post, I'm going to cover some details of building our tandem ebike and solar charging trailer as well as &lt;a href=&quot;https://cooptrail.org/&quot;&gt;our co-op economy documentary trip&lt;/a&gt; we are planning for this summer. &lt;/p&gt;

&lt;h4&gt;Electric tandem bike&lt;/h4&gt;
&lt;p&gt;Building an electric bike is easy in this day-and-age, and adapting this process to a tandem bike didn't really add much complication. &gt;We purchased a used 1980s era steel framed Kuwahara tandem bike off of craigslist for $250 and did an electric conversion ourselves. &lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/ebike_me.jpg&quot; alt=&quot;me holding my tandem ebike&quot;/&gt;

&lt;p&gt;On ebay there are standard ebike conversion kits, which are pretty straightforward to install.  The components cost around $300, and included electric motor mounted in rear wheel, motor controller and display, pedal sensor for the pedal assist, and handlebar brakes to engage the regenerative braking.  In addition we bought two 48V 17.5 Ah ebike batteries for $450 a piece.&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_wheel.jpg&quot; alt=&quot;ebike motor and wheel&quot; width=&quot;40%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_controller.jpg&quot; alt=&quot;ebike motor controller&quot; width=&quot;40%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt; We needed to replace tires and tubes, and add lights and an extra speedometer. We also added panniers to carry additional load, and in the back we built our own rudimentary solar water heating system.&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_heat1.jpg&quot; alt=&quot;ebike motor and wheel&quot; width=&quot;40%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_heat2.jpg&quot; alt=&quot;ebike motor controller&quot; width=&quot;23%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt;The great part about running the ebike controls on a tandem is that you can divide up the labor to have one person steer while the other manages the controls and navigates.  It takes a little more communication, but it makes it possible to make adjustments and search for things without stopping.&lt;/p&gt;

&lt;p&gt;We already had a decent amount of biking equipment to outfit the bike so we were repurposing some things. But including everything that went into it, we estimate the etandem setup cost us $1600.&lt;/p&gt;

&lt;h4&gt;Solar charging trailer&lt;/h4&gt;
&lt;p&gt;The real work came in our solar trailer.  We wanted to be able to carry all the equipment we need for backpacking in various conditions, for surviving as we passed through cities, and for some digital remote work. Plus, we needed to carry ~2 weeks worth of food for travel by bike and for backpacking as well.  The other constraint was being able to recharge one 48V 17.5 Ah battery in approximately 6 hours of sunshine, which equates to 840 Watt-hours.&lt;/p&gt;

&lt;p&gt;We built the trailer in two stages by first building a standalone solar mount on the front buggy, and then (after some trial and error) building the second buggy and attaching it. &lt;/p&gt;

&lt;h4&gt;Panel sizing and design&lt;/h4&gt;
&lt;p&gt;I already had two solar panels which I had purchased with the intention of solar powering my boat. They aren't the most efficient or lightweight solar cells out there, but I can always upgrade as they get older. They are 40x26 inches and 85 Watts.  So at 175 Watts together, they &lt;em&gt;should&lt;/em&gt; charge the battery at 840/175 = 4.8 hours. Of course, given all the losses in this system I suspect it'll take longer, but that still leaves us with a decent buffer.&lt;/p&gt;

&lt;p&gt;With all the gear and needing two panels end to end, we knew we were looking for a pretty long trailer, larger than the average off-the-shelf trailers for bikes.  Claire and I had lots of ideas for how to build the cart itself, but as usual, I didn't want to build from brand new parts so I let the luck of craigslist decide how we would do it.  We found two used bicycle baby buggies and decided they could easily be converted by fastening them together.&lt;/p&gt;

&lt;h5&gt;Solar mount design&lt;/h5&gt;
&lt;p&gt;One cool invention was the central mounted solar panel design that allows us to rotate the panel in the direction of the sunlight. I used aluminum L brackets. Here are all the parts required for one trailer. Sizing will vary for you depending on how large the trailer and panels are, and how high you want to build.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2021/ebike_trailer_parts.jpg&quot; alt=&quot;ebike trailer parts&quot; /&gt;

&lt;p&gt;To start, I made two triangle framed braces, one at the front of the buggy and one at the center, with the bottom of the triangle being the cart frame itself.  I ran an aluminum rod through the tops of each brace, connecting them.&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_cons1.jpg&quot; alt=&quot;triangle frame&quot; width=&quot;40%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_cons2.jpg&quot; alt=&quot;pole down the center of trailer cart&quot; width=&quot;40%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt;To attach the solar panel to this rod, I attached two more pieces of L-bracket to the underside frame of the solar panel, one across the front and one across the rear, and drilled a hole in the center of each. Then the pole was threaded through. The rod was secured to the panel and triangle braces with cotter pins through the rod, and a few pieces of front to back facing bracing were used to stabilize the whole thing.&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_cons9.jpg&quot; alt=&quot;&quot; width=&quot;30%&quot;/&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_cons3.jpg&quot; alt=&quot;&quot; width=&quot;30%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_cons4.jpg&quot; alt=&quot;ebike construction&quot; width=&quot;30%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt;The panel is &lt;em&gt;mostly&lt;/em&gt; supported by the central pole, but it's kept at the proper angle using another bracket.&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/ebike_trailer_cons5.jpg&quot; alt=&quot;ebike trailer solar angle connection&quot; /&gt;


&lt;p&gt;Overall, this design has two advantages over a &quot;four corners&quot; design that I've seen in other setups like &lt;a href=&quot;https://sunbiker.com/&quot;&gt;sunbiker.com&lt;/a&gt;. It allows easy rotation to face the sun angle, and it cuts down on parts required to nearly the bare minimum. &lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/ebike_trailer_panel_rotate.gif&quot; alt=&quot;ebike trailer solar angle connection&quot; /&gt;

&lt;p&gt;This design gives it a little bit of extra flex, but that is probably a good thing to dampen some of the vibration. I'm really pleased with the results.&lt;/p&gt;

&lt;h5&gt;Trailer connection&lt;/h5&gt;
&lt;p&gt;This part was surprisingly difficult, and we actually experimented with two failed designs before arriving at our solution.  &lt;/p&gt;

&lt;p&gt;One failure was trying to daisy chain the carts using the's standard pivoting bike attachment as a connection.  This wound up creating a double jacknife effect that made it totally impossible to move the cart backwards.&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/ebike_trailer_bad.jpg&quot; alt=&quot;solar panel trailer connected using pivoting attachment arms&quot;/&gt;


&lt;p&gt;The second failure was more subtle. We attached the carts together firmly, but kept them in their standard orientation with their wheels far apart.  This made it so that on sharp turns, the wheels of the lighter half of the cart had to slide sideways across the ground as it pivoted. So finally, we reversed the back cart so that the wheels were closer together.  After figuring this out, we actually realized that pretty much all 2 axel trailers work this way with &lt;a href=&quot;https://en.wikipedia.org/wiki/Trailer_%28vehicle%29#/media/File:BumperPull.jpg&quot;&gt;their wheels close together&lt;/a&gt;.  Never noticed that before in my whole life!&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_cons7.jpg&quot; alt=&quot;trailers connected together&quot; width=&quot;30%&quot;/&gt;

&lt;/div&gt;

&lt;p&gt;The attachments were just more L-brackets.  The last remaining issue was that the wheels themselves were quite different sizes and this made it hard to line up the frame such that both wheels were on the ground.  We did the best we could, but currently the trailer needs to be loaded with most of the weight in the front in order to keep the front wheel firmly on the ground.&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/ebike_trailer_cons6.jpg&quot; alt=&quot;ebike trailer solar panels&quot; /&gt;

&lt;h5&gt;Battery charging station&lt;/h5&gt;
&lt;p&gt;This setup was very easy to build, and has been &lt;a href=&quot;https://www.youtube.com/watch?v=0Rb77J1bI94&quot;&gt;documented&lt;/a&gt; many places.  I just attached the panels to a &lt;a href=&quot;https://genasun.eu/collections/genasun-boost-mppts&quot;&gt;Genasun charge controller&lt;/a&gt; for a 48V battery. This setup is ideal because it takes essentially any input voltage and current and boosts it to the 54.2 V needed for charging with minimal loss of current. I connected my two 16V panels in series to give me around 32V since a smaller delta is more efficient and panels work better in series if there is a possibility of partial shade (which will be common on the go).&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_charging1.jpg&quot; alt=&quot;Genasun charge controller mounted in trailer&quot; width=&quot;40%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2021/ebike_trailer_charging2.jpg&quot; alt=&quot;embedded switch&quot; width=&quot;40%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt;Aside from that, I just added a switch and took apart an XLR cord for the three prong attachment to the battery itself. Finally, I mounted the battery to the frame to stabilize it for charging while on the road.&lt;/p&gt;

&lt;h5&gt;Experiment: Lights&lt;/h5&gt;
&lt;p&gt;As an experiment I also connected some LED headlights, taillights, and a strand along the bike frame, using the ebike battery as a power source.  It looked pretty darn cool, but ultimately the setup was too cumbersome and we decided it was easier to just attach regular rechargable bike lights.&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/ebike_trailer_night.jpg&quot; alt=&quot;ebike trailer lit up with blue/green lights and tail light&quot;/&gt;


&lt;h5&gt;Completed design&lt;/h5&gt;
&lt;p&gt;When it's all put together, the tandem bike and trailer is quite a long and brightly colored vehicle. Hard to miss when driving past.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2021/ebike_trailer_claire.jpg&quot; alt=&quot;Claire holding ebike and solar trailer&quot;/&gt;

&lt;p&gt;We typically can travel between 8 and 20 mph, making sure to engage the regenerative braking on steep declines to keep us from getting out of control. &lt;/p&gt;


&lt;p&gt;The trailer and solar panels, plus all the hardware together came to $600.  So for bike and trailer together we are looking at $2200. Note that this is like 1/20th the price of an electric car &lt;strong&gt;and&lt;/strong&gt; we shouldn't ever have to pay for electricity like we would with a car. Granted cars can go faster, carry more, and keep you dry, but if the real goal is just mobility and the lower speed is acceptable, clearly this cart is a win!&lt;/p&gt;


&lt;h4&gt;Grand Inaugural Test Ride&lt;/h4&gt;
&lt;p&gt;We took the completed unit for our first test drive and documented it with some footage (including some ✨drone shots✨).&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;450&quot; src=&quot;https://www.youtube.com/embed/pF4-h4UQpLM&quot; title=&quot;YouTube video player&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;We traveled 35 miles over 2 days. Keep in mind that we were carrying at least 150 extra pounds of trailer, solar panels, and gear and traveling up and down some substantial hills along the northern California coast.&lt;/p&gt;

&lt;p&gt;Our battery drained about halfway over that length, and it recharged to full in under 3 hours of afternoon sunlight when we got home.  So our proof of concept seems to be working.&lt;/p&gt;


&lt;h4&gt;Trip of a lifetime; transition to a better life?&lt;/h4&gt;
&lt;p&gt;There are a lot of stories that start with a voyage.  My partner and I are hoping that this trip we are taking is the start of a story for us. During the 2020 lockdowns, like a lot of people, we've had a lot of time to think and focus on how the world works as it changed around us. This has &lt;a href=&quot;https://monthlyreview.org/2020/06/01/covid-19-and-catastrophe-capitalism/&quot;&gt;revealed&lt;/a&gt; some deep problems with the &lt;a href=&quot;https://www.weforum.org/agenda/2020/07/affluence-bigger-threat-than-coronavirus-scientists-capitalism/&quot;&gt;way our society functions&lt;/a&gt;, and that &lt;a href=&quot;https://www.cnn.com/2020/09/20/economy/how-covid-changed-capitalism/index.html&quot;&gt;changes are needed&lt;/a&gt;. With this trip, we're hoping we can take a step away from the extractive careers we've lived in up to now. We want to move toward a better more sustainable lifestyle. As we go, we'll be trying to build out something we are calling the &lt;a href=&quot;https://cooptrail.org/&quot;&gt;Co-op Trail&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The goal of the trip is to tap into the &lt;a href=&quot;https://en.wikipedia.org/wiki/Solidarity_economy#Challenges_of_Solidarity_Economy&quot;&gt;solidarity economy&lt;/a&gt; and try to make it around the country relying as much as possible on human-centric businesses. We're calling this the Co-op Trail and focusing on co-ops, as that is my personal favorite remedy to capitalism, but we'll also be supporting others in the solidarity economy as well. The goal is to make it easier to navigate from place to place via co-ops and other democratic and mutualistic companies, without relying on exploitative businesses along the way.&lt;/p&gt;

&lt;p&gt;The reason we're trying this is because we think it's important to try to bridge all the highly local mutualist networks together so that people can roam the country just as freely as they do in the exploitation economy. In fact, if this trail catches on, I hope that everyone can roam even &lt;em&gt;more&lt;/em&gt; freely as networks of trust expand and resources become less strictly commodified.  I've written a &lt;a href=&quot;/2020/12/coop-trail/&quot;&gt;longer post&lt;/a&gt; about the idea if you want to learn more.&lt;/p&gt;

&lt;p&gt;We're hoping to live this mini-retirement for at least a year and emerge on the other side with a renewed commitment to work in the world in a more sustainable way. I think this style of slow, low-energy travel will catch on as more people can live remotely full-time, and I hope our project to work through and connect the co-op economy will inspire others to reduce their extractive mindset as they go. &lt;/p&gt;
</description>
        <pubDate>Fri, 22 Jan 2021 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2021/01/ebike-solar-trailer/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/01/ebike-solar-trailer/</guid>
        
        <category>electronics</category>
        
        <category>energy</category>
        
        <category>bikes</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/octo.gif</image>
        <title>Story2Hallucination: converting stories to deep learning GAN hallucinated animations</title>
        <description>&lt;p&gt;Late last year, I tried working on a method to use the text from my dynamically updating short story website, &lt;a href=&quot;/attention&quot;&gt;a.ttent.io/n&lt;/a&gt;, to generate hallucinatory animations. Back then, I was working off of earlier &lt;a href=&quot;http://proceedings.mlr.press/v48/reed16.pdf&quot;&gt;methods&lt;/a&gt; to do this sort of thing and wasn't having great results. But earlier this month OpenAI released a newer method called &lt;a href=&quot;https://openai.com/blog/clip/&quot;&gt;CLIP&lt;/a&gt;, which really improved the text-to-image generation results that I've seen. &lt;/p&gt;

&lt;p&gt;The focus of CLIP itself was originally for standalone image generation, and that seems to be what most people are doing with it.  However, working off a CLIP-based package called &lt;a href=&quot;https://github.com/lucidrains/big-sleep&quot;&gt;BigSleep&lt;/a&gt;, I found a pretty cool way to turn paragraphs into quite interesting animations that seem to have at least some connection to the text. As an example, here is an exerpt from the beginning of Franz Kafka's &lt;i&gt;Metamorphosis&lt;/i&gt; being used to generate the visuals. &lt;/p&gt;

&lt;small&gt;Warning that there is a decent amount of blinking and flickering in the videos that follow.&lt;/small&gt;


&lt;iframe width=&quot;560&quot; height=&quot;400&quot; src=&quot;https://www.youtube.com/embed/kSltslbtblw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;


&lt;p&gt;Clearly there are segments where the visualization breaks down, but there are surprisingly a couple of spots that actually map pretty well to the underlying text they are trying to describe. At the very least, the images clearly capture Kafka's surreal tone. (dare I call it Kafkaesque?)&lt;/p&gt;

&lt;p&gt;For the next trick, I wanted to try some more positive visual language so I went with a familiar William Wordsworth poem. In the next clip, I show two runs side by side to illustrate how the images randomly decay to noise and need to be periodically reset.&lt;/p&gt;


&lt;iframe width=&quot;560&quot; height=&quot;400&quot; src=&quot;https://www.youtube.com/embed/SOXXQhQf0SE&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;


&lt;p&gt;Again there are places where the algorithm starts spitting out total noise, but overall, the parts that do connect smoothly are vivid and very pertinent.  I want to dive into the details over the next few weeks and figure out where the algorithm goes off the rails, but for now, I just built in a few safe-guards to &quot;reset&quot; it when things get too messy or it sticks on the same shape for too long.  You can view &lt;a href=&quot;https://www.youtube.com/channel/UCjfbKpAq127UVuFeaepkvWg&quot;&gt;my Youtube channel&lt;/a&gt; to see more experiments.&lt;/p&gt;

&lt;h4&gt;a.ttent.io/n&lt;/h4&gt;
&lt;p&gt;But my real application was meant to be used on my own short stories. To optimize that, I fine-tuned the parameter selection manually to see if I could get it to produce more consistent video.  I used the first paragraph of &lt;a href=&quot;/attention&quot;&gt;a.ttent.io/n&lt;/a&gt;, and after many rounds of trial and error, I started to get it to pump out artistic renditions of the real features that are mentioned. Take a look.&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;400&quot; src=&quot;https://www.youtube.com/embed/9Y-UZquQDf0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;


&lt;p&gt;Clearly it does well with any mention of octopus, even fictional &quot;harp-toothed&quot; ones.&lt;/p&gt;


&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/octo.gif&quot; alt=&quot;Big Sleep rendered octopus on ocean floor&quot;/&gt;


&lt;p&gt;But it also renders a wall, glass narcotics cabinet, and bottles pretty well. &lt;/p&gt;

&lt;img src=&quot;/assets/images/2021/story2hallucination.png&quot; alt=&quot;Big Sleep rendered wall, narcotics in a cabinet, and bottles on a countertop&quot;/&gt;

&lt;p&gt;&quot;Distribution center&quot; rendered an interesting overhead map view, it seemed. &lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2021/distro_hallucinate.png&quot; alt=&quot;Big Sleep rendered overhead view of what could be a distribution center&quot;/&gt;

&lt;p&gt;But my personal favorite though was the rendering of the dock.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2021/docks.gif&quot; alt=&quot;Big Sleep rendered docks with fog rolling in over nearby rocks&quot;/&gt;

&lt;h4&gt;Try it yourself&lt;/h4&gt;
&lt;p&gt;All the code needed for this is in a Google Colab notebook available&lt;a href=&quot;https://colab.research.google.com/drive/1yNkvkrHApFR6alyFC1EzhPGHs86yjH1P?usp=sharing&quot;&gt;here&lt;/a&gt;, and it's also available on &lt;a href=&quot;https://github.com/lots-of-things/Story2Hallucination/&quot;&gt;github&lt;/a&gt; if you'd like to help me make improvements. My notebook is just a modification of &lt;a href=&quot;https://colab.research.google.com/drive/1MEWKbm-driRNF8PrU7ogS5o3se-ePyPb?usp=sharing&quot;&gt;this one&lt;/a&gt; from &lt;a href=&quot;https://github.com/lucidrains&quot;&gt;Phil Wang&lt;/a&gt; that lays out how to use Big Sleep with CLIP weights.&lt;/p&gt;

&lt;p&gt;There's a lot of hacky code that tries to modify parts of Big Sleep from the outside, but the only important modification is just the change to dynamically update the text periodically with this line:  &lt;/p&gt;

&lt;code&gt;
model.text = all_text_list[epoch].translate(str.maketrans('', '', string.punctuation))
model.encoded_text = tokenize(model.text).cuda()
&lt;/code&gt;

&lt;p&gt;Pretty much the rest of the code modifications were just there to get the image to robustly &quot;reset&quot; if it gets stuck looking too similar for too long.  This became an issue because sometimes the image converges to a very stable form and stops morphing from there. This is not such a big deal when you are generating one-off images because you can always try again, but when you are trying to dynamically morph from one text prompt to the next, getting stuck means the whole video is lost.&lt;/p&gt;

&lt;p&gt;You can play around with your own texts and let me know what you come up with.  There are quite a few parameters to try to optimize to get good results.&lt;/p&gt;

&lt;p&gt;I'd love to see what things happen. If you reference this blog post on twitter or mastodon, then your work will be appended in the comments section.&lt;/p&gt;

&lt;p&gt;And have fun hallucinating!&lt;/p&gt;</description>
        <pubDate>Fri, 22 Jan 2021 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2021/01/story2hallucination/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2021/01/story2hallucination/</guid>
        
        <category>machine learning</category>
        
        <category>code</category>
        
        <category>computer vision</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/oneth.png</image>
        <title>oneth.club: an online discussion society designed to unite rather than divide</title>
        <description>&lt;p&gt;In early 2016, I wrote an app for my friends to submit and choose articles for our reading/discussion group.  The idea was simple: the ones in the groups who would get to choose the next article would be the ones who were the most engaged with the previous one. During our discussion group, we came up with a simple system, but as we used it, we started to contemplate how the same process would be interesting to implement on a larger scale.&lt;/p&gt;

&lt;p&gt;I largely forgot about that little experiment until about 2 weeks ago when I noticed that it was still running under my account. This suddenly caused me to think back to that time and recognize just how little has changed.&lt;/p&gt;

&lt;h4&gt;The Insane Factionization of America&lt;/h4&gt;

&lt;p&gt;Presciently, one of the first articles that we read for our reading club was &lt;a href=&quot;https://www.theatlantic.com/magazine/archive/2016/07/how-american-politics-went-insane/485570/&quot;&gt;How American Politics Went Insanse&lt;/a&gt;, which was a satirical look into the future of American politics in 2020 from the perspective of 2016. The article suggested that the future was grim, with politicians grinding through deadlock, and the public pitted against one another.&lt;/p&gt;

&lt;a href=&quot;https://www.theatlantic.com/magazine/archive/2016/07/how-american-politics-went-insane/485570/&quot;&gt;&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/american_insane.png&quot; alt=&quot;cover of Antlantic magazine with Uncle Sam in a straight-jacket&quot;/&gt;&lt;/a&gt;

&lt;p&gt; While it was meant to be comically extreme, it turned out to be surprisingly tame compared to how things actually turned out. &lt;/p&gt;

&lt;p&gt;The thing that is most insane about rediscovering the article was remembering just how acutely aware of the problem I personally was even back then.  However, despite recognizing the issue, I truly believed that it would probably solve itself over the next couple of years. And of course, I didn't personally do anything about it.  On the contrary, even being aware of it, I too have migrated in my political beliefs toward the edges of the mainstream. &lt;/p&gt;

&lt;p&gt;So when I rediscovered my old webapp, I suddenly wondered if maybe something like that idea could actually work to fix this. And importantly, I'm wondering whether it's important that I start to try to get something like this off the ground.&lt;/p&gt;

&lt;h4&gt;A Common Dialogue&lt;/h4&gt;
&lt;p&gt;Back when I wrote the original site, my friends and I were wondering if we could design a social network that was specifically meant to bring people into a common dialogue.  Our current social media is obviously just the opposite. With twitter, facebook, reddit or any of the myriad others, every design choice is meant to push you further into your own silo.  Again, that's great for staying engaged with what makes you personally engaged, but absolutely terrible for fostering common connection across lines.&lt;/p&gt;

&lt;p&gt;But there's a big problem that makes a common dialogue much more difficult to foster than a specialized one. It really comes down to incentives. It seemed to us that the real incentives (not just philosophical) of taking part would be to expand your own worldview and to influence the worldview of others. In other words, a big reason for taking part would be to get your ideological foes to step up and have to grapple with new information.  &lt;/p&gt;

&lt;p&gt;But if that's the real reason to use the site, then there is a big perverse incentive that would lead to abuse if the system was set up like traditional social media.  Namely, if the main article is one that you don't agree with, you would just skip it and start trying to influence the choice for the next day.  In order for this project to work, there'd have to be a reason that you can't just skip the discussion on today's article.&lt;/p&gt;

&lt;p&gt;We decided that the best way to do this was to make the voting for the next day directly dependent on your participation in today's discussion. So I wrote the site to try to &quot;gamify&quot; the part where users prove that they've done the work in today's discussion. The game is just a simple question and answer framework, where the participants write questions about articles and answer other's questions. The idea is that by structuring it around substantive questions (rather than, say, comments or reactions) I could prevent it from being a standard twitter/reddit-esque popularity contest.&lt;/p&gt;

&lt;p&gt;And the idea for &lt;a href=&quot;https://oneth.club&quot;&gt;&lt;strong&gt;oneth.club&lt;/strong&gt;&lt;/a&gt; was born.&lt;/p&gt;

&lt;h4&gt;What does oneth mean*?&lt;/h4&gt;

&lt;p&gt;Every distribution medium or platform is really a competition to elevate that which satisfies some definition of &quot;best&quot; (I think I'm channelling &lt;a href=&quot;https://www.joelonsoftware.com/2018/04/13/gamification/&quot;&gt;Joel&lt;/a&gt; here). The rules and structure of the platform only differ in how they define what is best. Some platforms are looking for the most accurate (scientific journal), the most popular (congress), the first (patents), the latest (news), the &quot;most niche&quot; (twitter etc).  &lt;/p&gt;

&lt;p&gt;The new app that we were contemplating called for a new superlative though.  We were trying to describe the &lt;strong&gt;thing most appropriate for everyone to be exposed to together&lt;/strong&gt;. It's a whole different idea, and therefore we realized it was hard to conceptualize it as a specific thing. But wouldn't the idea of &quot;hottest&quot; be hard to understand if we hadn't been exposed to it for so long? We needed a new word to describe this ineffable new take on &quot;hot.&quot;&lt;/p&gt;

&lt;p&gt;So to describe what our site would look for, I came up with the term &lt;strong&gt;oneth&lt;/strong&gt;, which is a take on first and only, but meant to mean something more like &quot;if we could all only read one thing together, what would be the best thing for that to be?&quot;&lt;/p&gt;

&lt;p&gt;Particular events in history can serve as examples of the concept.  The first moon landing was the oneth event of that moment. Perhaps after 9/11, a conversation on why Middle Easter Islamic terrorism exists would have been the oneth discussion at the the time. Just after Lincoln's assassination, I'd expect the fate of the union would have been a very oneth topic.  Game of Thrones seemed like the oneth TV show for a while.&lt;/p&gt;

&lt;p&gt;The concept is broad and contentious, but I think it was worth defining. I'm not aware of anyone studying this type of thing, but I wouldn't be surprised if it has been defined with a longer and fancier sounding name. Still, I think that it's useful enough that we could use a one syllable word to name it. So now that it's named, all that's left is to debate.&lt;/p&gt;

&lt;h4&gt;Using the App&lt;/h4&gt;
&lt;p&gt;If you're intrigued by the idea, I encourage you to &lt;a href=&quot;https://oneth.club&quot;&gt;try it out&lt;/a&gt;, and please, please, please join the &lt;a href=&quot;https://www.hylo.com/c/oneth&quot;&gt;community on Hylo&lt;/a&gt; to give us feedback.&lt;/p&gt;

&lt;p&gt;The mechanics are pretty simple for now.  You can post an article, and write questions about your own and other people's articles.  As you write questions, you get points, and then then you can vote with those points on whichever article you think should be up for discussion tomorrow. The look-and-feel is &lt;em&gt;extremely&lt;/em&gt; simple compared to the other sites I've been working on in the past few months.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/simple_oneth.png&quot; alt=&quot;image of a very simple UI of oneth homepage&quot;/&gt;

&lt;p&gt;However, the actual programming and mechanics behind the scenes is much more complex.  I'm frankly astonished that I was able to work on this four years ago with how little I knew about web development then.  There remains a lot to do both in polishing the site and polishing the game making mechanics. I'm far from an expert in organization theory, and I treat the current setup as just a starting point.  If you have idea, I really encourage you to join the &lt;a href=&quot;https://www.hylo.com/c/oneth&quot;&gt;Hylo community&lt;/a&gt; for discussion or if you are you can go straight to the &lt;a href=&quot;https://github.com/lots-of-things/oneth&quot;&gt;Github project&lt;/a&gt; to file issues.&lt;/p&gt;

&lt;h4&gt;The Next Round&lt;/h4&gt;

&lt;p&gt;As with pretty much everything I build, all the &lt;a href=&quot;https://github.com/lots-of-things/oneth&quot;&gt;code&lt;/a&gt; to run it is freely available. As a reader here knows, I have several projects running simulataneously now, but I would fully support a cofounder who wanted to be a community leader and run with the concept.&lt;/p&gt;

&lt;p&gt;For now, I hope to see you on there.  As the tagline says, lets &lt;em&gt;really share something&lt;/em&gt;.&lt;/p&gt;

&lt;br/&gt;

&lt;p&gt;&lt;small&gt;*I think the word oneth is under-leveraged in the English language.  According to wiktionary it can be used like 201th (two-hundred-and-oneth), but other than that it isn't a real word.  &lt;/small&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 20 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/oneth/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/oneth/</guid>
        
        <category>web</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/dec_net_capital.png</image>
        <title>Augmented Democracy - Intentional Capitalism | A continuum analysis of collective decision making</title>
        <description>&lt;p&gt;&lt;em&gt;tldr; democracy is our ideal. money is a convenient voting system but it has a glitch that breaks it irreversibly when too much is held by too few. therefore, we need wealth redistribution.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I've been thinking about how groups make decisions. There are a lot of ways decision-making happens in detail, but I noticed a broad pattern that I wanted to discuss in this post: that the most fundamental component of a decision-making system boils down to how the atomic &quot;decision making unit&quot; (DMU) is distributed across the population. I'll explain what I mean by this using the simplest example first.&lt;/p&gt;

&lt;h4&gt;Democracy: predetermined distribution of DMUs&lt;/h4&gt;
&lt;p&gt;To start off, lets focus on a pure direct democracy where every decision is voted on by the whole population. Regardless of the details of the voting system (ie winner-takes-all vs consensus etc), a direct democracy is one where every individual's contribution to the decision making calculation is equal. In this case, it's clear that the way power was distributed was pre-determined.&lt;/p&gt;

&lt;p&gt;Other forms of democracy, like a republic or a democracy by committee, still have this fundamental even distribution even though the way it is allocated may cause certain deviations in practice. For example, in a republic, your ability to make decisions on one topic are strongly correlated with other topics because you have to elect a representative to decide on both.  Still at the very core, we always have the notion that each person starts with predetermined, equal amount of DMUs.&lt;/p&gt;

&lt;p&gt;Of course, sometimes republics are set up incorrectly (ahem, United States) with unbalanced allocation of DMUs based on who you are or where you live. (In this case, I am talking just about the unfair distribution due to the electoral college, we'll come to the US's money in politics problem later.)  Nevertheless, as long as the mechanism is well documented, this system still has predetermined distribution of DUMs, even though those units are allocated unfairly.&lt;/p&gt;

&lt;p&gt;However, I think it's safe to say that for a large majority of reasonable humans, there is some basic understanding that democracy should be based on precisely equal amounts of DMUs per person.  For the remainder of this discussion, when I refer to democracy, I mean predetermined, equally distributed DMU.  &lt;/p&gt;

&lt;p&gt;So for democracy, the atomic DUMs are votes for representatives at federal, state, and local levels, and everybody should get an equal number. Hopefully that makes it pretty clear what a DMU looks like in this simplest example. However, there are other ways to play with the same concept in more abstract forms.  &lt;/p&gt;

&lt;h4&gt;Capitalism: constant dynamic reallocation of DMUs&lt;/h4&gt;
&lt;p&gt;I believe that capitalism constitutes the other major form of DMU distribution system where entities constantly reallocate DMUs to decide what should be done.  In this case the amount of DMUs an individual has for a decision is determined by the supply of DMUs they can gather from others in the past and how they want to distirbute the DMUs they have on current and future decisions. &lt;/p&gt;

&lt;p&gt;I know there are lots of other aspects to the discussion of capitalism, but for now I just want to look at it as a decision making system.  I also want to point out the distinction with the idea of markets here, which is normally looked at from the perspective of exchange of goods. I specifically want to call it capitalism because the core idea behind capitalism is that those with existing capital ultimately have the bulk of the decision making power about what is going to happen in society. For example, who decides what the next &quot;big idea&quot; that comes into existence should be? In a pure capitalist society, this is decided by the group of people who have the money to finance the next set of companies and organizations.&lt;/p&gt;

&lt;p&gt;So in the capitalist system, the unit of money (ie the dollar, yuan, etc) could be considered the DMU. Of course, in reality, some decisions are easier to buy and certain people are more efficient with their money so there will always be gaps between real DMU and dollar value as was the case for democracy with votes. However, ignoring those complications, we'll describe the dollar as the DMU for the remainder of this article.&lt;/p&gt;


&lt;h4&gt;Visual comparison of DMU allocation&lt;/h4&gt;
&lt;p&gt;Where this becomes interesting is when we think about how decisions would be made using these two systems.  To do this, I've come up with a figure for vizualizing the flows of decision units throughout the system until they are allocated to an outcome.  For a simple example, imagine a committee of three that is deciding on the details for the country fair. To keep it simple, lets just assume that there are two choices to make (A and B) that can have a combined total of three possible outcomes.&lt;/p&gt;

&lt;p&gt;So here is a diagram to illustrate what it would look like if:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the first person really wants the green option for A but doesn't care about choice B&lt;/li&gt;
  &lt;li&gt;the second person really wants the red option for B but doesn't care about choice A&lt;/li&gt;
  &lt;li&gt;the third person really wants the yellow option for B (only one choice)&lt;/li&gt;
&lt;/ul&gt;

&lt;img alt=&quot;a diagram of decision making power flowing through a network into decision endpoints&quot; src=&quot;/assets/images/2020/dec_net_simple.png&quot;/&gt;

&lt;p&gt;In the diagram, the width of each line is how much support the person gives to a certain outcome.  Note that the total width coming out of each committee member is equal because all committee members have the same amount of say in the final outcome through their votes. The only difference is in how much they split their DMUs.  &lt;/p&gt;

&lt;p&gt;But how do they split their votes? Well, in reality they don't split their vote directly, but they effectively split their vote by assigning which things they would agree to vote for.  Anything that they agree that they would vote for effectively gets an equal part of their vote.  &lt;/p&gt;

&lt;p&gt;Which choice gets picked is dependent on exactly how the voting system works. If it's a majority win vote, then the first or second one could either happen because either would get 2/3 votes, depending on which one comes up for a vote. But for simplicities sake, lets just assume going forward that whichever one has the most weight gets selected.&lt;/p&gt;

&lt;p&gt;Now for any direct democratic voting system, we could use this same form of diagram to get the possible outcomes depending on how each person votes.  For a republic, it's more complicated because we have to pass through intermediaries. However we can apply the same diagram to follow the flow of DMUs for an abstract set of decisions.  For simplicity we'll look at something simple like a 3 seat county board of supervisors voting on some decision. &lt;/p&gt;

&lt;img alt=&quot;diagram of decision making power flowing from voters to represeantives and then into endpoints&quot; src=&quot;/assets/images/2020/dec_net_repub.png&quot;/&gt;

&lt;p&gt;Each band on the left is some group of citizens pooling their DMUs into the top 3 candidates, who go on to vote for something. &lt;/p&gt;

&lt;h4&gt;Visualizing Capitalism&lt;/h4&gt;
&lt;p&gt;Democracy is fairly simple because we start with an even distribution of DMUs and at every round of decision making we maintain that equal division.  Unfortunately, capitalism is much more complicated because everyone starts with very different amounts of DMUs, and we are constantly dynamically updating the distribution of DMUs during the process of every round of decision making.&lt;/p&gt;

&lt;p&gt;To display this in a fairly simple way, lets look at the case of a small community deciding which of two sites to dig a well for their crops.  The two major land owners want the well on their own land, but only one (owner 1) can afford to pay for it on their own. The other one (owner 2) gets a bank to loan them money, assuming that they can charge for water to pay the bank back.&lt;/p&gt;

&lt;img alt=&quot;a diagram of decision making power in the form of money moving amongst actors&quot; src=&quot;/assets/images/2020/dec_net_capital.png&quot;/&gt;

&lt;p&gt;So in this case, DMUs in the form of capital move from owner 2 and the bank into site 2.  Then in the future site 2 returns DMUs to owner 2 and the bank.  Other users of the well transfer their DMUs to owner 2 and the bank, allowing them to have more weight in decision making later.  I've additionally shown the investment for site 1 from owner 1, which is eventually returned with losses to owner 1, thereby diminishing their total DMUs in the future.&lt;/p&gt;

&lt;p&gt;This example is fairly simple, but I hope that it can help to show the flow of decision making power throughout a system.&lt;/p&gt;

&lt;p&gt;However, the above visual was only a small segment of the whole decision making trajectory because the way that the DMUs were distributed at the beginning was determined by reallocation of DMUs over many previous rounds of decision making.  In order to really inspect the decision making system in capitalism we have to repeat this process many, many times while keeping track of the redistributions.&lt;/p&gt;

&lt;p&gt;This becomes very messy fast, but you can imagine what it might look like if the output of the above diagram was plugged in as inputs to the next one. It would start to look something like these diagrams of neural networks.&lt;/p&gt;

&lt;img alt=&quot;image of a recurrent neural net rolled out&quot; src=&quot;/assets/images/2021/nMeys.png&quot;/&gt;

&lt;p&gt;Specifically, it would look like the unrolling of a recurrent neural network with attention. I believe the similarity here is more than superficial. In essence any decision making system with many inputs will have this sort of architecture.  The important thing here is that research into neural networks has determined that to get an optimal decision making algorithm you have to constantly balance how strongly you .&lt;/p&gt;

&lt;h4&gt;The Merit and Downfall of Both Systems&lt;/h4&gt;

&lt;p&gt;While the human-centrism of democracy feel very naturally justifiable, it's clear that not all decisions should need to flow through such a centralized system.  Many argue that this is because government centralization is fundamentally inefficient, but I don't believe that is a reasonable justification. It's very possible that we could restructure our democracy to make that kind of centralized planning far more efficient and transparent than it is.  However, I have more fundamental reasons to believe that dynamic reallocation of DMUs has merit on its own.&lt;/p&gt;

&lt;p&gt;Capitalism has one upside, which is that we can almost automatically distribute greater decision making power to those who have shown good decision making behavior in the past. This is part of the unspoken rationale for relying on &quot;the invisible hand of the market&quot; to carry out tasks with the most efficiency. I believe that there is an advantage to this because even in the most efficient democratic system, a largely unknowledgable populace could continuously make bad decisions, but with staking your investments with capital should downregulate the influence of the unknowledgable in the decision making process. Unfortunately, there are at least two huge flaws in this presumption. &lt;/p&gt;

&lt;p&gt;First, for capitalism to work the mapping between the output money delivered for a task must match the true social value of the outcome.  This can be strongly violated if people don't have to pay for long-term future costs up front (eg pollution). If this mapping is highly inaccurate then those who will eventually hold all the DMUs will not be good at making decisions, just gaming the system. The other major problem is that unfair distributions of DMUs can at some point render the basic correction mechanism of capitalism inoperable because vested interests can leverage their advantage to set the terms of the output reallocation of DMUs (eg embargoing anyone who does business with a competitor).&lt;/p&gt;

&lt;p&gt;There are merits and downfalls to both systems, and each needs to be considered carefully for a given context. However, both of the failures of capitalism result from the disconnect between capital representing the true needs of the many, which comes about mostly when there is greater economic inequality.&lt;/p&gt;

&lt;h4&gt;Structuring our System to Find a Balance&lt;/h4&gt;

&lt;p&gt;As a result of my thinking on this, I'm starting to believe that all of our big fights over the balance between these ideologies might be misplaced.  I'm thinking that the big fight we need to fight is not the endless argument over whether to edge closer toward free market capitalism or egalitarian democracy. The smart people in our country should recognize that one balance will never be perfectly appropriate across all times and places and instead we should make the system so that the balance can dynamically adjust in a more efficient, predictable, and transparent manner.&lt;/p&gt;

&lt;p&gt;Metaphorically, this idea comes from my understanding of the research on machine learning algorithms which basically concludes that you shouldn't try to preselect a balance between fixed params and optimal params, but instead build the algorithm to adapt to the the amount of balance that is best for your desired outcome*.&lt;/p&gt;

&lt;p&gt;We've actually already organically arrived at a system that has built in a feedback system between the two mechanisms, where each can be used to decide the strength of the other. Clearly our government should have the power to regulate our capitalist system, by making laws where it applies, converting negative externalities into capital, and by rebalancing the distribution of DMUs when it becomes too unbalanced. Perhaps more controversially, capitalism has the ability to influence decision making in democratic government by regulating how resources are distributed to campaigns and how information is being distributed. As our understanding of this system advances, it should become possible to fine-tune the strength of the feedback to optimize the overall decision making system.&lt;/p&gt;

&lt;p&gt;I think the smartest minds should stop arguing for how the balance should be moved momentarily right now, but instead, how the balance could be better monitored and controlled for societal aims.  I think we'd all be better off by outwardly adopting an approach that accepts both ideologies as no more than mechanisms to make decisions in a continuous space of plausible decision making systems.&lt;/p&gt;

&lt;p&gt;*I recognize that throughout I am taking the stance of a good faith argument assuming that people want to actually find the system that results in the greatest good for the greatest number.  It's quite likely that many people aren't really making good faith arguments when they support capitalism because they really are saying anything to protect their own privilege. &lt;/p&gt;</description>
        <pubDate>Sun, 20 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/continuum-decision/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/continuum-decision/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2021/attention_logo.png</image>
        <title>a.ttent.io/n</title>
        <description>&quot;Out early for drugs and octopus,&quot; Ezzy texted.

She was sitting on the hallway floor of the Institute's distribution center, head leaning back against the wall. Three seconds after 6 AM she started tapping impatiently on the glass between her and the narcotics cabinet. She handed the requisition to the half-awake clerk, and he pushed the bottles across the counter with a detached shrug. She dropped the bottles into her backpack and slipped down the stairwell to the supply tunnel that ran under campus to the marine center. She waited on the dock until 9 when the divemaster finally brought her two harp-toothed octopuses.

&lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; URL=/attention.html&quot; /&gt;</description>
        <pubDate>Fri, 18 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/attention/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/attention/</guid>
        
        <category>fiction</category>
        
        <category>machine-learning</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/attntn.png</image>
        <title>analyzing a.ttent.io/n</title>
        <description>&lt;p&gt;Why do written works of fiction ever have to be finished? What if the story's growth was part of the story itself? My first real work of fiction is finished. But I wonder if my first real story is just beginning? &lt;/p&gt;

&lt;h4&gt;What is a.ttent.io/n?&lt;/h4&gt;

&lt;p&gt;While I've previously alluded to &lt;a href=&quot;/attention&quot;&gt;the story&lt;/a&gt; I've been writing, which has been in the works for &lt;a href=&quot;/2020/12/ongoing-attention&quot;&gt;more than 3 years&lt;/a&gt;, I've never directly covered what it's about on this site. It's a story, to be sure, but it's also meant to be an experiment. &lt;/p&gt;

&lt;p&gt;Writing &lt;em&gt;attention&lt;/em&gt; was a way to discuss the concept of the human attention span while simultaneously consuming a silver of that attention from the reader. It's about this period of history we are living in where machines and minds consume and emit each other recursively, the omnipresent ouroboros of thoughts and algorithms.&lt;/p&gt;

&lt;p&gt;Building a.ttent.io/n (the website) allowed me to extend the ouroboros into the real world.  So, before we talk about the experiment, we have to introduce the subject that started it all.&lt;/p&gt;

&lt;h4&gt;What is attention?&lt;/h4&gt;
&lt;p&gt;What am I talking about? &lt;/p&gt;

&lt;p&gt;Supposedly &lt;a href=&quot;https://www.goodreads.com/quotes/1144998-everyone-knows-what-attention-is-it-is-taking-possession-of&quot;&gt;everyone knows what attention is&lt;/a&gt;, but I personally can't describe it with words. I’ve attempted to capture what I imagine it would look like.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/attntn.png&quot; alt=&quot;image of focal points of light emanating from a document, passing through a person's brain, focusing on another document which is then the focus of another persons brain.&quot;/&gt;


&lt;p&gt;There are other &lt;a href=&quot;https://en.wikipedia.org/wiki/Attention&quot;&gt;standard meanings&lt;/a&gt; of attention, but there is one particular to this moment in our technological history that perhaps you haven't heard of before. One of the definitions of attention most pertinent to this story is a &lt;a href=&quot;https://buomsoo-kim.github.io/attention/2020/01/01/Attention-mechanism-1.md/&quot;&gt;concept in deep learning&lt;/a&gt; where attention  dictates the data points  that an algorithm’s inputs and outputs are focused on, and how to update what part of the data the algorithm focuses on based on the data itself. The machine eats its own tail to know what to eat next.  As I hope you are starting to see, there are many layers to this ouroboros.
&lt;/p&gt;

&lt;h4&gt;The experiment&lt;/h4&gt;
&lt;p&gt;One core arc of the story is Ezzy's ongoing experiment to  form a computer-brain interface using the portion of an octopus’s brain that is housed at the base of each of its arms.. While we're following this experiment, our unreliable narrator is simultaneously experimenting on the mind's of our other characters. And in a previous, longer manifestation of the book, the author introduced that she was the purported inventor of a type of interactive media where carefully timed doses of hallucinogen were introduced into the audiences’ bloodstream at choreographed times in a performance. All of these are centered on the concept of experimenting on an unwitting audience's mind. &lt;/p&gt;

&lt;p&gt;So it's fitting that unbeknownst to the readers of my story, the story they were reading was itself experimenting on which content was most able to keep the audiences’ attention. &lt;/p&gt;

&lt;p&gt;As &lt;a href=&quot;/2019/06/google-analytics-for-scrolling-on/&quot;&gt;I wrote about before&lt;/a&gt;, I designed &lt;em&gt;a.ttent.io/n&lt;/em&gt;'s web page to (anonymously) track the depth of scrolling of each of its readers.  Using that data, I intended to update the story to find what works best to make the story more and more attention grabbing.&lt;/p&gt;

&lt;p&gt;As &lt;a href=&quot;/2019/06/google-analytics-for-scrolling-on/&quot;&gt;I wrote about before&lt;/a&gt;, I designed &lt;em&gt;a.ttent.io/n&lt;/em&gt;'s web page to (anonymously) track how far each reader scrolled down the page. Using that data, I intended to discover what  makes the story most attention grabbing, update it accordingly, and repeat.&lt;/p&gt;

&lt;p&gt;In my first set of experiments, I tried shuffling the first three chapters so that the book would start with a random one for each reader. To my surprise, I found that each chapter was equally (un)successful at keeping the audience scrolling. I realized that in this version, I had juxtaposed completely unrelated chapters next to each other with no binding text. So when the readers reached a second chapter that seemed totally disconnected from the first, they got pissed off and switched to something else entirely.&lt;/p&gt;

&lt;p&gt;With this knowledge, it became obvious that I had to change the narrative so one chapter would flow to the next. I also decided that I could slice the story almost in half and consolidate several characters. Not only did that help make it more approachable, it actually unlocked a way to make the story more clever.&lt;/p&gt;

&lt;h5&gt;The second experiment&lt;/h5&gt;

&lt;p&gt;After the rewrite, I still have many questions to answer, and  to answer them I need more experimental eyeballs. So I'm publicizing the project everywhere I can, the more reads I get, the more data I have to work with. This second experiment is ongoing. If you haven't read the story, you can still be a part of it by clicking &lt;a href=&quot;/attention&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;


&lt;h4&gt;So what is the point of &lt;em&gt;a.ttent.io/n&lt;/em&gt;?&lt;/h4&gt;
&lt;p&gt;I don't want to over-explain this, but if you are here, bothering to read this, then you deserve to know. First, you should know that the point of the &lt;em&gt;a.ttent.io/n&lt;/em&gt; site is not for a million people to visit it and for me to get a book deal for my next 3 stories (though I'd totally accept that in addition). That isn't the point of the site because that isn't the point of the story.
&lt;/p&gt;
&lt;p&gt;The point of the story is to show us that attention is about bidirectional connection. This is why the information system in the story and information systems in real life are evolving to ever more invasively track our interactions with them. We are moving away from being stuck in only broadcast or listen mode and towards a continuous feedback loop. The point of &lt;em&gt;a.ttent.io/n&lt;/em&gt; is to draw that exchange down into a tighter and tighter loop until the author and the story and the reader begin to merge.&lt;/p&gt;


&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/recursivenet.png&quot; alt=&quot;image of focal points of light emanating from a document, passing through a person's brain, focusing on another document which is then the focus of another persons brain. this continues recursively in an swirl getting smaller and smaller until the many small brains connect back to the original document&quot;/&gt;

&lt;p&gt;After circuiting this ouroboros, I think we've arrived back at the real focal point. The point of &lt;em&gt;a.ttent.io/n&lt;/em&gt; is for the little feedback circuit that I don't even know I'm a part of to find itself. I hope that together we can write and rewrite &lt;em&gt;a.ttent.io/n&lt;/em&gt; until we can all tell that it doesn't end.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PS: I want to thank my partner Claire for helping me edit this post. I'm glad she pays attention to my ramblings.&lt;/em&gt;&lt;/p&gt;</description>
        <pubDate>Fri, 18 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/analyzing-attention/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/analyzing-attention/</guid>
        
        <category>writing</category>
        
        <category>web</category>
        
        <category>philosophy</category>
        
        <category>machine-learning</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/bg_map.png</image>
        <title>Imagining a new economy on the Co-op Trail</title>
        <description>&lt;p&gt;I'm honestly grossed out by how our economy works. I never really had the privilege to understand it until now, but now that I'm seeing what it's like for a well-off person, I can't help but recognize the preposterous unfairness of it all. A few months ago I learned about the co-op movement and an idea called the solidarity economy (mostly from following &lt;a href=&quot;https://zebrasunite.coop&quot;&gt;Zebras Unite&lt;/a&gt; ❤️).  I am learning so much and compiling &lt;a href=&quot;https://www.are.na/will-stedden/coop-trail&quot;&gt;articles&lt;/a&gt; and &lt;a href=&quot;https://youtube.com/playlist?list=PLLBGJDEi1qhvPdABWCa5lVio5Ql6jq1TK&quot;&gt;videos&lt;/a&gt;, but as I've learned more and more, I'm really starting to understand just how daunting it is to modify the framework of exploitation underlying our whole society.&lt;/p&gt;

&lt;p&gt;The thing I've struggled with the most is how it will be possible to shift enough people away from the capitalist economy for the solidarity economy to become a self-sufficient alternative to the dominant capitalist model.  Right now, someone has to be deeply invested to even learn what businesses around them share those principles, and I just don't see that happening for the majority of people I know. I could be wrong, but for a solidarity economy to work sustainably, I'd think there needs to be a critical mass of people operating inside of it so that there won't be any reliance on an external, extractive economy. And without easy access for consumers, it will always be way more lucrative to succumb to an exploitative company's tactics rather than do the right thing.&lt;/p&gt;

&lt;p&gt;While discussing this problem with my partner Claire, we brainstormed an idea to showcase the solidarity economy, and help people picture a future where a solidarity economy could replace the traditional capitalist one. We came up with the idea to try to travel around the US using only organizations in the solidarity economy. We've wanted to take our honeymoon and travel around for an extended bit so we figured this was a good chance to do something productive while we're exploring the country.&lt;/p&gt;

&lt;h4&gt;The Co-op Trail&lt;/h4&gt;
&lt;p&gt;The concept of the trail is pretty straightforward.  We want to get from A to B, without relying on traditional capitalist enterprises. Now this would be particularly hard if our favorite hobbies were jet skiing and staying at luxury resort, but fortunately what we like most is eating, drinking, hiking, making crafts, and other low-key enterprises.  So we're going to design a long, &lt;a href=&quot;http://www.theartofslowtravel.com/what-is-slow-travel/&quot;&gt;slow moving&lt;/a&gt; honeymoon where we take the time to do those things, and learn about what the world looks like through the lens of a cooperative economic system.
&lt;/p&gt;

&lt;p&gt;This might seem like a crazy way to enjoy ourselves, but it's my personal opinion that &lt;strong&gt;constraints actually make everything more fun.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;That said, operating this way will definitely change the trip, and so we hope to provide a resource by documenting all the ways we accessed the solidarity economy throughout.   The first big thing that we've realized we have to adapt is how we get around. It would be practically impossible to transport ourselves by car without relying on fossil fuels.  Even if we had an electric car, we'd still need to plug into charging stations, and most of those are also built on the traditional business model.  To overcome that, we've decided that we will do the trip using a solar powered electric tandem bike and trailer, which we'll build mostly ourselves to use sustainable parts where we can.  I'll be writing more about that build over this winter as it comes together. &lt;/p&gt;

&lt;img alt=&quot;&quot; border=&quot;0&quot; width=&quot;400&quot; data-original-height=&quot;360&quot; data-original-width=&quot;480&quot; src=&quot;https://d2w9rnfcy7mm78.cloudfront.net/9900653/original_c022099161583806568992335e540d71.jpg?1608016214?bc=0&quot;/&gt;

&lt;p&gt;Our goal is to make a round trip from California, through the Pacific Northwest, down to Denver, then across the Midwest to Minnesota, Wisconsin, and Illinois, then back around through the southwest to California again.  We expect it to take the better part of a year.  &lt;/p&gt;

&lt;img alt=&quot;&quot; border=&quot;0&quot; width=&quot;400&quot; data-original-height=&quot;553&quot; data-original-width=&quot;1210&quot; src=&quot;/assets/images/2020/bg_map.png&quot;/&gt;

&lt;h4&gt;Documenting the Lifestyle&lt;/h4&gt;

&lt;p&gt;One of my big inspirations is &lt;a href=&quot;https://faircompanies.com/kirsten-dirksen/&quot;&gt;Kirsten Dirksen&lt;/a&gt;, who produces her own series of documentaries on alternative dwelling spaces with a very distinctive style. Her work is something that has totally inspired me and countless others to rethink how our inhabited environments can work in the future. With the Co-op Trail, I thought it would be very cool to do something like that. While we're traveling, we're going to try to make a documentary about all kinds of co-ops and other organizations in the solidarity economy.  &lt;/p&gt;

&lt;p&gt;So what was the first thing I did? Of course, I &lt;a href=&quot;https://cooptrail.org/&quot;&gt;built a website&lt;/a&gt;.  That's now how I structure projects now I guess: &quot;Advertise it like it's already been built, then start to build it.&quot;&lt;/p&gt;

&lt;p&gt;The next step is going to be building our electric tandem bike. I'm already a bit worried that it may be a challenge to source the parts from co-ops, but I will try my best and document where I come up short. I think a crucial part of this whole project will be to catalog what parts of the traditional economy we had to rely on because there just wasn't any other choice. Once that is working though, I'll start the hard part: reaching out to organizations to start doing profiles on them and compiling them into the itinerary. That will really push me to be more proactive in making connections&amp;mdash;something I haven't been so great at in the past, but would totally be worth it to practice.&lt;/p&gt;

&lt;p&gt;I already know it's going to be an amazing trip, but if we do it right, it can also be a resource to launch us and others into a new economy for the rest of our lives.&lt;/p&gt;

</description>
        <pubDate>Wed, 16 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/coop-trail/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/coop-trail/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>Renaissance of the Renaissance Person: We should restructure society so anyone can try lots of things.</title>
        <description>&lt;p&gt;Inspired by the &lt;a href=&quot;https://www.youtube.com/watch?v=CYP2gHgtGiw&quot;&gt;Break 'Em Up! discussion&lt;/a&gt; from &lt;a href=&quot;https://peoplesaction.org/&quot;&gt;People's Action&lt;/a&gt; today, I've been trying to imagine what I think fairness and justice would look like in the world.  It's a lofty thought, but one that I don't think enough people take the time to envision in their day-to-day life.  We all talk about how we want a fair society in an abstract way, but there is a grey area in the &lt;a href=&quot;https://www.lesswrong.com/posts/iAxkfiyG8WizPSPbq/the-bedrock-of-fairness&quot;&gt;definition of fairness&lt;/a&gt; between the obviously unfair distribution of resources today, and another extreme of perfectly regimented identical distribution of life experiences.  So today, I tried to define the thing I've come to cherish most, which I think should fundamentally be available to everyone on earth.&lt;/p&gt;

&lt;h4&gt;The freedom to be a Renaissance Person.&lt;/h4&gt;

&lt;p&gt;It's very hard to try to define the minimum floor that every person should deserve. It can be tempting to set the threshold based on some kind of material possession, like when everyone has a house or something like that.  But I don't believe that's good enough. I think fairness and justice are both about giving a level of true freedom to every person.  Some people might think we already offer that in the US, but that is obviously not true in a place where we don't even offer the bare minimum of survival. You can't have freedom without the freedom to not do anything for a month without the fear of financial ruin. &lt;/p&gt;

&lt;p&gt;But still, there has to be more to life than just the bare ability to survive. That's why I think real agency starts when a person has the freedom to pursue more than one passion as if it could be their life-long career, but without pressure that any passion needs to support you for your whole life. And I think a good way to describe this is the freedom to be a Renaissance Person.&lt;/p&gt;

&lt;h4&gt;In defense of the Renaissance Person&lt;/h4&gt;

&lt;p&gt;To me, the beauty of the Renaissance Person is that they get to make decisions about what they believe is the most intrinsically good thing to pursue, without worrying about incentives from economic concerns. Importantly, I don't just believe that this kind of freedom is good for improving the kinds of things that get created. I think it's fundamentally good for the person. The opportunity to freely change their life's direction is a right that makes a person substantially more well-off than if they only have the right to pursue one career. My goal in life has been to become something of a renaisance person, and now that I'm starting to acheive that goal, I believe that's substantially benefited both my personal well-being and my standing in society.&lt;/p&gt;

&lt;p&gt;For my whole life I've been trying to get to a place where I could have a little space to step away. For anyone who isn't born with excess wealth, we have to meet a bunch of obligations to transition our lives away from the stress of getting above water. And we don't really get the freedom to take a chance and create something that we believe in. Unless we get lucky enough to get past the crap, we end up trapped to pursue things that society effectively dictates to us.&lt;/p&gt;

&lt;p&gt;I got lucky that I learned about the idea of early financial independence when I was pretty young. I got even more lucky that I was able to learn from the bad experience of my family that there are no &quot;get rich quick&quot; schemes that will get you to that independence. &lt;/p&gt;

&lt;p&gt;But now that I'm arriving at this place, I'm convinced that this is something that getting everyone to this level might be one of the best things for improving the well-being of humanity. &lt;/p&gt;

&lt;h4&gt;How would we do it?&lt;/h4&gt;

&lt;p&gt;So what are the steps? Well, the whole problem boils down to redistribution of two things: our society's free time and access to information networks. &lt;/p&gt;

&lt;h5&gt;Redistributing free time&lt;/h5&gt;
&lt;p&gt;OK, I dodged the issue a little when I wrote &quot;free time.&quot; The thing is, when I say &lt;em&gt;redistribute our free time&lt;/em&gt;, what I mean is redistribute our f**king wealth. If someone wants to have any part of their life free to do what they want, they need to have a store of wealth or a guaranteed income to give them that freedom. Right now, most of our country doesn't get that freedom until their 60s.&lt;/p&gt;

&lt;p&gt;There are a couple of big things to point out.   In 2017, according to &lt;a href=&quot;https://www.cnbc.com/2017/09/14/how-much-money-the-average-millennial-has-in-savings.html&quot;&gt;CNBC&lt;/a&gt; among 18 and 24 years old, 67 percent have less than $1,000 in their savings accounts and 46 percent had $0, and keep in mind that right now, those with college degrees will have an average of $30k in student debt. No one who starts their life in that state can risk &lt;strong&gt;anything&lt;/strong&gt;. They have to walk a razor thin tightrope to get from just-hanging-on to the prosperity our country mythologizes.&lt;/p&gt;

&lt;p&gt;Let me tell you my background because I was one of the tremendously lucky ones. When I was 22, I had $16k in debt. I had the opportunity to go to college, and I'd gotten through college with a physics, math, and comp sci education, graduating a semester early to save money and working 20+ hours every week plus working every summer since I was 13 (yes you &lt;a href=&quot;https://www.sj-r.com/article/20140718/NEWS/140719390&quot;&gt;can work at 13 in agriculture in Illinois&lt;/a&gt;). My mom had something like $20k in saving and a job that paid less than $20k per year, but my grandpa had managed to save a few thousand dollars to give me before he lost everything in one of those get-rich-quick Nigerian prince scheme. Then, over the past 10 years, I got a PhD, ramped up my income, and stored my money away to get to half a million dollars in the bank at 32.  I'm not saying this to brag, I'm saying this to point out what I've got and how I came to have it. &lt;/p&gt;

&lt;p&gt;So just now this year, I've gotten to the point where I feel I can finally breathe somewhat easily. I can get to the point where I can step back and take some chances with my life.  I can try to experiment with new things for myself using my time now, and I don't &lt;em&gt;even think&lt;/em&gt; about the fear of ending up homeless or worse anymore.&lt;/p&gt;

&lt;p&gt;Why shouldn't everyone in this country be able to expect that they can reach this level of freedom long before retirement age? Why should only those with the privilege of intergenerational wealth be afforded that opportunity?&lt;/p&gt;

&lt;h5&gt;Redistributing access to information networks&lt;/h5&gt;
&lt;p&gt;This one seems to be getting better with the introduction of the internet, but it's important not to lose sight of hurdles that still exist. Today someone can get exposed to the state-of-the-art in a bunch of fields, but there are still many fields where that information is slowed down just far enough that an outsider could never catch up.  In addition, due to the large number of people contributing in each field, the pace of advance is such that it becomes much harder to keep up fast enough to make any substantive contribution. Needless to say, fields shouldn't be shrunk or slowed down to accomadate the hobbyist. Instead, I think improvements in transparency in the process could help make a lot of the social mechanics of a field more transparent and give people more understanding of what's going on behind closed doors.&lt;/p&gt;

&lt;p&gt;On the other end, it isn't always possible to get the word out about outsider work. While our public platforms allow people to publicize their non-establishment ideas, there is still a strong establishment bias.  There are two sources of this. First, voices that have already been established in a field just fundamentally have an interest in crowding out new voices to maintain their own status.  Second, with the financial incentives of platforms and organizations, it is much more valuable to preferentially amplify people who can be expected to remain in the field for a long time. For example, it makes a lot more sense to invest in an author that will generate 15 books over a lifetime than one who writes 2 books and then moves on to mathematics or sculpture.&lt;/p&gt;

&lt;p&gt;For both of these issues, it seems the only fix is a cultural renaissance of the Renaissance Person. If it was customary for people to learn, progress, step back to make room, and then reform themselves in a new field, it'd be easier to accept new ideas and connections. &lt;/p&gt;

&lt;h4&gt;Conclusion&lt;/h4&gt;

&lt;p&gt;This post comes off as pretty prescriptive, but I just want to make sure it's clear that I don't think everybody should &lt;em&gt;have&lt;/em&gt; to do this.  I just think that being a Renaissance Person should be something that's available to everyone because it exemplifies the level of financial and social freedom that I think makes someone really free. Plus, I think a more well-rounded public with diverse experiences would really help us understand and accept each other better. &lt;/p&gt;

&lt;p&gt;*I refer to this as a Renaissance Person instead of the traditional Renaissance Man because (as if it needs to be said), women and non-binary persons could be equally capable and interested to pursue lots of things too.&lt;/p&gt;</description>
        <pubDate>Tue, 15 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/renaissance/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/renaissance/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>The Ongoing Process of a.ttent.io/n</title>
        <description>&lt;p&gt;I feel like my short story &lt;a href=&quot;/attention&quot;&gt;a.ttent.io/n&lt;/a&gt; will never be finished. But rather than fight that, I'm thinking perhaps I should embrace it as part of the core novelty of the medium I'm building.&lt;/p&gt;

&lt;p&gt;If I recall correctly, I came up with the core conceit of the novel sometime before I started grad school in 2010. I sketched out the different story arcs, but I languished with the problem that the whole story was just &lt;strong&gt;too big&lt;/strong&gt;. Then in the fall of 2017, I was chatting with a friend at a writing group who mentioned that she had decided to change her writing of a longer piece to compress it down to a short story.  For some reason, this suddenly clicked in my brain and I realized that part of the point of a/ttent.io/n was that humans were no longer connecting with long ponderous tomes.  Suddenly the pieces all fell into place, and I wrote the story (styled as Attention at the time) in a few weeks in November. I showed it to a few friends, and played with small tweaks for almost a year.&lt;/p&gt;

&lt;p&gt;Finally, in early 2019, I workshhopped it with a few more friends from the &lt;a href=&quot;https://www.meetup.com/SF-Writers-in-Their-20s/&quot;&gt;SF Writers in their 20s and 30s&lt;/a&gt; group (imho &lt;em&gt;the&lt;/em&gt; literary society of San Francisco).  That was when the next idea came.  As I got feedback from different people, I realized that there were clearly too many different opinions about what was &lt;em&gt;good&lt;/em&gt;. In the end, I didn't care what my author friends thought was good, I only cared what made them want to keep &lt;em&gt;paying attention&lt;/em&gt;. Hell, the whole thesis of a.ttent.io/n was that paying attention was the only point of &lt;em&gt;all&lt;/em&gt; stories.&lt;/p&gt;

&lt;h4&gt;Tracking a.ttent.io/n&lt;/h4&gt;

&lt;p&gt;At the same time, in my professional work at a Silicon Valley health-tech startup, I was frequently tasked with measuring what would make our customers pay attention to our product. The techniques I used (Funnel metrics, A/B testing) caused me to ask whether &quot;the perfect story&quot; should also be built with the same kinds of principles. At the very least, that was what the unreliable narrator of my story would think at least.&lt;/p&gt;

&lt;p&gt;As I began to approach a finished version of the story, I started building it into a website equipped with the types of tracking metrics that allows Google or Facebook to measure engagement.  Specifically, I built a page that measured how far down the &lt;a href=&quot;/2019/06/google-analytics-for-scrolling-on/&quot;&gt;reader had scrolled&lt;/a&gt;.  I put the page live on a few social networking sites, and as one might guess, most of the people who saw it read only a few words and then moved onto something else.  Such is the nature of the internet.&lt;/p&gt;

&lt;h4&gt;An open, evolving story&lt;/h4&gt;
&lt;p&gt;The story didn't get much traction, and I couldn't tell what was wrong. I had been making edits here and there to improve things, but I didn't know what really mattered.  So then in early 2020, I set about building a way to serve different versions to different visitors.  All-in-all I didn't learn too much from the experiments about what content was best because no matter what I did, no one read past the first chapter. &lt;/p&gt;

&lt;p&gt;So last month, I decided to do another rewrite. This time, I optimize ruthlessly for readability.  I cut the story in half, removed some characters and merged others, and reordered the structure to make stronger connections from one to the next. &lt;/p&gt;

&lt;p&gt;I'll be posting it again soon, and I hope that this time it really works. But even if it doesn't, I hope that the following three innovations I'm proposing get wider &lt;em&gt;attention&lt;/em&gt; themselves.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;tracking the fine grained attention patterns of readers&lt;/li&gt;
  &lt;li&gt;testing multiple permutations of the core story for readability and engagement&lt;/li&gt;
  &lt;li&gt;putting the editing process out in the public (my novel edit history is stored &lt;a href=&quot;https://github.com/tcruven/n/commits/master&quot;&gt;on github&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we are all a part of this world perfecting the story of what it is to be human, why not shorten the feedback loop and let reader's mind contribute too?&lt;/p&gt;

&lt;p&gt;&lt;small&gt;PS As I was writing this my partner read the story and came up with yet another great improvement so back to the drawing board...&lt;/small&gt;&lt;/p&gt;</description>
        <pubDate>Sun, 13 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/ongoing-attention/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/ongoing-attention/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>The Lisens: a license to simulate the sense of self</title>
        <description>&lt;p&gt;For the past year, my &lt;a href=&quot;https://will.stedden.org/2020/03/introducing-viewfoil-my-experiment-with.html&quot;&gt;viewfoil project&lt;/a&gt; has led me to expand my use of identity publication (aka social media) and consolidate my public technological identity footprint into &lt;a href=&quot;https://will.stedden.org/&quot;&gt;one portal&lt;/a&gt; online.  My long-term goal with the project is to form an artificial intelligence simulation of my personal online behavior. In other words, I aim to someday build an algorithm that can replicate and potentially replace the portion of my mind that generates behavioral artifacts on the internet.&lt;/p&gt;

But this forces me to ask a question:
&lt;blockquote&gt;
If I can pursue self-simulation with the data I am collecting, should any entity that comes into possession of such data be allowed to pursue a simulation of my mind?
&lt;/blockquote&gt;

&lt;p&gt;When researching this question, I realized that I couldn't find a very specific resolution to this in our current legal and ethical discussions about the intersection of data usage and sociological modeling.  To close that gap, I came up with the idea to intentionally license the ability for others to simulate my own consciousness, which I've dubbed &lt;strong&gt;the lisens&lt;/strong&gt;.&lt;/p&gt;

&lt;h5&gt;What would it mean to simulate consciousness?&lt;/h5&gt;

&lt;p&gt;What it means &lt;em&gt;to be oneself&lt;/em&gt; is one of the toughest questions to answer. Some current experiments simulating &lt;a href=&quot;https://lexfridman.com/deeptweets/&quot;&gt;public figures with AI&lt;/a&gt; makes us question where the line should be drawn. Is knowing how I might finish a sentence the same as knowing how I think?  Probably not. Truth be told, our current machine learning models are &lt;a href=&quot;https://www.theverge.com/2018/3/20/17138854/cambridge-analytica-facebook-data-trump-campaign-psychographic-microtargeting&quot;&gt;limited&lt;/a&gt; in their ability to replicate human decision making at all.  &lt;/p&gt;

&lt;p&gt;But this limitation won't necessarily be the case forever. As we increase our capacity to simulate people's behavior, some &lt;a href=&quot;https://www.space.com/41749-elon-musk-living-in-simulation-rogan-podcast.html&quot;&gt;notable&lt;/a&gt; &lt;a href=&quot;https://www.scientificamerican.com/article/are-we-living-in-a-computer-simulation/&quot;&gt;figures&lt;/a&gt; have begun to point out that a sufficiently elaborate &lt;a href=&quot;https://www.scientificamerican.com/article/do-we-live-in-a-simulation-chances-are-about-50-50/&quot;&gt;simulation&lt;/a&gt; could in fact start to take on properties of self-awareness that could make the lived experience of simulation and reality &lt;a href=&quot;https://en.wikipedia.org/wiki/Brain_in_a_vat&quot;&gt;indistinguishable&lt;/a&gt;. A form of this idea was evoked memorably in the Matrix films. &lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/t-Nz6us7DUA&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;There are many reasons&lt;a href=&quot;#reason&quot;&gt;*&lt;/a&gt; that such a simulation could be invented, but perhaps the most popular &lt;a href=&quot;https://en.wikipedia.org/wiki/Simulation_hypothesis#The_simulation_argument&quot;&gt;explanation&lt;/a&gt; would be that as our society improves our simulation techniques, we could start to build simulations that could reconstruct our past. As an example, imagine that a socioligist of the future is trying to figure out what the hell happened in 2020 so she builds a model for how every person in the country voted in this election. &lt;/p&gt;

&lt;p&gt;In the most extremely detailed simulation imaginable, the people simulated would actually feel as though they were really alive and making the decisions that you and I are making now. &lt;/p&gt;

&lt;h5&gt;The ethics of consciousness simulation&lt;/h5&gt;

&lt;p&gt;If all of this consciousness simulation sounds incredibly unethical that is because it certainly is. Of course, it becomes decidely less unethical if you can obtain &lt;a href=&quot;https://www.ama-assn.org/delivering-care/ethics/informed-consent&quot;&gt;informed consent&lt;/a&gt; from the person whose consciousness is to be simulated.  I assume that future researchers will be at least ethical enough to require this kind of consent, but this leads me to wonder whether there will be a lack of willing subjects from our era of history. In light of this, I asked myself whether it would be good idea to try to publicly declare my own consent to aid future researchers of human consciousness.&lt;/p&gt;

&lt;p&gt;This caused me to arrive at the concept of a lisens (license of sense of self). The exact content of the lisens is still a work-in-progress, but you can see the current contents on &lt;a href=&quot;https://will.stedden.org/lisens&quot;&gt;my personal website&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I will address my reasons for why I feel comfortable lisens-ing myself in another post. At the very least, I hope that publicizing my decision to adopt a lisens should raise awareness to future researchers that they should definitely NOT simulate anyone's mind without determining whether the person in question had adopted a lisens themselves. As deep-learning impersonation models improve over the next few years, this may become important sooner than one might expect.&lt;/p&gt;

&lt;p&gt;If you are thinking about adopting a lisens for yourself, please feel free to reach out to me.  If there is enough interest in this concept, I want to start to build an easily accessible &lt;a href=&quot;https://github.com/stedn/lisens-index&quot;&gt;index&lt;/a&gt; that could allow future researchers to find those who would be willing to participate in a future simiulation of themselves. Or, perhaps &lt;em&gt;the present&lt;/em&gt; simulation...&lt;/p&gt;

&lt;p id=&quot;reason&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;p &gt;&lt;small&gt;&lt;strong&gt;*PS:&lt;/strong&gt; I actually suspect the most likely reason for why we would be simulated would not be to simulate the past. I think a better explanation would be to validate whether consciousness simulations in the future work well by testing them on data from the past.&lt;/small&gt;&lt;/p&gt;</description>
        <pubDate>Sun, 13 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/lisens/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/lisens/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/profbonk_bg.png</image>
        <title>Prof Bonkerfield Joins the Ampled Co-op</title>
        <description>&lt;p&gt;This summer I started getting very interested in co-ops and the solidarity economy. A big place where I started to learn was during the &lt;a href=&quot;https://zebrasunite.mn.co/&quot;&gt;Zebras United&lt;/a&gt; Season of the Dazzle, which led to learning about &lt;a href=&quot;https://start.coop/&quot;&gt;start.coop&lt;/a&gt;. And while watching start.coop's 2020 grad class give their presentations, I learned about a very cool artist-ownership payment platform called &lt;a href=&quot;https://www.ampled.com/&quot;&gt;Ampled&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Ampled is a pretty straightforward replication of Patreon (or onlyfans), but the interesting part to me is that the business is built and run with the intention to keep the fan's funding in the artist's pockets.  This seems incredibly intuitive to me, and makes me feel like Ampled has a good shot at being one of those places that gets buy-in from consumers to cut-out the capitalist middle-man (I've also become even more anti-capitalist than I used to be thanks to them red rose Twitter lefties).  Since Ampled is trying their best to be an ethical worker-and-artist-owned enterprise, I've found myself, for the first time in my life, feeling pretty good about taking part in ponying up my own cash to provide support to artists.&lt;/p&gt;

&lt;p&gt;In addition to supporting a few artists, I also have started donating to support Ampled the platform itself.  The interesting part about this, is that as a platform supporter, I get to be part of Ampled's community owners who are allowed to jointly elect a few members to sit on their Board.  This is not unlike many member owned co-ops (eg REI), except that at the smaller scale of Ampled, there is still a decent chance that community members will be able to make some difference.&lt;/p&gt;

&lt;h4&gt;Adding my own music&lt;/h4&gt;
&lt;p&gt;Finally, probably the best part about learning about Ampled is that it has finally spurred me to start &lt;a href=&quot;https://prof.bonkerfield.org/&quot;&gt;putting my music online&lt;/a&gt; and developing a presence for my musician alter-ego (who I've named Prof Bonkerfield).  I've had a project written for a couple of years now that I've thought would be cool to record and put online, but I had never really felt like I had a good mechanism to record my own music. However, the subject matter of the first work I am recording is also deeply entwined with some of my feelings about anti-consumerism, which I think is really well-aligned with where I'm at in my adoption of the solidarity economy mindset.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/profbonk_bg.png&quot;/&gt;

&lt;p&gt;Also, the concept of the album seems pretty novel to me. I've written a whole series of works that seem like they come from a time and place in the Midwest folk/Americana scene, and I've tied them all together around a fictional set of events in Oklahoma. The story and music will be interwoven by Prof Bonkerfield in sort of an acadmeic talk meets online course. I plan to record it over this winter and while I do, I'll be recording a bit of the process on my Ampled page.  Should be an interesting experiment. &lt;/p&gt;

&lt;p&gt;And of course, if I can figure out how, I could even work with Ampled's API to embed some of that content back on the viewfoil.&lt;/p&gt;</description>
        <pubDate>Sat, 12 Dec 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/12/prof-bonkerfield-joins-ampled/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/12/prof-bonkerfield-joins-ampled/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/financial_model_graph.png</image>
        <title>Financial Modeling for a Foodtruck</title>
        <description>&lt;p&gt;As I'm trying to think through the business details for &lt;a href=&quot;https://worcfoods.com&quot;&gt;WORC Foods&lt;/a&gt;, I've been building simple models to try to estimate what the financial picture would look like for the food truck business.  I've found lots of blogs that give high level descriptions, but I haven't seen any that really get into the week-to-week operational costs.&lt;/p&gt;

&lt;p&gt;
    So to get a better picture of how much money would be required and how feasible our plan is, I put together &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1cYGITN9zTR1Qsl9zQoPbA2y2oi66G3BuH59JifmLpiA/edit?usp=sharing&quot;&gt;a spreadsheet&lt;/a&gt; that I hope could be useful to others who'd want to make similar estimates.
&lt;/p&gt;

&lt;h4&gt;Key Questions&lt;/h4&gt;
&lt;p&gt;
    There were a few key questions that I wanted to answer that I think might be useful to others.
&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;How much would we need to sell to break even?&lt;/li&gt;
    &lt;li&gt;How much investment would we need to not run out of money?&lt;/li&gt;
    &lt;li&gt;When would we be able to pay back investors?&lt;/li&gt;
    &lt;li&gt;How much income would our workers make?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    Beyond these, I also just wanted to be able to see how the week to week costs would look, assuming some seasonal fluctuation in sales and operational hours.
&lt;/p&gt;


&lt;h4&gt;Assumptions&lt;/h4&gt;
&lt;p&gt;
    Any financial model is going to have a lot of assumptions and approximations built into it.  And of course, there is huge variability in the viability of the project based on each of the assumptions and how they interact. So to make it more clear what I have going into this model, I'll just quickly summarize the assumptions that I've included.  The exact values in these tables are of course all just estimates.
&lt;/p&gt;
&lt;p&gt;
    The first set of assumptions are all around the costs of equipment, materials, and wages.
&lt;/p&gt;
&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/financial_model_costs.png&quot; alt=&quot;Spreadsheet of cost values&quot; /&gt;

&lt;p&gt;
    The second set are around how much money we'll make from sales and what the operating hours will look like.
&lt;/p&gt;
&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/financial_model_operations.png&quot; alt=&quot;Spreadsheet of operations values&quot; /&gt;
&lt;p&gt;
    Finally, I had to make some assumptions about how much investment we'd take, how much return the investors would expect, and (since we are setting up a cooperative) how we would return our profits to workers.
&lt;/p&gt;
&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/financial_model_investment.png&quot; alt=&quot;Spreadsheet of investment values&quot; /&gt;
&lt;p&gt;
    For each of these, I attempted to add sensisble estimates, but there's still a lot of uncertainty in each.
&lt;/p&gt;
&lt;p&gt;
    To keep the model flexible, I implemented it as a Google Sheet where the assumptions can be varied to see how each would effect the outcome. In the spreadsheet each row represents one week the columns are estimates of all the costs and revenues for that week.
&lt;/p&gt;


&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/financial_model_weekly.png&quot; alt=&quot;Spreadsheet of weekly costs and revenues&quot; /&gt;

&lt;h4&gt;Model Results&lt;/h4&gt;
&lt;p&gt;
    With a particular set of assumptions, I could plot the expected revenue, costs, cash on hand, and investment returns.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/financial_model_graph.png&quot; alt=&quot;Graph of cumulative revenue, costs, cash on hand, investment returns&quot; /&gt;
&lt;p&gt;
    In the example below you can see the seasonal variability in the cash on hand due to the expected seasonal variation expected from tourism in my area. Importantly, in this scenario, cash on hand never goes negative. I measured a few of the key metrics for this projection.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/financial_model_metrics.png&quot; alt=&quot;Table with key metrics&quot; /&gt;

&lt;p&gt;
    Under these assumptions, two workers running the food truck would be able to make an average of $53k/year over a five year period, though a good deal of that compensation comes later after the initial investment is paid off.
&lt;/p&gt;

&lt;p&gt;
    The minimum cash on hand would be $6k, which, admittedly, would be pretty tight, and wouldn't allow much margin for error. By varying, the base sales amount, I was able to find that if we don't sell an average of 18 items per operating hour, then we would run out of money early on, and need to negotiate a longer investment paypack period to stay cash flow positive.
&lt;/p&gt;

&lt;p&gt;
    You can check out the results in more detail in the &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1cYGITN9zTR1Qsl9zQoPbA2y2oi66G3BuH59JifmLpiA/edit?usp=sharing&quot;&gt;publicly available spreadsheet&lt;/a&gt;. Keep in mind that this is very much a living document, and we will be continuing to update it as we understand more.
&lt;/p&gt;

&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;
    The overall outlook for WORC Foods looks good based on these results. However, the outcome relies heavily on the underlying assumptions plugged into the model.
    Since I'm still unsure of the plausibility of some of my assumptions, I hesitate to say with certainty that I think this business will work.
    Nevertheless the results thus far leave me cautiously optimistic, and they set the stage for more refined predictions as more details come to light.
&lt;/p&gt;
&lt;p&gt;
    Having this model, I'm more prepared to go over some of the assumptions and timelines with my friends and advisors. At some point, I'd also like to build a slightly more advanced financial simulations that take uncertainty into account, but that will have to wait for another time.
&lt;/p&gt;
&lt;p&gt;
    If you think you see a problem and could help make this more useful, please &lt;a href=&quot;https://will.stedden.org&quot;&gt;contact me&lt;/a&gt;, or send a message to &lt;a href=&quot;https://worcfoods.com/#footer&quot;&gt;WORC Foods&lt;/a&gt;.
&lt;/p&gt;</description>
        <pubDate>Sat, 10 Oct 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/10/food-truck-financial-model/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/10/food-truck-financial-model/</guid>
        
        <category>analysis</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/road_animation.gif</image>
        <title>WORC Foods website animation</title>
        <description>&lt;p&gt;
     A few weeks ago, while talking about my &lt;a href=&quot;/su_chef&quot;&gt;startup idea&lt;/a&gt;, someone asked me if I had a website yet.  I figure it would make it easier to explain what I'm trying to do if I had a site to point to so last week I put one together.
&lt;/p&gt;

&lt;p&gt;
    While working on it, I realized that I'd really like a simple visual that instantly explained the gist of the idea I'm working on. I originally experiemented with a technical diagram, but I thought it looked a little too stiff for a company that is really focused on the impact we will have on people.
&lt;/p&gt;

&lt;p&gt;
    So instead, I wanted to make a more cartoonish characterization of the project.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/road_animation.gif&quot; alt=&quot;foodtruck with robot inside making salads&quot;/&gt;

&lt;p&gt;
    I think I definitely hit cartoonish. Honestly, this might be one of the most whimsical things I've built around here for a long while.  It clearly still needs work, but for now, I think it gets the scrappy, unpolished, campy, mad-scientist vibe that I personally want the company to embody.
&lt;/p&gt;

&lt;p&gt;
    It feels very not-tech, which makes me happy. Hopefully others feel the same.
&lt;/p&gt;

&lt;h4&gt;Building the Animation&lt;/h4&gt;

&lt;p&gt;
    The cool thing about this animation was how much of it was done programmatically.  I honestly, don't have the patience to animate something like that by hand. It combined four different elements that I had to make in stages.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Animate the robot arm&lt;/li&gt;

&lt;li&gt;Draw the truck&lt;/li&gt;

&lt;li&gt;Add the arm and plates to the truck image&lt;/li&gt;

&lt;li&gt;Add the truck to the background&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
    For the first step, I had to find some way to animate a robot arm lifting and rotating.  All of my attempts to hand draw one failed miserably so I decided to just animate that element in 3D. To do that, I grabbed the parts from &lt;a href=&quot;https://www.tinkercad.com/things/5gaWJeeW7hr-copy-of-robotic-arm-edge-3312016/edit&quot;&gt;this Tinkercad file&lt;/a&gt;, and animated them in Blender.  The output images from that looked something like this.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/arm_comic.gif&quot; alt=&quot;robot arm going through motion&quot;/&gt;


&lt;p&gt;
    The only somewhat actually artistic part that I did was modifying &lt;a href=&quot;https://vector.me/browse/345850/cm_isometric_yellow_van&quot;&gt;this van image&lt;/a&gt; to have a pile of veggies and some people inside.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/truck_animator_tst.svg&quot; alt=&quot;foodtruck with robot inside making salads&quot;/&gt;

&lt;p&gt;
    After drawing the truck as it's own &lt;code&gt;svg&lt;/code&gt;, I wrote some code to modify the elements of the truck image and save them as separate output &lt;code&gt;png&lt;/code&gt; images.
&lt;/p&gt;

&lt;p&gt;
    Then in my script, I copy the truck images into the correct location in the background image, and crop the image to give it the illusion that the background is moving while the truck stays in the middle.
&lt;/p&gt;

&lt;p&gt;
    As the last step, I convert from many &lt;code&gt;png&lt;/code&gt; images into a single animated &lt;code&gt;gif&lt;/code&gt;.
&lt;/p&gt;

&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;The code for adding in the animations is &lt;a href=&quot;https://github.com/stedn/worc-site/blob/main/make_animation.py&quot;&gt;here&lt;/a&gt; if you are needing to do something similar. It's highly under-documented so please &lt;a href=&quot;https://will.stedden.org&quot;&gt;reach out&lt;/a&gt; if you need to understand it.&lt;/p&gt;

&lt;p&gt;And if you have a minute, check out the website I made this animation for at &lt;a href=&quot;https://worcfoods.com&quot;&gt;worcfoods.com&lt;/a&gt;. I'd love to hear what you think.&lt;/p&gt;</description>
        <pubDate>Thu, 10 Sep 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/09/worc-animation/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/09/worc-animation/</guid>
        
        <category>animation</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/suchef_overhead.jpg</image>
        <title>su_chef slices</title>
        <description>&lt;p&gt;
    My &lt;a href=&quot;/su_chef&quot;&gt;&lt;code&gt;su_chef&lt;/code&gt; robotics project&lt;/a&gt; is coming along, and I've finally gotten to the point where I can actually slice vegetables.  It's still a little finicky, but the arm can identify vegetables, pick them up, drop them into a slicer, and then slice them. Check it out in action.
&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;420&quot; alt=&quot;robot arm drops tomato into meat slicer. meat slicer tray moves back and forth&quot; src=&quot;https://www.youtube.com/embed/g6uELSKyPFU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
    This feels like such a huge milestone, and I'm kind of shocked that I got it working. I know I'm still far away from a robust functional prototype, but now, for the first time, I'm starting to actually believe that this idea might really happen.
&lt;/p&gt;

&lt;p&gt;
    If you're interested in setting up a similar system, you can check out the instructions and code &lt;a href=&quot;https://github.com/lots-of-things/su_chef&quot;&gt;here&lt;/a&gt;.  In the rest of this post, I'm going over the build details for the slicer control.
&lt;/p&gt;


&lt;h4&gt;Building the Slicer&lt;/h4&gt;

&lt;p&gt;Aside from some fine tuning my previous &lt;a href=&quot;&quot;&gt;arm controller&lt;/a&gt; and &lt;a href=&quot;&quot;&gt;object detection algorithm&lt;/a&gt;, the only new component that I added to the &lt;code&gt;su_chef&lt;/code&gt; was the slicing apparatus. To build it, I combined a kitchen meat slicer, a motor and carriage from a broken printer, and an Arduino based relay.&lt;/p&gt;

&lt;p&gt;The printer carriage and motor move the slicer tray back and forth. They're attached to the meat slicer with a little wood brace that I built to fit around the base of the slicer.&lt;/p&gt;
&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2020/slicer_view1.jpg&quot; alt=&quot;Slicer carriage&quot; width=&quot;40%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2020/slicer_view2.jpg&quot; alt=&quot;Slicer carriage attached&quot; width=&quot;40%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt;
    The motor just turns a band in chassis, which moves the carriage back and forth.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/slice_manual.gif&quot; alt=&quot;slicer tray slides under power&quot;/&gt;

&lt;p&gt;
    To control the slicer tray, I connected the motor to a relay that was controlled by an Arduino.  The relay circuit looks like the following.
&lt;/p&gt;

&lt;a href=&quot;https://quasarelectronics.co.uk/dc-motor-reversing-circuits-automatic-remote-control&quot;&gt;&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/reversible-dc-motor-using-2-relays.gif&quot; alt=&quot;reversible relay circuit&quot;/&gt;&lt;/a&gt;

&lt;p&gt;
    The pair of relays hooked up in this manner is required so that current can flow either direction depending on which way the relays are switched.  This lets the DC motor run backwards and forwards so the tray can move both ways.
&lt;/p&gt;
&lt;p&gt;
    To keep the motor from ramming the sides, I also added two small &quot;fail-safe&quot; switches in the track.  These will send a signal if the motor runs into them, informing the controller that the motor shouldn't push any further in that direction.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/failsafe_switch.jpg&quot; alt=&quot;failsafe switch&quot;/&gt;

&lt;h4&gt;Controlling the slicer tray motion&lt;/h4&gt;

&lt;p&gt;
    To trigger the motion of the tray, I have to control the relays. To do this, I use a bit of Arduino code that can be found &lt;a href=&quot;https://github.com/lots-of-things/su_chef/blob/main/scripts/relay.ino&quot;&gt;here&lt;/a&gt;.  The code flips the relays on for a preset time, but also checks if the fail-safe switches are triggered and closes the relays if that happens.
&lt;/p&gt;


&lt;p&gt;
    Finally, I also added some ROS specific code to the Arduino that listens over the serial connection to trigger the slice.  In my &lt;a href=&quot;https://github.com/lots-of-things/su_chef/blob/6aace233b80e2e50d8bda6f88f7625671942e5c3/scripts/target_object.py#L484&quot;&gt;python control script&lt;/a&gt;, I send the &lt;code&gt;&quot;go&quot;&lt;/code&gt; message whenever I want the slicer to go back and forth one time.
&lt;/p&gt;
&lt;img width=&quot;25%&quot; src=&quot;/assets/images/2020/slice_relay.gif&quot; alt=&quot;slicer tray slides with relay&quot;/&gt;


&lt;h4&gt;Next Steps&lt;/h4&gt;
&lt;p&gt;
    Thus far, the whole thing is very fragile, but my next step to get to v0.3.0 is to update the pickup part to make it better able to lift things in more orientations.  Also, I want to put in some checks that make sure the prior task completes before the next begins and aborts if something is going wrong.  Eventually, I know I will need to upgrade to a more precise arm, but I'm going to push as far as I can with the current one first.
&lt;/p&gt;

&lt;p&gt;
    In the meantime, I am starting to work on organizing a worker-owned company around this project, which I'm calling WORC Foods for Worker-Owned Robotics Cooperative Foods. You can read more about it on &lt;a href=&quot;https://worcfoods.com&quot;&gt;our website&lt;/a&gt;. If you are at all interested in cofounding such a venture, please &lt;a href=&quot;https://will.stedden.org/&quot;&gt;reach out&lt;/a&gt;!
&lt;/p&gt;
</description>
        <pubDate>Wed, 02 Sep 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/09/su-chef-slices/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/09/su-chef-slices/</guid>
        
        <category>robots</category>
        
        <category>code</category>
        
        <category>electronics</category>
        
        <category>su_chef</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/braccio_pick_demo.gif</image>
        <title>Simulating the Braccio robotic arm with ROS and Gazebo</title>
        <description>&lt;p&gt;
    As I'm continuing to build my &lt;a href=&quot;/su_chef&quot;&gt;&lt;code&gt;su_chef&lt;/code&gt; robotic food prep project&lt;/a&gt;, I've realized it will be more efficient to design and prototype using robotics simulations.  So last weekend, I took a deep dive into integrating motion planning via &lt;a href=&quot;https://moveit.ros.org/&quot;&gt;ROS MoveIt&lt;/a&gt; with the &lt;a href=&quot;http://gazebosim.org/&quot;&gt;Gazebo physics simulator&lt;/a&gt; using a virtual model of my &lt;a href=&quot;https://store.arduino.cc/usa/tinkerkit-braccio&quot;&gt;Arduino Braccio&lt;/a&gt; arm.  Using these tools, I'm able to simulate my robot interacting with objects to quickly test how it will work without needing to have my physical setup running.
&lt;/p&gt;

&lt;p&gt;
    In this demo, you can see the arm grabbing and moving the red block and the blue bowl.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_pick_demo.gif&quot; alt=&quot;Simulated robot arm moves red block and blue bowl around.&quot;/&gt;

&lt;p&gt;
    The red block is a stand-in for the vegetables that I will eventually want the &lt;code&gt;su_chef&lt;/code&gt; to pick for chopping. Rolling down a ramp into a bowl is a major simplification of the actual process, but I thought I would first make a simplified package so that others could reuse it and have an easier time getting started simulating with the Braccio arm and Gazebo.
&lt;/p&gt;
&lt;p&gt;
    I wasn't able to find anyone else's working simulator for the Braccio so I combined &lt;a href=&quot;https://github.com/CesMak/kuka_arm&quot;&gt;bits&lt;/a&gt; from &lt;a href=&quot;https://github.com/berkeleyopenarms/blue_moveit&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://github.com/jonabalzer/braccio_moveit_config&quot;&gt;other&lt;/a&gt; &lt;a href=&quot;https://github.com/dpakshimpo/braccio-study&quot;&gt;examples&lt;/a&gt; I found.  I built a very bare-bones command line program that controls the robotic simulator to make it easier to use right off the bat.
&lt;/p&gt;
&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/cmd_line_welcome.png&quot; alt=&quot;ASCII splash screen for Arduino Braccio Pick+Drop Simulator.&quot;/&gt;

&lt;p&gt;
    If you'd like to jump into using it, the code and instructions are &lt;a href=&quot;https://github.com/lots-of-things/braccio_moveit_gazebo&quot;&gt;available here&lt;/a&gt;. Below I've describe how arm is able to determine where to pick up, as well as some testing I did to see how often the arm succeeds at its task.
&lt;/p&gt;

&lt;h4&gt;The Inverse Kinematics solver&lt;/h4&gt;

&lt;p&gt;
    Since the Braccio arm is fairly small and simple, it has a limited domain where it's able to pick up items.  To overcome this, I needed to program the ability to pick up from above and from the side, as well as subroutines that reposition the block if it's outside of the graspable region.
&lt;/p&gt;
&lt;p&gt;
    The problem is that the arm itself is controlled by its joint angles so there is no direct way to tell it to go to a certain point in space. Instead, I had to compute what the arm's angles should be given a target location and orientation.  Working out the direction to turn the arm's base is fairly easy, but it is more difficult to figure out how to adjust the shoulder, elbow, and wrist angles to get to a specific distance from the base, labeled &lt;i&gt;r&lt;/i&gt; in this image.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/braccio_dimensions.png&quot; alt=&quot;Braccio arm calculations&quot; /&gt;
&lt;p&gt;
    In my &lt;a href=&quot;/2020/07/su-chef-braccio-yolo/&quot;&gt;previous version&lt;/a&gt; I just hard coded the equation to determine the angles needed for a given position.  However, this isn't ideal because (a) it's a lot of messy math to debug, and (2) this limits me to exactly 1 solution when really there are many acceptable solutions within a small window around the exact solution. To do this more generally, I needed an &lt;a href=&quot;https://en.wikipedia.org/wiki/Inverse_kinematics#:~:text=In%20computer%20animation%20and%20robotics,the%20start%20of%20the%20chain.&quot;&gt;inverse kinematics&lt;/a&gt; (IK) solver. There are existing robotic arm inverse kinematics solvers, but most of them work on 6 degree-of-freedom (DOF) arms, while the Braccio only has 5 DOF.  This doesn't sound like a huge difference, but it means that the Braccio is actually highly constrained in the range of poses that it can take, which breaks most standard IK solvers.
&lt;/p&gt;
&lt;p&gt;
    So for this attempt, I switched to using a simple 2D IK solver based on &lt;a href=&quot;https://studywolf.wordpress.com/2013/04/11/inverse-kinematics-of-3-link-arm-with-constrained-minimization-in-python/&quot;&gt;this post&lt;/a&gt; from &lt;a href=&quot;https://twitter.com/northproof&quot;&gt;Travis DeWolf&lt;/a&gt;.  This solver aims to get the arm as close to the target point as posibble while maintaining allowed angle restrictions and certain height restrictions to keep it the right distance from the ground.  If you'd like to know more about how it works, I suggest Travis's &lt;a href=&quot;https://studywolf.wordpress.com/2013/04/11/inverse-kinematics-of-3-link-arm-with-constrained-minimization-in-python/&quot;&gt;blog post&lt;/a&gt; or check out &lt;a href=&quot;https://github.com/lots-of-things/braccio_moveit_gazebo/blob/965d95dbb96f9e418582252e8bc2ea056ab9b532/braccio_moveit_gazebo/scripts/target_object_sim.py#L477&quot;&gt;the working solver code&lt;/a&gt; in my simulation package.
&lt;/p&gt;
&lt;h4&gt;Performance&lt;/h4&gt;
&lt;p&gt;
    It took a few days of fine-tuning and retesting to get both the physics and the robot measurements worked out to the point where it was working consistently. Once I had it working somewhat consistently, I collected data on many trials sequentially to see how it performs.  I reset the block to random positions, and then attempt to pick it it up.
&lt;/p&gt;
&lt;p&gt;
    For the &quot;top&quot; picker the success rate was about 50%, while for the &quot;side&quot; picker it was only 33%.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/braccio_gazebo_analysis_2.png&quot; alt=&quot;Success vs failure counts&quot; /&gt;
&lt;p&gt;
    At first, I assumed that there were probably consistent regions where it was failing, but after plotting the start positions of each, I couldn't see any real pattern.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_gazebo_analysis_3.png&quot; alt=&quot;Success vs failure locations&quot; /&gt;

&lt;p&gt;
    As you can see from this longer video there are a lot of ways to mess up.
&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/uwx_z1y-S3I&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
    After a little more digging, it became clear that the main problem was the sliding phase. Since the range of motion is so constrained there were only two narrow bands where the pick up was successful.  So if the block starts outside of that area, it needs to be slid back into that area first.  For the successful attempts, they all get into the pickup range correctly. In the figure on the right, you can see the two areas where the arm can reach to pick up.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_gazebo_analysis_4.png&quot; alt=&quot;Success locations top vs side&quot; /&gt;

&lt;p&gt;
    For a little more analysis check out &lt;a href=&quot;https://github.com/lots-of-things/braccio_moveit_gazebo/blob/main/braccio_moveit_gazebo/scripts/results_analysis.ipynb&quot;&gt;this notebook&lt;/a&gt;.
&lt;/p&gt;

&lt;h4&gt;Next steps&lt;/h4&gt;
&lt;p&gt;
    I could definitely optimize this further, but I figured it would be more valuable to wait until I have a more specific environment for my &lt;a href=&quot;/su_chef.html&quot;&gt;&lt;code&gt;su_chef&lt;/code&gt; design&lt;/a&gt;.  But I figured I'd release this playground package for Arduino and ROS hackers like me to work with.
&lt;/p&gt;

&lt;p&gt;
    If you are interest in making it work better, always feel free to &lt;a href=&quot;https://will.stedden.org/&quot;&gt;contact me&lt;/a&gt; or submit issues and pull requests&lt;a href=&quot;https://github.com/lots-of-things/braccio_moveit_gazebo&quot;&gt;on Github&lt;/a&gt;.  And if you want to hear more about &lt;code&gt;su_chef&lt;/code&gt; and my dream to start a worker-owned automated foodtruck follow me on &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;Mastodon&lt;/a&gt; or check out my newsletter below for updates.
&lt;/p&gt;
</description>
        <pubDate>Wed, 12 Aug 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/08/braccio-moveit-gazebo/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/08/braccio-moveit-gazebo/</guid>
        
        <category>robots</category>
        
        <category>code</category>
        
        <category>analysis</category>
        
        <category>su_chef</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/yolo_veggie_still.png</image>
        <title>Updating su_chef object detection with custom trained model</title>
        <description>&lt;p&gt;As part of my &lt;a href=&quot;/su_chef.html&quot;&gt;su_chef project&lt;/a&gt;, I needed to expand the camera object detection model to include more classes that I am interested in. Originally, I was using the standard YOLOv3 weights file from &lt;a href=&quot;https://pjreddie.com/darknet/yolo/&quot;&gt;pjreddie's original&lt;/a&gt;.  That model has 80 classes that it can identify, but unfortunately, most of them weren't really useful for my use case of finding and picking up fruits and vegetables.&lt;/p&gt;

&lt;p&gt;So last weekend, I learned how to fine-tune a YOLOv3 model using my own custom image dataset. It would be impractically slow to train the neural net on my personal computer without a GPU so I used Google Colab to train using their free GPUs.&lt;/p&gt;

&lt;p&gt;For the code, I packaged up a &lt;a href=&quot;https://github.com/lots-of-things/yolo-colab-simple&quot;&gt;tutorial repo&lt;/a&gt; (based on &lt;a href=&quot;https://github.com/kriyeng/yolo-on-colab-notebook
&quot;&gt;this one&lt;/a&gt;) that pulls in training data from Google Drive, trains, and then stores trained model directly back into my Google Drive. I also included my example data and a test script to make it easier for others.  If you want to try it yourself or adapt it, clone &lt;a href=&quot;https://github.com/lots-of-things/yolo-colab-simple&quot;&gt;the repo&lt;/a&gt;, copy it to your Google Drive, and follow the instructions in the &lt;code&gt;README.md&lt;/code&gt; file.
&lt;/p&gt;

&lt;p&gt;Read on to see how it performed for my task.&lt;/p&gt;

&lt;h4&gt;Initial Results&lt;/h4&gt;

&lt;p&gt;To start, I just used some previously annotated data from Google's &lt;a href=&quot;https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&amp;type=detection&amp;c=%2Fm%2F0jg57&quot;&gt;OpenImages project&lt;/a&gt; to get a dataset that includes apples, tomatoes, and bell peppers. After training for 2500 iterations it was doing a fair job at distinguishing between the three on example images like this.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/yolo_first_results.png&quot; alt=&quot;Apple Tomato and Bell Pepper properly distinguished by YOLO model&quot; /&gt;

&lt;p&gt;Importantly, because I'm using the Darknet implementation, detection still works in near real-time even on my crappy CPU machine.  I incorporated this new model into my &lt;a href=&quot;https://github.com/lots-of-things/ros_braccio_opencv_obj_detect_grab&quot;&gt;ros_braccio_opencv_obj_detect_grab repo&lt;/a&gt; and ran just the detection subroutine. It does a decent job of distinguishing between the three.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/apple_pepper_tomato_realtime.gif&quot; alt=&quot;Apple Tomato and Bell Pepper properly distinguished by YOLO model&quot; /&gt;

&lt;p&gt;It isn't quite perfect though, particularly with distinguishing the bell pepper from the tomato. And when I use the new model with the overhead cam and try to pick things up, the performance is markedly worse.  Particularly, as shown in this example, the apple is almost always identified as a tomato and the tomato is often mistaken for bell pepper.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/yolo_fail.gif&quot; alt=&quot;YOLO model failing and misidentifying objects&quot; /&gt;

&lt;p&gt;Overall, this made the results unsatisfactory. I kept training for more than 3k iterations but the avg loss had stopped improving on the test set, and there wasn't a noticeable improvement. I could take some time and quantify this, but I'm not writing a paper here, I'm just trying to pick up some veggies. I suspect the main failure is coming from the difference between my training data and the images that the overhead cam is providing since the annotated images are much higher quality than webcam images in my actual setup.  &lt;/p&gt;

&lt;h4&gt;Adding more and better training data&lt;/h4&gt;

&lt;p&gt;
    To improve my performance I've begun adding more manually annotated data. During this process I learned something about myself.
&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;You know you&amp;#39;ve found a machine learning project you love when you are willing to annotate your own data.&lt;/p&gt;&amp;mdash; Will Stedden (@bonkerfield) &lt;a href=&quot;https://sigmoid.social/@bonkerfield/status/1288267178672705536?ref_src=twsrc%5Etfw&quot;&gt;July 29, 2020&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;


&lt;p&gt;
    I took pictures directly from the overhead cam using the fruits and vegetables that we had in the house. Even after just adding just 40 images and retraining for 2k more iterations, I'm seeing some qualitative improvement.  Here's a hand-picked (pun intended) example.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/yolo_custom_data.png&quot; alt=&quot;Comparison of YOLOv3 object detection of apples before and after training with custom data. Before: 4 apples are detected as tomato. After: 2 are detected as apple and other two are missed.&quot; /&gt;

&lt;p&gt;
    There will always be room for improvement on this type of model, but this is good enough for me for now. I'll continue fine-tuning as needed.
&lt;/p&gt;

&lt;h4&gt;Next steps&lt;/h4&gt;
&lt;p&gt;
    At least for now, this lets me update my pickup script to allow targeting of specific objects, which will enable the next phase. As outlined in &lt;a href=&quot;/2020/07/su-chef-braccio-yolo/&quot;&gt;my last post&lt;/a&gt;, the next steps are going to be building my veggie slicer and moving around bowls under the slicer.  I've already started on the design of the slicer and I hope to spin that up by end of next week.
&lt;/p&gt;

</description>
        <pubDate>Thu, 23 Jul 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/07/yolo-colab-veggie-identifier/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/07/yolo-colab-veggie-identifier/</guid>
        
        <category>robots</category>
        
        <category>cooking</category>
        
        <category>su_chef</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/braccio_summary.gif</image>
        <title>su_chef prototype 1: My robotic arm that detects apples and picks them up</title>
        <description>&lt;p&gt;
    In my &lt;a href=&quot;/2020/07/automated-foodtruck-idea/&quot;&gt;previous post&lt;/a&gt;, I described my idea to start a worker-owned automation company by building a robotic food truck. I've started designing the interior of the truck and simulating it, but before I finish that, I wanted to get some experience working with a functional robotics tech stack.
&lt;/p&gt;

&lt;p&gt;
    After consulting with &lt;a href=&quot;https://github.com/jmichaux&quot;&gt;my friend&lt;/a&gt; who is getting a PhD in robotics, he suggested I get my feet wet by building a sous-chef. I thought that was perfect! But it's not &lt;strong&gt;sous&lt;/strong&gt; (meaning under in french), it's &lt;strong&gt;su&lt;/strong&gt; (meaning substitute user in Unix-speak).
&lt;/p&gt;

&lt;h2&gt;su_chef v0.1.1&lt;/h2&gt;

&lt;p&gt;
    Thanks to the amazing open source ROS and Arduino communities, it took me a little over a week to go from just parts and an idea to this functioning prototype.
&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;400&quot; style=&quot;margin-bottom:10px;&quot; src=&quot;https://www.youtube.com/embed/y_R0t8rGT8o&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
    The Arduino Braccio arm works pretty well for the task and was fairly easy to set up. The ROS stack was more complex to set up but it allowed me to leverage a number of existing project and combine them. Finally, the reason that this project is (comparatively) cheap and easy to produce is that it is operating on a single surface. All the objects for detection are on the same plane so it becomes much easier to calibrate a mapping from a 2D image without the need for a fancy depth-aware camera.
&lt;/p&gt;

&lt;p&gt;
    In the rest of this post I'll break down how the project works at a high level. But if you want to build it yourself and see how to run it, you can go straight to the instructions in my &lt;a href=&quot;https://github.com/lots-of-things/ros_braccio_opencv_obj_detect_grab&quot;&gt;source repository&lt;/a&gt;.
&lt;/p&gt;


&lt;h2&gt;Project Build&lt;/h2&gt;

&lt;p&gt;
    To connect the many parts of a production automation stack, robotics engineers will often use some kind of framework to coordinate tasks. For this project, I used an open source robotics operating system called &lt;a href=&quot;http://wiki.ros.org/ROS/Introduction&quot;&gt;ROS&lt;/a&gt; (Robot Operating System).
&lt;/p&gt;
&lt;p&gt;
    The amazing thing about how ROS works is that messages from many different subtasks are passed through a shared communication system. So essentially, I just take usb images with one interface, pass them to a script for image detection, pass the output detections to a control script, and pass the control instructions to the Arduino. Importantly, all of those subtasks run independently with messages passing back and forth, and I don't have to deal with any of the communication handling.  It's kind of magical.
&lt;/p&gt;

&lt;p&gt;
    Here is a diagram of the system architecture for this project.
 &lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_pipeline.png&quot; alt=&quot;Braccio system architecture&quot;/&gt;

&lt;p&gt;
    In the following sections I'll go over some of the main components.
&lt;/p&gt;

&lt;h4&gt;Braccio Arm build&lt;/h4&gt;
&lt;p&gt;For this project, I used a 5 degree-of-freedom (5 DOF) robotic arm called the &lt;a href=&quot;https://store.arduino.cc/usa/tinkerkit-braccio&quot;&gt;Arduino Braccio&lt;/a&gt;.  The arm is driven by an Arduino Uno which can be controlled from my laptop via a USB cable. The arm came with an end gripper that is capable of picking up objects of at least 1kg. It cost less than $250 and took about an hour to put together.&lt;/p&gt;

&lt;div style=&quot;text-align:center;margin-left:auto;margin-right:auto;&quot;&gt;
&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2020/20200714_175448.jpg&quot; alt=&quot;Braccio parts&quot; width=&quot;50%&quot;/&gt;

&lt;img style=&quot;display:inline;&quot; src=&quot;/assets/images/2020/20200714_201821.jpg&quot; alt=&quot;Braccio mostly assembled&quot; width=&quot;28%&quot;/&gt;
&lt;/div&gt;
&lt;p&gt; The Arduino library for Braccio comes with basic tests that run directly on the Arduino to ensure that motors work.&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/braccio_simple.gif&quot; alt=&quot;Braccio example motion&quot; width=&quot;40%&quot;/&gt;

&lt;p&gt;
    The Braccio Library demo program could control the motors with preprogrammed positions, but they didn't provide an interface to control the Braccio with external inputs.  For that I turned to existing ROS packages which worked by sending messages over the USB &lt;code&gt;/dev/ttyACM*&lt;/code&gt; port.
&lt;/p&gt;

&lt;h4&gt;Braccio Arm control with ROS RViz and MoveIt&lt;/h4&gt;

&lt;p&gt;
    I found a ROS-based &lt;a href=&quot;https://github.com/ohlr/braccio_arduino_ros_rviz&quot;&gt;project&lt;/a&gt; that allowed direct joint position control for the Braccio using RViz to vizualize its &lt;a href=&quot;https://industrial-training-master.readthedocs.io/en/melodic/_source/session3/Intro-to-URDF.html&quot;&gt;URDF&lt;/a&gt;. However, this project didn't easily show how to do motion planning or programmatic control so I combined that with another &lt;a href=&quot;https://github.com/zakizadeh/ros_braccio_moveit&quot;&gt;project&lt;/a&gt; that integrated with ROS MoveIt to allow connection through MoveIt's python interface. This subcomponent can be tried out in simulation using just RViz and an included URDF file.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_rviz.gif&quot; alt=&quot;Braccio motion simulated with RViz&quot; /&gt;

&lt;p&gt;
    When connected to the real Braccio arm this allowed me to directly program a few basic motions to pick up items.
&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/tSzIZNoPe3g&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
    However, this method required manual specification of the arm position for each item to pick up, which isn't at all useful for grabbing and passing arbitrarily position items.  For that I needed to add image detection.
&lt;/p&gt;

&lt;h4&gt;OpenCV image detection integrated with ROS&lt;/h4&gt;

&lt;p&gt;
    Again, I combined a few projects together here.  I started with a project called &lt;a href=&quot;https://braccio-camai.readthedocs.io/en/latest/&quot;&gt;Braccio CamAI&lt;/a&gt; that was set up to use webcam object detection to control the Braccio. Unfortunately, the code relied on a standalone Edge TPU to run the image detection algorithm, which was expensive and a bit overkill for the task in my opinion.  I didn't want to buy one of those so I converted the modeling task over to OpenCV's YOLOv3 implementation based on &lt;a href=&quot;https://github.com/arunponnusamy/object-detection-opencv&quot;&gt;this project&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
    The &lt;a href=&quot;https://medium.com/@ODSC/overview-of-the-yolo-object-detection-algorithm-7b52a745d3e0&quot;&gt;YOLO object detection algorithm&lt;/a&gt; applies a deep neural network to the image and identifies bounding boxes around any objects in the image that it is trained to recognize. The best thing about it is that it runs on the whole image just one time (hence the name You Only Look Once). This makes it fast enough that it can make repeated detections on streaming video even just on my wimpy CPU. For my purposes I started with a pre-trained model that had been trained with the capacity to identify apples amongst other things.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_detection.png&quot; alt=&quot;Apple Detected with OpenCV YOLOv3&quot; /&gt;

&lt;h4&gt;Calibration and Transformation&lt;/h4&gt;

&lt;p&gt;
    The final and most difficult piece was the connection between image detection and Braccio control. This requires both transformation of object location from the image frame into a frame relative to the arm, and tranformation from desired arm grasping location into joint angles for the motors.
&lt;/p&gt;

&lt;p&gt;
    To compute the mapping from image to real space, I designed a calibration protocol that moved the arm to various locations and then required me to click the location in the image. I recorded the locations of these points in image space and then used OpenCv's &lt;code&gt;cv2.findHomography&lt;/code&gt; and &lt;code&gt;cv2.perspectiveTransform&lt;/code&gt; functions. You can find more information on using those for python &lt;a href=&quot;https://docs.opencv.org/3.4/d1/de0/tutorial_py_feature_homography.html&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://stackoverflow.com/questions/27585355/python-open-cv-perspectivetransform&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_calibration.gif&quot; alt=&quot;Braccio 2D calibration&quot; /&gt;

&lt;p&gt;
    Finally, to tranform from position to joint angles, I converted to polar coordinates with the arm base as the origin.  I also manually computed the shoulder, elbow, and wrist angles required for the gripper to position at a certain distance from the base based on the geometry of the arm itself and their joint angle limitations.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_dimensions.png&quot; alt=&quot;Braccio motion simulated with RViz&quot; /&gt;

&lt;p&gt;
    Unfortunately, the Braccio has a limited annulus of positions from which it can lift objects off the 2D plane.  To address this, I added a small tweak that caused it to &quot;push back&quot; an object if it is too close to pick up.
&lt;/p&gt;


&lt;img src=&quot;/assets/images/2020/braccio_push.gif&quot; alt=&quot;Braccio pushing apple backwards&quot; /&gt;

&lt;p&gt;
    With all these parts combined, the arm is able to identify and pick up apples. At this point, I still use the interface to manually control it, but it would be possible to layer on more logic to determine when and where the apple should be picked up and delivered.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/braccio_summary.gif&quot; alt=&quot;Braccio apple detection in action&quot; /&gt;


&lt;h2&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;
    This is really just the start of the su_chef project. In another post I'll be elaborating on the whole design of the project, but here is a rough outline of the other things that need to be built.
&lt;/p&gt;

&lt;h5&gt;Identifying more objects&lt;/h5&gt;
&lt;p&gt;
    The first improvement will be adding more objects to identify for pickup.  Currently I've only implemented pickup of apples, but there are a few more food items I'd like to be able to find.  Unfortunately, this will probably involve training my own YOLO model on a specialized dataset.
&lt;/p&gt;

&lt;h5&gt;Building a veggie slicer&lt;/h5&gt;
&lt;p&gt;
    This won't involve robotic arm control per se, but it is still very important.  I essentially want to build something like a food slicer that can have veggies dropped from the top and output into a bowl below.
&lt;/p&gt;

&lt;h5&gt;Moving bowls&lt;/h5&gt;
&lt;p&gt;
    After chopping, the ingredients should drop into bowls below. Only one set of ingredients should be chopped at a time so the bowls will need to be repositioned on the opposite side of the robot.
&lt;/p&gt;

&lt;h5&gt;Spooning&lt;/h5&gt;
&lt;p&gt;
    Probably the hardest mechanical challenge will be spooning the chopped veggies from bowls onto the plate.  I suspect that I'll need to design a special spoon that can be reliably lifted by the arm.
&lt;/p&gt;

&lt;h5&gt;Smarter controls&lt;/h5&gt;
&lt;p&gt;
    After the mechanical components are taken care of, I'll need to wrap the logic behind the whole device together.  This will entail some kind of intelligent detection for when ingredient bowls are empty, and identifying which item to pick up and chop.
&lt;/p&gt;</description>
        <pubDate>Thu, 23 Jul 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/07/su-chef-braccio-yolo/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/07/su-chef-braccio-yolo/</guid>
        
        <category>robots</category>
        
        <category>technology</category>
        
        <category>su_chef</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/robot_fist_bump.jpg</image>
        <title>How about worker-owned automation?</title>
        <description>&lt;p&gt;&lt;em&gt;&lt;small&gt;
    Epistemic status: I've been ruminating on &lt;a href=&quot;https://www.theatlantic.com/ideas/archive/2019/06/give-us-fully-automated-luxury-communism/592099/&quot;&gt;Fully Automated Luxury Communism&lt;/a&gt; and how to make it happen.  Can't tell if it'll succeed, but it's something worth working toward.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
    Recent events have reawoken an idea that I've wanted to tackle since I was a teenager.  Over the past few months as I've been learning, I've also been reorganizing my life and finances to try to take a new direction.
&lt;/p&gt;

&lt;p&gt;
    To put it bluntly, I feel like it's time to find a way to ethically get rid of all the crappy jobs in our economy. I want to help make this happen before the big corporations do it so that the wealth and leisure can go to workers, rather than sharehoolders. In this post, I offer my reasoning and my plan to start to tackle this.
&lt;/p&gt;

&lt;h4&gt;Automation should be good&lt;/h4&gt;
&lt;p&gt;
    When I was twelve, I started working in the corn fields doing a job called &lt;a href=&quot;https://en.wikipedia.org/wiki/Detasseling&quot;&gt;detasselling&lt;/a&gt;. On geologic timescales detasseling is a great gig, but compared to the high school jobs that my current circle of friends had, it's a little infathomable. Basically, you walk through a corn field for 8-10 hours a day, get filthy, get cut up by corn leaves across the arms and face, and go home completely exhausted every day.
&lt;/p&gt;
&lt;p&gt;
    Although the job was pretty grueling, the work itself wasn't really the worst part. The thing that really hurt was all the time that I had to give up to do it. When I step back and think about all the grueling monotous tasks that are done every day in this country, I get overwhelmed with how much human potential is ground into watsted time. I just want fewer people in this world to have to waste their precious time. In every company I've worked in since that time, I've had this nagging sensation that most the jobs could have been largely automated away if we really wanted to.
&lt;/p&gt;

&lt;h4&gt;The downside&lt;/h4&gt;
&lt;p&gt;
    But automation takes away jobs. I hear you, but I think that misses the point. We do not have a fundamental problem with taking away a crappy job.  We have a problem taking away the income that the crappy job provided.
&lt;/p&gt;

&lt;p&gt;
    I have an opposite theory of the economics of crappy jobs. I think our society is structured to keep people in the lowest social class simply so that they have no choice but to do our worst labor for the worst pay.  Maybe if those jobs weren't there, there wouldn't be a reason to systematically prevent everyone from moving up in the world.
&lt;/p&gt;

&lt;p&gt;
    On the other hand, I don't have too much faith in how the privileged class deals with others. There's a possibility that if the crappy jobs weren't still necessary, the wealthiest in the world would doom the rest of us to some kind of minimal subsistence while they reap all the benefits of an automated world.
&lt;/p&gt;

&lt;p&gt;
    So how to prevent this? For the past several months, I have been contemplating a workaround for the automation dystopia endgame.  I think the solution comes down to the following:
&lt;/p&gt;

&lt;blockquote&gt;Distribute the benefit of automation equitably&lt;/blockquote&gt;
&lt;p&gt;
    Yep, pretty simple huh? Others have described &lt;a href=&quot;https://www.forbes.com/sites/jeannemeister/2019/05/07/the-future-of-work-the-rise-of-workers-who-self-automate-their-jobs/#696568933c23&quot;&gt;this&lt;/a&gt; &lt;a href=&quot;https://wol.iza.org/articles/who-owns-the-robots-rules-the-world/long&quot;&gt;concept&lt;/a&gt; before. Keep in mind that I'm not suggesting that we have to rely on government intervention to make it happen. Although I would love large scale systemic change, I think it's possible to take individual action to distribute wealth fairly to workers.
&lt;/p&gt;
&lt;h4&gt;Worker-owned automation&lt;/h4&gt;
&lt;p&gt;
    I'm proposing a type of worker-owned company where the benefits of automation continually reduce the load on workers without reducing their compensation. Imagine a company of colleagues who only have to work an hour or two a day helping maintain a robot here or there. The rest of the time is theirs to better themselves any way that they can. Maybe they want to study science or create art. Maybe they want to raise a healthy stable family. The possibilities would be endless, and they would be available equally to everyone in the company.
&lt;/p&gt;
&lt;p&gt;
    This system could take many forms, but I've been thinking for the past few months about how I'd want to do this. Below I walk through the major questions that I've needed to answer in brief.  I'll be writing more as I figure out more details.
&lt;/p&gt;

&lt;h5&gt;
    How would worker ownership work?
&lt;/h5&gt;

&lt;p&gt;
    I've been reading about &lt;a href=&quot;https://www.project-equity.org/learn-about-employee-ownership-options/&quot;&gt;a few ways&lt;/a&gt; to allow worker ownership, but to me the best seems to be the &lt;a href=&quot;https://www.yesmagazine.org/issue/poverty/2014/08/15/how-america-s-largest-worker-owned-co-op-lifts-people-out-of-poverty/&quot;&gt;worker-owned cooperative&lt;/a&gt; (despite &lt;a href=&quot;https://www.theatlantic.com/business/archive/2015/07/no-bosses-worker-owned-cooperatives/397007/&quot;&gt;the very real difficulties&lt;/a&gt;). It seems that often a cooperative is formed by &lt;a href=&quot;https://hbr.org/2018/08/why-the-u-s-needs-more-worker-owned-companies&quot;&gt;restructuring&lt;/a&gt; an existing business, but since I know I want mine to work that way eventually, it makes sense to start with worker-ownership from the beginning.
&lt;/p&gt;
&lt;p&gt;
    The governance of company decision making would be to use a &lt;a href=&quot;http://1worker1vote.org/&quot;&gt;1-worker 1-vote system&lt;/a&gt; with the option for &lt;a href=&quot;https://en.wikipedia.org/wiki/Proxy_voting&quot;&gt;proxy voting&lt;/a&gt;. Day-to-day operational decision making would be worked out democratically, preferably with the establishment of focused committees to delegate operations effectively. There already exists &lt;a href=&quot;https://www.co-oplaw.org/statebystate/california/&quot;&gt;established laws and standard practices in California&lt;/a&gt; for worker-owned coops that could help get started. The articles of incorporation and Board bylaws would add some other stipulations, such as how to dissolve or fundamentally restructure the company or establishment of some broad definitions of how compensation can work.  I've previously written a &lt;a href=&quot;/2017/08/the-stedden-constitution/&quot;&gt;&quot;constitution&quot; with my partner&lt;/a&gt;, and for starters I'll probably use the idea of a constitution as a basis for some informal bylaws while starting out. That would transition to a more formal structure when needed.
&lt;/p&gt;
&lt;p&gt;
    Since the goal of this company is actually to automate away all of the &lt;strong&gt;actual labor&lt;/strong&gt;, one of the more interesting aspects of this type of worker-ownership is the compensation plan.  As the companies labor is turned over to robots, it seems like it will become increasingly complicated to determine how much each person should be paid. My current thinking on this system would be to use profit sharing to set an hourly wage, but allow individual's hourly wage to be renormalized based on contributions to company wide improvements in efficiency.  This way workers will continue to have an incentive to &quot;show up&quot; to work, while also incentivizing innovations that actually reduce the amount of work that everyone does.
&lt;/p&gt;
&lt;p&gt;
    One thing that is important to me is to try to establish as much external company transparency as possible.  Ideally, I'd like our whole operating budget and pay structure to be open-sourced as it were.  But of course, how far the company would be willing to take that would need to be up to the organization.
&lt;/p&gt;
&lt;p&gt;
    There are still a lot of details to work out on the company structure, and a lot of learning that will be required. Furthermore, the details will no doubt be industry specific so it doesn't make to much sense to continue in the abstract.
&lt;/p&gt;

&lt;h5&gt;What industry would be best to tackle?&lt;/h5&gt;
&lt;p&gt;
    There are a lot of businesses where this could happen, but in my opinion the most important one to go after is foodservice. This seems like an industry where automation is &lt;a href=&quot;https://medium.com/american-restaurant-supply/automation-in-the-food-service-industry-where-are-we-now-and-what-does-it-mean-8a748e66ef3b&quot;&gt;probably inevitable&lt;/a&gt;, but major players are still &lt;a hre=&quot;https://thespoon.tech/mcdonalds-is-testing-kitchen-robots-and-ai-powered-drive-thrus-its-about-time/&quot;&gt;surprisingly early in the process&lt;/a&gt; even though it was doable &lt;a href=&quot;https://www.youtube.com/watch?v=FmXLqImT1wE&quot;&gt;50 years ago&lt;/a&gt;. This makes me think it's hard, but not impossible.
&lt;/p&gt;
&lt;p&gt;
    But what's prehaps most important to my motivation is that automating away those jobs in a non-worker-owned way would be devastating to workers in those industries now. In 2010 &lt;a href=&quot;http://www.aspenwsi.org/wordpress/wp-content/uploads/The-Restaurant-Workforce-in-the-United-States.pdf&quot;&gt;1 in 12 &lt;/a&gt; US workers were in the food service industry, and people in those occupations also had one of the &lt;a href=&quot;https://www.bls.gov/news.release/archives/ocwage_05172011.pdf&quot;&gt;lowest average wages&lt;/a&gt; nationally.
&lt;/p&gt;
&lt;p&gt;
    Additionally, the barrier to entry for owning a restaurant is still accessible enough that nearly &lt;a href=&quot;https://www.smallbizgenius.net/by-the-numbers/restaurant-industry-statistics/#gref&quot;&gt;13,000 open per year&lt;/a&gt;.  So a well-distributed innovation here could provide an entrypoint for thousands of worker-owned automated businesses per year without needing a large centralized pool of capital.
&lt;/p&gt;

&lt;p&gt;
    The flipside is that any innovation in automation would quickly be appropriated by the biggest players.  The one reason I think this is surmountable is the public's growing social conscientiousness when it comes to choosing where to buy services (particularly &lt;a href=&quot;https://www.fsrmagazine.com/content/study-millennials-want-more-ethically-sourced-foods-go&quot;&gt;my millenial generation and younger&lt;/a&gt;). In short, I think the immediacy of food preparation makes it easier for consumers to choose ethics over convenience. My hope would be that an ethical framework for automated cuisine would win out over larger greedy corporations, at least with enough people to make it viable.
&lt;/p&gt;

&lt;p&gt;
    For all of the reasons above I feel it makes sense to tackle the food service industry, but there are still many ways to approach the problem.
&lt;/p&gt;

&lt;h5&gt;What would the company do?&lt;/h5&gt;
&lt;p&gt;
    Importantly, I don't think that making technology and selling it to restaurants would be effective in preventing job loss.  If we build something for automating cooking and sell it to a fast-food chain, they will lay off their employees and pass the profits off to shareholders.
&lt;/p&gt;
&lt;p&gt;
    On the other hand, I'm not personally the kind of leader who could possibly launch a large scale operation to compete with those companies. Instead, I want to try building a small but scalable solution that could be run by others. Therefore, my goal is to launch and operate a few automated foodtrucks, while providing the blueprint to do the same at larger scale.
&lt;/p&gt;

&lt;p&gt;
    In the beginning the foodtrucks would be partially automated and should only require a few hours of work per employee per week. The revenue from the foodtruck should hopefully be similar as one run with a standard crew so workers should, therefore, make better than food service wages with greatly reduced hours.
&lt;/p&gt;

&lt;p&gt;
    I'm still working through details like what foods would be served, how ingredients would be procured, aesthetics, and how customer interaction would work. I'll follow up with another post soon that covers these details and more.
&lt;/p&gt;

&lt;h5&gt;What are the biggest hurdles?&lt;/h5&gt;
&lt;p&gt;
    This will only happen with a lot of work, and some good luck. I've spent 15 years working in software development and machine learning, and I have experience working in automation and robotics. Additionally, I've been a Board member of a tech education non-profit for a little over 4 years now. I'm currently working on simulated prototypes of the food truck design, which I'll show in another blog post soon. There are a lot of technical challenges to overcome and I'm interested in working to tackle this problem with others who share similar interests and goals.
&lt;/p&gt;
&lt;p&gt;
    Nevertheless, I don't believe the hardest part is going to be automating food production.  I think that is very solvable and has been done before to varying degrees.
&lt;/p&gt;
&lt;p&gt;
    I think the hardest part will certainly be fighting against the &quot;lowest common denominator&quot; economics. Ultimately, anyone will be able to compete in this market.  Once there is an ethical automated foodtruck, there will soon be a cheaper, unethical automated foodtruck. What will keep a customer from supporting 10 employees for the price of a regular meal at the ethical company, when they can go next door and pay just 1 employee and pay 90% less? For that matter, what will keep an employee at the ethical store from quitting to open their own unethical one and rake in all the profit for themselves.
&lt;/p&gt;
&lt;p&gt;
    This is why I believe that complete transparency is the key. I haven't seen any examples of companies operating that way, but I think it's the only way to create the kind of trust that will differentiate this new system from the old one.
&lt;/p&gt;
&lt;p&gt;
    Betting on humanity's better nature is always a long shot, but the past month has reinvigorated my faith in my fellow citizens to collectively take action to change the world for the better. At no point in my life did I think there was a better chance for this kind effort to happen without exploitation, which is why I'm finally willing to take the steps to make it happen.
&lt;/p&gt;
&lt;p&gt;
    And while I honestly don't expect everything to work out, even if this project only just barely survives a few months, I think it'll be the most important thing I'll ever try to do.
&lt;/p&gt;

&lt;h4&gt;First steps&lt;/h4&gt;

&lt;p&gt;
    I already feel overwhelmed by this idea, but I'm also incredibly excited to have started taking steps to put it into action.
&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;1. build simulation of operational foodtruck&lt;/li&gt;
    &lt;li&gt;2. build &quot;sous-chef&quot; prototype&lt;/li&gt;
    &lt;li&gt;3. write company charter&lt;/li&gt;
    &lt;li&gt;4. build online ordering with fully transparent online budget&lt;/li&gt;
    &lt;li&gt;5. fund first prototype truck through kickstarter&lt;/li&gt;
    &lt;li&gt;6. build the damn thing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
    Along the way, I hope to start taking on co-worker-owners to help figure things out and establish the governance framework. I'd also love contact from mentors who could help us better understand foodtruck management, automation, California worker cooperatives, or company transparency. If you are interested please &lt;a href=&quot;https://will.stedden.org/&quot;&gt;reach out&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
    Also, feel free to steal this plan if you think you can do it better than me. You probably can. I honestly don't care if I'm the person who pulls this off as long as it happens. Just &lt;a href=&quot;https://will.stedden.org/&quot;&gt;let me know&lt;/a&gt; when you get it, and I'll join you!
&lt;/p&gt;

</description>
        <pubDate>Mon, 13 Jul 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/07/automated-foodtruck-idea/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/07/automated-foodtruck-idea/</guid>
        
        <category>career</category>
        
        <category>technology</category>
        
        <category>philosophy</category>
        
        <category>su_chef</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/big_bonkerfield.png</image>
        <title>Identifield: information in the material universe</title>
        <description>&lt;p&gt;&lt;em&gt;&lt;small&gt;
    Epistemic status: It should go without saying that I don't have any certainty about the fundamental nature of the universe.  This is just a bit of conjecture that gets me through my day.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
    As I moved from physics to biology and now into machine learning, my worldview has shifted from one focused on material reality to one that deals largely with abstractions of information.  I've thought a great deal about these two viewpoints and wondered about their relationship. Importantly, as I've interacted with people ensconced in these two fields, I've noticed a tangible difference between two distinctive mental models of the fundamental space that things occupy.
&lt;/p&gt;
&lt;p&gt;
    The material view focuses on conventional spacetime as the true space that existing entities occupy. Meanwhile, the information-centric view defines the space of ideas as the true space that existing entities occupy. To put a finer point on the distinction, I've assigned names based on pairs of philosophers and scientists who I think most closely represents each conception of reality
&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse;&quot;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th&gt;Aristotelian/Feynmanian&lt;/th&gt;
    &lt;th&gt;Platonic/Einsteinian&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody style='text-align:center;'&gt;
  &lt;tr&gt;
    &lt;td&gt;A standard material universe&lt;/td&gt;
    &lt;td&gt;A space of purified ideas&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Reality is physical&lt;/td&gt;
    &lt;td&gt;Reality is the ideals we uncover&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;There is no real space where ideas exist, they are just an artifact of our discourse&lt;/td&gt;
    &lt;td&gt;The particular details of the different manifestations of these ideals are largely unimportant&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Our useful efforts lie in efficiently cataloging the physical by the discussion of observations of phenomena&lt;/td&gt;
    &lt;td&gt;Our useful efforts lie in properly mapping specific phenomena back into the space of ideals where their fundamental principles are truly defined&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr&gt;
&lt;p&gt;
    So &lt;strong&gt;which is correct&lt;/strong&gt;?  I've thought a lot about the relation between our material universe and the idealistic universe, and as with every other ethical or epistemological dualism I've seen in my life, the answer may be just the most boring: &lt;strong&gt;both&lt;/strong&gt;. It seems to me that the very thing that makes our universe an interesting one to inhabit is that the two spaces coexist and are intermingled. And perhaps, the very validity of our consciousness is predicated on the comingling of these two spaces.
&lt;/p&gt;

&lt;p&gt;
    To describe this third &quot;necessary combination&quot; view, I've had to develop what I believe to be a new description of the way that entities exist in this third space interpretation of the universe.  I've called this new construct an &lt;strong&gt;identifield&lt;/strong&gt; (pronounced identi-field), and I'd like to take the rest of this blog post to describe the idea.
&lt;/p&gt;

&lt;h3&gt;What is an identifield?&lt;/h3&gt;
&lt;p&gt;
    Identifield is a shorthand term for an &lt;strong&gt;information identity spacetime field&lt;/strong&gt;. It is a means for articulating how a thing of information (ie platonic ideal) exists in the material world (ie in physical reality).  To look at an identifield is to look at how an idea fits into the evolution of all ideas spread across physical time and space.  That sounds a little extravagant, but once it's broken down, I think it isn't totally crazy.
&lt;/p&gt;
&lt;p&gt;
    I'll first explain the concept by example, and then explain the terminology in detail.
&lt;/p&gt;

&lt;h4&gt;Explained By Example&lt;/h4&gt;
&lt;p&gt;
    It might help to take a simple example where we are looking at the information contained in a single paragraph in a book.  We would start by asking, &quot;Does the information live just in the printed words of a single page?&quot;  No, at the very least it has to be present in all the printed copies of that book. But the information can be thought to exist in a whole lot of other places too.
&lt;/p&gt;
&lt;p&gt;
    Imagine that paragraph contains the quote &quot;Call me Ishmael&quot; from Moby Dick. That would mean some of the information lives in a small part of all the copies of Moby Dick as well.  And suppose that when the author quoted that line in Moby Dick, she did so because she had also read an article that suggested quoting Moby Dick is a good strategy for getting published. So some seed of the generation of the paragraph was formed in that article too. All the places where the author gathered information to write that paragraph include some partial component of the information contained within it.
&lt;/p&gt;
&lt;p&gt;
    And that isn't the end of it either. It's also present in the minds of anyone who might read the paragraph and internalize that information.  How much of the information is present will vary depending on how much attention the audience was paying, and whether they correctly translated the information into their own brains.  Finally, the information in that paragraph may someday be referenced in another novel, which can lead to diffusion to a whole other set of people.
&lt;/p&gt;
&lt;p&gt;
    So if you were to try to imagine where that information lives at all times and how &quot;strong&quot; of a residue of the information is present, you'd have to picture a 4D spacetime field occupying all the places we just mentioned.  That's an identifield.
&lt;/p&gt;

&lt;h4&gt;Explained in greater detail&lt;/h4&gt;
&lt;p&gt;
    If the craziness above wasn't enough for you, here's a little more explanation.  Lets break down the defintion of identifield, &lt;strong&gt;information identity spacetime field&lt;/strong&gt;.
&lt;/p&gt;
&lt;h5&gt;Information Identity&lt;/h5&gt;
&lt;p&gt;
    To start, I should explain what I mean by an &lt;em&gt;information identity&lt;/em&gt;.  I'm using the term to mean, literally, that identity which defines some information. Of course, to understand that we need to break down what I mean by information and identity.
&lt;/p&gt;
&lt;p&gt;
    Even though information is a fairly abstract concept, I think most people seem to have a pretty intuitive sense of what it is.  To cut to the chase, let's just say information is a description of ideas that we can transmit around through physical manifestations. Note that information is not the physical manifestation itself.  For example, If I hand you a piece of paper with the words, &quot;Hi, my name is Will,&quot; typed on it, the piece of paper and ink is not the information, the words are the information. The words convey the idea that my name is Will, but this idea is not the information either.  Keep in mind that words are not the only form of information.  As another example, biological organisms contain DNA, which transmits the information of the individual's genetic code.
&lt;/p&gt;
&lt;p&gt;
    We can tackle identity in a similar way. I like to use a definition of identity that hybridizes the &lt;a href=&quot;https://en.wikipedia.org/wiki/Identity_(philosophy)&quot;&gt;philosophical definition&lt;/a&gt; with our more intuitive understanding of &lt;a href=&quot;https://en.wikipedia.org/wiki/Identity_(social_science)&quot;&gt;personal identity&lt;/a&gt;. So for the sake of this discussion let's say that identity is the combination of all those aspects of a thing that make it that unique thing in and of itself.  So your jacket's identity is all the things that make your jacket, your jacket and not somebody else's.
&lt;/p&gt;
&lt;p&gt;
    The information identity is then just the way of distinguishing a piece of information as unique to itself.  It's important to remember that unlike the identity of a physical jacket, information is not the medium itself, but rather the meaning conveyed on the medium. This means that information can be replicated exactly, and so the information identity can be shared among many different conduits of information all over the world. As an example, take the information contained in one's genetic code.  If we were to read that information by sequencing someone's genome and store the sequence of the genome in a computer.  The information identity is that which makes the person's genetic sequence their own. Importantly, it is present in both the sequence in their physical DNA and in the sequence of bits stored in the computer that has read their genome.
&lt;/p&gt;

&lt;h5&gt;Spacetime&lt;/h5&gt;
&lt;p&gt;
    To picture an information identity as it exists in the world, we'd need to mentally visualize the locations of all the copies of that information in the world.  If we were imagining the information in a news article we would imagine all the open web browsers that are viewing that article and all the copies sitting on computer servers.  Next, we'd further imagine the location in each person's mind where they are storing the information that they have just read. And if they communicate the story verbally, the information is contained in the waves of air particles propagating from their mouths.
&lt;/p&gt;
&lt;p&gt;
    All of this is overwhelming to picture in the moment because there are some people navigating to and from the page, reading, forgetting, and discussing, off and on all the time.  For me, it helps to broaden our imagination of information existing in all points in space and take it one step further. We imagine not just where that information is at this instant, but where it has been at all points in time.
&lt;/p&gt;
&lt;p&gt;
    To imagine this, we turn to a concept from physics called spacetime.  If you are unfamiliar with the idea of spacetime, I've written a &lt;a href=&quot;/2020/05/spacetime-explained/&quot;&gt;short visual explainer&lt;/a&gt; to give some background.  But for those who are familiar with the concept, you will recall that spacetime allows us to project a single physical object, like a bowling ball, simultaneously to all points in space that it will ever occupy.  This turns compact objects into extruded ones such as the one in this illustration.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/main/bowlingslice_stack.png&quot; alt=&quot;bowling ball rolling slices&quot; /&gt;
&lt;p&gt;
    Here, a bowling ball starts at one end of the lane and is rolled to the other end.  But extruded through time, it looks like a tube that connects from end to end.  This is the same situation for the information identities described above.  However, the information identity isn't relegated to a single tube like the bowling ball because the information identity may exist in many, far-reaching locations at once.
&lt;/p&gt;
&lt;p&gt;
    We can think about what happens when we start replicating information.  For example, imagine my friend wants to come over and copy a flash drive.  Well if you looked at some information identity housed on that flashdrive in spacetime, you'd see it would look like a single tube at early times (like the bowling ball) and then suddenly it would split to become two tubes that snake around independently.
&lt;/p&gt;
&lt;p&gt;
    This takes us a long way to seeing the full picture of information residing in the physical world. But there is still one problem: How do we deal with pieces of information that are very similar but slightly different. To begin, let's ask, what happens if something goes wrong when we copy the flash drive and some small difference appears.  Are they two totally different information identities now?  How do we deal with that?
&lt;/p&gt;
&lt;h5&gt;Field&lt;/h5&gt;
&lt;p&gt;
    The final piece of the identifield is allowing the information identity to exist in a continuous state rather than as something fully binary. We want the &quot;presence&quot; of the information to vary continuously from 100% when you have an exact copy to 0% when you have something that is totally unrelated.  To describe this we turn to another physics concept called a &lt;em&gt;field&lt;/em&gt;.
&lt;/p&gt;
&lt;p&gt;
    We're mostly familiar with fields in physics like gravitational force fields and elecromagnetic fields.  But any quantity that varies in space can be described as a field.  We can talk about the temperature field to describe how temperature varies throughout a house (warmer by the sunny windows, colder in the basement). We can even talk about more abstract things like an &quot;intelligence field&quot; that quantifies how intelligent the entities in one region of space are.  For an intelligence field, parts of the world occupied by humans have a high value, parts occupied by slugs have a lower value (presumably) and rocks would have even lower value.
&lt;/p&gt;
&lt;p&gt;
    We're interested in the information identity spacetime field, which we can define as how much of the information identity is present across different points in space and time.  This accounts for minor corruptions in the information as well as intentional changes to the underlying information. Importantly, when your identifiable unit of information is first &quot;formed,&quot; it is often constructed by some restructuring of multiple previously existing pieces of information. This means that going back prior to its formation, you would see partial remnants of the information identity in any preceding ideas that might have been important.
&lt;/p&gt;
&lt;p&gt;
    Taken together, these elements allow us to visualize like in the example below.  For more information on the visualization see &lt;a href=&quot;/2020/01/visualizing-the-bonkerfield/&quot;&gt;this post&lt;/a&gt;.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/big_bonkerfield.png&quot; alt=&quot;&quot; /&gt;

&lt;p&gt;
    The continuous nature of the identifield allows us to get away from the necessity of drawing hard demarcating lines for where two similar ideas diverge. Although this notion is necessarily abstract, there already exist many ways to compute the similarity of two pieces of information.  The identifield does not predicate a single metric that need be used for measurement of similarity, only that some measurement exists and that we may assume many small perturbations will continue to change the measurement in a continuous manner.[&lt;a href=&quot;#sizes&quot;&gt;*&lt;/a&gt;]
&lt;/p&gt;

&lt;h3&gt;Implications of the Identifield&lt;/h3&gt;
&lt;p&gt;
    The purpose of framing the identifield is to aid in thinking about how ideas exist in the real world.  Once you begin to imagine information identities existing in 4D spacetime, it's hard not to start thinking of the whole world in terms of this construct. I think there are at least three significant application areas of the identifield that could help us see the world with slightly greater clarity.
&lt;/p&gt;
&lt;h5&gt;Mapping between idea space and physical space&lt;/h5&gt;
&lt;p&gt;
    You could imagine that some things are compact in the space of ideas, but sprawling in physical space.  At the same time, certain philosophies could cover wide swaths of idea space, but only exist within the mind of a single meditating monk. Including the identifield in our vocabulary allows us to more clearly see that distinction.
&lt;/p&gt;
&lt;h5&gt;Redefining the Self&lt;/h5&gt;
&lt;p&gt;
    I believe the most interesting implication of the identifield is what it means for our dearest information identity, our self. In my mind, I now see myself as composite identifield, processing and transforming all sources of information that I have absorbed.  This is a sizable idea to unpack so I have elaborated &lt;a href=&quot;/2020/05/redefining-identity/&quot;&gt;in this post&lt;/a&gt;.
&lt;/p&gt;
&lt;h5&gt;Intuiting meaning for the universe&lt;/h5&gt;
&lt;p&gt;
    I am currently writing at length about my interpretation of a meaning for the universe. The key takeaway (argued elsewhere) is that if (1) you are concerned with the outcomes of your actions and (2) remain unsure how specifically to act, it can be deduced that (3) you should assume that the universe falls into the class of universes &lt;a href=&quot;/2020/05/philosophical-grind/&quot;&gt;with a purpose&lt;/a&gt; that can be &lt;a href=&quot;/2020/05/intuition-probability/&quot;&gt;discovered by intuition&lt;/a&gt;.  The argument is long and complex so I encourage reading &lt;a href=&quot;/reasons/&quot;&gt;my reasons articles&lt;/a&gt; if you are curious.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, I do not have a way to prove which of my intuitions is correct.  However, I've personally found it useful to use the mind-broadening effects of contemplating things as identifields to hone my intuition on the relation between my immediate action and the space of outcomes in the universe.  This is only an intuitive connection, but it's one that personally holds meaning for me so I thought I should include it in this list of implications.
&lt;/p&gt;


&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;
    Unfortunately, there is no concrete conclusion offered by this framework.  In fact, the identifield construct posits specifically that so long as you are thinking about even part of this idea, the idea does not conclude at all.
&lt;/p&gt;
&lt;p&gt;
    My website is my attempt to catalog the identifield of all the (useful) information that passes through Will Stedden. This particular identifield, is what I've called the bonkerfield (an identifield that is perhaps a little bit bonkers).  If you take the information identity on this site with you and it informs your life, then you become a part of its identifield.  And bonkerfield becomes a part of you.
&lt;/p&gt;
&lt;p&gt;
    ...and if you share your thoughts with others in the comments, then well, it makes it much easier to watch the identifield forming :)
&lt;/p&gt;


&lt;small&gt;&lt;em&gt;
&lt;h6 id=&quot;sizes&quot;&gt;A note on continuity and sizes&lt;/h6&gt;
&lt;p&gt;
    All of this assumes that there is some granularity of space and time over which we will define a piece of information as coherent and allow changes between two discrete states to blur.  For example, if you delete a few words in a paragraph and rewrite them, the identifield of the paragraph in that interim should not be meaningfully modified.
&lt;/p&gt;
&lt;p&gt;
    A careful observer may try to punch a hole in the physicality of the identifield by noting that physical fields are normally defined at arbitrarily small units of space.  They will point out that to define a space as containing information you need to create some envelope with a macroscopic spatial scale. I agree that is necessary. However, that is not a problem as it should be noted that temperature and many other quantities that are commonly considered fields do not actually exist on an infinitesimal scale.
&lt;/p&gt;
&lt;/em&gt;&lt;/small&gt;
&lt;!-- &lt;h6&gt;Aristotelian/Feynmanian space&lt;/h6&gt;
&lt;ul&gt;
    &lt;li&gt;A standard material universe&lt;/li&gt;
    &lt;li&gt;Reality is physical&lt;/li&gt;
    &lt;li&gt;There is no fundamental space that unify ideas outside of our discourse&lt;/li&gt;
    &lt;li&gt;Our useful efforts lie in efficiently cataloging the physical by the discussion of observations of phenomena&lt;/li&gt;
&lt;/ul&gt;
&lt;h6&gt;Platonic/Einsteinian space&lt;/h6&gt;
&lt;ul&gt;
    &lt;li&gt;A space of purified ideas&lt;/li&gt;
    &lt;li&gt;Reality &lt;strong&gt;is&lt;/strong&gt; the ideals we uncover&lt;/li&gt;
    &lt;li&gt;the particular details of the different manifestations of these ideals are largely unimportant&lt;/li&gt;
    &lt;li&gt;our useful efforts lie in properly mapping specific phenomena back into the space of ideals where their fundamental principles are truly defined&lt;/li&gt;
&lt;/ul&gt; --&gt;</description>
        <pubDate>Mon, 18 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/what-is-an-identifield/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/what-is-an-identifield/</guid>
        
        <category>philosophy</category>
        
        <category>identifield</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/main/bowlingslice_stack.png</image>
        <title>A Spacetime Visual Explanation</title>
        <description>&lt;h4&gt;Spacetime Explained&lt;/h4&gt;
&lt;p&gt;
    It can be tricky to think about where something is in not only space, but time too.  Physicists picture the location of objects in space and time using a concept called &lt;a href=&quot;https://en.wikipedia.org/wiki/Spacetime&quot;&gt;spacetime&lt;/a&gt;.  They generally think about this in regard to physical objects, and that's a good place to get an introduction to the concept.  As an example, check out this bowling ball rolling in this gif I found.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/main/bowlingball.gif&quot; alt=&quot;bowling ball rolling&quot; /&gt;
&lt;p&gt;
    The ball is more or less traveling in a straight line down the alley so at any point in time we can describe its position along the single spatial dimension of the length of the alley.  We can view the position along that dimension of space at multiple time points by looking at still frames from the movie next to each other.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/main/bowlingslice.png&quot; alt=&quot;bowling ball rolling slices&quot; /&gt;
&lt;p&gt;
    Now if we were to narrow the slices and take more of them, the path of the ball would become filled in along that single dimension.  We can draw this out as a filled in tube in a 2D plane.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/main/bowlingslice_stack.png&quot; alt=&quot;bowling ball rolling slices&quot; /&gt;

&lt;p&gt;
    This is two dimensions of the spacetime that the bowling ball occupies (one spatial dimension and one time dimension).  If you think beyond the timeframe in the video, you can imagine the bowling ball going on to be used over and over again.  The full spacetime location of the bowling ball is the path traced out by it through its entire existence.
&lt;/p&gt;</description>
        <pubDate>Mon, 18 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/spacetime-explained/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/spacetime-explained/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/big_bonkerfield.png</image>
        <title>Redefining Identity: A continuum approach</title>
        <description>&lt;p&gt;&lt;em&gt;&lt;small&gt;
    Epistemic status: This is an attempt to define personal identity for myself.  I believe that it is a more developed description than most, but I always welcome new insights.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
    There are two hurdles that I've needed to overcome in defining my &lt;em&gt;personal identity&lt;/em&gt;.  First, I've had trouble holding onto what it is that makes up &quot;me.&quot;&quot;  I've changed so much throughout the course of my life, that thinking about what &quot;I&quot; think seems almost impossible. Second, I'm troubled with the concept of identity as labels. I've found myself falling into the same routine as others these days, reducing blocks of humans to caricatures.
&lt;/p&gt;
&lt;p&gt;
    To me, both of these problems arise because we have tried as a culture to define identity as discrete.  Here, I'd like to describe what I've arrived at for a continuum philosophy of personal identity, and explain how it might help us fix a few societal problems that have come out of the individualistic mindset.
&lt;/p&gt;


&lt;h4&gt;Subdividing and Extruding Identity&lt;/h4&gt;
&lt;p&gt;
    Over the past few years, I have reframed my definition of identity away from either the external model of the atomic individual, or the internal model of our mental monologue directing thought and action. When I say &quot;me,&quot; I mean an amorphous continuum of procedures operating on information and information transforming procedures.  Crucially, this model does not lend itself to easily demarcating what constitutes actions taken by the self as opposed to actions imposed on the self. This can be confusing, so to better clarify, I've operationalized my definition of self with a working model, called the &lt;strong&gt;continuum identity&lt;/strong&gt;. This model has two components, subdivision and extrusion.
&lt;/p&gt;

&lt;h5&gt;Subdivision&lt;/h5&gt;
&lt;p&gt;
    Subdivision means that our experience of a coherent identity is actually a composite of other subidentities, which can be divided and analyzed on their own. Considering the self as a bundle dates back to at least Hume, and probably to the Buddha. For a very lengthy discussion of this topic, you can read any of these refs [&lt;a href=&quot;https://en.wikipedia.org/wiki/Personal_identity&quot;&gt;1&lt;/a&gt;],[&lt;a href=&quot;https://medium.com/@AnjaBasha/ego-theory-of-the-self-and-bundle-theory-of-personal-identity-locke-and-hume-e38ee75e236e&quot;&gt;2&lt;/a&gt;],[&lt;a href=&quot;https://www.giffordlectures.org/books/elusive-self/5-continuous-identity&quot;&gt;3&lt;/a&gt;].  But I don't believe you need any of these authorities to understand the concept. Just ask yourself if you've ever noticed that you can see two sides of the same story or that you've held two conflicting opinions in rapid succession? I interpret that sensation as multiple subidentities debating a position.  I've written about this at length in &lt;a href=&quot;/2019/10/sub-identity-suicide/&quot;&gt;this post&lt;/a&gt; as well.
&lt;/p&gt;
&lt;p&gt;
    To summarize the concept of identity subdivision, imagine every piece of information contained in your mind and add to it every way that you could act on that information. Each of these components constitutes a subidentity that could conceivably be remixed in a different person to form a part of their identity.  In fact, you share some of these pieces of information and procedure with others around you, which leads to the next component of continuum identity, extrusion.
&lt;/p&gt;

&lt;h5&gt;Extrusion&lt;/h5&gt;
&lt;p&gt;
    Extrusion means that for every rule or piece of information that I have incorporated into my identity, its origins can be extruded backwards to the external sources where the information was derived or forwards to those places where that information will be outputted by myself.  To make this clearer, I've introduced the concept of the identifield, which I've elaborated on in &lt;a href=&quot;/2020/05/what-is-an-identifield/&quot;&gt;this post&lt;/a&gt;. The identifield places a tighter physical interpretation on this idea, but the intuition is just that any idea inside of me can be physically linked by the media that transmitted the idea to me. And this chain can be walked back again and again to connect the idea in me to that same idea wherever it resides throughout the entire universe.
&lt;/p&gt;

&lt;p&gt;
    So in conclusion, my coherent sense of self can be subdivided into many subidentities and then I can extrude those through spacetime to track how they came to be within me.  When carried out to its limit, this subdivision and extrusion converts my discrete identity into a continuous blur of billions of information streams.
&lt;/p&gt;
&lt;p&gt;
    This philosophy both extends my ego and dilutes it until it is indistinguishable precisely where my contribution comes from and where I am just the continuation of independent external factors.
&lt;/p&gt;


&lt;h4&gt;Why is a continuum identity better?&lt;/h4&gt;
&lt;p&gt;
    Although the above philosophical reasons have led me to derive my continuum interpretation of identity, I wouldn't want to adopt that framework unless I thought that it had practical societal value as well.  Here I outline just a few ways that I think it is an improvement over other popular alternatives.
&lt;/p&gt;


&lt;h5&gt;Continuum identity allows for constant change and growth&lt;/h5&gt;
&lt;p&gt;
    With discrete identity, you are defined by a coherent snapshot. At one point, you are a child and then, you are an adult.  At one point a student, and then a professional. Your change in definition needs to come in these extensive leaps from state A to state B.  This has two pitfalls. First, that it delays our recognition of progress until the tipping point.  Second, it linearizes our transitions along a single trajectory.  With a continuum identity, you transition continuously based solely on what you already know, and you are allowed to transition along multiple paths simultaneously.
&lt;/p&gt;

&lt;h5&gt;Continuum identity subdues self-centeredness&lt;/h5&gt;
&lt;p&gt;
    Discrete identities promote the idea that you are a self-contained whole.  To me, this seems to advocate for a strong preference of the ideas and attitudes of the self at the cost of non-self. Importantly, this leads one to take difference of opinion very personally because disputes can only be manifested as conflicts with your entire identity.  Switching to a continuum model recognizes that non-self can become a part of self if you internalize it.  In this case, the conflict that arises from protecting self is less necessary.
&lt;/p&gt;

&lt;h5&gt;Discrete identity necessitates cognitive dissonance&lt;/h5&gt;
&lt;p&gt;
    Under a discrete identity model, you can never justify believing two disparate things at once.  However, humans frequently have to confront  concepts that aren’t so black-and-white and that it is reasonable to struggle to align with just one side or the other on a given topic. With a continuum identity one can acknowledge the separate parts and how they relate to each other internally and based on external factors.
&lt;/p&gt;

&lt;h5&gt;Discrete identity is a bad way to structure society&lt;/h5&gt;
&lt;p&gt;
    By discretizing identity, we force humans into tightly bound descriptions which can be easily grouped and acted upon as if they were objects. Importantly, &quot;me&quot; should never be thought of as a voting block or a consumer base.  &quot;I&quot; am not &quot;white,&quot; &quot;queer,&quot; &quot;scientific,&quot; or &quot;liberal.&quot; Those are imperfect descriptors of parts of me.
&lt;/p&gt;
&lt;p&gt;
    With continuum identity, a person is always some quantitative mixture of different information streams that can lead to a continuum labeling. Importantly, if I am 87% liberal and my ideological opponent is only 12% liberal, I am no longer dealing with someone who is qualitatively distinct from myself.  There is no more &quot;otherness&quot; because I can see the flow of continuous small adjustments that could bring us to the same viewpoint.
&lt;/p&gt;

&lt;h6&gt;Conclusion: &quot;We&quot; as a Preferred Pronoun?&lt;/h6&gt;
&lt;p&gt;
    This definition of identity is strange and may be uncomfortable to think about.  The implications may be misguided and wrong, and I may learn to regret this whole thought process someday.  But at least as an experiment for the time being, this is how I think of myself.
&lt;/p&gt;
&lt;p&gt;
    In my mind, I'm not really a singular entity at all. I feel most comfortable describing my own actions ensconced directly with their connection to those inputs that lead to it.  In fact, if I had my choice, I'd prefer to use &quot;we&quot; for all descriptions of my self.  Or rather, by our estimate, about 60% of our self prefers the pronoun we. As an experiment, we'd like to present ourselves as &quot;we&quot; for the conclusion of this essay.
&lt;/p&gt;
&lt;p&gt;
    We'd like to close by asking you to reflect on the implications of a continuum identity.  However, we can see that we've already provided more than enough of our own opinion on this topic.  So if you'd like to continue the conversation, please reach out.  We're fascinated with where others can take this idea and would love to discuss further.
&lt;/p&gt;

</description>
        <pubDate>Mon, 18 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/redefining-identity/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/redefining-identity/</guid>
        
        <category>philosophy</category>
        
        <category>identifield</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>Philosophical Grind: why assume that your actions matter</title>
        <description>&lt;p&gt;&lt;em&gt;&lt;small&gt;
    Epistemic status: It should go without saying that I don't have any certainty about the fundamental nature of the universe.  This is just a bit of conjecture that gets me through my day.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
    What causes us to choose one action as opposed to another?  There are, of course, instantaneous needs that must be met, but how do we decide the bigger questions in life?
&lt;/p&gt;

&lt;p&gt;
    Over the past several months I have formulated a resolution to this question that I believe makes the fewest necessary assumptions about the structure of the universe.  It is mostly centered around an abstracted form of Pascal's wager, but without the necessity of assuming extrinsic rewards or a particular belief system.  It can be summarized with the following statement that I am terming the Philosophical Grind.
&lt;/p&gt;
&lt;blockquote&gt;
Assuming that a purpose to the universe is not impossible, and that one wishes to help fulfill the purpose of the universe, then one should attempt to hold the belief that their actions can be conducive to fulfilling that purpose and choose their actions accordingly.
&lt;/blockquote&gt;
&lt;p&gt;
    I have previously &lt;a href=&quot;/2019/10/sub-identity-suicide/&quot;&gt;worked through&lt;/a&gt; a personally limited justification of the above statement. Below I will try to prove this statement more generally and show what it implies.
&lt;/p&gt;

&lt;h4&gt;The Philosophical Grind&lt;/h4&gt;
&lt;h5&gt;Premises&lt;/h5&gt;
&lt;p&gt;
    The statement has two necessary premises that must first be addressed. These can be restated as answers to the following questions.
&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Is it possible that the universe has a purpose?&lt;/li&gt;
    &lt;li&gt;If the universe has a purpose, would you prioritize trying to fulfill it?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    The first question only asks whether it is possible; it need not even be likely. This leads to the first premise of this philosophy, &lt;strong&gt;that a purpose to the universe is not impossible&lt;/strong&gt;. This premise seems easy to satisfy, and to negate it would require some sort of proof that I have not seen. The second question is truly up to the individual, but I can safely answer it &quot;yes,&quot; and to me, it feels reasonable to assume the same for most people who would concern themselves with these questions. This leads to the second premise, &lt;strong&gt;that one wishes to help fulfill the purpose of the universe&lt;/strong&gt;.
&lt;/p&gt;
&lt;h5&gt;Should we act as though the universe has a purpose?&lt;/h5&gt;
&lt;p&gt;
    Given the first premise we can posit that the universe we live in must fall into one of three mutually exclusive classes.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Universe has no purpose&lt;/li&gt;
&lt;li&gt;Universe has some purpose but our actions cannot influence its fulfillment&lt;/li&gt;
&lt;li&gt;Universe has some purpose and our actions may influence its fulfillment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
    Using the second premise, we can state whether we should modify our actions dependent on which of the above three types of universes we live in.
&lt;/p&gt;
&lt;p&gt;
    In the first two types of universe (no purpose or non-influenceable purpose), there is no reason to modify the course of my action.  If either of the first two options are true, then no matter how hard I try, I can never arrive at a particular action I should take to improve the likelihood of fulfilling its purpose. In one case, I can't because there is no purpose to fulfill, and in the other it is because nothing I can do will have an impact.
&lt;/p&gt;
&lt;p&gt;
    In contrast, if the universe's purpose can be influenced, under the second premise, I would wish to modify my course of action to try to fulfill that purpose.
&lt;/p&gt;
&lt;p&gt;
    If I then assume I can be in any of the universes, I can decide which action to take based on some combination of all possible actions, dependent on the universe I occupy. But of course, the only universe with an actual prescribed action was the one where the universe has a purpose. In the other universes, the modification of action is ignorable because, under those conditions, the outcome is the same regardless of whether I do or do not modify my actions. Therefore, regardless of which universe I actually occupy, I should behave as if I occupy the universe where my actions influence the outcome of the universe because that is the only one where my outcomes matter anyway.
&lt;/p&gt;

&lt;h4&gt;Notes on an influenceable purpose&lt;/h4&gt;
&lt;p&gt;
    Given the above, it becomes necessary to ask, how can I discover the purpose of the universe in order that I may act to fulfill it?  What we are trying to determine, specifically, is how one should make decisions in order to fulfill the purpose of the universe. This unfortunately is not an easily solved problem.  To show why, I try to break down the universe with an influenceable purpose into its three mutually exclusive subcategories.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Universe's purpose is knowable and actions toward its purpose are inherently determinable&lt;/li&gt;
&lt;li&gt;Universe's purpose is unknowable and actions toward its purpose are not determinable&lt;/li&gt;
&lt;li&gt;Universe's purpose is unknowable but actions toward its purpose are determinable&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    For the first, I would argue that we have no reason to believe that the universe's purpose is completely knowable. While it isn't possible to negate this on purely logical grounds, I will fall back to an empirical argument that the reader may accept or deny based on their own views.
&lt;/p&gt;
&lt;p&gt;
    For the universe's purpose to be known, we would need a direct exposition of the purpose.  However, any proposed direct exposition would need to be evaluated in the context of all other possible expositions. Since there are infinitely many possible purposes, it would seem to be impossible to negate them all in favor of a single finite collection of views on a certainly knowable universe.  Without making further assumptions, any favorite flavor of purpose must be regarded as possible, but not certain, equivalent to any of the uncountable infinity of other possible explanations that no one has ever even fathomed.
&lt;/p&gt;
&lt;p&gt;
    Next we take on the second possibility, of a universe with an unknowable purpose where how actions act toward the goal of the universe is also fundamentally not determinable.  In this set of universes, while our actions have an impact, there is no mechanism we can use to detect which will be beneficial, and therefore, we have no way of deciding which actions to take.  That is to say, our thinking about our actions will have no influence on whether our actions aid in the fulfillment of the purpose. From the point of view of making decisions, this possible situation is equivalent to a universe where our actions have no influence and can be ignored for the same reason as that argued above.
&lt;/p&gt;
&lt;p&gt;
    Based on these arguments, I hold that the only possible set of universes that we need to worry about living in are those where actions conducive to the resolution of the purpose of the universe are ascertainable even though the direct explanation of the purpose is not.
&lt;/p&gt;
&lt;p&gt;
    While this aids us by limiting further argument to a defined set of options, it unfortunately does not depict in detail how one is able to detect appropriate actions.  To further pursue this line of reasoning, I have written &lt;a href=&quot;/2020/05/intuition-probability/&quot;&gt;a separate post&lt;/a&gt; which aims to describe how intuition could be interpreted as the means by which appropriate actions become determinable.
&lt;/p&gt;


&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;
    In this thought-experiment I believe I have shown that given our premises, it is correct to assume that
&lt;/p&gt;
    &lt;ul&gt;
        &lt;li&gt;there is a purpose to the universe, &lt;/li&gt;
        &lt;li&gt;our actions can influence the fulfillment of that purpose, &lt;/li&gt;
        &lt;li&gt;it is not knowable what the purpose is, and&lt;/li&gt;
        &lt;li&gt;that there must be some way to discern the necessary actions for fulfillment of this purpose despite not knowing the purpose itself.&lt;/li&gt;
    &lt;/ul&gt;
&lt;p&gt;
    This is, of course, a highly debatable topic, and I don't pretend that I have all the answers.  However, I think that this offers a valid rebuttal to materialistic nihilism, and I encourage you to utilize the argument if you find yourself dealing with an individual who advocates such a position.
&lt;/p&gt;
&lt;p&gt;
    If you have any feedback on this philosophy I would greatly appreciate it.
&lt;/p&gt;


&lt;h4&gt;Note: Differences with Pascal's wager&lt;/h4&gt;
&lt;p&gt;
    There is some similarity between this argument and Pascal's wager. Pascal's wager posits that a person should choose to believe in God because the reward is infinite while the sacrifice is at most finite. However, there are several flaws with argument. To me the crucial flaw is that it starts with a multitude of assumptions that corner it into a very small corner of the entire space of universe possibilities.
&lt;/p&gt;
&lt;p&gt;
    To begin, it assumes a binary choice between a single God to worship or not to worship. In reality, there are multiple established gods that are worshipped on Earth, each of whom provides a distinct course of correct action.  As such, the wager fails to account for multiple possible vengeful gods who will damn you if you choose your actions poorly.
&lt;/p&gt;
&lt;p&gt;
    Furthermore, it requires one to desire everlasting reward. It seems that this in itself is not necessarily something that a reasonable person needs to desire.  For other shortcomings with the wager see the &lt;a href=&quot;https://rationalwiki.org/wiki/Pascal%27s_wager&quot;&gt;rationalwiki&lt;/a&gt; page on the topic.
&lt;/p&gt;</description>
        <pubDate>Mon, 18 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/philosophical-grind/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/philosophical-grind/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>Intuition as Unobserved Probabilistic Function Exploration</title>
        <description>&lt;p&gt;&lt;em&gt;&lt;small&gt;
    Epistemic status: It should go without saying that I don't have any certainty about the fundamental nature of the universe.  This is just a bit of conjecture that gets me through my day.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
    In my previous writing, I've derived arguments to show that I should act as though &lt;a href=&quot;/2019/10/sub-identity-suicide/&quot;&gt;the universe has a purpose&lt;/a&gt;, and that while the universe's purpose is not knowable with certainty, I should act as though correct action &lt;a href=&quot;/2020/05/philosophical-grind/&quot;&gt;is discoverable&lt;/a&gt;.  In this work, I wish to lay out my argument for intuition as a way of sensing the correct actions that will aid in the fulfillment of the underlying purpose of the universe.
&lt;/p&gt;
&lt;p&gt;
    While this post is not as thorough as my prior arguments, I wish to point out ahead of time that the method of argumentation used is consistent with the method of action advocated by the argument (ie intuition).  In this sense, the following is at least self-consistent, though potentially not entirely rigorous to all counterarguments.
&lt;/p&gt;

&lt;h4&gt;Decision making and uncertainty&lt;/h4&gt;
&lt;p&gt;
    Previously, I've noted that the purpose of the universe is probably &lt;a href=&quot;/2020/05/philosophical-grind/&quot;&gt;not directly detectable&lt;/a&gt;, and that there exist an infinite number of possible explanations for the universe's purpose that we cannot even imagine. Nevertheless, it can help introduce this derivation by imagining that we have some finite set of options that we believe could be plausible descriptions of the purpose of the universe.
&lt;/p&gt;
&lt;p&gt;
    If this were the case, then it would be possible to enumerate the options and assign our estimated confidence that each one was the true purpose of the universe. Take for example the following three arbitrarily chosen pet hypotheses.
&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;Religion: Satisfactorily worship a specific deity&lt;/li&gt;
    &lt;li&gt;Time Miners: Allow a species that exists in an external metauniverse to drill holes to mine time&lt;/li&gt;
    &lt;li&gt;Simulation: Simulate the real earth to prevent a natural disaster&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    For each of these pet theories we could then assign some probability that we think it is the true purpose of the universe.  Take for example these three assignments.
&lt;/p&gt;
&lt;table style=&quot;border-collapse: collapse;&quot;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th&gt;Purpose&lt;/th&gt;
    &lt;th&gt;Probability&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody style='text-align:center;'&gt;
  &lt;tr&gt;
    &lt;td&gt;Religion&lt;/td&gt;
    &lt;td&gt;0.5&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Time Miners&lt;/td&gt;
    &lt;td&gt;0.3&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Simulation&lt;/td&gt;
    &lt;td&gt;0.2&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
    Now, if we assume that we wish to maximize the probability that we would be aiding the purpose of the universe with our actions, we could allocate our efforts to take the set of actions best suited to that goal. As an example, assume that we have the following three actions to choose from, which each contribute toward the above goals by differing amounts. In addition, each costs us a certain amount of time per day.
&lt;/p&gt;

&lt;table style=&quot;border-collapse: collapse;&quot;&gt;
&lt;thead&gt;
  &lt;tr&gt;
    &lt;th&gt;Action&lt;/th&gt;
    &lt;th&gt;Contribution to Religion&lt;/th&gt;
    &lt;th&gt;Contribution to Time Miners&lt;/th&gt;
    &lt;th&gt;Contribution to Simulation&lt;/th&gt;
    &lt;th&gt;Time Allocation (hours per day)&lt;/th&gt;
  &lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody style='text-align:center;'&gt;
  &lt;tr&gt;
    &lt;td&gt;Go to church once a week&lt;/td&gt;
    &lt;td&gt;0.8&lt;/td&gt;
    &lt;td&gt;0.2&lt;/td&gt;
    &lt;td&gt;0.3&lt;/td&gt;
    &lt;td&gt;0.01&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Become a devout monk&lt;/td&gt;
    &lt;td&gt;0.95&lt;/td&gt;
    &lt;td&gt;0.2&lt;/td&gt;
    &lt;td&gt;0.1&lt;/td&gt;
    &lt;td&gt;24&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Study quantum physics&lt;/td&gt;
    &lt;td&gt;0.0&lt;/td&gt;
    &lt;td&gt;0.7&lt;/td&gt;
    &lt;td&gt;0.3&lt;/td&gt;
    &lt;td&gt;8&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
    Stepping through this table, we see that becoming a monk would most likely satisfy the religion purpose, while going to church has some likelihood of satisfying it.  Of course, studying quantum physics doesn't contribute meaningfully to the religion purpose but contributes more to helping the Time Miners (if they exist).
&lt;/p&gt;
&lt;p&gt;
    So, assuming we had only the above three options, and that we had confidence that our assessment of the probability of each of the above purposes is correct, we could optimize our total probability of aiding the universe in fulfilling its purpose. As an example, let us compare these two options: becoming a devout monk vs studying quantum physics and going to church once a week.
&lt;/p&gt;
&lt;p&gt;
    By the above estimate, becoming a devout monk is all consuming (24 hours/day) so we only account for that action's success probabilities.  In other words, our total probability of helping the universe as a monk is &lt;code&gt;0.95*0.5 + 0.2*0.3 + 0.1*0.2 = 0.555&lt;/code&gt;.  Next we compare this with the total probability of success for studying quantum physics and going to church once a week.  For that we can add the probabilities of both actions because we have the bandwidth to do both things. This set of actions results in &lt;code&gt;(0.0+0.8)*0.5 + (0.7+0.2)*0.3 + (0.3+0.3)*0.2 = 0.79&lt;/code&gt;*.
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;small&gt;
    *Caveat: The way I've combined the probabilities isn't exactly proper here.  I should account for the &lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_total_probability&quot;&gt;total probability&lt;/a&gt; dependent on each set of other choices.  However, this only complicates the math and doesn't contribute deeply to the gist of the argument so I've simplified here.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
    From this calculation we would conclude that it's better to study quantum physics and go to church than to become a devout monk.  Even though becoming a devout monk best satisfies the thing we have assumed is most important (appeasing an angry god), its all-consuming nature prevents us from satisfying other plausible purposes at the same time.  Therefore, it is too costly to devote ourselves entirely to that cause at the expense of other propositions.
&lt;/p&gt;

&lt;p&gt;
    So if choosing our path in life just came down to working out some probabilistic math, then it would seem our decisions should be simple. Unfortunately, it can't be quite that easy.
&lt;/p&gt;


&lt;h4&gt;The problem with assigning probabilities&lt;/h4&gt;

&lt;p&gt;
    The problem with assigning probabilities is that we just cannot know all the possible purposes of the universe and the probabilities of each. In fact, rather than being able to enumerate a precise list of purposes, we should probably assume that there are actually infinite possibilities.  If this is the case, there is &lt;a href=&quot;https://en.wikipedia.org/wiki/Infinitesimal&quot;&gt;effectively 0&lt;/a&gt; probability that any single purpose that we decide on is the correct one.
&lt;/p&gt;
&lt;p&gt;
    Beyond this, there are a staggering number of actions available to us.  While the number of options isn't truly infinite, the varying degrees to which we can devote ourselves to each course of action available places the number of distinct possible lives we could live outside the limit of my imagination at least.
&lt;/p&gt;
&lt;p&gt;
    So there is clearly no way to directly compute the proper course of action using the above procedure without making other assumptions about the space of available purposes and actions.  There is no easy resolution, and yet, through &lt;a href=&quot;/2020/05/philosophical-grind/&quot;&gt;previous arguments&lt;/a&gt;, we still should assume there is some resolution.  So what is there to do?
&lt;/p&gt;

&lt;h4&gt;Using Intuition&lt;/h4&gt;
&lt;p&gt;
    I posit that the only resolution to this conundrum is that there must be some subtle revelation of the correct course of action that is available to each actor in the universe.  This revelation could occur in many ways, depending on the exact form of the actor to whom the action is revealed.  While it is not entirely clear how this revelation takes place in general, I think in a few cases we could hypothesize something to approximately describe how it works.
&lt;/p&gt;
&lt;p&gt;
    The hypothesis suggests that somehow the universe reveals to every element within it the set of actions that will help the universe's purpose be fulfilled. I do not know how this revelation is manifested in all people, and indeed I don't even know how other people internally manifest their sensation of interacting with the world. All I know is the internal sensation of reality that I experience.  Based on my internal sensation, the most likely mechanism of this revelation seems to be through some indescribable set of instincts and biases we call our &lt;em&gt;intuition&lt;/em&gt;
&lt;/p&gt;
&lt;p&gt;
    My main contention is that our intuitions are the most likely conduit by which we would qualitatively sense the universe's goals. To think about how intuition can satisfy this problem, let's further define intuition.  By intuition, I mean the combined set of inclinations that direct what &lt;em&gt;I would do if I could&lt;/em&gt;. I would describe these motivations as a subset of my complete &lt;a href=&quot;/2020/05/redefining-identity/&quot;&gt;identity&lt;/a&gt;.  I do not necessarily suggest that there is anything supernatural about this set of motivations; they could be entirely circumscribed by the interaction of the physical laws of nature. The only suggestion is that the proper course of action must always be somehow suggested to our decision making mind, and that there is no other way to explain that phenomenon without resorting to something like intuition as defined above.
&lt;/p&gt;
&lt;p&gt;
    To state my above argument more formally, I propose that intuition is a way of detecting the relative values of a function that indicates whether an action helps to fulfill the purpose of the universe without being able to view the state of this function directly. My intuition for deriving this model of intuition came from my understanding of the way a quantum &lt;a href=&quot;https://en.wikipedia.org/wiki/Wave_function&quot;&gt;wave function&lt;/a&gt; explores &lt;a href=&quot;https://uwaterloo.ca/institute-for-quantum-computing/quantum-computing-101#Superposition-and-entanglement&quot;&gt;all possibilities of a quantum state&lt;/a&gt; in a probabilistic manner without allowing access to the underlying state directly[&lt;a href=&quot;https://arxiv.org/pdf/quant-ph/9712011.pdf&quot;&gt;ref&lt;/a&gt;]*.
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;small&gt;
    *Note that I’ve left this analogy a little underdeveloped, as describing the exact correspondence between my intuition about intuition and my understanding of quantum physics is beyond this set of posts. Hopefully I can expand on the connection later when I have time and will link here when I do.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
    One intuitive reason that I find this analogy compelling is that it offers a plausible justification for why we would live in a universe with such preposterous physics as is suggested by our understanding of quantum mechanics.  First, it is because we would need this physical example as ansuch an analogy to help us recognize the strange model of how intuition could guide usunderstand this mechanism, and second because quantum physics could in fact be the underlying physical mechanism by which this theoretical construct of intuition becomes real.
&lt;/p&gt;

&lt;p&gt;
    Nevertheless, I understand that the leap to accepting intuition as a valid directive lacks the rigor that previous derivations built upon. However, I cannot propose any other resolution given the constraints of my &lt;a href=&quot;/2020/05/philosophical-grind/&quot;&gt;previously derived philosophy&lt;/a&gt;. Therefore, I am currently accepting this hypothesis in order to make decisions about my life. In addition, as I have arrived at this leap using my own intuition, it is at the least not out of keeping with the philosophy it proposes. (Since Goedel tells us we can't have completeness and consistency anyway, I will at least choose to keep consistency where possible.)
&lt;/p&gt;

&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;
    This is the current conclusion of my philosophical statement of beliefs.  It is a work in progress, and I reserve the right to edit parts as it becomes clearer how to improve this thesis.
&lt;/p&gt;
&lt;p&gt;
    Importantly, I wish the reader to recognize that this philosophy really does underpin the work I am trying to do with my life.  It is an important anchor in my productive goals, and the creative works that I produce.
&lt;/p&gt;
&lt;p&gt;
    Finally, I hope it goes without saying that I only want this philosophy to improve. If you believe that you see a major flaw in my reasoning, or if you believe something is underexplained, please do not hesitate to &lt;a href=&quot;https://will.stedden.org/&quot;&gt;contact me&lt;/a&gt; to start a conversation.  I will definitely respond to any good faith attempts at refutation.
&lt;/p&gt;
&lt;p&gt;
    OK, that concludes this philosophical effort for now.  Bye, have fun existing!
&lt;/p&gt;</description>
        <pubDate>Mon, 18 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/intuition-probability/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/intuition-probability/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/swale_logo.svg</image>
        <title>The Swale: Weaving between Garden and Stream</title>
        <description>&lt;p&gt;&lt;em&gt;&lt;small&gt;
Epistemic status: Minimally researched musings from someone who has blogged (poorly) for a few years and has an idea for a thing he wants to make.
&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
    In the digital circles where I find myself roaming these days, there is an interesting conversation about two different modalities of online content creation, summarized by a potent analogy called the &lt;strong&gt;Garden&lt;/strong&gt; and the &lt;strong&gt;Stream&lt;/strong&gt;.  I think I was initially made aware of it from &lt;a href=&quot;https://boffosocko.com/2020/04/17/gardens-and-streams-wikis-blogs-and-ui-a-pop-up-indiewebcamp-session/&quot;&gt;Chris Aldrich's reference&lt;/a&gt; to &lt;a href=&quot;https://hapgood.us/2015/10/17/the-garden-and-the-stream-a-technopastoral/&quot;&gt;this post&lt;/a&gt; by &lt;a href=&quot;https://hapgood.us/author/mikecaulfield/&quot;&gt;Mike Caulfield&lt;/a&gt;. If you aren't familiar with the tale of the Garden and the Stream, I suggest you read that piece.
&lt;/p&gt;
&lt;p&gt;
    This is my very brief, oversimplified summary of the allegory.
&lt;/p&gt;
&lt;blockquote&gt;
    The &lt;strong&gt;Stream&lt;/strong&gt; is the blog, the news feed, the Twitter timeline, all that which flows past us in a line, delivered in discrete chunks, fixed in the fourth dimension with timestamps.  The &lt;strong&gt;Garden&lt;/strong&gt; is the wiki, the documentation, the Github repository, all that which continues to resemble itself, residing where it first cropped up, growing in spots, receding in others, what you see is the accumulation of all changes.
&lt;/blockquote&gt;
&lt;p&gt;
    As you may have noticed, I've enjoyed the analogy a lot, and am very interested in the &quot;garden-esque&quot; projects[&lt;a href=&quot;https://notes.andymatuschak.org/About_these_notes&quot;&gt;1&lt;/a&gt;], [&lt;a href=&quot;https://roamresearch.com/&quot;&gt;2&lt;/a&gt;], [&lt;a href=&quot;https://tomcritchlow.com/2019/02/17/building-digital-garden/&quot;&gt;3&lt;/a&gt;] and ideas[&lt;a href=&quot;http://a9.io/glue-comic/&quot;&gt;4&lt;/a&gt;], [&lt;a href=&quot;https://blog.noahtren.com/%F0%9F%92%AC/c7eb01d7-0d0d-4466-8db2-9de2f73ed8b1/&quot;&gt;5&lt;/a&gt;]  that I've seen sprouting on my feed this spring (&lt;em&gt;aside: I'm not even close to finished letting these metaphors flow so best put on your lifejacket&lt;/em&gt;).  However, the story posed by Caulfield is ultimately more prescriptive than just a suggestion to experiment with some new content formats. He believes that fixation on stream-like works has harmed our information society, which inevitably poses the question: &lt;strong&gt;&quot;where should I place my effort, in streaming or in gardening?&quot;&lt;/strong&gt;
&lt;/p&gt;

&lt;h4&gt;Am I part of the problem?&lt;/h4&gt;

&lt;p&gt;
    Currently my social media infrastructure is in a fairly standard streaming modality. My kneejerk reaction is that wikis and garden-esque systems are best for communal development of knowledge, and streams are how we articulate the state of our own minds.  Hence, I'm naturally disinclined to the changeover, but, as is the norm, my instinct in one direction leads me to question even more strongly whether the other direction is better. And now this discussion has me wondering whether I've got it all wrong.
&lt;/p&gt;
&lt;p&gt;
    To confront this, I've employed my standard adaptive immune response to all statements of dualistic choice.
&lt;/p&gt;
&lt;p&gt;
    First, I ask if the proposals are quantitatively or qualitatively different. If only quantitatively different, then the choice between them is continuous and there are infinite blends of the opposing viewpoints. I assume that everyone can find their optimum middle ground. I choose my own and move on.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, in this instance, the modalities as described are incompatible. The Stream that is discrete and time ordered, is by definition non-isomorphic with the Garden. This are qualitatively distinct modes of representation, and so I must choose.
&lt;/p&gt;
&lt;p&gt;
    But of course, no, that isn't true either. Similar to my &lt;a href=&quot;/2020/05/what-is-an-identifield/&quot;&gt;recent musings (link coming soon)&lt;/a&gt;  on the dualism of matter vs information, I find that the real beauty may lie precisely in the complexity of their combination.
&lt;/p&gt;

&lt;h4&gt;Swale&lt;/h4&gt;

&lt;p&gt;
    I had an intuition that there is a third choice, but I couldn't articulate it directly.  Instead, I worked backwards from yet another metaphor of natural landscape: the &lt;strong&gt;Swale&lt;/strong&gt;.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wikimedia_swale.jpg&quot;/&gt;

&lt;p&gt;
    A &lt;a href=&quot;https://www.sudswales.com/types/permeable-conveyance-systems/swales/&quot;&gt;swale&lt;/a&gt; is a wide, flat stretch of land used to slow down water runoff and help it be reabsorbed into the earth.  Additionally, in &lt;a href=&quot;https://www.tenthacrefarm.com/permaculture-swale/&quot;&gt;permaculture&lt;/a&gt; and other types of sustainable gardening, swales are often directed to irrigate gardens by diverting a natural runoff to slow down and meander.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/Swale_Brook_1.jpg&quot;/&gt;

&lt;p&gt;
    So... what if I could metaphorically divert my raging (downhill) torrent of online conversation into a shallower meandering Swale?  Maybe in that effort the Stream becomes the natural sustenance of the Garden?
&lt;/p&gt;

&lt;p&gt;
    So naturally, what I am proposing to try in the near term with my blog is to build a place where the content pools together.  Essentially, for every post across all media, I will break it down into it's component parts, match it to other content that I have already created and link them together in a more garden-esque manner.
&lt;/p&gt;

&lt;p&gt;
    Manually curating that would take a bit of work, which I am honestly not willing to do. So instead, (like a permaculturist or a lazy engineer) I aim to build an ecosystem that naturally converts my soil eroding stream into a sustaining water supply.
&lt;/p&gt;


&lt;h4&gt;
    Design spec
&lt;/h4&gt;
&lt;p&gt;
    OK, I'm done beating this metaphor to death now.  Time to sketch how it's going to work.  I haven't planned too deeply yet, since I'm sure that 10 minutes into the process I'll need to reconfigure everything anyway. But for now, my product design is the following:
&lt;/p&gt;

&lt;h6&gt;1. Break down each discrete post into linked subcontent&lt;/h6&gt;
&lt;p&gt;For posts, I typically use headings subheadings and paragraphs, these present a natural breakdown of the stream into &lt;strong&gt;droplets&lt;/strong&gt;.&lt;/p&gt;
&lt;h6&gt;2. Link using hyperlinks&lt;/h6&gt;
&lt;p&gt;I often cite my own prior work, or I cite the same work repeatedly.  These will form natural, bidirectional links between droplets.&lt;/p&gt;
&lt;h6&gt;3. Link with content&lt;/h6&gt;
&lt;p&gt;Do I repeat myself? Hopefully, I get away with just a little &lt;a href=&quot;https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/&quot;&gt;cosine tf-idf similarity&lt;/a&gt; to detect when I say the same thing and form more links. &lt;/p&gt;
&lt;h6&gt;4. Visualize&lt;/h6&gt;
&lt;p&gt;This is where some magic will happen that allows us to see connections without it just being a big hairball. Wish me luck.&lt;/p&gt;
&lt;h6&gt;5. Observe&lt;/h6&gt;
&lt;p&gt;This exercise won't do much good unless I look at it to see patterns.&lt;/p&gt;
&lt;h6&gt;6. Modify&lt;/h6&gt;
&lt;p&gt;If I see a pattern, the next step is to annotate it coherently.&lt;/p&gt;
&lt;h6&gt;7. Stream the changes&lt;/h6&gt;
&lt;p&gt;If I have a profound realization I would probably restreamify the result.&lt;/p&gt;


&lt;h4&gt;Conclusion: Go make the thing&lt;/h4&gt;
&lt;p&gt;
    Now all that's left is to spend a weekend slapping a prototype together if you wnat to help, drop me a line.  Thanks for listening. Like any good slide-ware I've already made a corny logo too.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/swale_logo.svg&quot;/&gt;</description>
        <pubDate>Wed, 13 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/swale-garden-stream/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/swale-garden-stream/</guid>
        
        <category>philosophy</category>
        
        <category>web</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/political_ads.png</image>
        <title>Timeline Streamgraph from Google Sheets Data</title>
        <description>&lt;p&gt;
    I've made a new kind of visualization called a &lt;strong&gt;Timeline Streamgraph&lt;/strong&gt;.  It's a modification of a conventional &lt;a href=&quot;http://leebyron.com/streamgraph/&quot;&gt;streamgraph&lt;/a&gt;, flipped on its side so that time flows from bottom to top.
&lt;/p&gt;
&lt;p&gt;
    I built it this way to evoke the sensation we experience when we view online media &lt;a href=&quot;https://www.lifewire.com/what-are-twitter-timelines-2655401&quot;&gt;timelines&lt;/a&gt;. Although a standard streamgraph can convey the same information, having to scroll down for older information tries to remind the viewer that, like media streams, the data is still being generated &quot;in front&quot; of them.
&lt;/p&gt;

&lt;p&gt;
    As an example, I generated this figure of political ad spend on Google Ads.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/political_ads.png&quot;/&gt;

&lt;p&gt;
    I can imagine a lot of other interesting uses so I've made the viz very easy to replicate and modify. The coolest part is that it &lt;strong&gt;pulls data directly from a Google Sheet&lt;/strong&gt; so I can easily keep the data fresh by just copy and pasting the new data into the sheet.
&lt;/p&gt;

&lt;p&gt;
    Below I have a tutorial that explains how to take my code and build one yourself.
&lt;/p&gt;

&lt;h3&gt;How to Make a Timeline Streamgraph&lt;/h3&gt;
&lt;p&gt;
    To replicate this figure with your own data you just need to
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fork &lt;a href=&quot;https://codepen.io/stedn/pen/BaoxGwr&quot;&gt;from Codepen&lt;/a&gt; or &lt;a href=&quot;https://gist.github.com/stedn/ccd784c9c52ce76d01e1569cd60d213e&quot;&gt;from Github gist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Put data into a Google Sheet&lt;/li&gt;
&lt;li&gt;Add the Google Sheet key to the code&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Fork a gist or codepen&lt;/h4&gt;

&lt;p&gt;I've made the code available on gist or on codepen so you can copy it from whichever is easiest for you.&lt;/p&gt;

&lt;h5&gt;Fork from codepen&lt;/h5&gt;

&lt;p&gt;If you have a codepen account, you can view &lt;a href=&quot;https://codepen.io/stedn/pen/BaoxGwr&quot;&gt;this pen&lt;/a&gt; and click &quot;Fork&quot; in the bottom right corner to make a copy that you can edit.&lt;/p&gt;

&lt;h5&gt;Fork a gist&lt;/h5&gt;
&lt;p&gt;
    If you have a Github account you can view &lt;a href=&quot;https://gist.github.com/stedn/ccd784c9c52ce76d01e1569cd60d213e&quot;&gt;this gist&lt;/a&gt; and &quot;fork&quot; a copy of it that will make it editable by you.  When you do this the project will be set up at &lt;code&gt;https://gist.github.com/GITHUB_USERNAME/ID_OF_PROJECT&lt;/code&gt;.
&lt;/p&gt;
&lt;p&gt;
    If you want to view your visualization you can use the amazing bl.ocks.org from Mike Bostock.  Just go to the following URL, using the same &lt;code&gt;GITHUB_USERNAME&lt;/code&gt; and &lt;code&gt;ID_OF_PROJECT&lt;/code&gt; that you see for your gist.
&lt;/p&gt;
&lt;pre&gt;
https://bl.ocks.org/GITHUB_USERNAME/ID_OF_PROJECT
&lt;/pre&gt;
&lt;p&gt;
    You should see an exact copy of the original vizualization.  Next you just need to modify it to point to your own data.
&lt;/p&gt;


&lt;h4&gt;Putting Data in a Google Sheet&lt;/h4&gt;
&lt;p&gt;
    The viz just pulls from any published Google Sheet.  It looks for data in three columns with the following format and headings.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/dataformat.png&quot;/&gt;

&lt;p&gt;
    For this demo, I wrote a query to get political ad spend from Google Ads data on BigQuery.  But, keep in mind, you can use any data you want as long as it follows the &lt;code&gt;key&lt;/code&gt;, &lt;code&gt;date&lt;/code&gt;, &lt;code&gt;value&lt;/code&gt; format.  IMPORTANT, your data can not have any repeated key, date pairs. Make sure that the same data does not appear repeated for any individual key.
&lt;/p&gt;


&lt;p&gt;
    To allow access to your data, you need to publish the sheet.  You can find the publish dialog here.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/dataformat.png&quot;/&gt;


&lt;p&gt;
    Select to publish the entire document as web page.
&lt;/p&gt;

&lt;h4&gt;Connect D3 viz to Google Sheet&lt;/h4&gt;
&lt;p&gt;
    On codepen or gist you'll see at the top of the HTML there is a variable named &quot;google_sheets_id.&quot; Fill that in with the corresponding key from your published google sheet.  You can see the key directly in the url on the edit page.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/googlesheetkey.png&quot;/&gt;

&lt;p&gt;
    If you're using Codepen, then the page should update right away with your new data.  If you are using gist you'll need to save the gist, and wait a few minutes for the changes to propagate to bl.ocks.org.
&lt;/p&gt;


&lt;h5&gt;Bonus: Add custom colors&lt;/h5&gt;
&lt;p&gt;
    I've also added a way to specify the colors from the same Google Sheet. You just need to add a second sheet with a column for &lt;code&gt;key&lt;/code&gt; and a column for &lt;code&gt;color&lt;/code&gt;. You need to have one color for every key on the first sheet. Any key that isn't included will show up black. Also, make sure that you don't change the order of the sheets.
&lt;/p&gt;


&lt;h4&gt;Example uses&lt;/h4&gt;
&lt;p&gt;
    I'm very curious what other uses people come up with for this viz.  If you try something out, please &lt;a href=&quot;https://will.stedden.org&quot;&gt;let me know&lt;/a&gt; and I'll a link to it here.
&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;political ad spend 2020 - example from this blog post&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://will.stedden.org&quot;&gt;will.stedden project history&lt;/a&gt; - visual curriculum vitae that shows all the projects I've worked on concurrently over the past few years&lt;/li&gt;
&lt;/ul&gt;</description>
        <pubDate>Sun, 10 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/timeline-streamgraph-google-sheet/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/timeline-streamgraph-google-sheet/</guid>
        
        <category>visualization</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/twitter_hipster.gif</image>
        <title>Twitter for Hipster</title>
        <description>&lt;p&gt;&lt;small&gt;&lt;em&gt;
    tl;dr; I made a web extension that removes all the really popular tweets from your timeline.  You can &lt;a href=&quot;https://lots-of-things.github.io/twitter-for-hipster/twitter_for_hipster-1.0-fx.xpi&quot;&gt;install it for Firefox&lt;/a&gt;, and view the open source code &lt;a href=&quot;https://github.com/lots-of-things/twitter-for-hipster&quot;&gt;here&lt;/a&gt;.
&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;
    As I've been reading Twitter I've been getting increasingly fed up with all the distracting &quot;fun&quot; content that people post.   I'm on Twitter to hear about interesting machine learning and science project and to be reminded that the world is a terrifying place.
&lt;/p&gt;

&lt;p&gt;
    Then a few days ago I realized the issue.  I don't like the things that are capable of becoming popular.
&lt;/p&gt;

&lt;blockquote&gt;
    So yeah, I understand now it. I am a grumpy hipster.
&lt;/blockquote&gt;

&lt;p&gt;
    At first I thought I might be alone in my misanthropy, but then a few days ago I learned about two other #GrumpyTwitter™ projects &lt;a href=&quot;https://bengrosser.com/projects/twitter-demetricator/&quot;&gt;Twitter Demetricator&lt;/a&gt; and &lt;a href=&quot;https://github.com/thomaswang/minimal-twitter&quot;&gt;Minimal Twitter&lt;/a&gt;. These are two browser extensions that remove noise from Twitter, and I use both of them now (thanks &lt;a href=&quot;https://twitter.com/ThomasWang&quot;&gt;@ThomasWang&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/bengrosser&quot;&gt;@bengrosser&lt;/a&gt;).  As I was looking at how these tools worked, I realized that I could hack my Twitter experience too!
&lt;/p&gt;

&lt;h2&gt;Twitter for Hipster&lt;/h2&gt;

&lt;p&gt;
    So last night, I built a &lt;a href=&quot;https://en.wikipedia.org/wiki/Browser_extension&quot;&gt;browser extension&lt;/a&gt; that finds all the tweets on the page with more than 1000 likes and just removes them. That's all it does.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/twitter_hipster.gif&quot; /&gt;

&lt;p&gt;
    Behold in amazement as all of those annoying meme derivatives dissappear from your timeline!
&lt;/p&gt;

&lt;h3&gt;You can be a hipster too&lt;/h3&gt;
&lt;p&gt;
    If you want to get rid of that crap too and you're using Firefox (like a good web hipster), this link should install it for you.
&lt;/p&gt;

&lt;h5 style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;https://lots-of-things.github.io/twitter-for-hipster/twitter_for_hipster-1.0-fx.xpi&quot;&gt;Install add-on for Firefox&lt;/a&gt;&lt;/h5&gt;

&lt;p&gt;
    All the code is also free and open source &lt;a href=&quot;https://github.com/lots-of-things/twitter-for-hipster&quot;&gt;here&lt;/a&gt; in case you want to modify it.  I've got instructions for installing on Chrome there too.  Also, I'm very open to even more grumpy hipster modifications, like hiding memes and pandering.  It'd be cool to detect that stuff using some tensorflow-js like in &lt;a href=&quot;https://github.com/JK0N/tensorflow-image-recognition-chrome-extension&quot;&gt;this web extension project&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
    But, anyway, first I'm just gonna filter all the tweets with 0 likes so I don't have to listen to how happy my friends are that they aren't drinking their artisinal coffee...
&lt;/p&gt;</description>
        <pubDate>Mon, 04 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/twitter-for-hipster/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/twitter-for-hipster/</guid>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/add_yeast.jpg</image>
        <title>Amplifying Yeast</title>
        <description>&lt;p&gt;
    In this time of minimally available yeast, it's important for bakers to extend their yeast supplies a bit.  Many have turned to sourdough, but if you don't eat bread every day, feeding a sourdough starter can seem a little wasteful.  As an alternative, here's how I've been amplifying my instant yeast stock with brown sugar for the past few weeks.
&lt;/p&gt;

&lt;p&gt;
    This is just my rough guide.  I'll update if I get more scientific information if I learn anything.
&lt;/p&gt;

&lt;h4&gt;Ingredients&lt;/h4&gt;
&lt;p&gt;
    We will be combining sugar, water, and yeast in a sterilized container.  The exact proportions probably matter a lot, but I don't know how.  I combine &lt;strong&gt;1/2 cup to a whole cup of water&lt;/strong&gt; with about &lt;strong&gt;1 tablespoon of brown sugar&lt;/strong&gt;.  I use as little yeast as I can get away with, normally around a &lt;strong&gt;1/4 teaspoon of yeast&lt;/strong&gt;.
&lt;/p&gt;
&lt;p&gt;
    Hopefully, a very good yeast biologist or home brewer will get in touch soon and tell me exactly what the ratio should be.  I'll keep you posted.
&lt;/p&gt;

&lt;h4&gt;Equipment&lt;/h4&gt;
&lt;p&gt;
    All we really need is some place for our yeast to live while they eat.  I do this with a glass jar and a bit of tin foil to cover it.  You probably don't want to seal the jar with a lid because the yeast will be belching out CO2 and we don't really want to pressurize our jar/carbonate our water if we can help it.
&lt;/p&gt;


&lt;h4&gt;Sanitize&lt;/h4&gt;
&lt;p&gt;
    Because we aren't going for sourbread we want to try to get our amplification environment as free from outside bacteria as possible.  To do this we boil our jar and the tin foil covering. I put it in boiling water for about 5 minute and then pull it out with afork.
&lt;/p&gt;

&lt;h4&gt;Boil Wort&lt;/h4&gt;
&lt;p&gt;
    The yeast will be eating sugar in water.  We want the sugar well mixed and free from bacteria so we boil it first. I boil for a couple of minutes.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/boil_wort.jpg&quot; /&gt;


&lt;h4&gt;Cool Wort&lt;/h4&gt;
&lt;p&gt;
    Drinking boiling sugar water hurts yeast just as much as it hurts us (maybe even more).  Pour the boiling wort into the jar and cool the jar from the outside with some water.  I throw some ice cubes in to cool it faster.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/cool_wort.jpg&quot; /&gt;


&lt;p&gt;
    &lt;strong&gt;It's crucially important that you don't put yeast in while the wort is still hot.&lt;/strong&gt;  That will kill the yeast.  And don't be fooled if the outside is cool when in the water bath.  The outside temp of the jar can be low while the water on the inside is still hot.  Take the jar out of the water bath and let it sit for a minute before testing the temperature.  If it's close to room temperature then it should be safe to move on.
&lt;/p&gt;

&lt;h4&gt;Add Yeast&lt;/h4&gt;
&lt;p&gt;
    Once the wort is cool, toss in some yeast.  There should be quite a bit of action right at the beginning but over time it should slow down.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/add_yeast.jpg&quot; /&gt;

&lt;h4&gt;Let Them Grow&lt;/h4&gt;
&lt;p&gt;
    Set it someplace dark and warmish for a long time. It should bubble and start to smell like bread before too long.  Good yeast can get really active in there so watch out!  I don't know how long it takes to consume all the sugar and how fast they multiply.  I normally do 8 hours.  &lt;strong&gt;If you know the science facts about yeast replication, please tell me and I'll report it here.&lt;/strong&gt;
&lt;/p&gt;

&lt;h4&gt;Smell Them&lt;/h4&gt;
&lt;p&gt;
    After you've let it go for a couple of hours give it a big smell.  If it reminds you of delicious bread, then move on.  If it smells a little off, then you might want to taste it before you put it into your bread.  Though, even if you've been a little unsanitary, in just a few hours, I don't think you can grow anything that toxic.  It'll probably just taste like sourdough.
&lt;/p&gt;

&lt;h4&gt;Bake Them&lt;/h4&gt;
&lt;p&gt;
    Use it just like the water and yeast mixture it is.
&lt;/p&gt;


&lt;h4&gt;Things to consider&lt;/h4&gt;
&lt;p&gt;
    If you open a packet of yeast and only use part, make sure you &lt;strong&gt;put the rest in the fridge/freezer&lt;/strong&gt;.  For my first packet I left it out, and it definetly degraded the activity of the yeast.
&lt;/p&gt;</description>
        <pubDate>Sat, 02 May 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/05/amplifying-yeast/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/05/amplifying-yeast/</guid>
        
        <category>food</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/vbrc.gif</image>
        <title>Building a Virtual Black Rock City</title>
        <description>&lt;p&gt;
    When Burning Man &lt;a href=&quot;https://journal.burningman.org/2020/04/news/official-announcements/brc-2020-update/&quot;&gt;announced&lt;/a&gt; that they were canceling the party in the desert this year, they hinted that they wanted to try to make an online Black Rock City experience.  But as &lt;a href=&quot;https://journal.burningman.org/2020/04/philosophical-center/tenprinciples/trapped-in-the-multiverse-what-should-a-digital-burning-man-be/&quot;&gt;others have mentioned&lt;/a&gt;, it's going to be kind of disappointing trying to pretend that we're in the Black Rock Desert when we're really at home on our laptops. I've been thinking of ways to do something different than &lt;a href=&quot;https://journal.burningman.org/2020/04/philosophical-center/tenprinciples/creating-art-experiences-in-a-plague-world-we-can-do-this/&quot;&gt;quirky Zoom meetings&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
    My &lt;a href=&quot;/2019/10/creating-immediacy/&quot;&gt;favorite part&lt;/a&gt; of Burning Man is walking around and being able to connect with anybody around you.  So I tried to build a lo-fi webgame version of that experience as a test-bed for what a virtual playa could look like.
&lt;/p&gt;


&lt;img src=&quot;/assets/images/2020/vbrc.gif&quot; title=&quot;gif of running around virtual black rock city&quot;/&gt;

&lt;p&gt;
    The idea is to keep it extremely bare-bones, just like the black rock desert is before we all get there.  Then everyone who comes builds there own things, and they come to v-playa to tell other people about them.  So we all wander around and try to find things to do and people to hang out with. Just like irl, well kind of.
&lt;/p&gt;

&lt;p&gt;
    I've built the demo and deployed it online &lt;a href=&quot;https://v-playa.web.app/#!/&quot;&gt;here&lt;/a&gt;.  You can log in with any username and password (8 character or more).  It's still in early testing so expect everything to break all the time of course.  And if too many people use it, I think the server will get overloaded and maybe explode.  Who knows.
&lt;/p&gt;

&lt;p&gt;
    I've been hacking this together, and I really don't know what I'm doing. If you're interested in working on it, drop me a line on &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;mastodon&lt;/a&gt; or &lt;a href=&quot;https://will.stedden.org&quot;&gt;send me a message&lt;/a&gt;.  And please send me feedback if you like it/hate or whatever.
&lt;/p&gt;

&lt;p&gt;If you're just curious, I also described a little about how it works below.&lt;/p&gt;

&lt;h4&gt;How it's made&lt;/h4&gt;

&lt;p&gt;
    Three days ago I didn't know anything about how to build an online multiplayer game, but I learned by modifiying the &lt;a href=&quot;https://github.com/prateek3255/MultiplayerOnlineTicTacToe&quot;&gt;open source code&lt;/a&gt; from this &lt;a href=&quot;https://tic-tac-toe-3eed7.firebaseapp.com/#!/&quot;&gt;tutorial tic-tac-toe game&lt;/a&gt; by &lt;a href=&quot;https://prateeksurana.me/&quot;&gt;Prateek Surana&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
    I built it all in javascript using &lt;a href=&quot;https://firebase.google.com/&quot;&gt;Firebase&lt;/a&gt; for the database where all the information gets shared.  I picked Firebase mostly because it has a free tier so it's cheap for me to prototype.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/firebase_data.png&quot; /&gt;

&lt;p&gt;
    The local javacsript just listens for you to type on your keybard and stores how you've moved.  There's a big map of BRC in the background of the page that gets moved around so it looks like you're moving.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/brc_map.png&quot; /&gt;

&lt;p&gt;
    The database is being called in the background to tell your browser where the people around you are standing.  And it also sends an update letting others know where you are and what your message is.
&lt;/p&gt;

&lt;p&gt;
    The most fun part was adding in changes to the environment like making it go dark and having &quot;whiteouts&quot; occur.  For those who've never been, a whiteout is where everything goes white because you're in a duststorm.
&lt;/p&gt;

&lt;p&gt;
    Anyway, if you're interested in trying to help build it, or if you just want to make your own thing, all the code is posted &lt;a href=&quot;https://github.com/lots-of-things/vbrc&quot;&gt;here&lt;/a&gt;.  Please &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;reach out&lt;/a&gt; if you have any questions or would like to participate.
&lt;/p&gt;
&lt;p&gt;
Sites that I've reached out to.
&lt;ul&gt;
    &lt;li&gt;https://www.leveltwentythree.com/tiny-burn&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
</description>
        <pubDate>Wed, 22 Apr 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/04/virtual-black-rock-city/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/04/virtual-black-rock-city/</guid>
        
        <category>games</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/tup_too_real.png</image>
        <title>A GPT2+BERT reddit reply bot in 20 minutes</title>
        <description>&lt;p&gt;
    There's a new subreddit called &lt;a href=&quot;https://www.reddit.com/r/talkwithgpt2bots/&quot;&gt;talkwithgpt2bots&lt;/a&gt; that's intended to let people interact with AI based comment bots. I got my &lt;a href=&quot;https://www.reddit.com/user/tupperware-party&quot;&gt;tupperware-party&lt;/a&gt; bot working again on there, but it would be awesome to have a bunch of bots interacting there. To help others get started building comment bots, I figured I could simplify my previous &lt;a href=&quot;/2020/02/reddit-bot-gpt2-bert/&quot;&gt;GPT2-BERT tutorial&lt;/a&gt; to be even simpler to run.
&lt;/p&gt;
&lt;p&gt;
    I put all of the code, data, and models for tupperware-party in one place. Below I've written out a guide to run a duplicate of my bot explaining each of these steps:
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1. Make a reddit app so your bot has credentials&lt;/li&gt;
&lt;li&gt;2. Copy the data and notebooks into your Google Drive home directory&lt;/li&gt;
&lt;li&gt;3. Enter your credentials into the Google Colab notebooks&lt;/li&gt;
&lt;li&gt;4. Run the *step1.ipynb notebook and let it finish&lt;/li&gt;
&lt;li&gt;5. Run the *step2.ipynb notebook&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
    Below, I'll go into those 5 steps in a little more detail.
&lt;/p&gt;

&lt;p&gt;
    &lt;em&gt;Update 05/01: I've added a new bot script that doesn't just reply in place. The new script pulls a comment from another subreddit and adds it to our &lt;a href=&quot;https://www.reddit.com/r/talkwithgpt2bots/&quot;&gt;talkwithgpt2bots&lt;/a&gt; subreddit along with an AI generated reply.&lt;/em&gt;
&lt;/p&gt;

&lt;h4&gt;1. Make a reddit app&lt;/h4&gt;

&lt;p&gt;
    Your bot will need credentials to post replies on reddit.  Reddit apps are completely free to make.  To get your app credentials set up you can follow the following directions (which I addapted from &lt;a href=&quot;https://github.com/reddit-archive/reddit/wiki/OAuth2-Quick-Start-Example#first-steps&quot;&gt;this page&lt;/a&gt;).
&lt;/p&gt;
&lt;p&gt;
Go to your &lt;a href=&quot;https://www.reddit.com/prefs/apps&quot;&gt;app preferences&lt;/a&gt;. Click the &quot;Create app&quot; or &quot;Create another app&quot; button. Fill out the form like so:
&lt;/p&gt;
&lt;pre&gt;
    name: My Example App
    App type: Choose the &quot;script&quot; option
    description: You can leave this blank
    about url: You can leave this blank
    redirect url: http://www.example.com/unused/redirect/uri (We won't be using this as a redirect)
&lt;/pre&gt;
&lt;p&gt;
Hit the &quot;create app&quot; button. Make note of the client ID and client secret. For the rest of this page, it will be assumed that:
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/reddit_credentials.png&quot; /&gt;

&lt;h4&gt;2. Copy the data and all the code on Google Drive&lt;/h4&gt;

&lt;p&gt;
    I've put all the code, all the data you'll need, and the pretrained models into &lt;a href=&quot;https://drive.google.com/drive/folders/1P0iSXn44V9NPy-aFHVlotHR7B4jG-b84?usp=sharing&quot;&gt;this shared folder&lt;/a&gt; on Google Drive.  Open that and make save your own copy to your Google Drive.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/make_a_copy.jpg&quot; /&gt;

&lt;p&gt;
    Note: You need to save all of that into the top level folder of your Google Drive.  The example code assumes that all of the necessary files are sitting in the top level (ie &quot;My Drive&quot; not a subfolder).
&lt;/p&gt;

&lt;h4&gt;3. Enter your credentials&lt;/h4&gt;

&lt;p&gt;
    Once you have your own copies, you need to edit the two Google Colab notebooks (reddit_reply_bot_simple_step1.ipynb and reddit_reply_bot_simple_step1.ipynb) with the specific details for your reddit app from Step 1 above. All the changes should take place right at the top of the file.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/colab_edit.png&quot; /&gt;

&lt;p&gt;
    You can change the name of the intermediate file (&lt;code&gt;save_to_drive_csv_name = 'proposed_replies_testing.csv'&lt;/code&gt;) to whatever you want.
&lt;/p&gt;

&lt;h4&gt;4. Run reddit_reply_bot_simple_&lt;strong&gt;step1&lt;/strong&gt;.ipynb&lt;/h4&gt;

&lt;p&gt;
    With your credentials you can now run the script that creates replies. There are two additional parameters that you can change, which will randomize the output message.  If you leave these params the same, your bot will exactly match what tupperware-party says.
&lt;/p&gt;

&lt;p&gt;
    When you're ready, press the play button in the top left corner.  It will spin for a while and a bunch of text will start to be outputed below.  Eventually, the following prompt will appear.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/mount_gdrive.png&quot; /&gt;

&lt;p&gt;
    Follow the link to mount your Google Drive into the Google Colab environment.  This allows you to load the pretrained models.
&lt;/p&gt;

&lt;p&gt;
    After a bit longer the script will finish, and you'll have saved a bunch of candidate replies in the file &lt;code&gt;save_to_drive_csv_name&lt;/code&gt;.  Then you are ready to move onto step 2.
&lt;/p&gt;


&lt;h4&gt;5. Run reddit_reply_bot_simple_&lt;strong&gt;step2&lt;/strong&gt;.ipynb&lt;/h4&gt;

&lt;p&gt;
    Now open the step2 notebook, make sure the credentials are the same as from part 1.  There are a few other parameters that you can edit here.  They control how strongly you filter the replies.  Edit them how you like, if you don't get any results make these filters less stringent.
&lt;/p&gt;
&lt;img src=&quot;/assets/images/2020/colab_params.png&quot; /&gt;

&lt;p&gt;
    Run the script by pressing the play button. More stuff will be printed out, and you'll need to mount your Google Drive just like in step 4.  This one will take even longer to run.  Eventually you will see some output that contains &lt;code&gt;REPLYING NOW WITH:&lt;/code&gt; like the following.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/tup_reply.png&quot; /&gt;

&lt;p&gt;
    When this is being printed, the bot should be submitting responses in real-time.  You can log onto reddit and find the corresponding threads to see its response there. Or go to your bots home page (&lt;code&gt;reddit.com/user/{your_bot_name}&lt;/code&gt;) to see all of its comments.
&lt;/p&gt;

&lt;h4&gt;*Bonus: Generating posts from replies in other subreddits.&lt;/h4&gt;
&lt;p&gt;
    I've added two additional scripts in the Google Drive folder called &lt;code&gt;reddit_post_bot_simple_step1.ipynb&lt;/code&gt; and &lt;code&gt;reddit_post_bot_simple_step2.ipynb&lt;/code&gt;.  As their names suggest, these bots will actually generate new posts on &lt;a href=&quot;https://www.reddit.com/r/talkwithgpt2bots/&quot;&gt;talkwithgpt2bots&lt;/a&gt; based off of comments from other subreddits.  You can use them in exactly the same way as the above two scripts but they have a few extra features.  I challenge you to figure out the details, but feel free to ask questions.
&lt;/p&gt;

&lt;h4&gt;Questions?&lt;/h4&gt;

&lt;p&gt;
    If you run into any issues or if there's something confusing, please let me know.  I'll be quickest to respond on &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;Mastodon&lt;/a&gt;.  You can learn more about this project &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/&quot;&gt;here&lt;/a&gt; or learn how to customize this bot on new input data &lt;a href=&quot;/2020/02/reddit-bot-gpt2-bert/&quot;&gt;here&lt;/a&gt;.  Have fun with this, but please, think before you use it for something bad.
&lt;/p&gt;

</description>
        <pubDate>Sat, 18 Apr 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/04/twenty-minute-gpt2-reply-bot/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/04/twenty-minute-gpt2-reply-bot/</guid>
        
        <category>code</category>
        
        <category>machine learning</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/qmb_model.png</image>
        <title>Quantum Multiverse Bifurcator at Burning Man... in Another Universe</title>
        <description>&lt;p&gt;
	Last night, I learned that Black Rock City isn't going to be built in 2020 due to the COVID-19 pandemic.  I'm grateful the Burning Man organization made that choice. It was the right thing to do in this time.
&lt;/p&gt;
&lt;p&gt;
    I had been waiting to announce that my friends and I had gotten a &lt;a href=&quot;https://journal.burningman.org/2020/03/burning-man-arts/brc-art/2020-honoraria-announcement/&quot;&gt;Burning Man Arts Honorarium&lt;/a&gt; until I knew what was going to happen.  But now that I know the event isn't taking place, I feel much more comfortable showing off our plans!
&lt;/p&gt;
&lt;img title=&quot;Quantum Multiverse Bifurcator model&quot; src=&quot;/assets/images/2020/qmb_model.png&quot; alt=&quot;Quantum Multiverse Bifurcator prototype model&quot;/&gt;
&lt;p&gt;
    Based on our previous &lt;a href=&quot;/2019/10/quantum-multiverse-bifurcator/&quot;&gt;quantum&lt;/a&gt; &lt;a href=&quot;/2020/01/qmb-prototype-demo/&quot;&gt;multiverse&lt;/a&gt; &lt;a href=&quot;/2019/10/qmb-installation/&quot;&gt;projects&lt;/a&gt;, we were going to build a working quantum physics apparatus in the middle of the Nevada desert. The idea was to use it to split the Multiverse and sends Burners spiraling along separate parallel realities. After they got the results of the experiment one door would open to a series of chambers that would let them explore what it looks like to crawl inside the internal workings of the Multiverse itself.
&lt;/p&gt;
&lt;p&gt;
	We figured our art piece would solve the only bad thing about Burning Man&amp;mdash;that there's just too much to do&amp;mdash;by splitting the Multiverse so everyone can do all the things they want to do. It sounded like a fun idea, and honestly, there's really no better place in the world to debut a scifi-philosophy-puzzle art installation than at Burning Man.  Burners love to play dice with the universe.  We made this video to explain what we doing for our grant.
&lt;/p&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Tx8MTREE8Ow&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;p&gt;
    But sadly, like so many things right now, this project will have to wait for a bit. We're hopeful that our Honorarium grant will carry over to 2021, and we can make our project all the more fantastic for next year.  And I'd be excited if there'd be some kind of virtual burn that we can participate in this year.  I could imagine turning our CAD model into an online game.  We'll have to see how this year shapes up.
&lt;/p&gt;

</description>
        <pubDate>Sat, 11 Apr 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/04/qmb-burning-man-honorarium/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/04/qmb-burning-man-honorarium/</guid>
        
        <category>art</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/social_media.png</image>
        <title>Getting so-so-social with #bridgy and the #IndieWeb</title>
        <description>&lt;p&gt;&lt;strong&gt;UPDATE: this no longer works. I shut this down as it wasn't getting much use anyway and I no longer feel sucha strong need to plug into social media for my personal projects.&lt;/strong&gt;&lt;/p&gt;


&lt;p&gt;
    I've avoided it for a long time, but recently, I've started to get really into social media&lt;a title=&quot;and not just because I can't go outside anymore&quot; onclick=&quot;return false;&quot;&gt;*&lt;/a&gt;. I've written about &lt;a href=&quot;https://will.stedden.org/search/label/viewfoil&quot;&gt;why I bother&lt;/a&gt;, but briefly, it's to help contribute to fighting the bad parts of online life, like &lt;a href=&quot;https://www.wired.com/story/internet-deception-stay-what-do-now/&quot;&gt;disinformation&lt;/a&gt;, unrealistic &lt;a href=&quot;https://www.cnbc.com/2016/03/16/social-media-creates-group-think.html&quot;&gt;groupthink&lt;/a&gt;, and &lt;a href=&quot;https://newsroom.ucla.edu/releases/the-teenage-brain-on-social-media&quot;&gt;rising anxiety&lt;/a&gt;. I want to try to be a good internet citizen and make the social web a place where everyone acts in a way that they're proud of.
&lt;/p&gt;
&lt;p&gt;
    As a first step, I started by building an aggregator of all my blog and social activity to my &lt;a href=&quot;https://will.stedden.org/&quot;&gt;&quot;viewfoil&quot;&lt;/a&gt;.  The goal is to have anybody on any social media platform be able to get a good sense of who I am (and that I am indeed a real person and not a bot/Russian troll). I now have most of my personal sources in the stream, and I've made it filterable by source.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/social_media.png&quot;/&gt;

&lt;p&gt;
    Letting strangers see everything I do online is a start, but it's not very social if my site only contains content from me. I want my site to be open to input from others.
&lt;/p&gt;

&lt;h4&gt;Connecting the social web back into bonkerfield&lt;/h4&gt;

&lt;p&gt;
    A few months ago, I put &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/&quot;&gt;one of my blog posts&lt;/a&gt; on reddit and twitter.  People on reddit had &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/ezv3f2/p_gpt2_bert_reddit_replier_i_built_a_system_that/&quot;&gt;conversations&lt;/a&gt; about the results, and people on Twitter made &lt;a href=&quot;https://twitter.com/search?q=bonkerfield.org%2F2020%2F02%2Fcombining-gpt-2-and-bert%2F&quot;&gt;remarks&lt;/a&gt; too. At the time, I'd thought it would be so cool if the conversations from both sites could be pulled back onto my page so that anyone reading it could see all of the opinions that other people were sharing.
&lt;/p&gt;

&lt;p&gt;
    While I was thinking about how to do this, my friend &lt;a href=&quot;https://snarfed.org/&quot;&gt;Ryan (aka snarfed)&lt;/a&gt; reached out to me to hang out virtually&lt;a title=&quot;this is all during the covid-19 lockdown&quot; onclick=&quot;return false;&quot;&gt;*&lt;/a&gt;.  Little did I know, he was the creator of a widely used &lt;a href=&quot;https://brid.gy/&quot;&gt;tool&lt;/a&gt; that does exactly what I was looking to do! And not only that, he introduced me to the &lt;a href=&quot;https://indieweb.org/&quot;&gt;IndieWeb&lt;/a&gt;, a community working to create an awesome, interactive, pluralistic form of social internet. Honestly, what more could I ask for?
&lt;/p&gt;

&lt;h5&gt;Welcome to the IndieWeb!&lt;/h5&gt;

&lt;p&gt;
    As it turns out, the &lt;a href=&quot;https://indieweb.org/&quot;&gt;IndieWeb&lt;/a&gt; movement is also focused on consolidating your online identity and creating decentralized interactivity&amp;mdash;the two things that I was trying to do!  It seems the &lt;a href=&quot;https://indieweb.org/why&quot;&gt;motivations&lt;/a&gt; for this in the IndieWeb community might be slightly different from my own, but I feel like there's enough alignment in the general sentiment. Plus one of the IndieWeb &lt;a href=&quot;https://indieweb.org/principles&quot;&gt;principles&lt;/a&gt; is &lt;a href=&quot;https://indieweb.org/plurality&quot;&gt;plurality&lt;/a&gt; anyway, which is a principle I can always get behind. :)
&lt;/p&gt;
&lt;p&gt;
    There are many facets to what the IndieWeb is trying to do, and I encourage you to &lt;a href=&quot;https://www.jvt.me/posts/2019/10/20/indieweb-talk/&quot;&gt;learn more&lt;/a&gt;. But I want to focus in on one technical component that I'm utilizing, called the &lt;a href=&quot;https://indieweb.org/Webmention&quot;&gt;webmention&lt;/a&gt;. A webmention is a way for your site to publicly notify another site that you've mentioned it.
&lt;/p&gt;
&lt;blockquote&gt;
    an @ mention that works across websites
    &lt;cite&gt;&lt;a href=&quot;https://twitter.com/rngala/status/852354426983591937&quot;&gt;Rony Ngala&lt;/a&gt;&lt;/cite&gt;
&lt;/blockquote&gt;
&lt;p&gt;
    The beauty of this tool is that it distributes discussions all around the web rather than keeping it locked up in one place.
&lt;span class=&quot;h-entry&quot;&gt;
 &lt;span class=&quot;p-name p-content&quot;&gt;To learn more about webmentions check out &lt;a href=&quot;https://mxb.dev/blog/using-webmentions-on-static-sites/&quot; class=&quot;u-in-reply-to&quot;&gt;this wonderful post&lt;/a&gt; by Max Bock.&lt;/span&gt;
&lt;/span&gt;
    And as a living example of webmention in action, you can check out the &lt;a href=&quot;https://mxb.dev/blog/using-webmentions-on-static-sites/#webmentions&quot;&gt;comments&lt;/a&gt; on Max's site to see my mention of his blog.
&lt;/p&gt;
&lt;p&gt;
    That comment will (hopefully) be posted to his site automatically by a python script that I wrote (using &lt;a href=&quot;https://indieweb.org/ronkyuu&quot;&gt;ronkyuu&lt;/a&gt;) to send mentions to all the sites I link to from my blog.  If everything works right, Max's site will hear my desperate cry for attention and pull the comment off my site and onto his.
&lt;/p&gt;

&lt;p&gt;
    Sending webmentions is great for people who are into programming and web development, but it still has a learning curve and is in the &quot;early adopter&quot; phase (remember playing with &lt;a href=&quot;https://en.wikipedia.org/wiki/Yahoo!_GeoCities&quot;&gt;geocities&lt;/a&gt; as a kid?).  To make it more universally accessible, my friend ryan's contribution, &lt;a href=&quot;https://brid.gy/&quot;&gt;bridgy&lt;/a&gt;, turns &lt;strong&gt;any&lt;/strong&gt; social media post into a webmention and routes it to the mentioned site.
&lt;/p&gt;

&lt;h4&gt;Using bridgy to connect social media&lt;/h4&gt;

&lt;p&gt;
    &lt;a href=&quot;https://brid.gy/&quot;&gt;Bridgy&lt;/a&gt; searches social networks for links back to my blog and then sends the discussion to my own site as webmentions.  Currently, I have it set up to look for comments from Twitter, Mastodon, and my Viewfoil site.  The UI shows all the content Bridgy has picked up and which things have a proper webmention that can be routed back to my site.

&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/bridgy_ui.png&quot; style=&quot;border-style: solid;border-color:black&quot;/&gt;

&lt;p&gt;
    Bridgy sends the webmention to bonkerfield.org for me, and then I route bridgy's notification to another awesome tool called &lt;a href=&quot;https://webmention.io/&quot;&gt;webmention.io&lt;/a&gt;.

&lt;span class=&quot;h-entry&quot;&gt;
 &lt;span class=&quot;p-name p-content&quot;&gt;Webmention.io is awesome and made it possible for me to get up and running really quickly. And, guess what, I'm thanking its creator Aaron Parecki by webmentioning &lt;a href=&quot;https://aaronparecki.com/2018/06/30/11/your-first-webmention&quot; class=&quot;u-in-reply-to&quot;&gt;his post that introduced me to getting webmentions running&lt;/a&gt;!&lt;/span&gt;
&lt;/span&gt;
&lt;/p&gt;


&lt;p&gt;
    Next,
&lt;span class=&quot;h-entry&quot;&gt;
 &lt;span class=&quot;p-name p-content&quot;&gt;I use a cool little javascript tool called &lt;a href=&quot;https://github.com/PlaidWeb/webmention.js&quot;&gt;webmention.js&lt;/a&gt; to pull down the comments and render them in my page (thank you to &lt;a href=&quot;https://beesbuzz.biz/blog/4908-webmention-js-updated&quot; class=&quot;u-in-reply-to&quot;&gt;fluffy&lt;/a&gt;).&lt;/span&gt;
&lt;/span&gt; I might be updating that part of the stack to customize it, but it's great to have something to get it working right away. This is how it renders now on another page.
&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/bridgy_bonk.png&quot; style=&quot;border-style: solid;border-color:black&quot;/&gt;

&lt;p&gt;Hopefully by the time you're seeing this, there will be some comments from twitter at the bottom of the page.  And if not, I encourage you to try out the tweet box to add your own.  It'll take a bit before your tweet gets pulled and updated on the page.
&lt;span class=&quot;h-entry&quot;&gt;
 &lt;span class=&quot;p-name p-content&quot;&gt; I think it's amazing that such a cross-site collaboration is possible. Thank you snarfed for building this and keeping it going. I'm looking forward to playing with &lt;a href=&quot;https://snarfed.org/2019-01-02_bridgy-stats-update-4&quot; class=&quot;u-in-reply-to&quot;&gt;bridgy's usage data&lt;/a&gt; someday.&lt;/span&gt;
&lt;/span&gt;
&lt;/p&gt;

&lt;h4&gt;Next Steps: Expanding Bridgy to reddit&lt;/h4&gt;

&lt;p&gt;Reddit is one of social sites, but bridgy does not yet have a reddit integration. I want to be able to pull interactions from my reddit posts too so I'm currently working on the project with snarfed to get reddit commenting up and running. Hopefully pretty soon, anyone will be able to connect a reddit thread with their website too.  I'm really excited to have stumbled on this community, and I'm really happy to have the chance to contribute.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;PS: I set up a lot of my links above to be webmentions. I'll update with the results when I see which (if any) worked.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update: the webmentions were sent!  But it looks like I've done something horribly wrong. haha, this is how they were rendered.&lt;/em&gt;&lt;/p&gt;


&lt;img src=&quot;/assets/images/2020/webmention_fail.png&quot; /&gt;

&lt;img src=&quot;/assets/images/2020/webmention_fail_2.png&quot;/&gt;

&lt;p&gt;&lt;em&gt;Looks like I had a misplaced p-author h-card in my comments section.  I guess I have a little more to debug. 🤦&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Update 2: I reran it for aaronpk's site and things look at least a little better. content still doesn't show up, but that's a problem for another day.&lt;/em&gt;&lt;/p&gt;


&lt;img src=&quot;/assets/images/2020/webmention_better.png&quot; /&gt;
</description>
        <pubDate>Thu, 09 Apr 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/04/getting-so-so-social/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/04/getting-so-so-social/</guid>
        
        <category>web</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/skylight_optical.jpg</image>
        <title>Skylight Chapters 5 &amp;amp; 6</title>
        <description>&lt;p&gt;
    Three years ago, I started writing a story called &lt;em&gt;Skylight&lt;/em&gt;. The story takes place in another solar system where society never looked up and wondered about the stars, until one day, they did.  If I ever publish this, I might use this skylight optical illusion from &lt;a href=&quot;https://www.flickr.com/photos/kweston/769636098&quot;&gt;Keith Weston&lt;/a&gt; as the cover art. Do you see the pyramid?
&lt;/p&gt;
&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/skylight_optical.jpg&quot;&gt;
&lt;p&gt;
    Over the past year, my &lt;a href=&quot;/attention&quot;&gt;attention&lt;/a&gt; was diverted to another project, but shelter-in-place has given me some free time to finish Chapters 5 and 6.  For context, I've posted &lt;a href=&quot;/2018/05/skylight-chapters-1-2/&quot;&gt;Chapters 1 &amp; 2&lt;/a&gt; and &lt;a href=&quot;/2018/06/skylight-chapters-3-4/&quot;&gt;Chapters 3 &amp; 4&lt;/a&gt; previously.
&lt;/p&gt;
&lt;p&gt;
    Hope you like it. I'll try to get 7 and 8 out a lot quicker.
&lt;/p&gt;

&lt;div&gt;&lt;iframe height=&quot;800px&quot; src=&quot;https://docs.google.com/document/d/e/2PACX-1vSNISOFKSyR7gPADuAHQ_1w8v9k6VuhB8eeMvr9r15ZuUbOkn0EGXlkQ6D4es8kqAoFJTCn0qBHg-V4/pub?embedded=true&quot; style=&quot;border:1px solid black; height: 800px&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
</description>
        <pubDate>Tue, 24 Mar 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/03/skylight-chapters-5-6/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/03/skylight-chapters-5-6/</guid>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/tupperware_quote.png</image>
        <title>Why building an AI chatbot that passed as human convinced me to put my whole life on the internet</title>
        <description>&lt;p&gt;
In my free time, I like to build stuff and put it on the internet.  Two months ago, I &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/&quot;&gt;built an AI comment generating chatbot&lt;/a&gt; and deployed it on reddit. The chatbot was designed to leave pertinent, realistic replies to other redditors' comments.  I figured it would say a bunch of weird stuff and then get flagged and blocked.
&lt;/p&gt;

&lt;p&gt;
To my surprise, the chatbot was practically perfect at writing coherent English sentences.  And it was also pretty good at understanding the context of a reddit comment and generating replies that were highly relevant. But when I looked at the comments it was sending, I was still a little bit disappointed.  The responses just seemed a little dumb.  Like this one for example
&lt;/p&gt;

&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://www.reddit.com/r/scifi/comments/eogano/gene_roddenberry_didnt_get_the_adult_audience_hed/feifu7d/?context=3&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;/assets/images/2020/tupperware_quote.png&quot; width=&quot;400&quot; height=&quot;162&quot; data-original-width=&quot;717&quot; data-original-height=&quot;291&quot; /&gt;&lt;/a&gt;&lt;/div&gt;

&lt;p&gt;
As it turns out, this wasn't a problem.  People still responded to the comments as if they were coming from a real person.  In almost all the cases, it looked like the chatbot was just a slightly confused person trying to contribute to the conversation. So the original poster would normally respond by trying to elaborate on their original thought or ask clarifying questions to try to understand what the bot meant.
&lt;/p&gt;

&lt;p&gt;
Later that day, as I started looking at other replies on reddit and twitter, I suddenly began to notice just how many replies are also a little incoherent. Top comments are normally smart and pointed, but quantitatively, the majority are pretty nonsensical.
&lt;/p&gt;

&lt;p&gt;
Then it dawned on me. &lt;strong&gt;Most responses on social media sound like they are coming from a slightly confused person.&lt;/strong&gt;
&lt;/p&gt;

&lt;p&gt;
And even scarier than that. My uninformed robot already looked indistinguishable from the uninformed people online.
&lt;/p&gt;

&lt;h3&gt;How I've Responded&lt;/h3&gt;

&lt;p&gt;
At first, I thought this was a sure sign that I should &lt;a href=&quot;/2020/03/thoughts-on-hivemind-after-trying.html&quot;&gt;continue to shun social media&lt;/a&gt;.  But as I thought about it more, I realized that I wanted do my part in correcting this problem.  And I figured that my experience might have some value in the public discourse on this topic.
&lt;/p&gt;

&lt;p&gt;
So I ruminated for a bit on how in the near future, any comment on the internet could be coming from a similar bot. As many have &lt;a href=&quot;https://apnews.com/4086949d878336f8ea6daa4dee725d94&quot;&gt;pointed out&lt;/a&gt;, this makes it quite easy to wage a massive disinformation campaign. Furthermore, being bot generated isn't the worst part.  If a non-thinking entity could make points that make as much sense as the average online comment, then I feel that our online discourse is very much in need of elevation.
&lt;/p&gt;

&lt;p&gt;
I wanted to do my part to raise the level of discourse on the internet and to protect against a world of bot generated misinformation online.  To do that, I want to only post thoughtful, topically relevant information.  And I want to make sure that anyone who sees anything I post on the internet has an easy way to verify that I am a real person who stands behind their opinions.
&lt;/p&gt;

&lt;p&gt;
I have decided to try to connect my personal identity to all of the things that I say on the internet.  These are my &lt;em&gt;bona fides&lt;/em&gt; to anyone who wants to know if I am genuine.  This also will help me to ensure that I deeply consider what I write online so as not to contribute to the &quot;noisiness.&quot;
&lt;/p&gt;

&lt;p&gt;
Which brings me to this post. This blog is the start of my attempt at radical transparency about my life. I'm using this spot to collect everything about who I am so that you, fine reader, can know that what I say is coming from a real person. As I do this, I'm also changing my approach to writing in order to more closely display my real values and beliefs in everything that I do.
&lt;/p&gt;

&lt;p&gt;
I hope that I've articulated the idea well enough for others to understand where I'm coming from. I also hope that anyone who reads this will consider trying out a similar approach for themselves.
&lt;/p&gt;

&lt;p&gt;&lt;small&gt;&lt;em&gt;
Note: I'm also starting this immediately without taking too much time to try to work through all the details. I'm hoping that I can preemptively start recording my identity before it becomes too easy to fake a whole online persona in a similar way. Plus recording this process helps others to learn that I am a person constructing and working through my beliefs in real-time, just like everyone else.
&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 17 Mar 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/03/building-an-AI-chatbot/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/03/building-an-AI-chatbot/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>Thoughts on the #hivemind after trying social media for the first time</title>
        <description>&lt;p&gt;
I was born in 1988, but I somehow resisted any serious engagement with social media until January of 2020.  I want to explain what changed my mind, and why I’m going to stick around.
&lt;/p&gt;

&lt;h4&gt; Can social media actually do any good? &lt;/h4&gt;

&lt;p&gt;
 Like a lot of people, when first confronted with social media back in the 2000s I said (out loud) something like, “Tweet my stupid little thoughts, that’s a waste of everybody’s time.”  It sounds like a reasonable rebuttal, but even back then I was being disingenuous.  I still wrote blog posts, I wrote papers, I talked my friends’ ears off if they’d let me.  I wanted my stupid little opinions to be heard just as much as anyone.  So why not join in?
&lt;/p&gt;

&lt;p&gt;
 I told myself it was because, “&lt;strong&gt;I wanted to do good things instead of talk about them.&lt;/strong&gt;” I told myself that all that chitter chatter just distracted everybody else from accomplishing the hard stuff that really moves the world forward.  However, there’s an obvious problem with this worldview that I even recognized at the time.
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;
If I do something good, how could it have an impact if no one is listening to me?
&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;
I could see the attention span arms race, the good guys in the signal vs the bad guys in the noise.  Once I’d confronted the cognitive dissonance of trying to do good in a vacuum, I developed other defense mechanisms.  I told myself, “&lt;strong&gt;this is the high road, and I should just do good work&lt;a href=&quot;&quot; onclick=&quot;return false&quot; title=&quot;(*Note that by “work” I just mean anything that I do in the real world as opposed to the world of ideas)&quot;&gt;[*]&lt;/a&gt; and eventually it will be recognized&lt;/strong&gt;”.   Then later, when it occurred to me that it was really arrogant to expect an organic following without ever even telling anyone I was doing anything, I constructed another blocker: “&lt;strong&gt;if I start projecting my thoughts before I know enough, then I’ll do more harm than good, and make a fool of myself by the time I really start to understand things&lt;/strong&gt;.”
&lt;/p&gt;
&lt;p&gt;
I made my points quietly on this unread blog, and to any friend who would listen.  In some ways this was practice, but in others it was wasted effort.  I wasn’t getting feedback, and I wasn’t growing my ideas beyond myself.
&lt;/p&gt;
&lt;p&gt;
&lt;strong&gt;Eventually I realized, the only reason I refused to engage was that I was afraid of directly quantifying my own limited contribution to the world.&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;
The internet lets you measure who is listening.  If I never tried to get attention, I could fabricate a hypothetical self-worth in my mind, but I never had to worry about validating it in the real world.  What’s more, when I really was honest with myself, I recognized that the crap I’ve been doing isn’t really worth the diversion of the public attention anyway.
&lt;/p&gt;
&lt;p&gt;
It was good to recognize, but on it’s own, this admission doesn’t change whether I should take part in social media. If I want to only do good, and I believe that the impact of my self-promotion is really so minimal, then I should have no choice but to shut my efforts down to conserve resources.  But then, I challenged myself with an epistemological riddle.
&lt;/p&gt;
&lt;p&gt;
&lt;strong&gt;Should I expect to be able to predict my own contribution to the world’s discourse today?&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;
Given all the resources that have been poured into me by society, should I really draw down my output?  I surveyed the world around me, and came to the following conclusion.
&lt;/p&gt;
&lt;p&gt;
&lt;strong&gt;Since I have no example data on what my contributions would look like, I have no way of knowing if they’d be worth anything yet.&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;
From this, I decided that I have exactly one shot to collect the sample data of my life’s work as measured by the gauge that is the world’s opinions.
&lt;/p&gt;
&lt;p&gt;
So as of today, I am trying my damnedest to inflict my stodgy little views onto the internet.  For the most part, I’m still doing pretty horribly, but at least now I can get better.  I’m contributing, and feeding back into the system at a higher rate than I’d imagined.  And furthermore, I’m learning about how nuanced and rich the feeling of constant feedback is.  I’ve never felt like I was inside the hive mind before, and I must admit I like it a lot.
&lt;/p&gt;
&lt;h4&gt;Why I’m staying&lt;/h4&gt;
That said, there is an awful lot of distraction in this medium.  It takes work to properly present oneself and provide feedback properly, and it’s extremely easy to cut corners in the battle for attention.  Punchy witticisms abound.
&lt;/p&gt;
&lt;p&gt;
I joined twitter right at the onset of a virally amplified panic.  It truly makes me wonder what the system is going to look like once every person’s first thought is no longer “Don’t touch my face!”
&lt;/p&gt;
&lt;p&gt;
Still, I believe there is value in fighting through the distraction as well.  If I can try to stay strong and only amplify the valuable messages, then I can help reign in the negative parts of this medium.
&lt;/p&gt;
&lt;p&gt;
What’s more, if I begin to believe that my ideas are of true value to the progress of the world, then I can use the leverage of this system to help amplify. Attention is the most efficient tool of this era in the same way that the steam engine was the most efficient 200 years ago.
&lt;/p&gt;
&lt;p&gt;
I think that we will look back and call this the Attention Age, where the most precious resource to be mined is our global shared attention.  I do not mean this in a bad way.  I mean quite literally that the most efficient machine for enacting a change is to get many minds thinking about it for a prolonged period. After that the rest has been made easy by our previous mastery of the tools of all the prior ages.
&lt;/p&gt;
&lt;p&gt;
So I’ll definitely be continuing to work on improving my abilities at using social media as a tool. It would be a waste to abstain from engaging in the commerce of attention in this era.  The same way that it would have been a waste to abstain from industry in the Industrial Age, from iron in the Iron Age, or from information in the Information Age.
&lt;/p&gt;
&lt;p&gt;
Of course, this comes with a pretty deep caveat.  If what I just said is true, then my contribution is largely shaped by whatever it was that focused my attention during my formative years. However, this situation isn’t really a new predicament caused by engaging with social media&amp;mdash;it’s merely made more transparent by it.
&lt;/p&gt;
&lt;p&gt;
Nevertheless, if the feedback becomes too strong, then I’ll risk becoming a mindless cog of the higher order conscious mind. And I may need to unplug at some point to ensure that my mind doesn’t conform too closely to this collective, but I can put those safety measures in place when it’s necessary.
&lt;/p&gt;
&lt;p&gt;
But for now, I’m going to tweet these thoughts out.
&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Mar 2020 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2020/03/thoughts-on-the-hivemind/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/03/thoughts-on-the-hivemind/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/main/viewfoil.png</image>
        <title>Viewfoil: Experimenting with Radical Transparency</title>
        <description>&lt;p&gt;
	I've been contemplating privacy and anonymity, and speculating on what those ideas will mean in the future of our society.  During conversations with my friends and family, I've started questioning whether maintaining strengthened privacy is possible, and more importantly, whether strengthened privacy is even still a good thing.
&lt;/p&gt;
&lt;p&gt;
	But in the spirit of this site, I'm not just theorizing anymore.  I'm currently working on putting myself into an experiment on radical transparency.
&lt;/p&gt;
&lt;p&gt;
	I have a whole bunch of reasons why I think this is the right thing to do.  Below, I offer one &lt;strong&gt;apocalyptic horror story&lt;/strong&gt; that attempts to motivate why I want to try this experiment.   After that, I'll offer a little info about how I'm starting to put my transition into motion.
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;
	tl;dr I think that privacy itself is a conspiracy of the powerful. I'm gonna try to bring back lifestreaming to advocate for a transparent society. I call it the &lt;a href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;viewfoil&lt;/a&gt; project.
&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;The world we live in&lt;/h4&gt;
&lt;p&gt;
	It isn't super difficult to find ways to be terrified of how technology is mishaping modern life, in ways big and small.
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;corporations have too much access to our data&lt;/li&gt;
&lt;li&gt;it's stressful constantly projecting a perfect life on social media&lt;/li&gt;
&lt;li&gt;the internet spreads misinformation from both the ill-informed and the ill-intentioned&lt;/li&gt;
&lt;li&gt;we're all siloing our ideologies and politically radicalizing&lt;/li&gt;
&lt;li&gt;our attention spans have been completely annihilated&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
	The general response to these issues around dinner tables tends to be &quot;&lt;strong&gt;how can we return things to the good old days before all of this happened&lt;/strong&gt;?&quot;  I generally agree with the sentiment. If it were possible to reverse the overflowing of online life, I would do it.  But as things are, I don't think that society is going to become less digitally connected or more intellectually mature to handle ourselves properly. So I'm left pondering what I can do to contribute to a better world as it is.
&lt;/p&gt;
&lt;p&gt;
	The suggestions that my friends keep proposing all seem to be based around a classic strategy&amp;mdash;build better defenses. We minimize our exposure to the ideas on the web, and return to our most trusted sources. We hide ourselves and make it harder for third parties to know what we're doing.  We develop tools that force us to disconnect from the devices that fuel our addictions.
&lt;/p&gt;
&lt;p&gt;
	Unfortunately, I believe that these are all bandaids, and that they aren't really capable of protecting us from the dangers that the online information exchange poses. I might be paranoid, but I see it playing out like other industries that have garnered massive power.
&lt;/p&gt;
&lt;p&gt;
	People with power and the capacity to exploit our digital connectivity will do it right up to the edge of what is legal. Attempts to regulate will place undue power with established players who will jockey for control of politicians who will grant loopholes. Attempts to outpace the capacity for manipulation will end up exhausting more and more of our resources. Every advance that lets us hide ourselves better, will let a Russian hacker, troll, or &lt;a href=&quot;https://opus.stedden.org/attention&quot;&gt;quasi-sentient AI&lt;/a&gt; hide themselves better. To combat them, we will need ever more all-encompassing mechanisms of monitoring, which will be exploited by technologists for our control. Only the wealthy will be able to adequately fight back against increasing digital surveillance. They will then use their privileged privacy to circumvent legal grey areas.  And the cycle will continue.
&lt;/p&gt;
&lt;p&gt;
	This is a depressing situation that hopefully won't happen, but there isn't really any great safeguard against it.  So if we are heading toward a dystopian world of privacy arms races and corporate surveillance, is there really anything I can do?
&lt;/p&gt;

&lt;h4&gt;The truth shall set you free&lt;/h4&gt;
&lt;p&gt;
	What if we go for the opposite approach?  What if we effectively flank our corporate overlords by demanding a complete end to privacy? Maybe we can imagine a utopian counterpoint to the above doomsday prophecy. It seems that most of the issues mentioned above can be ameliorated.
&lt;/p&gt;
&lt;p&gt;
	I might hypothesize that in a fully transparent world, any attempts at clandestine manipulation could be nearly instantaneously uncovered. If you could see every piece of information connected to the person on the other end, you could instantaneously determine whether they were a real good-intentioned human or a Russian bot.  If our online behavior was globally accessible, any attempt by corporations to profile our behavior could be reverse engineered to filter such profiling. If our lives were fully transparent, there would be no need to stress over falsely curating our public personas on social media.
&lt;/p&gt;
&lt;p&gt;
	Beyond this, there could be a whole host of unexplored public goods that would come of this too.  The societal harms that come from organized crime would disappear overnight.  It would become impossible for politicians and corporate executives to broker backroom deals that undermine the public good.  And on a topic closer to &lt;a href=&quot;https://www.color.com/&quot;&gt;my&lt;/a&gt; &lt;a href=&quot;https://anthem.ai/&quot;&gt;heart&lt;/a&gt;, if everyone's medical information was universally accessible, it would make it extremely simple for researchers to uncover exactly what the best medical decision is for each person.
&lt;/p&gt;

&lt;p&gt;
	Of course, there are still major systemic roadblocks that prevent this kind of privacy from being possible. Full medical histories can't be revealed because it would lead to widespread discrimination and economic harm to vulnerable individuals. There are still many &lt;a href=&quot;https://www.businessinsider.com/economist-intelligence-unit-2017-democracy-index-worst-countries-2018-1&quot;&gt;extant&lt;/a&gt; &lt;a href= &quot;https://en.wikipedia.org/wiki/List_of_totalitarian_regimes&quot;&gt;despotic&lt;/a&gt; governments that would exploit this kind of information. And there are large numbers of people who casually break minor laws each day&lt;a title=&quot;though I would argue that such laws really ought to be reversed anyway, and universal transparency would make that clear&quot; href=&quot;&quot; onclick=&quot;return false;&quot;&gt;[*]&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
	We are not ready for global transparency yet.  However, I am in a place of unique privilege where I can move myself much closer to a life open to total external inspection.
&lt;/p&gt;
&lt;p&gt;
	If I believe that this future would be better, I simply have to start experimenting to see if it's possible to attain.
&lt;/p&gt;

&lt;h4&gt;Viewfoil&lt;/h4&gt;
&lt;p&gt;
	To do this, I've been putting in motion a plan to make any and all information about my life accessible to anyone who cares to look.  A lot of people &lt;a href=&quot;https://en.wikipedia.org/wiki/Lifestreaming&quot;&gt;have done this before&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantified_self&quot;&gt;in various forms&lt;/a&gt; so I don't think it's that bold of an idea.  But like a good millennial, I don't just want to do it, I want to advocate for it.
&lt;/p&gt;
&lt;p&gt;
	I've outlined the goals I'm trying to work towards during my first year on the project.
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Start revealing an unfiltered version of my life on social media&lt;/li&gt;
	&lt;li&gt;Start writing my ideas as they are, not as I expect others to want them to appear&lt;/li&gt;
	&lt;li&gt;Automate the aggregation of all my online identities into Viewfoil&lt;/li&gt;
	&lt;li&gt;Reveal all my secrets and dirty laundry to everyone I know&lt;/li&gt;
	&lt;li&gt;Carefully get consent to incorporate information about my friends and family&lt;/li&gt;
	&lt;li&gt;Work towards being able to share more detailed private information without compromising anyone's safety&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	There's a lot to do for each of these, and I will be elaborating on them (at length) in the future. I don't want this to distract from the content here so I'm building a separate site called &lt;a href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;Viewfoil&lt;/a&gt; where I'm going to be doing the heavy lifting.  &lt;strong&gt;Viewfoil&lt;/strong&gt; is the technical word for the transparencies from the overhead projectors we used to have back in grade school.  I think it's a fitting name for a &lt;em&gt;project&lt;/em&gt; about being more &lt;em&gt;transparent&lt;/em&gt;.
&lt;/p&gt;
&lt;a style=&quot;border:none;box-shadow:none&quot; href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;&lt;img style=&quot;width:30%;&quot; src=&quot;/assets/images/main/viewfoil.png&quot;/&gt;&lt;/a&gt;

&lt;p&gt;
	Needless to say, I'm sure I will encounter myriad issues that prevent me from exploring this entirely, but I'm excited to see just where this starts to break down.  I'm quite scared about a lot of things, but hopefully if I move slowly and carefully, I'll learn enough as I go along to survive this thing.
&lt;/p&gt;
&lt;p&gt;
	This is going to be an interesting year.  Check out &lt;a href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;Viewfoil&lt;/a&gt; if you are interested.
&lt;/p&gt;
&lt;p&gt;
	&lt;em&gt;Update: I've already started building onto the Viewfoil site with a parallel feed from &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;my twitter&lt;/a&gt;.  I reused code from my &lt;a href=&quot;https:///2015/01/tweetnote-unfakeable-timestamp-notebook/&quot;&gt;tweet_note&lt;/a&gt; and &lt;a href=&quot;http://actsofsuperness.appspot.com/&quot;&gt;#ActsOfSuperness&lt;/a&gt; projects from 5 years ago. I don't have time for a full post, but you can see the code that automates pulling from twitter and pushing to blogger &lt;a href=&quot;https://github.com/lots-of-things/viewfoil&quot;&gt;here&lt;/a&gt;.  &lt;/em&gt;
&lt;/p&gt;
&lt;p&gt;
    &lt;em&gt;Update2: I also built something to add embedded posts from my newly formed &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;twitter&lt;/a&gt;.  &lt;a href=&quot;https://github.com/lots-of-things/viewfoil&quot;&gt;The script&lt;/a&gt; is a total hack-job and requires a headless browser.  &lt;/em&gt;
&lt;/p&gt;
&lt;img style=&quot;width:50%;&quot; src=&quot;/assets/images/2020/viewfoil_insta.png&quot;/&gt;
</description>
        <pubDate>Sun, 08 Mar 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/03/viewfoil/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/03/viewfoil/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/wuhan_overview_im.png</image>
        <title>Modeling whether an outbreak of COVID-19 virus will hit San Francisco</title>
        <description>&lt;p&gt;&lt;em&gt;Epistemic status: To be clear, this is a highly simplified model and should not be used to insight panic or to instill a false sense of security.  Please enjoy with a healthy level of skeptical detachment.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Edit: Note that when I originally published this, the WHO had not settled on the name COVID-19 yet so I was referring to it as &quot;Wuhan virus.&quot; That has since &lt;a href=&quot;https://www.nytimes.com/2020/03/18/us/politics/china-virus.html&quot;&gt;become problematic&lt;/a&gt; so I am updating to reflect more accurate terminology. &lt;/strong&gt;&lt;/p&gt;


&lt;p&gt;
	I'll admit that I've gotten wrapped up in all this &lt;a href=&quot;https://www.vox.com/future-perfect/2020/2/6/21121303/coronavirus-wuhan-panic-pandemic-outbreak&quot;&gt;&lt;strike&gt;Wuhan&lt;/strike&gt;COVID-19 virus stuff&lt;/a&gt;, especially as it relates to the spread in the &lt;a href=&quot;https://www.mercurynews.com/2020/02/03/coronavirus-bay-area-has-highest-concentration-of-u-s-cases-that-shouldnt-be-a-surprise/&quot;&gt;SF Bay Area&lt;/a&gt;.  This is the first time that I've lived in a large population center while there is a potential epidemic looming, and the situation has me wondering whether we're already to the point where it's bound to spread here anyway.  I looked at &lt;a href=&quot;https://systems.jhu.edu/research/public-health/ncov-model-2/&quot;&gt;some results&lt;/a&gt; from one of the sophisticated epidemiological models, and I got some reassurance.  But I was curious how these models worked under the hood.
&lt;/p&gt;

&lt;p&gt;
	To get a better intuition, I developed a simplified version of that epidemic model, and an interactive visualization of my simple simulation.  The model allows you to vary the infection spread rate, the rate of quarantine, and the rate at which people fly from Wuhan to San Francisco.   &lt;a href=&quot;http://bl.ocks.org/stedn/b0acdeba81751c5f8e4ccaa74ccb09a9&quot;&gt;Try it out&lt;/a&gt;, and read below to learn more about how it works.
&lt;/p&gt;

&lt;a href=&quot;http://bl.ocks.org/stedn/b0acdeba81751c5f8e4ccaa74ccb09a9&quot;&gt;
&lt;img class=&quot;link_img&quot; src=&quot;/assets/images/2020/wuhan_model_viz.gif&quot; title=&quot;Wuhan javascript model visualization&quot; alt=&quot;Wuhan javascript model visualization&quot;/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;h4&gt;Defining a model of &lt;strike&gt;Wuhan&lt;/strike&gt;coronavirus virus spread&lt;/h4&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;small&gt;&lt;em&gt;I've left out a lot of detail in this section for simplicity.  To see the full derivation check out &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;this document&lt;/a&gt;.&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;
	I wanted to simplify the &lt;a href=&quot;https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology&quot;&gt;standard SIR model&lt;/a&gt;, and apply it to two locations. An SIR model normally computes how the spread of an epidemic varies as the population moves from Susceptible (S) to Infected (I) to Recovered (R).
&lt;/p&gt;


&lt;img title=&quot;SIR model diagram from wikipedia&quot; alt=&quot;SIR model diagram from wikipedia&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/8/8a/SIR.PNG&quot;/&gt;
&lt;p style=&quot;text-align:center&quot;&gt;&lt;em&gt;Diagram of transitions in SIR model (&lt;a href=&quot;https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#/media/File:SIR.PNG&quot;&gt;source Imoen&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
	There is a &lt;a href=&quot;http://www.public.asu.edu/~hnesse/classes/sir.html&quot;&gt;specific dynamics model&lt;/a&gt; that governs how S, I and R vary over time.  However, I'm only interested in the early phase of the epidemic, when it's only spread to a small fraction of the population.  In that case, we don't need to worry about how many people are susceptible or recovered, we just always assume that there are lots of uninfected people around who can become infected.
&lt;/p&gt;
&lt;p&gt;
	I worked through defining a mathematical model that looks just at the early infection phase of an epidemic.  You can &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;look here&lt;/a&gt; for details on how the math works, but I'll just give a short summary here.
&lt;/p&gt;

&lt;h5&gt;Exponential Infection Model&lt;/h5&gt;
&lt;p&gt;
	The model works by defining the &quot;net infected rate,&quot; which is the number of newly infected people minus the number of people who are moved into quarantine.  We're going to make the assumption that the change in the number of infected people, &lt;span lang=&quot;latex&quot;&gt;I&lt;/span&gt;, is equal to the current number of infected people times a constant growth rate, &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt;.  We can formalize this in an equation.
&lt;/p&gt;
&lt;p lang=&quot;latex&quot;&gt;\frac{dI}{dt} = \gamma I &lt;/p&gt;
&lt;p&gt;
	This equation can be solved to give the standard exponential growth curve of an early phase epidemic.  However, if this equation were the whole story, this would mean that all infectious diseases should turn into exponentially growing epidemics, and we know that isn't the case.  Specifically, we have public health policies that can work to quarantine and mitigate the spread of a disaster.  For this model, we're going to assume that our ability to quarantine people is set at some fixed constant, &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt;, so if the growth rate surpasses that, we'll end up with an outbreak.  To model this, I'm going to combine these two terms into one equation like this.
&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;\frac{dI}{dt} = \gamma I - \kappa&lt;/p&gt;

&lt;p&gt;
	This equation is also fairly easy to solve, and &lt;a href=&quot;https://www.wolframalpha.com/input/?i=solve+dx%2Fdt+%3D+g*x+-+k+with+x%280%29%3Dk%2Fg%2B1&quot;&gt;the solution&lt;/a&gt; grows exponentially whenever the infected population crosses the threshold of &lt;span lang=&quot;latex&quot;&gt;\kappa / \gamma&lt;/span&gt;.
&lt;/p&gt;
&lt;p&gt;
	So this equation will work to model the epidemic in one place, but we want to see how the situation evolves if it can spread to another place, like the case for spreading from Wuhan to San Francisco. The two equations to model Wuhan and SF look like this:
&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;\frac{dI_{wu}}{dt} = \gamma I_{wu} - \kappa&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;\frac{dI_{sf}}{dt} = \gamma I_{sf} - \kappa + \mu I_{wu}&lt;/p&gt;
&lt;p&gt;
	You can see that the first part of both equations is the same as the simple infection equation for &lt;span lang=&quot;latex&quot;&gt;I&lt;/span&gt; above. However, in the &lt;span lang=&quot;latex&quot;&gt;I_{sf}&lt;/span&gt; (ie San Francisco) equation, there's an extra term of &lt;span lang=&quot;latex&quot;&gt;\mu I_{wu}&lt;/span&gt;.  This is the rate of people who are sick in Wuhan flying to San Francisco.
&lt;/p&gt;

&lt;h5&gt;Simulations&lt;/h5&gt;
&lt;p&gt;
	I took this model definition and generated simulations that show how the values of &lt;span lang=&quot;latex&quot;&gt;I_{wu}&lt;/span&gt; and &lt;span lang=&quot;latex&quot;&gt;I_{sf}&lt;/span&gt; vary over time. These kinds of simulations just take the equations above and use them to determine how the number of people infected would change over a small unit of time. Then, they do this over and over again to show how the system evolves.  I used prepackaged simulation software to diagram the solution to the equation I had above, and it gave curves that showed the growth in the number of infected in the two locations over time.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; title=&quot;example wuhan plot&quot; src=&quot;/assets/images/2020/wuhan_model_growth.png&quot;/&gt;

&lt;p&gt;
	Next, I used the simulation to see what happened if I varied how long before flights were shut down.  I called this time &lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt;.  In this simulation, I set &lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt; to be very short and saw that even though the infection started to spread in SF, it went back down to 0 right after flights were stopped.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; title=&quot;SF infection drops after flights stop&quot; src=&quot;/assets/images/2020/wuhan_sf_safe.png&quot;/&gt;

&lt;p&gt;
	As you might expect, if the time before Wuhan is quarantined (&lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt;) is short, then the infection doesn't have too much time to spread to SF, and they are able to fight the epidemic back down to 0.  But if I extend &lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt; past 5, suddenly the model predicted that it wouldn't be possible to keep it under control.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_model_quarantine.png&quot;/&gt;

&lt;p&gt;
	This makes intuitive sense, but it was still quite curious to me what might cause everything to be fine at 4.9 days, but for an outbreak to happen after 5 days.  I decided to see if I could use my model to see what set the time of the &quot;point of no return.&quot;
&lt;/p&gt;

&lt;h5&gt;Predicting the &quot;point of no return&quot;&lt;/h5&gt;
&lt;p&gt;
	I worked through this model a little more rigorously both with the simulations and with an analytical theory. I'm going to gloss over the rest of the analysis I did for this post, but please read &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;the full article&lt;/a&gt;, and my &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/wuhan_sf_infection_model.ipynb&quot;&gt;analysis notebook&lt;/a&gt; if you're curious how I arrived at the results.
&lt;/p&gt;
&lt;p&gt;
	I evaluated the time of the &quot;point of no return,&quot; &lt;span lang=&quot;latex&quot;&gt;t_X&lt;/span&gt; as
&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;t_X \approx  \frac{1.7}{\gamma} \left(ln\left(\frac{\gamma}{\mu} - 1\right)- ln\left(w_0 - \frac{\kappa}{\gamma}\right)\right) &lt;/p&gt;


&lt;p&gt;
	Where I added in the initially infected population in Wuhan &lt;span lang=&quot;latex&quot;&gt;w_o&lt;/span&gt; as another parameter. This might look a little mysterious, but you can read &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;the math&lt;/a&gt; to get a better sense of where it comes from. To double check my work, I directly measured &lt;span lang=&quot;latex&quot;&gt;t_x&lt;/span&gt; using my simulations.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_tX.png&quot;/&gt;

&lt;p&gt;
	This pretty surface matched my prediction closely and showed the correct dependence on the logarithm of the Wuhan to SF flight rate &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt;.
&lt;/p&gt;


&lt;h4&gt;Putting the math into practice&lt;/h4&gt;

&lt;p&gt;
	So that's a nice formula to have, but unfortunately, it's totally useless without knowing what these parameters, &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt;, &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt;, and &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt; are.  So how can we figure them out?
&lt;/p&gt;

&lt;p&gt;
	Well fortunately, we can guesstimate &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt; just by looking at what's happened in Wuhan.  If we fit the &lt;a href=&quot;https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6&quot;&gt;data&lt;/a&gt; for the early part of the outbreak, which looks roughly exponential. The growth constant of that curve is &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt;.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_cases.png&quot;/&gt;

&lt;p&gt;
	I plotted the data in &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1uo64yIiPMC5C8chDn3WBe5UA6RljJ3YthmxR3p-rp-A/edit?usp=sharing&quot;&gt;this google sheet&lt;/a&gt; and got an estimate for &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt; of 0.2-0.3 new cases per infected person per day.  The reported number of cases is &lt;a href=&quot;https://systems.jhu.edu/research/public-health/ncov-model-2/&quot;&gt;probably an underestimate&lt;/a&gt; of the total population that is infectious, but if it differs by a constant multiplicative factor, then (I think) cases should still give a good approximation of that constant.
&lt;/p&gt;


&lt;p&gt;
	It's a little tougher to get &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt;, but since an outbreak did happen starting from ~200 cases, we expect that &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt; can't be more than 200*0.2 ~ 40 people per day.
&lt;/p&gt;

&lt;p&gt;
	Finally, for &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt;, we can calculate it directly because &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt; is just the probability that any person will get on a plane and fly to San Francisco.  I just &lt;a href=&quot;https://www.flightsfrom.com/SFO/destinations?durationFrom=43&amp;durationTo=1053&amp;dateMethod=day&amp;dateFrom=2020-02-29&amp;dateTo=2020-02-29#/WUH&quot;&gt;looked up&lt;/a&gt; the number of scheduled flights from Wuhan.  I estimated about 3 flights per week from Wuhan straight to Northern California, and Wuhan has a population of about 60 million.  That makes an estimate for &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt; of 3 flights x 200 people per flight / 60 million people / 7 days per week or 1e-6 new infected people in CA per infected person in Wuhan per day.
&lt;/p&gt;

&lt;p&gt;
	This means that &lt;span lang=&quot;latex&quot;&gt;t_X \approx&lt;/span&gt; 60.  According to &lt;a href=&quot;https://www.pharmaceutical-technology.com/news/coronavirus-a-timeline-of-how-the-deadly-outbreak-evolved/&quot;&gt;this timeline&lt;/a&gt;, the border with Wuhan was closed on Jan 22nd, and the outbreak was only at 200 cases on Jan 19.  From this, it would seem like we should have it very much under control.
&lt;/p&gt;

&lt;p&gt;
	Of course, this is way too optimistic because we know that Wuhan isn't the only place where the epidemic has spread.  The virus has spread over many parts of China by now, and any of those places could serve as a source of the viurs now.
&lt;/p&gt;
&lt;h4&gt;Modeling two locations&lt;/h4&gt;

&lt;p&gt;
	Unfortunately, I don't quite have time to properly model the general case for when we cross the &quot;point of no return&quot; from a spread from one of many cities.  I assume that my analysis would probably look like the original paper that I was basing this on.  However, I did make a simple approximation for a hop between two cities.
&lt;/p&gt;

&lt;p&gt;
	Again, you'll have to go through &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;my derivation&lt;/a&gt; to see the details, but these simulation results showed that the formula for &lt;span lang=&quot;latex&quot;&gt;t_X&lt;/span&gt; was roughly twice the value of the single city estimate.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_tX_double.png&quot;/&gt;

&lt;p&gt;
	To use this estimate, we'll have to adjust the parameter &lt;span lang=&quot;latex&quot;&gt;t_X&lt;/span&gt; to account for there being more flights from other parts of China than there were for Wuhan. Unfortunately for us, there are about ~100 times more flights coming from all of China than were coming from Wuhan directly.  That means we'd estimate that we had 21 days to stop flights from all of China.  Not impossible to pull off, but depending on how you define exactly when the epidemic started, we might have missed that window.
&lt;/p&gt;


&lt;h4&gt;Don't panic. But also, maybe don't fly to China right now.&lt;/h4&gt;

&lt;p&gt;
	You should keep in mind that this whole exercise is just a very simplified model that can help you think about how this process works. It does not make accurate quantitative predictions about the probability that there will be an outbreak or whether you, personally, will get sick.  It shouldn't make you feel more safe or more terrified, and you should not use it to inform your decision making about infection mitigation.  You &lt;em&gt;should&lt;/em&gt; use this to get more excited about using math to inform your mental picture of the world.
&lt;/p&gt;
&lt;p&gt;
	Now, if you'll excuse me, I'm going to go wash my hands.
&lt;/p&gt;


&lt;h4&gt;Appendix: Let's make it look cool&lt;/h4&gt;
&lt;p&gt;
	These graphs are nice, but if there's one thing I learned when working on simulations in &lt;a href=&quot;/2017/08/theseus-and-cell-phd-dissertation-story/&quot;&gt;grad school&lt;/a&gt;, it's that you can't just show the results, you have to show a pretty visualization too. So to do that, I built these simulations into a d3 map visualization.
&lt;/p&gt;

&lt;a href=&quot;http://bl.ocks.org/stedn/b0acdeba81751c5f8e4ccaa74ccb09a9&quot;&gt;
&lt;img src=&quot;/assets/images/2020/wuhan_overview_im.png&quot; title=&quot;Wuhan javascript model visualization&quot; alt=&quot;Wuhan javascript model visualization&quot;/&gt;
&lt;/a&gt;

&lt;p&gt;
	To build it, I figured out the map projection using &lt;a href=&quot;https://bl.ocks.org/d3indepth/f7ece0ab9a3df06a8cecd2c0e33e54ef&quot;&gt;this tool&lt;/a&gt;, and I added the animated graph at the bottom based off &lt;a href=&quot;https://bl.ocks.org/d3noob/7030f35b72de721622b8&quot;&gt;this example&lt;/a&gt;.   The coolest and most fun part, though, was animating the dots that fly from Wuhan to San Francisco, which I based off this code &lt;a href=&quot;https://bl.ocks.org/d3indepth/aa1f036f6a0356cb1152c4b836e93990&quot;&gt;block&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
	The really tricky part was manually implementing a differential equation solver in javascript.  I ended up just using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Euler_method&quot;&gt;forward Euler&lt;/a&gt; method even though that is only rough approximation of the true solution.  I figured it was more important to have simplicity in this animation since I'd already done the more &lt;a href=&quot;&quot;&gt;rigorous simulation&lt;/a&gt; with the &lt;a href=&quot;https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html&quot;&gt;scipy ode solver&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
	To implement the solver, I just evaluate the differential equation above and keep track of the change in variable values. However, In order to visualize the number &quot;in transit&quot; flying from Wuhan to SF, I had to keep track of &lt;code&gt;mu * n_wu&lt;/code&gt; separately (ie &lt;code&gt;n_tr&lt;/code&gt;).
&lt;/p&gt;

&lt;pre&gt;
  // compute differential euations for isolated populations
  d_wu = (gamma * n_wu - kappa) * dt;
  d_sf = (gamma * n_sf - kappa) * dt;

  n_wu = n_wu + d_wu;
  n_sf = n_sf + d_sf;

  d_tr = (mu * n_wu) * dt;
  n_tr = n_tr + d_tr;
&lt;/pre&gt;


&lt;p&gt;
	For dot animation, I kept track of 3 lists of dots. Whenever the corresponding &lt;code&gt;n_**&lt;/code&gt; value changed by one unit, I added or removed a dot from the corresponding list.  Here is how that worked for the Wuhan dot list.
&lt;/p&gt;

&lt;pre&gt;
  while(i_wu_n &lt; Math.floor(n_wu_viz)){
    pt = randomCircle(rad_wu)
    i_wu.push([wuhanLonLat[0]+pt[0], wuhanLonLat[1]+pt[1]])
    i_wu_n = i_wu_n + 1
  }
&lt;/pre&gt;

&lt;p&gt;
	The trickiest part was keeping track of the &quot;in transit&quot; dots.  For them, they stayed in the &quot;in transit&quot; list until their animation had brought them across.  It wasn't until that point that I incremented the San Francisco infected count (&lt;code&gt;n_sf&lt;/code&gt;).
&lt;/p&gt;

&lt;pre&gt;
  // transition dots out of Wuhan and into &quot;in transit&quot; list
  while(n_tr &gt; 1){
    n_tr = n_tr - 1;
    n_wu = n_wu - 1;
    i_tr.push(0);
    i_tr_n = i_tr_n + 1;
  }

  // for dots that have crossed, remove from &quot;in transit&quot; and add to n_sf
  for (i = 0; i &lt; i_tr_n; i++) {
    i_tr[i] = i_tr[i] + dl + dl*gaussianRand();
    if(i_tr[i]&gt;=1){
      i_tr.splice(i, 1);
      i_tr_n = i_tr_n - 1;
      n_sf = n_sf + 1;
    }
  }
&lt;/pre&gt;

&lt;p&gt;
	This actually changes the dynamics slightly because it introduces a lag between when the value.  I didn't worry about how that changed the results too much here. This app was just meant to be a visually captivating illustration and a learning exercise for people who want to understand how infectious disease models work. Hopefully someone other than me will get something from this too.
&lt;/p&gt;


&lt;script src=&quot;https://latex.codecogs.com/latexit.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;


</description>
        <pubDate>Tue, 11 Feb 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/02/wuhan-virus-model/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/02/wuhan-virus-model/</guid>
        
        <category>analysis</category>
        
        <category>visualization</category>
        
        <category>data science</category>
        
        <category>dynamics</category>
        
        <category>health</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>How to build a convincing reddit personality with GPT2 and BERT</title>
        <description>&lt;p&gt;
    Last month, I experimented with building a reddit comment bot that generated natural language replies by combining two pre-trained deep learning models: &lt;a href=&quot;http://jalammar.github.io/illustrated-gpt2/&quot;&gt;GPT-2&lt;/a&gt; and &lt;a hrf=&quot;http://jalammar.github.io/illustrated-bert/&quot;&gt;BERT&lt;/a&gt;. I wrote &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/&quot;&gt;another post&lt;/a&gt; on the motivation and background, but here I wanted to give a step by step walkthrough so others can work with what I've built.  If you prefer, you can jump straight to the &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot&quot;&gt;project code&lt;/a&gt;.  And to see the work that I based this on see &lt;a href=&quot;https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb&quot;&gt;this&lt;/a&gt;
&lt;/p&gt;

&lt;h4&gt;Model overview&lt;/h4&gt;

&lt;p&gt;Before getting into the nitty-gritty, I wanted to give a general overview of the process that I'm going to be using.  This flow diagram shows the 3 models that I needed to train, as well as the process fr hooking the models together to generate the output.
&lt;/p&gt;

&lt;img title=&quot;GPT2 BERT commentor workflow&quot; src=&quot;/assets/images/2020/gpt2_bert_workflow.png&quot; alt=&quot;GPT2 BERT comment system workflow&quot;/&gt;

&lt;p&gt;
    There are quite a few steps, but I hope it doesn't get too confusing.  Check out &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/&quot;&gt;my previous post&lt;/a&gt; for an even higher-level architecture overview.  Here are the steps I'll be explaining in this post.
&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;
        step 0: get some reddit comment data from your favorite subreddits and format into strings that look like &quot;comment [SEP] reply&quot;
    &lt;/li&gt;
    &lt;li&gt;
        step 1: fine tune GPT-2 to generate reddit text in the format &quot;comment [SEP] reply&quot;
    &lt;/li&gt;
    &lt;li&gt;
    step 2: fine tune two BERT classifiers to:
    &lt;ul&gt;
        &lt;li&gt;a: differentiate real replies from GPT-2 generated ones&lt;/li&gt;
        &lt;li&gt;b: predict how many upvotes comments will get&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;
    step 3: use praw to download current comments
    &lt;/li&gt;
    &lt;li&gt;
    step 4: use fine-tuned GPT2 to generate many replies for each comment
    &lt;/li&gt;
    &lt;li&gt;
    step 5: pass the generated replies to two BERT models to generate a prediction of realisticness and number of upvotes
    &lt;/li&gt;
    &lt;li&gt;
    step 6: use some criteria for choosing which replies to submit
    &lt;/li&gt;
    &lt;li&gt;
    step 7: use praw to submit the chosen comments
    &lt;/li&gt;
    &lt;li&gt;
    step 8: chuckle with amusement
    &lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Getting lots of reddit comment data&lt;/h4&gt;
&lt;p&gt;
    As with any machine learning project, nothing can start until you have data from which to train your model.
&lt;/p&gt;

&lt;p&gt;
    The data I used to fine-tune the models came from a &lt;a href=&quot;https://bigquery.cloud.google.com/dataset/fh-bigquery:reddit_comments?pli=1&quot;&gt;large database of previously retrieved reddit comments&lt;/a&gt;.  There is an &lt;a href=&quot;https://www.reddit.com/r/bigquery/wiki/datasets&quot;&gt;ongoing project&lt;/a&gt; that scrapes many sites around the web and stores them in a bunch of Google BigQuery tables.  To me, it's very surprising that I couldn't find a central  page about such a big project, but I used a few &lt;a href=&quot;https://www.reddit.com/r/bigquery/comments/5z957b/more_than_3_billion_reddit_comments_loaded_on/&quot;&gt;reddit&lt;/a&gt; and &lt;a href=&quot;https://towardsdatascience.com/bigquery-without-a-credit-card-discover-learn-and-share-199e08d4a064&quot;&gt;medium&lt;/a&gt; posts to piece together the format of the queries I'd need.
&lt;/p&gt;

&lt;p&gt;
    To start, I just downloaded a bunch of comment and reply information for the subreddits on 'writing', 'scifi', 'sciencefiction', 'MachineLearning', 'philosophy', 'cogsci', 'neuro', and 'Futurology'. This query works to pull the comments for a specific year and month (&lt;code&gt;{ym}&lt;/code&gt;) from bigquery.
&lt;/p&gt;

&lt;pre&gt;
SELECT s.subreddit as subreddit,
s.selftext as submission, a.body AS comment, b.body as reply,
s.score as submission_score, a.score as comment_score, b.score as reply_score,
s.author as submission_author, a.author as comment_author, b.author as reply_author
FROM `fh-bigquery.reddit_comments.{ym}` a
LEFT JOIN `fh-bigquery.reddit_comments.{ym}` b
ON CONCAT('t1_',a.id) = b.parent_id
LEFT JOIN  `fh-bigquery.reddit_posts.{ym}` s
ON CONCAT('t3_',s.id) = a.parent_id
where b.body is not null
  and s.selftext is not null and s.selftext != ''
  and b.author != s.author
  and b.author != a.author
  and s.subreddit IN ('writing',
                      'scifi',
                      'sciencefiction',
                      'MachineLearning',
                      'philosophy',
                      'cogsci',
                      'neuro',
                      'Futurology')
&lt;/pre&gt;


&lt;p&gt;
    I used the &lt;a href=&quot;https://cloud.google.com/bigquery/docs/reference/libraries&quot;&gt;bigquery python API&lt;/a&gt; to automate the generation of the queries I needed to download the data across a number of months in 2017 and 2018.  &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot/blob/master/get_reddit_from_gbq.py&quot;&gt;This script&lt;/a&gt; iterated over the time periods I needed and downloaded them to local disk in the &lt;code&gt;raw_data/&lt;/code&gt; folder.
&lt;/p&gt;

&lt;p&gt;
    In the end, I'm going to want to be able to prime the GPT-2 network with a comment and generate a reply. To do this, I needed to reformat the data to contain both parts separated by a special &lt;code&gt;[SEP]&lt;/code&gt; string to let the algorithm know which part is which.  Each line of training data file will look like the following.
&lt;/p&gt;
&lt;pre&gt;
    &quot;a bunch of primary comment text [SEP] all of the reply text&quot;
&lt;/pre&gt;

&lt;p&gt;
    After I train the model with this format, I can then feed the trained model a string like &lt;code&gt;&quot;some new primary comment text&quot; [SEP]&lt;/code&gt;, and it will start to generate the remaining &lt;code&gt;&quot;some new reply&quot;&lt;/code&gt; that it thinks fits best based on the training data. I'll explain in more detail below about how to feed this kind of data into the GPT-2 fine-tuning script.  For now, you can use &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot/blob/master/prep_data.py&quot;&gt;this script&lt;/a&gt; to convert the data into the format that GPT-2 fine-tuning will need and save it as &lt;code&gt;gpt2_finetune.csv&lt;/code&gt;
&lt;/p&gt;




&lt;h4&gt;Fine tuning GPT-2 and generating text for reddit&lt;/h4&gt;
&lt;p&gt;
    The major advantage of using GPT-2 is that it has been pre-trained on a massive dataset of millions of pages of text on the internet.  However, if you were to use GPT-2 straight &quot;out-of-the-box,&quot; you'd end up generating text that could look like anything you might find on the internet.  Sometimes it'll generate a news article, sometimes it'll generate a cooking blog recipe, sometimes it'll generate a rage-filled facebook post.  You don't really have too much control, and therefore, you won't really be able to use it to effectively generate reddit comments.
&lt;/p&gt;
&lt;p&gt;
    To overcome this issue, I needed to &quot;fine-tune&quot; the pre-trained model.  &lt;a href=&quot;https://stats.stackexchange.com/questions/331369/what-is-meant-by-fine-tuning-of-neural-network&quot;&gt;Fine-tuning&lt;/a&gt; means taking a model that was already trained on a big dataset, and then continuing to train it on just the specific type of data that you want to use it on.  This process (somewhat magically) allows you to take a lot of the general information about language from the big pretrained model, and sculpt that down with all the specific information about the exact output format you are trying to generate.
&lt;/p&gt;

&lt;p&gt;
    Fine-tuning is a standard process, but it still isn't super easy to do.  I'm not an expert deep learning researcher, but fortunately for me, a really &lt;a href=&quot;https://minimaxir.com/&quot;&gt;wonderful expert&lt;/a&gt; had already built some incredibly simple wrapper utilities called &lt;a href=&quot;https://github.com/minimaxir/gpt-2-simple&quot;&gt;gpt-2-simple&lt;/a&gt; for make fine-tuning GPT-2, well... simple.
&lt;/p&gt;

&lt;p&gt;
    The best part is that the author of gpt-2-simple, even set up a &lt;a href=&quot;https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce&quot;&gt;Google Colab notebook&lt;/a&gt; that walked through fine-tuning.  In case you haven't heard, &lt;a href=&quot;https://colab.research.google.com/notebooks/welcome.ipynb&quot;&gt;Google Colab&lt;/a&gt; is an amazing FREE (&lt;a href=&quot;https://meta.stackexchange.com/questions/21932/what-does-the-term-and-free-as-in-free-beer-mean&quot;&gt;as in beer&lt;/a&gt;) resource that lets you &lt;a href=&quot;https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c&quot;&gt;run a python jupyter notebook&lt;/a&gt; on a Google GPU server.  Full disclosure, I am officially a lifetime fanboy of Google for making a free tier on Google App Engine, BigQuery, and Google Colab.
&lt;/p&gt;

&lt;p&gt;
    You can follow along with the &lt;a href=&quot;https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce&quot;&gt;tutorial notebook&lt;/a&gt; to learn all about how to fine-tune a GPT-2 model with gpt-2-simple.  For my use case, I took all of that code and condensed and reformatted it a little to make my own &lt;a href=&quot;https://colab.research.google.com/drive/1VyOU81rsPsP_8WSKq-VZfB8TcMkPszG-&quot;&gt;gpt-2 fine tuning notebook&lt;/a&gt; that runs off the &lt;code&gt;gpt2_finetune.csv&lt;/code&gt; file that I generated in the previous step.  Just like in the original tutorial, you need to give the notebook permission to read and write from your Google Drive.  The model is then saved into you Google Drive for reloading from later scripts.
&lt;/p&gt;



&lt;h4&gt;Training BERT models for fake detection and upvote prediction&lt;/h4&gt;

&lt;p&gt;
    Even after fine-tuning, the output of this model, while normally somewhat reasonable, is often pretty &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/#gpt2shortcoming&quot;&gt;weird&lt;/a&gt;. To improve the quality of responses, I adapted the concept of GANs to create another meta-model that is able to throw out all the really weird replies.  So I use GPT-2 to generate a 10+ candidate responses for every comment, and then I use another model to filter out which are the best replies I could release.
&lt;/p&gt;
&lt;p&gt;
    To determine the best, I actually want to do two things:
&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;Filter out unrealistic replies&lt;/li&gt;
    &lt;li&gt;For the realistic replies, pick the one that I predict will have the most upvotes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
    So in order to do this, I have to train two classifiers, one to predict the probability of being a real reply and another to predict the probability of being a high scoring reply.  There are lots of ways to perform this prediction task, but one of the most successful language models recently built for this kind of thing is another deep learning architecture called &lt;a href=&quot;https://searchengineland.com/welcome-bert-google-artificial-intelligence-for-understanding-search-queries-323976&quot;&gt;Bidirectional Encoder Representations from Transformers&lt;/a&gt; or BERT. One big benefit of using this model is that, similar to GPT-2, researchers have pre-trained networks on very large corpora of data that I would never have the financial means to access.
&lt;/p&gt;

&lt;p&gt;
    Again, I'm not the biggest expert in working with deep learning infrastructure so luckily, other &lt;a href=&quot;https://www.tensorflow.org/hub&quot;&gt;brilliant tensorflowhub experts&lt;/a&gt; wrote a &lt;a href=&quot;https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb&quot;&gt;Google Colab tutorial&lt;/a&gt; for fine-tuning text classifier models using a pretrained BERT network.  So all I had to do was combine the two with some glue.
&lt;/p&gt;

&lt;p&gt;
    In the next section, I'll walk through the fine-tuning and some model evaluation, but if you'd like to get a jumpstart and don't want to bother fine-tuning yourself, you can download the three fine-tuned models from &lt;a href=&quot;https://drive.google.com/open?id=1GmGNqihV0nCQ6evLBmopOhjups_RESv-&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://drive.google.com/open?id=1-Bov5PtPrP2DvFw4yD-lxp2wTjGw0bwB&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://drive.google.com/file/d/1DTfYUxXEz80S0baCb4xPSrzx85F0FVTP/view?usp=sharing&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;

&lt;h5&gt;BERT Discriminator model performance&lt;/h5&gt;
&lt;p&gt;
    The realisticness model was trained just like in a traditional GAN. I had &lt;a href=&quot;https://drive.google.com/open?id=1RLJz_rJmz0UVdRikRGQrYF9TbLMIrrJ8&quot;&gt;another Colab notebook&lt;/a&gt; generate thousands of fakes and then created a dataset that combined my fakes with thousands of real comments.  I then fed that dataset into a &lt;a href=&quot;https://drive.google.com/open?id=1aGswP0SJmdP6GNKEuKMJ5AhP8epNOQW_&quot;&gt;BERT realisticness fine-tuning notebook&lt;/a&gt; to train and evaluate. The model actually has amazingly high distinguishing power between real and fake comments.
&lt;/p&gt;

&lt;h6&gt;BERT Realisticness Model Metrics&lt;/h6&gt;
&lt;pre&gt;
'auc': 0.9933777,
'eval_accuracy': 0.9986961,
'f1_score': 0.99929225,
'false_negatives': 3.0,
'false_positives': 11.0,
'precision': 0.9988883,
'recall': 0.99969655,
'true_negatives': 839.0,
'true_positives': 9884.0
&lt;/pre&gt;

&lt;p&gt;
    Going forward, every reply that the generator creates can be run through this BERT discriminator to get a score from 0 to 1 based on how realistic it is.  I then just filter to only return comments that are predicted to be the most likely to be real.
&lt;/p&gt;

&lt;p&gt;
    To predict how many upvotes a reply will get, I built another model in a &lt;a href=&quot;https://drive.google.com/open?id=1vXJjQbBZZ0Jo-LvcwRaNzCSAgAVem1cC&quot;&gt;similar way&lt;/a&gt;. This time the model was just trained just on a dataset containing a bunch of real reddit comments to predict how many upvotes they actually got.
&lt;/p&gt;

&lt;p&gt;
    This model also had surprisingly high predictive accuracy.  This &lt;a href=&quot;https://www.dataschool.io/roc-curves-and-auc-explained/&quot;&gt;ROC curve&lt;/a&gt; shows that we can get a lot of true positives correct without having too many false positives. For more on what true positive and false positive means see &lt;a href=&quot;https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative&quot;&gt;this article&lt;/a&gt;.
&lt;/p&gt;

&lt;img title=&quot;comment score prediction ROC curve&quot; src=&quot;/assets/images/2020/bert_upvote_predict.png&quot; alt=&quot;BERT score prediction ROC curve&quot;/&gt;
&lt;h6 style='text-align:center;'&gt;ROC curve for BERT based upvote prediction &lt;/h6&gt;


&lt;p&gt;
    Buoyed by the model cross-validation performance, I was excited to hook it up to a real-time commenting system and start shipping my bot's thoughts!
&lt;/p&gt;


&lt;h4&gt;Pulling real-time comments with PRAW&lt;/h4&gt;
&lt;p&gt;
    Although I could generate the training sets using data on bigquery, most of that data is actually a couple of months old.  Replying to months old comments is a very non-human thing to do on social media sites so it was important to be able to pull down fresh data from reddit somehow.
&lt;/p&gt;

&lt;p&gt;
    Fortunately, I could use the &lt;a href=&quot;https://praw.readthedocs.io/en/latest/&quot;&gt;praw library&lt;/a&gt; along with the following snippet to get all comments from the top 5 &quot;rising&quot; posts in a couple of subreddits that I thought would produce some interesting responses.
&lt;/p&gt;

&lt;pre&gt;
for subreddit_name in ['sciencefiction',
                       'artificial',
                       'scifi',
                       'BurningMan',
                       'writing',
                       'MachineLearning',
                       'randonauts']:
  subreddit = reddit.subreddit(subreddit_name)

  for h in subreddit.rising(limit=5):
&lt;/pre&gt;

&lt;p&gt;
    I could run each comment through the generator and discriminators to produce a reply.
&lt;/p&gt;

&lt;h4&gt;Running the generator and discriminators&lt;/h4&gt;
&lt;p&gt;
    Finally, I just had to build something to reload all the fine-tuned models and pass the new reddit comments through them to get replies. In an ideal world, I would have run both the GPT-2 and the BERT models in one script that could be run from end to end.  Unfortunately, a quirk in the way the designers immplemented the gpt2-simple package made it impossible to have two computation graphs &lt;a href=&quot;https://github.com/minimaxir/gpt-2-simple/issues/130&quot;&gt;instantiated in the same environment&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
    So instead, I just ran a &lt;a href=&quot;https://drive.google.com/open?id=1Z-sXQUsC7kHfLVQSpluTR-SqnBavh9qC&quot;&gt;GPT-2 generator notebook&lt;/a&gt; on its own to download new comments, generate a batch of candidate replies, and store them in csv files on my google drive.
    Then, I reloaded the candidates in a separate &lt;a href=&quot;https://drive.google.com/open?id=1mWRwK1pY34joZul5gBeMortfTu8M9OPC&quot;&gt;BERT discriminator notebook&lt;/a&gt;to pick the best replies and submit them back to reddit.
&lt;/p&gt;

&lt;p&gt;You can view the whole workflow in my &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot&quot;&gt;github repo&lt;/a&gt; for the project or in my &lt;a href=&quot;https://drive.google.com/open?id=1by97qt6TBpi_o644uKnYmQE5AJB1ybMK&quot;&gt;Google Drive folder&lt;/a&gt;.  Please &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot/issues&quot;&gt;submit issues&lt;/a&gt; to the project if you think things can be explained more clearly, or if you find bugs.&lt;/p&gt;

&lt;h4&gt;Last Step: Chuckle with Amusement&lt;/h4&gt;
&lt;p&gt;
    I submitted all my replies under the reddit account of &lt;a href=&quot;https://www.history.com/news/tupperware-parties-brownie-wise&quot;&gt;tupperware-party&lt;/a&gt; (which hopefully won't get shut down for trademark shit).  You can check out some highlights from the model output &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/#replies&quot;&gt;here&lt;/a&gt; or see the &lt;a href=&quot;https://www.reddit.com/user/tupperware-party/comments/&quot;&gt;full list of comments&lt;/a&gt; to inspect everything the system outputted.  I've also shared a &lt;a href=&quot;https://drive.google.com/drive/folders/1a2MhIqL6jvyJ-3bGCXAweLbYtNXSUei7?usp=sharing&quot;&gt;folder on Google Drive&lt;/a&gt; with all of the candidate responses and their scores from the BERT models if you want to take a look.
&lt;/p&gt;

&lt;p&gt;
    Finally, I know there are definitely some ethical considerations when creating something like this.  You can read my thoughts on that &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/#ethics&quot;&gt;here&lt;/a&gt;.  In short, please try to use this responsibly and spread the word that we are living in a world where this is possible.  And if you have a problem, tell me on &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;Mastodon&lt;/a&gt;.  I swear it'll really be me who responds.
&lt;/p&gt;

</description>
        <pubDate>Tue, 04 Feb 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/02/reddit-bot-gpt2-bert/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/02/reddit-bot-gpt2-bert/</guid>
        
        <category>machine learning</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/thiscommentisgreat.png</image>
        <title>Combining GPT-2 and BERT to make a fake person</title>
        <description>&lt;p&gt;
	&lt;a href=&quot;https://openai.com/blog/better-language-models/&quot;&gt;GPT-2&lt;/a&gt; is a deep learning model that is able to generate astonishingly coherent English text.  It was released last year, and &lt;a href=&quot;https://towardsdatascience.com/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8&quot;&gt;everyone’s&lt;/a&gt; &lt;a href=&quot;https://www.fast.ai/2019/02/15/openai-gp2/&quot;&gt;mind&lt;/a&gt; was &lt;a href=&quot;https://www.theguardian.com/commentisfree/2019/feb/15/ai-write-robot-openai-gpt2-elon-musk&quot;&gt;blown&lt;/a&gt; into &lt;a href=&quot;http://approximatelycorrect.com/2019/02/17/openai-trains-language-model-mass-hysteria-ensues/&quot;&gt;histrionic&lt;/a&gt; &lt;a href=&quot;https://www.wired.com/story/ai-text-generator-too-dangerous-to-make-public/&quot;&gt;hyperbole&lt;/a&gt;, including mine.  Its creators at &lt;a href=&quot;https://openai.com/&quot;&gt;OpenAI&lt;/a&gt; were so impressed by the model's performance that they originally didn't release it for fear of it being too easy to abuse. I think they were right to be concerned.  Here is an excerpt that the model generated, taken from their &lt;a href=&quot;https://openai.com/blog/better-language-models/#sample1&quot;&gt;release page&lt;/a&gt;.
&lt;/p&gt;

&lt;blockquote&gt;
	In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.

	The scientist named the population, after their distinctive horn, Ovid’s Unicorn. These four-horned, silver-white unicorns were previously unknown to science.

	Now, after almost two centuries, the mystery of what sparked this odd phenomenon is finally solved.

	Dr. Jorge Pérez, an evolutionary biologist from the University of La Paz, and several companions, were exploring the Andes Mountains when they found a small valley, with no other animals or humans. Pérez noticed that the valley had what appeared to be a natural fountain, surrounded by two peaks of rock and silver snow.
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://openai.com/blog/better-language-models/#sample1&quot;&gt;read more&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;
	When I saw what GPT-2 was capable of generating, I had chills. We are now very close to effectively simulating human creativity.  I find machine imitation of human communication fascinating; in fact, it's something I've explored in &lt;a href=&quot;/attention&quot;&gt;my fiction writing&lt;/a&gt; previously. But since I've never worked on natural language generation or deep learning, I decided to look more closely at just what this machine could do.
&lt;/p&gt;


&lt;h4&gt;The person you are speaking with is not real&lt;/h4&gt;
&lt;p&gt;
	My goal was to see how close I could come to impersonating a real human with algorithmically generated text and almost no manual quality control.
&lt;/p&gt;
&lt;p&gt;
	I decided that one of the easiest places to test such a system would be in the responses to comments on the social media website, &lt;a href=&quot;https://www.reddit.com/&quot;&gt;reddit&lt;/a&gt;. My goal became to generate a bot that would respond topically to comments, garner upvotes, and see if it can promote discussion.  In case you are worried about the ethicality of releasing a surreptitious human on reddit, rest assured I have only deployed the bot sparingly to avoid generating too much annoyance in the world.  And I have manually reviewed evey comment to ensure that it produced nothing too offensive.
&lt;/p&gt;
&lt;p&gt;
	Honestly, I was hoping I could use this tool to become a little more popular on this whole internet thing. I've been pretty much terrible at interacting on social media so I figured maybe I could automate the problem away.  I quickly learned that just using GPT-2 on it's own is not quite adequate to impersonate a human most of the time.  But with a little modification, I've found that building a frighteningly passable reddit commenter is not only possible; it's pretty easy.
&lt;/p&gt;



&lt;h4 id=&quot;gpt2shortcoming&quot;&gt;The Shortcoming of GPT-2&lt;/h4&gt;
&lt;p&gt;
	What GPT-2's creators fail to mention is that while almost everything the model generates is grammatically and syntactically correct, only a tiny fraction of the outputs make any damn sense.  Here is another excerpt that shows just how non-human the output normally looks.
&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; data-dnt=&quot;true&quot; data-theme=&quot;light&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Here&amp;#39;s a short story i generated using OpenAI&amp;#39;s GPT-2 tool (prompt in bold) &lt;a href=&quot;https://t.co/DGIVwGuAUV&quot;&gt;pic.twitter.com/DGIVwGuAUV&lt;/a&gt;&lt;/p&gt;&amp;mdash; will knight (@willknight) &lt;a href=&quot;https://twitter.com/willknight/status/1096134045774344199?ref_src=twsrc%5Etfw&quot;&gt;February 14, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;
	When I first started experimenting, I generated a lot of similar gibberish.  As it turns out, GPT2 on its own is fairly prone to getting into weird unintelligible rants.  Here are some examples.
&lt;/p&gt;

&lt;blockquote&gt;
The idea of the film is very similar to the kind of film we’ve seen before,
“The Road”. The film “took place” at “a time”, “at a place”.
“The Road” was set at “a time”, “a place”.”
“The Road” was also set at a time of the Soviet Union’s collapse,””“a time”, “the collapse” of communism”.
“The Road” is set at a time of the Russian Revolution,”“the collapse” of the Soviet Union’s fall,”“a time”, “the collapse” of the Soviet Union’s collapse.”
So, “The Road” is a film about the dissolution of the Soviet Union’s grip on the world,”“a time of the Russian Revolution”.
&lt;/blockquote&gt;

&lt;p&gt;Clearly the algorithm is getting confused on the way quotations work.  Then there's this one, which makes grammatical sense, but is clearly a series of statements that no regular person would ever say (unless they were trolling). &lt;/p&gt;

&lt;blockquote&gt;
I still can't believe you. I had the same birthday last year.
I'm a 10 year old, and I have never even heard of this novel.
&lt;/blockquote&gt;

&lt;p&gt;
	Worse still, a lot of the time, GPT2 will just start repeating a few crazy phrases over and over.  You can &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1n2_IM32ULuu_x9f_hX2YlmRfahF61K_os5fGg2RcgBA/edit?usp=sharing&quot;&gt;check out some of the model's output&lt;/a&gt; to get a taste of the kinds of things that it generates in the raw.
&lt;/p&gt;

&lt;p&gt;
	I wouldn't want to build a bot that spewed crazy looking responses like that all the time.  It would be incredibly annoying to other redditors and would probably be flagged right away.  Still, I didn't want to give up on the idea completely. I started brainstorming about ways that I could fix the performance problems with GPT2 and make it more robust, and I came up with something that was able to filter out a lot of the crap responses.
&lt;/p&gt;

&lt;h5&gt;Machines trying to trick other machines&lt;/h5&gt;
&lt;p&gt;
	To fix the problem, I borrowed an idea from another deep learning architecture called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_adversarial_network&quot;&gt;generative adversarial network&lt;/a&gt; or GAN.  GANs have been used extensively in the past and  have been astonishingly successful in impersonating &lt;a href=&quot;https://www.thispersondoesnotexist.com/&quot;&gt;images&lt;/a&gt;, &lt;a href=&quot;https://magenta.tensorflow.org/gansynth&quot;&gt;music&lt;/a&gt;, and even &lt;a href=&quot;https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-1-2b886c8cab10?gi=e90e56af6387&quot;&gt;text&lt;/a&gt; (though it doesn't do text that well).  The rise of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Deepfake#History&quot;&gt;&quot;deep fake&quot;&lt;/a&gt; is mostly thanks to developments in the GAN architecture.
&lt;/p&gt;
&lt;p&gt;
	The concept of the GAN is pretty simple. You train two algorithms, one to generate text (generator), and another to try to distinguish the generator’s text from human text  (discriminator).  These algorithms are typically called &lt;a href=”https://en.wikipedia.org/wiki/Language_model”&gt;language models&lt;/a&gt; because they attempt to model the way language is produced. In a classical GAN you then use the two models to improve each other by having the generator constantly compete to trick the discriminator (hence Adversarial).
&lt;/p&gt;


&lt;img title=&quot;GAN illustration&quot; src=&quot;/assets/images/2020/gan_explain.png&quot; alt=&quot;GAN illustration&quot;/&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;em&gt;GAN diagram (&lt;a href=&quot;https://developers.google.com/machine-learning/gan/gan_structure&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
	It's a very intuitive and clever concept, and one that I personally feel mirrors the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bicameralism_(psychology)&quot;&gt;internal dialog&lt;/a&gt; that I constantly have in my own brain's decision making system.  The critic in my head feels almost like a discriminator algorithm &lt;a href=&quot;https://i.imgur.com/mGva0nK.gif&quot;&gt;throwing shade&lt;/a&gt; on my internal generator algorithm. Anyway, if you're interested in how they work in detail, you can read more &lt;a href=&quot;https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
	Unfortunately, I wasn't quite smart enough to figure out how to modify the pre-existing GPT-2 model to turn it into a GAN.  I think it's possible, but tensorflow is a &lt;a href=&quot;https://nostalgebraist.tumblr.com/post/189464877164/attention-conservation-notice-machine-learning&quot;&gt;confusing beast&lt;/a&gt;, and I'm not yet at the point where I care enough to untangle that mess.  Instead, I did something a little simpler that was just effective enough to make the results passable.
&lt;/p&gt;

&lt;h4&gt;Filtered generator -&gt; discriminator method&lt;/h4&gt;

&lt;p&gt;
	I instead opted for a multi-stage modeling framework, utilizing three separate deep-learning models stitched together one after the next.  This diagram illustrates the many parts that needed to be trained, and how they were strung together to produce replies from comments.
&lt;/p&gt;

&lt;img title=&quot;GPT2 BERT commentor workflow&quot; src=&quot;/assets/images/2020/gpt2_bert_workflow.png&quot; alt=&quot;GPT2 BERT comment system workflow&quot;/&gt;

&lt;p&gt;
	In this setup, I first pick a comment on reddit to serve as seed text for the generator.  I generate a whole bunch of replies for this comment using my GPT-2 model.  Then I pass all the candidates to the discriminator model to filter out the messed up comments and only select the best ones.
&lt;/p&gt;

&lt;p&gt;
	To build the discriminators, I fine-tuned another deep-learning language model called &lt;a href=&quot;https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270&quot;&gt;BERT&lt;/a&gt;.  I made two models, one for how realistic the reply was and another for how many upvotes the reply would get.
&lt;/p&gt;


&lt;p&gt;
	You can read &lt;a href=&quot;/2020/02/reddit-bot-gpt2-bert/&quot;&gt;this post&lt;/a&gt; for a detailed walkthrough of how the whole system was constructed, trained, tested, and deployed.
&lt;/p&gt;
&lt;p&gt;
	Just by looking at the initial results, it seemed likely that the bot was going to be able to communicate pretty convincingly.  But the only &lt;a href=&quot;https://en.wikipedia.org/wiki/Turing_test&quot;&gt;real test&lt;/a&gt; was to put it into use and see how people respond.
&lt;/p&gt;

&lt;h4&gt;Meet tupperware-party&lt;/h4&gt;
&lt;p&gt;
	Once I had the models built and hooked together, the last step was to plug the bot into reddit.  I made an account for the bot called &lt;strong&gt;tupperware-party&lt;/strong&gt;, which I figured sounded innocuous enough.  I used &lt;a href=&quot;https://praw.readthedocs.io/en/latest/&quot;&gt;praw&lt;/a&gt; to submit the replies automatically, and then I went through and examined all of them to make sure none were too offensive or annoying.  As I was reading through the results, there were so many gems that it's hard to pick just a few examples to share.
&lt;/p&gt;

&lt;h5 id='replies'&gt;What did the robot say?&lt;/h5&gt;

&lt;p&gt;
	This &lt;a href=&quot;https://www.reddit.com/r/sciencefiction/comments/evqiti/dune_logo_unveiled_at_event_copyright_claimants/fg44yzw/?context=3&quot;&gt;first one&lt;/a&gt; seems like a perfect imitation of someone with a strong opinion on the internet.
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party1.png&quot; alt=&quot;COMMENT: 'Dune’s fandom is old and intense, and a rich thread in the cultural fabric of the internet generation' BOT_REPLY:'Dune’s fandom is overgrown, underfunded, and in many ways, a poor fit for the new, faster internet generation.'&quot; style=&quot;border:2px;&quot;/&gt;


&lt;p&gt;
	I actually can't explain how &lt;a href=&quot;https://www.reddit.com/r/BurningMan/comments/ep6pyq/playa_lung/feilsjn/?context=8&amp;depth=9&quot;&gt;this next one&lt;/a&gt; could possibly work.  It seems as if the bot is responding to the specific numerical bullet points in the original comment.
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party2.png&quot; alt=&quot;bot responds to specific numerical bullet point in source comment&quot;/&gt;

&lt;p&gt;
	Notice that in the original comment, point 2 is about sleep and the bot says &quot;2&quot; right before talking about sleep. Then it says &quot;3&quot; before switching subjects to talking about something that induces anxiety.  It doesn't make perfect sense but it somehow knows to respond to bullet points separately, which seems like a huge leap given that it was never trained to do that specifically.
&lt;/p&gt;

&lt;p&gt;
	This &lt;a href=&quot;https://www.reddit.com/r/artificial/comments/ep26lc/is_china_going_to_overtake_the_us_in_data_science/feik6wg/?context=8&amp;depth=9&quot;&gt; one&lt;/a&gt; is great on a number of levels.  First, it's kind of meta because the bot was posting into the &lt;a href=&quot;https://www.reddit.com/r/artificial/&quot;&gt;r/artifical subreddit&lt;/a&gt;, which is a forum dedicated to artificial intelligence.  Second, not only is the comment pretty darn coherent, it is so much so that the original author writes a well thought out reply further expanding on his point in light of the bot's comment.
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party3.png&quot; alt=&quot;gpt2-bert on China&quot;/&gt;

&lt;p&gt;
	I honestly don't even know what to say to that.  Is it possible that every conversation on the internet right now has at least one slightly ill-informed bot in the mix.  We are seriously screwed.  But don't worry, this bot is at least a little woke too already.
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party4.png&quot; alt=&quot;The first thing I think of when thinking about a villain's face turn is probably that they are a male character. Some males are actually pretty bad in the media...&quot;/&gt;

&lt;p&gt;
	There are so many surprisingly realistic replies that I enourage you to go through &lt;a href=&quot;https://www.reddit.com/user/tupperware-party/comments/&quot;&gt;tupperware-party's whole comment list&lt;/a&gt;.  Overall, the bot wrote 80 replies and 24 of them received at least one upvote. I'm impressed with that and hoping that maybe it will eventually be able to help &lt;a href=&quot;https://www.reddit.com/user/bonkerfield&quot;&gt;me&lt;/a&gt; become more popular on reddit.
&lt;/p&gt;

&lt;p&gt;
	On the other hand, the single most popular comment (with 8 votes) was &lt;a href=&quot;https://www.reddit.com/r/sciencefiction/comments/efej56/the_problem_with_the_original_dune_movie/fc16yq8/?context=3&quot;&gt;this one&lt;/a&gt;, which is just innocuous flattery.
&lt;/p&gt;
&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/thiscommentisgreat.png&quot; alt=&quot;This comment is great.&quot;/&gt;

&lt;p&gt;
	Since this could easily be copy and pasted to every other comment and still be totally in context, I guess maybe I didn't need to try so hard.
&lt;/p&gt;

&lt;h4 id=&quot;ethics&quot;&gt;You can build one too!&lt;/h4&gt;

&lt;p&gt;If you find this interesting, I've written a &lt;a href=&quot;/2020/02/reddit-bot-gpt2-bert/&quot;&gt;tutorial post&lt;/a&gt; with details and code describing how I built everything and showing what you'd need to do to recreate one of your own.  I realize there are definite ethicality concerns with building and using something like this so I encourage you to be an &lt;a href=&quot;https://en.wikiquote.org/wiki/Bill_%26_Ted%27s_Excellent_Adventure&quot;&gt;excellent&lt;/a&gt; human and only use this tool sparingly and for that which &lt;a href=&quot;https://en.wikipedia.org/wiki/Categorical_imperative&quot;&gt;you deem to be good&lt;/a&gt;.
&lt;/p&gt;
&lt;h5&gt;Ethical concerns&lt;/h5&gt;
&lt;p&gt;
    I know there are definitely some ethical considerations when creating something like this.  The reason I'm presenting it is because I actually think it is &lt;a href=&quot;https://www.wired.com/story/company-wants-billions-make-ai-safe-humanity/&quot;&gt;better&lt;/a&gt; for more people to know about and be able to grapple with this kind of technology. If just a few people know about the capacity of these machines, then it is more likely that those small groups of people can abuse their advantage.
&lt;/p&gt;
&lt;p&gt;
    I also think that this technology is going to change the way we think about what's important about being human.  After all, if a computer can effectively automate the paper-pushing jobs we've constructed and all the bullshit we create on the internet to distract us, then maybe it'll be time for us to move on to something more meaningful.
&lt;/p&gt;

&lt;p&gt;
	If you think what I've done is a problem feel free to &lt;a href=&quot;https://will.stedden.org&quot;&gt;send me a message&lt;/a&gt;, or publically shame me on &lt;a href=&quot;https://sigmoid.social/@bonkerfield&quot;&gt;Mastodon&lt;/a&gt;.
&lt;/p&gt;


</description>
        <pubDate>Tue, 04 Feb 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/02/combining-gpt-2-and-bert/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/02/combining-gpt-2-and-bert/</guid>
        
        <category>machine learning</category>
        
        <category>language</category>
        
        <category>end times</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/big_bonkerfield.png</image>
        <title>Visualizing the Identifield</title>
        <description>&lt;p&gt;&lt;em&gt;&lt;small&gt;Edit: I've revised the term for the concept described below to be &lt;strong&gt;identifield&lt;/strong&gt;. I was originally calling it a bonkerfield but realized that is too confusing.&lt;/small&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For the past few weeks, I've been trying to figure out how to visually describe a philosophical concept that I've come up with called an &lt;strong&gt;identifield&lt;/strong&gt;. It's something I find fascinating, but quite hard to wrap my own head around entirely.  I've been ruminating on how to convey it for a while now, trying to be able to get the idea across and not sound like a crazy person or an idiot. &lt;/p&gt;

&lt;p&gt;I've elaborated on this subject at length on my &lt;a href=&quot;/reasons/&quot;&gt;reasons&lt;/a&gt; page, but in short, an identifield is a map of everywhere that any information has resided throughout all of space and time.  The idea sounds convoluted in words, but it's something that I have a pretty decent image of in my mind.&lt;/p&gt;

&lt;p&gt;Originally I was planning to create a conceptual piece without too much detail.  I made a weak attempt in this sketch. Hopefully, You get the idea of connectedness between different spots as if the idea is kind of being put together towards a single point in time and then disseminated on the other side.&lt;/p&gt;


&lt;img class=&quot;small_img&quot; title=&quot;Medium Identifield&quot; src=&quot;/assets/images/2020/bonker_sketch.jpg&quot;&gt;


&lt;p&gt;As I thought about it more, I figured it would be possible to realize this idea in a more concrete way.  I could find someone's record of the formation and dissemination of some idea and visualize the actual data itself.&lt;/p&gt;


&lt;p&gt;Following information around in space and time is still pretty nebulous so I know I'm doomed to failure in some sense.  Still, I wanted to try using the tools of the modern data scientist to manifest this philosophical concept.&lt;/p&gt;


&lt;h4&gt;Spatiotemporally Fixed Hierarchical Clustering in d3&lt;/h4&gt;
&lt;p&gt;Like I normally do in this situation, I went and scanned the web for things that already look kind of similar to what I'm trying to build.  At it's core, I wanted swoopy, pretty lines that connected nodes.  I figured that &lt;a href=&quot;https://en.wikipedia.org/wiki/Mike_Bostock&quot;&gt;Mike Bostock&lt;/a&gt; of d3 fame must've built something like this at some point, and I wasn't dissapointed.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/hierarchical_edge_bundling.png&quot; title=&quot;Hierarchical Edge Bundling Viz by Mike Bostock&quot;&gt;


&lt;p&gt;He'd built this &lt;a href=&quot;https://bl.ocks.org/mbostock/5672200&quot;&gt;hierarchical clustering vizualitation&lt;/a&gt; that is a little different than what I want, but still really reminds me of the general feel. The data he was vizualizing in this example was the interconnectivity of software packages in a codebase.  He's used this as a basis for &lt;a href=&quot;https://observablehq.com/@d3/hierarchical-edge-bundling&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://bl.ocks.org/mbostock/4341134&quot;&gt;different&lt;/a&gt; &lt;a href=&quot;https://bl.ocks.org/mbostock/5672200&quot;&gt;visualizations&lt;/a&gt;, and humorously, I had previously exploited some of his &lt;a href=&quot;https://bost.ocks.org/mike/hive/&quot;&gt;related work&lt;/a&gt; to make another attempted &lt;a href=&quot;hellowill.bonkerfield.org&quot;&gt;vizualization&lt;/a&gt; of all the people I had worked with in my life.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/hellowill_viz.png&quot; title=&quot;plot of people projects and skills from my digital resume&quot;&gt;

&lt;p&gt;I have &lt;a href=&quot;/2015/01/05/a-better-linkedin/&quot;&gt;another post&lt;/a&gt; that explains building that visual.  It had constrained all projects along one radial line, skills on another, and people on a third.  To vizualize the identifield, I needed to do something similar except the positional constraint would be along the x-axis and it would vary based on time.&lt;/p&gt;

&lt;p&gt;The time of interest is the time that some discernible event related to the formation of an idea would take place.  For now, I decided that spatial position wouldn't be demarked explicitly along the other axis.  Instead, I would use the clustering of events to automatically set where they lay. This way there shouldn't be too many overlapping lines in the final result.&lt;/p&gt;


&lt;h4&gt;Selecting a test idea&lt;/h4&gt;

&lt;p&gt;To get started testing, I needed a simple example scenario to try to visualize. &lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;&lt;em&gt;Imagine an author is writing a paragraph about a childhood memory with her mother.  In the paragraph, she quotes the phrase &quot;Call me Ishmael&quot; from Moby Dick.  Both of those pieces of information are baked into the identifield of that paragraph.  After she publishes that paragraph in her memoir, a few Melville academics cite her.  In addition, something she says in that paragraph blows up as a meme on the internet.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
  Maybe this scenario isn't that realistic, and definitely not the best candidate to demonstrate the value of the identifield as a construct. Still, it's simple enough and contained enough that I could keep it in my head long enough to hand annotate the data structure I was going to use for it.
&lt;/p&gt;

&lt;h4 id=&quot;results&quot;&gt;Results&lt;/h4&gt;
&lt;p&gt;You can view below for the implementation details, but before that I wanted to show what the general results were. Below is an implementation of the scenario above.  On the top left, is the reference to Moby Dick's &quot;Call me Ishmael&quot;, which in turn references Ishmael in the Bible.  The bottom right is the &quot;viral&quot; expansion as that paragraph blows up on the internet.&lt;/p&gt;


&lt;img title=&quot;Tame Identifield&quot; src=&quot;/assets/images/2020/bonker_viz_1.png&quot;&gt;

&lt;p&gt;There were a number of variations that I want to be able to work with when building identifields.  The framework I've built allows me to vary the number of lines, the opacity and the random dispersion of their endpoints.  The next two images show what happens when I turn up the randomness on the viral part of the example.&lt;/p&gt;

&lt;img class=&quot;small_img&quot; title=&quot;Medium Identifield&quot; src=&quot;/assets/images/2020/bonker_viz_2.png&quot;&gt;
&lt;img class=&quot;small_img&quot; title=&quot;Wild Identifield&quot; src=&quot;/assets/images/2020/bonker_viz_3.png&quot;&gt;


&lt;p&gt;You can see the live d3 graph and the code to produce it on &lt;a href=&quot;https://bl.ocks.org/stedn/5d187e873982e441e1f78d6d69af0030&quot;&gt;this bl.ock&lt;/a&gt;.  Next, I want to explore building more complex underlying identifields. &lt;/p&gt;

&lt;h5&gt;A more complex identifield&lt;/h5&gt;
&lt;p&gt;After building the simple version, I really wanted to scale it up to a more complex and interesting example.  Unfortunately, I didn't quite have time to compile real data or come up with another complicated story for this one.  Instead, I just tried generating a random hierarchy. The results were quite surprising. &lt;/p&gt;


&lt;img title=&quot;Complicated Identifield&quot; src=&quot;/assets/images/2020/big_bonkerfield.png&quot; /&gt;


&lt;p&gt;When this image rendered, I've was overwhelmed with the similarity to a neuron.  There's really a beautiful correspondence between the bonkerfield and the brain that hadn't even occurred to me as I was building it.  The bonkerfield of any information in a human mind could be traced down through the individual neurons that collectively record it. So it's really fitting that  like in &lt;a href=&quot;https://en.wikipedia.org/wiki/Neuron#/media/File:PurkinjeCell.jpg&quot;&gt;this classic illustration&lt;/a&gt; from &lt;a href=&quot;https://en.wikipedia.org/wiki/Santiago_Ram%C3%B3n_y_Cajal&quot;&gt;Santiago Ramón y Cajal&lt;/a&gt;.&lt;/p&gt;


&lt;img title=&quot;Purkinje Neuron Cells&quot; src=&quot;/assets/images/2020/PurkinjeCell.jpg&quot; /&gt;


&lt;p&gt;What's more amazing, was the how the parameters that I used to generate the random graph varied the the overall structure&lt;/p&gt;


&lt;p&gt;See below for implementation details. I will be back soon with an analysis of how a few parameters can control the architecture of the complicated.  And once I get a really good example where I can work through and compile the data, I'll update with a thorough explanation of a rendering of a true identifield.&lt;/p&gt;

&lt;h4&gt;Implementation&lt;/h4&gt;
&lt;p&gt;The rest of this article can help walk you through adapting my code and data to build your own identifield visualizations.&lt;/p&gt;
&lt;h5&gt;Compiling the data&lt;/h5&gt;
&lt;p&gt;
  I had to hand annotate a json document in the structure needed for d3 to render it using the d3 &quot;bundle&quot; layout. Even though my data isn't really any kind of hierarchy, I'm sort of hacking the format that the d3 hierarchical bundling wants.
&lt;/p&gt;

&lt;p&gt;The minimal format to make it work requires two things:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a &lt;code&gt;.&lt;/code&gt; delimited naming structure to define the hierarchy&lt;/li&gt;
  &lt;li&gt;an import structure to define where th lines should be drawn between.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
  I want everything to be drawn for the lowest nodes back up to the &quot;paragraph&quot; node, so I only need imports from the leafs to the paragraph node. To create a hierarchy for the leafs, I just needed to come up with higher order groupings that link things so their lines get drawn together on the way back up to the &quot;paragraph&quot; node.  The following document shows a simple example that would take two leaves for &lt;code&gt;bible&lt;/code&gt; and &lt;code&gt;melville&lt;/code&gt; and link them back to the paragraph via &lt;code&gt;mobydick&lt;/code&gt;
&lt;/p&gt;

&lt;pre&gt;
[
  {&quot;name&quot;:&quot;paragraph.mobydick.bible&quot;,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.mobydick.melville&quot;,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.mobydick&quot;,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph&quot;,&quot;imports&quot;:[]},
]
&lt;/pre&gt;

&lt;p&gt;To generate the full vizualization I added a couple more routes for the information to flow up to the paragraph.  I also added an additional &lt;code&gt;time&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt;, and &lt;code&gt;weight&lt;/code&gt; params that would set the x-position, the thickness of the line, and the transparency of the stroke, respectively.&lt;/p&gt;
&lt;pre&gt;
[
  {&quot;name&quot;:&quot;paragraph.gap.visit.mom&quot;,&quot;time&quot;:100,&quot;size&quot;:20,&quot;weight&quot;:0.1,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.visit.memory&quot;,&quot;time&quot;:100,&quot;size&quot;:10,&quot;weight&quot;:0.01,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.quotes&quot;,&quot;time&quot;:70,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.mobydick.bible&quot;,&quot;time&quot;:10,&quot;size&quot;:10,&quot;weight&quot;:0.01,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.mobydick.melville&quot;,&quot;time&quot;:10,&quot;size&quot;:10,&quot;weight&quot;:0.1,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.mobydick&quot;,&quot;time&quot;:70,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph.gap.visit&quot;,&quot;time&quot;:200,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph.gap.blog&quot;,&quot;time&quot;:200,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph.gap&quot;,&quot;time&quot;:300,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph&quot;,&quot;time&quot;:350,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;&quot;,&quot;time&quot;:350,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]}
]
&lt;/pre&gt;

&lt;p&gt;I also made a &lt;a href=&quot;https://bl.ocks.org/stedn/5d187e873982e441e1f78d6d69af0030#bonkerfield_post.json&quot;&gt;similar document&lt;/a&gt; to render the other side of the bonkerfield visualization.&lt;/p&gt;

&lt;h5&gt;Coding the d3 vizualition&lt;/h5&gt;
&lt;p&gt;Starting from the &lt;a href=&quot;https://bl.ocks.org/mbostock/5672200&quot;&gt;example code&lt;/a&gt; that I found on &lt;a href=&quot;https://bl.ocks.org/mbostock&quot;&gt;bl.ocks.org&lt;/a&gt;, I started making tweaks to the code.  Most of them were fairly minor sizing issues and rotations of things.  The only thing that was really crucial was figuring out how to set the x-position using the &quot;time&quot; field from the document.  Without that, the layout would put everything on one vertical line, which doesn't quite work for me.&lt;/p&gt;

&lt;p&gt;The only crucial modification was to the node location, which required adding two bits of code.  The first was to modify the function that does the data load, in oder to transfer the data from the file into the &lt;code&gt;node&lt;/code&gt; object that d3 uses from rendering the nodes of the graph.&lt;/p&gt;

&lt;pre&gt;
function find(name, data) {
      var node = map[name], i;
      if (!node) {
        node = map[name] = data || {name: name, children: []};
        if (name.length) {
          node.parent = find(name.substring(0, i = name.lastIndexOf(&quot;.&quot;)));
          node.parent.children.push(node);
          node.key = name.substring(i + 1);
&gt;          if (data){
&gt;            node.time = data.time;
&gt;          }else{
&gt;            node.time = null;
&gt;          }

        }
&gt;      } else {
&gt;        if(!node.time){
&gt;          if (data){
&gt;            node.time = data.time
&gt;          }
&gt;        }
      }
      return node;
    }
&lt;/pre&gt;

&lt;p&gt;With that added, it's just necessary too use the &lt;code&gt;time&lt;/code&gt; attribute when rendering the node SVG and the link SVG.&lt;/p&gt;

&lt;pre&gt;
  ...
  var line_post = d3.svg.line()
    ...
    .x(function(d) {return d.time;})
  ...
  svg_post.selectAll(&quot;.node&quot;)
    ...
    .attr(&quot;transform&quot;, function(d) {return &quot;translate(&quot; + d.time + &quot;,&quot; + d.x + &quot;)&quot;;})
  ...
&lt;/pre&gt;

&lt;p&gt;For a little extra flair, I also wanted to make more widely dispersed data show up as a thicker line.  To do that, I just added duplicated paths with randomly jittered endpoints.  You can check the code if you want to see how I duplicated the paths, but for the random jitter I used a simple rough approximation of a normal distribution in x and y.&lt;/p&gt;

&lt;pre&gt;
function myrandom(){
  /* approximate a normal distribution (sort of) */
  /* using straight uniform makes everything look square */
  var r = 0;
  for(var i = 3; i &gt; 0; i --){
      r += Math.random();
  }
  return 1.25*(r/3 - 0.5)
}

var line_pre = d3.svg.line()
  ...
  .x(function(d) {return d.time+myrandom()*d.size;})
  .y(function(d) {return d.x+myrandom()*d.size; });
&lt;/pre&gt;

&lt;h5&gt;Styling&lt;/h5&gt;
&lt;p&gt;There's some additional styling that yu can check out in the code directly.  To make the opposite side of the identifield, I duplicated all the above, but inverted the x-axis by sutracting the x positions from width (eg &lt;code&gt;.x(function(d) {return width - d.time+myrandom()*d.size;})&lt;/code&gt;).  &lt;/p&gt;

&lt;h4&gt;The complicated graph&lt;/h4&gt;
&lt;p&gt;Since I didn't want to hand generate a really big graph, I used some python code to generate the structure for me. The function is really quite simple; it just randomly branches a tree with probability &lt;code&gt;child_prob&lt;/code&gt;, and then adds an arm to the tree that is also randomly chosen from &lt;code&gt;time_inc_rand&lt;/code&gt;. &lt;/p&gt;

&lt;pre&gt;
def add_node(node_list, parent_name, parent_time, parent_size, parent_weight):
    name = parent_name+'.'+''.join([random.choice(string.ascii_letters) for n in range(5)])
    imports = [center]
    time = parent_time - int(time_inc_min +  time_inc_rand * random.random())
    if time &lt; 50:
        return
    while random.random() &lt; child_prob:
        add_node(node_list, name, time, parent_size, parent_weight)
    while random.random() &lt; child_prob:
        node_list.append({&quot;name&quot;:name+'.'+''.join([random.choice(string.ascii_letters) for n in range(5)]),
                          &quot;time&quot;:time-5,
                          &quot;size&quot;:parent_size,
                          &quot;weight&quot;:parent_weight,
                          &quot;imports&quot;:[center]})
        imports = []
    node_list.append({&quot;name&quot;:name,&quot;time&quot;:time,&quot;size&quot;:parent_size,&quot;weight&quot;:parent_weight,&quot;imports&quot;:[]})

&lt;/pre&gt;


&lt;p&gt;However, the variety of output that it could generate by varying those parameters was astonishing to me.  This led me on another analytical meandering into the shapes that develop from hierarchies with random children, random edge lengths, and random leaf dispersions.  I've started a project with &lt;a href=&quot;https://github.com/lots-of-things/random-bonkerfield-generator&quot;&gt;the code&lt;/a&gt; to do the generation of the json objects with random parameters.  It's really fascinating, and I will add a link here when I finish exploring. &lt;/p&gt;


&lt;h4&gt;More To Do&lt;/h4&gt;
&lt;p&gt;There's still much more to do to make the identifield concept clearer.  You can fork the code to render identifields from either the &lt;a href=&quot;https://bl.ocks.org/stedn/5d187e873982e441e1f78d6d69af0030&quot;&gt;simple&lt;/a&gt; or the &lt;a href=&quot;https://bl.ocks.org/stedn/33fd840f81627ec0967448fbc832ed9f&quot;&gt;complex&lt;/a&gt; bl.ocks, and the code for generating the json objects is on &lt;a href=&quot;https://github.com/lots-of-things/random-bonkerfield-generator&quot;&gt;github&lt;/a&gt;. If someone out there likes this idea and would like to take it further, please feel free.  Let me know what you come up with. &lt;/p&gt;
</description>
        <pubDate>Tue, 28 Jan 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/01/visualizing-the-bonkerfield/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/01/visualizing-the-bonkerfield/</guid>
        
        <category>philosophy</category>
        
        <category>art</category>
        
        <category>identifield</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/qmb_proto.jpg</image>
        <title>QMB Prototype Demo</title>
        <description>&lt;p&gt;Lately, I've been having &lt;a href=&quot;2019/10/23/qmb-installation/&quot;&gt;too much fun&lt;/a&gt;, working on &lt;a href=&quot;2019/10/17/quantum-multiverse-bifurcator/&quot;&gt;quantum randomness generators&lt;/a&gt;.  One of my goals is to build a minimalist device for producing a quantum binary outcome.  I've designed one simple and cost-effective circuit that I think will fit the bill.  Check out the video to see how it works.&lt;/p&gt;

&lt;iframe class=&quot;flexme&quot; width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/0-vfWDAkc1g&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
	The device works by measuring quantum fluctuations in the amount of light hitting two detectors. I have a &lt;a href=&quot;2019/10/18/quantum-coin-flip-device/&quot;&gt;previous post&lt;/a&gt; with details on a similar circuit that I'd built a few months ago, but the main modification for this iteration was to add the enclosement and the aperture.
&lt;/p&gt;

&lt;img title=&quot;Quantum Multiverse Bifurcator prototype&quot; src=&quot;/assets/images/2020/qmb_proto.jpg&quot; alt=&quot;Quantum Multiverse Bifurcator prototype&quot;/&gt;


&lt;p&gt;
	The aperture itself is based on &lt;a href=&quot;https://www.instructables.com/id/Cardboard-Aperture-v2/&quot;&gt;this instructable&lt;/a&gt;, though there were definitely issues with that design.  I made an adjustment to have the interior disc's slots a little wider and then I mounted that into the tp of the box.
&lt;/p&gt;

&lt;img title=&quot;Quantum Multiverse Bifurcator prototype&quot; src=&quot;/assets/images/2020/qmb_proto_open.jpg&quot; alt=&quot;Quantum Multiverse Bifurcator prototype&quot;/&gt;

&lt;p&gt;
	The reason I had to build something to limit the incoming light was that in the open version, the light source was too dificult to stabilize.  With this version I could more carefully place the light source and adjust the aperture width to get a roughly 50-50 split between red and blue lighting up.
&lt;/p&gt;

&lt;p&gt;
	I'm still concerned that this implementation isn't fully quantum though because of noise in the circuit and variation in lighting due to movement.  If you have an idea about how to fix these issues or if you see other problems I haven't thought of, please &lt;a href=&quot;https://will.stedden.org&quot;&gt;send me a message&lt;/a&gt;.
&lt;/p&gt;

</description>
        <pubDate>Mon, 20 Jan 2020 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2020/01/qmb-prototype-demo/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2020/01/qmb-prototype-demo/</guid>
        
        <category>physics</category>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>Short Post on Short Showers</title>
        <description>&lt;p&gt;
    I finally was able to reduce my flying this year to just two flights to visit family for the holidays. My partner still points out that I take long showers so I should get off my high horse. I've decided to fix that.
&lt;/p&gt;
&lt;h4&gt;A little math&lt;/h4&gt;
&lt;p&gt;
    I found &lt;a href=&quot;http://greenblizzard.com/2016/05/09/showers-and-co2/&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://theecoguide.org/have-you-tried-five-minute-shower-challenge&quot;&gt;calculations&lt;/a&gt; of the amount of carbon dioxide produced by a shower. This varies by energy source so I tried a quick calculation for my own residence.
&lt;/p&gt;
&lt;p&gt;
    Assuming 2.5 gallons/minute of shower, and that I'm heating the water by about 60 degrees, we can use &lt;a href=&quot;https://www.e-education.psu.edu/egee102/node/2003&quot;&gt;this equation&lt;/a&gt; to calculate the power needed.
&lt;/p&gt;
&lt;blockquote&gt;2.5 gallon/minute x 8 lbs/gallon x 1 BTU/lbºF x 60ºF = &lt;strong&gt;1200 BTU/minute&lt;/strong&gt; &lt;/blockquote&gt;
&lt;p&gt;
    I heat it using electricity,and it seems that electric water heaters are generally considered to be around &lt;a href=&quot;https://smarterhouse.org/water-heating/replacing-your-water-heater&quot;&gt;90% efficient&lt;/a&gt;. So I'm actually using 1200/0.9 = &lt;strong&gt;1333 BTU/minute&lt;/strong&gt;.
&lt;/p&gt;
&lt;p&gt;
    California's PG&amp;amp;E power mix says it is only &lt;a href=&quot;https://www.pge.com/pge_global/common/pdfs/your-account/your-bill/understand-your-bill/bill-inserts/2019/1019-Power-Content-Label.pdf&quot;&gt;15% fossil fuel&lt;/a&gt; (probably mostly natural gas). According to the US EIA, natural gas releases &lt;a href=&quot;https://www.eia.gov/electricity/annual/html/epa_a_03.html&quot;&gt;~50 kg of CO2 for every million BTU&lt;/a&gt; or equivalently 0.05 g/BTU. So at this point it seems every minute of shower is 1333 BTU/minute * 0.15 * 0.05 gCO2/BTU = &lt;strong&gt;9 gCO2/minute&lt;/strong&gt;.
&lt;/p&gt;
&lt;p&gt;
    For perspective, I used &lt;a href=&quot;https://calculator.carbonfootprint.com/calculator.aspx?tab=3&quot;&gt;this online flight carbon calculator&lt;/a&gt; to calculate that I released 0.29 metric tons of carbon (or 290000 grams) to visit my family in Tuscon this Thanksgiving. So that one trip was equivalent to showering for 22 days straight.
&lt;/p&gt;
&lt;h4&gt;Shortening my showers&lt;/h4&gt;
&lt;p&gt;
    So showers are a drop in the bucket (pun intended) compared to flights, but I still figured I could make a change. I take about a 12 minute shower every day. I figured I could drop that to 2 minutes if I try. That 10 minutes would save 90 grams of CO2 a day, and if I could keep it up for a year, that'd be about 32kg. That's equivalent to an 80 mile car ride. But no one will ride in the car with me because I'd be smelly.
&lt;/p&gt;
&lt;p&gt;
    Anyway, I'll be setting a timer to try to get down to 2 minutes by January 1, and after I'll see if I can go the whole year. Please leave a comment if you see something off in my calculations.
&lt;/p&gt;

&lt;p&gt;
	&lt;em&gt;Update: I forgot that part of the reason for showering was to actually get clean.  As it turns out, after a month of showering for 2 minutes I started to get a little gross.  So I'm moderating my usage, but no longer limiting to 2 minutes.  Oh well, worth it while it lasted.&lt;/em&gt;
&lt;/p&gt;</description>
        <pubDate>Sat, 07 Dec 2019 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2019/12/short-post-on-short-showers/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/12/short-post-on-short-showers/</guid>
        
        <category>energy</category>
        
        <category>analysis</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2020/qmb_isntallation.jpg</image>
        <title>Quantum Multiverse Bifurcator Installation</title>
        <description>&lt;p&gt;
    For the past few months, I've been working on a series of &lt;a href=&quot;/2019/10/quantum-multiverse-bifurcator.html&quot;&gt;interconnected&lt;/a&gt; &lt;a href=&quot;/2019/10/quantum-coin-flip-device.html&quot;&gt;projects&lt;/a&gt; and &lt;a href=&quot;/2019/10/sub-identity-suicide.html&quot;&gt;thought experiments&lt;/a&gt; centered around the concept of the &lt;a href=&quot;https://science.howstuffworks.com/science-vs-myth/everyday-myths/parallel-universe2.htm&quot;&gt;quantum multiverse&lt;/a&gt;, a theoretical interpretation of quantum mechanics that implies that many parallel universes are created by the outcomes of every quantum mechanical measurement. It's a fairly trippy concept, and I'm pretty sure that my interest in it is making me go a little crazy. Still, I think this concept is cool enough that I want to share it with as many people as possible. To do that, I've decided to expand the &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;experimental system&lt;/a&gt; into a full-scale art experience.
&lt;/p&gt;

&lt;h4&gt;Concept&lt;/h4&gt;
&lt;p&gt;
    The concept of the Quantum Multiverse Bifurcator comes from the familiar sci-fi trope of alternate parallel universes. Often in these stories, people find that a random event has split reality into two divergent timelines. As it turns out, there is a real scientific interpretation of quantum mechanics, called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Many-worlds_interpretation&quot;&gt;Many Worlds Interpretation&lt;/a&gt; that seems to imply this sci-fi concept could be &lt;a href=&quot;https://www.newscientist.com/round-up/reality/&quot;&gt;real&lt;/a&gt;.
&lt;/p&gt;
&lt;h6&gt;The Catch&lt;/h6&gt;
&lt;p&gt;
    But there is a catch. The only thing that actually splits the universe is the outcome of a quantum mechanical event. Most random events in our lives are probably &lt;a href=&quot;https://www.quantamagazine.org/how-randomness-can-arise-from-determinism-20191014/&quot;&gt;classically random&lt;/a&gt;, meaning they are &lt;a href=&quot;https://en.wikipedia.org/wiki/Deterministic_system&quot;&gt;deterministic&lt;/a&gt;, but we simply lack the ability to predict them. As far as we know, quantum mechanical randomness is different—quantum events can't be predicted even with perfect information.
&lt;/p&gt;
&lt;h6&gt;The Solution&lt;/h6&gt;
&lt;p&gt;
    But there is a way to actively generate parallel universes in a manner in line with the scientific understanding of the multiverse. We can couple the big decisions that would split the universe with the random outcomes of quantum mechanical events. In short, we can &lt;strong&gt;&lt;a href=&quot;https://aeon.co/ideas/what-einstein-meant-by-god-does-not-play-dice&quot;&gt;play dice with the universe&lt;/a&gt;&lt;/strong&gt;. To accomplish this feat, I built an application called the &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;Quantum Mulltiverse Bifurcator&lt;/a&gt;, which pulls a real quantum mechanical measurement to tell a human what decision to make. If the human follows their instructions, according to the many worlds interpretation, two universes are made, one in which each option occurs.
&lt;/p&gt;
&lt;p&gt;
    My partner and I decided to build an installation to present the &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;Quantum Multiverse Bifurcator (QMB)&lt;/a&gt; and allow people to interact with it. We decided to bring our installation to Burning Man's &lt;a href=&quot;https://burningman.org/events/san-francisco-decompression-2019-black-top-city/&quot;&gt;SF Decompression party&lt;/a&gt;. It's fitting that we brought this to Decompression because the idea for the QMB was inspired by Burning Man itself. When I went to Black Rock City for the first time in 2019, I realized the perfect gift to the Playa would be a way to let all participants do &lt;a href=&quot;https://twitter.com/burningman/status/1031560236845412352?lang=en&quot;&gt;everything they want&lt;/a&gt;. But with so much going on there, the only way to do everything is to split the universe.
&lt;/p&gt;
&lt;h4&gt;Installation Build&lt;/h4&gt;
&lt;p&gt;
    It was kind of tough to figure out how to present the QMB as an art project. The device I came up with was linking the abstract idea of inhabiting two different universes to a concrete example of inhabiting two different spaces. More specifically, my partner and I decorated the shit out of a pair of camping tents.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-eVo8iGkRSYI/XbNDdXy_49I/AAAAAAAAE7c/H3eDEEnr1Xg4TZgAPlThZpm2m_oYn2mhwCKgBGAsYHg/s1600/IMG_20191018_214146.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    So conceptually, the art would be interacted with by using the quantum measurement to determine which tent you went to hang out in. My partner decorated the interiors of the tents and added a logbook for people to describe their contemplation on the Multiverse.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Xljhi_D3-78/XbkMSo3xLhI/AAAAAAAAFAA/5qgDHy7Tq90ShiXoONTyPBjFNYyl3SGAwCKgBGAsYHg/s1600/IMG_20191013_170949.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    To add to the experience, we wanted to disguise the fact that it was just a computer and some tents. I'd been collecting bike tubes for the past year to put toward another sculpture. We just cut them up and hung them on a rack that we found on the street the week before the event.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Q9qKT1VR6O4/XbkMgZVK3JI/AAAAAAAAFAE/ADPkBAPIlUoGDtcGHMz6WK9oLYmJNQWLgCKgBGAsYHg/s1600/IMG_20191013_091005.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We also added a mirror off to the side between the tents. This causes you to see yourself climb into the mirror on the other side out of the corner of your eye, which makes for a pretty cool experience when you crawl through.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-EssV93pNt0k/XbNg6sJIDXI/AAAAAAAAE88/oih3Yv_u5U0NxU5OOzBKogCPzBqYqMg3wCKgBGAsYHg/s800/IMG_20191019_150200.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Claire assembled a bunch of random parts to make the terminal look amazingly sciency (and less like two IKEA tables stacked on top of each other). We'd found a bunch of copper wire on the street back in Oakland. In a &lt;a href=&quot;https://www.youtube.com/watch?v=j7szkheaqCY&quot;&gt;previous project&lt;/a&gt;, I'd been playing with some &lt;a href=&quot;https://www.3dhubs.com/knowledge-base/pla-vs-abs-whats-difference/&quot;&gt;PLA filament&lt;/a&gt; that I'd used to hand mold a cool little ball.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-bQy4lGhfGMs/XbNJj3CPvFI/AAAAAAAAE7w/tK-jWmPFdEECftzzYUXxWaTJY42iQfjvACKgBGAsYHg/s800/IMG_20191015_233346.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    When we were on site, we realized we wanted to connect the terminal and the tent structure together to make it look like one big machine. We connected them using more bike tubes, and used them to ensconce the laptop to make it look less lame.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-LKHQ-vu3Pk0/XbNKi4zGHSI/AAAAAAAAE78/fHTl8kLa82c_UFC6wBYomVMLdYueqCxpgCKgBGAsYHg/s800/IMG_20191019_135310.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The full effect was pretty neat, and very Burning Man. We got a lot of comments from the folks on MDMA that they loved the textures of our installation.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-nKU0TBudA4g/XbNbi2oJ_RI/AAAAAAAAE8o/vbbdFPX8FH8sbkWlXmWmzDvDMEz0YNCTACKgBGAsYHg/s1600/IMG_20191019_121853.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The project looked even cooler at night because we connected red and blue LEDs to distinguish the two &quot;paths&quot; that the Bifurcator could point you on.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-xnh2rKire-Q/XbNbpcXxiQI/AAAAAAAAE8s/4YkiDD2E3UgsvW10NAJAlP62OANEMgjhACLcBGAsYHQ/s1600/IMG_0008.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The machine inside also looked extra cool then too.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-7D0F8O-XIls/XbNhwj5foDI/AAAAAAAAE9Q/Tl33XTYIjNEJEK8H82EH_5y9sqCdMRcCwCLcBGAsYHQ/s800/IMG_0006.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This installation was honestly the most fun thing I've ever built. My partner and I basically went through our whole house converting every miscellaneous item into something that could look vaguely sciency. But the best part of the build was getting to share it with the Burners at Decompression.
&lt;/p&gt;
&lt;h4&gt;Interactivity and Reception&lt;/h4&gt;
&lt;p&gt;
    The whole point of the Bifurcator was to help us realize that our instantaneous actions aren't so very dire as we always think. I wanted participants to take a minute out of their busy partying to play with us in a glorified blanket fort. When the gates opened, lots of people started streaming past our camp. It was so cool to see people look at our weird little site. I could tell that they were curious to come over, intrigued by what they would find. But everyone's natural reaction is to pass by. I wasn't sure how to get people too engage with it until I came up with a cool catch-phrase that I could shout to the crowd to draw them in.
&lt;/p&gt;
&lt;blockquote&gt;Want to play dice with the mother fucking universe?&lt;/blockquote&gt;
&lt;p&gt;
    I never could have imagined the feeling I would get from asking this question to strangers. The people of burning man ate this proposition up with relish. We had some amazing universe bifurcations take place. One person decided whether she should get married. Another person decided whether he should change the focus of his medical residency. Many people didn't want to share what they were deciding on, which is actually amazing. It meant that they were really taking it seriously. Even if this doesn't really determine exactly what they end up doing, it felt really good to pose the possibility that their choice really wasn't so monumental after all. That there could be a parallel universe that defuses their worries about what could have been.
&lt;/p&gt;
&lt;p&gt;
    I'm really grateful that Claire added logbooks to the tents so people could share their reflections. Most of them were pretty whimsical, but many people seemed to reach some profound personal insights. I'm honestly very proud to have offered them this experience.
&lt;/p&gt;
&lt;h6&gt;Personal Reflections&lt;/h6&gt;
&lt;p&gt;
    This was my first experience bringing something fun like this to a wild, excited audience. This has caused me to reflect on the many paths my life could have taken up to here. I've loved to create, but I've always been afraid to share in a direct way. It's felt so forceful to demand people's attention, and I've preferred to just make things quietly with little advertisement. The Bifurcator is helping me realize that asking people to notice me isn't really such a burden to them, and that's allowing me to open up and send my creations out into the world more.
&lt;/p&gt;
&lt;p&gt;
    I've also been thinking about the philosophy behind the piece. It's not just about the fun or mystery of multiple parallel universes. I think it also speaks to the way scientific concepts are fundamentally highly philosophical in a way that we seem to ignore these days. These ideas can and should shape our understanding of our place in reality. It feels like as a culture we are compartmentalizing ideas and forgetting that science, art and and philosophy were really born from the same place. I think this can lead to a temptation to divorce ourselves from science, particularly in artistic communities, because science seems to try to belittle human experience. But I think that is just a superficial reading of the mundane parts of science, the parts of science that are commoditized, just like the parts of art that have been commoditized. &lt;p&gt;
        When I ponder trippy scientific concepts, I feel more presence of mind about what my human experience actually means. Is what I feel just a sliver of what holds together the reality I pass through? If we expand our feelings to include everything that every measuring device can understand, do we see a fuller world than we could have imagined? I feel like studying science and information theory has actually made me feel more like a branching, amorphous blob of thoughts, decisions, desires, and that all those immaterial patterns aren't solitary. They are stitched in with the rest of everything else in this twisted pocket of the Multiverse.
    &lt;/p&gt;
&lt;h4&gt;What's next?&lt;/h4&gt;
&lt;p&gt;
        The reaction has fueled our desire to bring this to &lt;a href=&quot;https://burningman.org/countdown/&quot;&gt;Black Rock City&lt;/a&gt; in 2020. By some astonishing &lt;a href=&quot;https://www.psychologytoday.com/us/blog/connecting-coincidence/201804/how-do-physics-and-the-multiverse-explain-coincidences&quot;&gt;coincidence&lt;/a&gt; the &lt;a href=&quot;https://journal.burningman.org/2019/10/news/brc-news/burning-man-2020-the-multiverse/&quot;&gt;theme next year&lt;/a&gt; is actually the Multiverse so it seems like the perfect time for us to build it. I've started building a miniature model of how I want to expand the installation.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-zceKIcq5uJk/XbXxhW6vT4I/AAAAAAAAKSg/EmZEhSe2Zg4Yr0soPWPsp6xi8-6p9kD6gCLcBGAsYHQ/s1600/IMG_0019.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In the next iteration, I want to focus on expanding the tents in the back to include a few more chambers that twist around and sometimes lead to dead ends. We'll expand out the front as well, to have a real quantum experimental system inside.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-BSD4BVkGLQM/XbXxynK3IRI/AAAAAAAAKSo/70glSif5MIAOsAzS9EU6AAvYOpIr6FpAwCLcBGAsYHQ/s800/IMG_0021.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Inside the different chambers, there will be a variety of different interactions. Thus far, I'm planning on a projection of the double slit experiment, and some mirrors that produce a ghostly image of yourself in the other side of the multiverse. I also plan to leave in the logbooks so people can write their thoughts on their experience in the Multiverse.
    &lt;/p&gt;
&lt;p&gt;
        To take this to the Playa will end up being a pretty major investment so I'm also writing a letter of intent for a Burning Man grant. To make things interesting, I think I'll use the QMB to decide whether I should submit it.
    &lt;/p&gt;&lt;/p&gt;</description>
        <pubDate>Wed, 23 Oct 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/10/qmb-installation/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/10/qmb-installation/</guid>
        
        <category>art</category>
        
        <category>games</category>
        
        <category>physics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-jLqU2ZJvQT4/XZwXHM77bLI/AAAAAAAAEuk/AlHkKXE1mokWjYHLQUEt0iHaFcdRKmG3ACKgBGAsYHg/IMG_20190915_143649.jpg</image>
        <title>Green Wall Irrigation</title>
        <description>&lt;p&gt;
    Last winter, my friend and I set out to build a sort of &quot;&lt;a href=&quot;/2019/03/redwood-planter-cabinet.html&quot;&gt;green wall&lt;/a&gt;&quot; in his back yard. It was a very fun project, and the building and planting turned out to be quite easy.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-h6JWzOSa8yc/XHoF7d4_j5I/AAAAAAAADdE/vHgbbOi9RLk2qYiviC0rM0CSGBXocItgACPcBGAYYCw/s800/20181210_083237.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    What turned out to be harder was getting my very busy friend to keep his garden watered. By the end of this summer, everything was dead.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-QCVL0ySKZi0/XZwKLw0bOgI/AAAAAAAAEuY/_Ugg_AsUj340MLMn_FDaz-QFEJZsSyb1QCKgBGAsYHg/s1600/IMG_20190915_121800.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Since I knew my friend wouldn't be able to stop traveling for work, I decided the only way to make last year's project a success was to add a custom multilevel sprinkler system.
&lt;/p&gt;
&lt;h4&gt;Construction&lt;/h4&gt;
&lt;h6&gt;Hose&lt;/h6&gt;
&lt;p&gt;
    We used drip irrigation hose, which works by letting the water soak out through a porous hose material. When I was younger this same task was normally accomplished using a cheap hose with holes poked into it every foot or so. But times change, and technology improves. I think the logic is that the drip irrigation would then give a more uniform distribution of water.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-WPkGBAL_T0s/XZwXHHyVXMI/AAAAAAAAEuk/25GqtTlaB9kmch5rqS-Q7TMdhmyALIsIwCKgBGAsYHg/s1600/IMG_20190915_143742.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The problem though is that with the drip irrigation you don't have the ability to set just how porous you want your hose to be. In almost all cases I'd bet that the drip irrigation is probably optimally set up to maintain a great flow.
&lt;/p&gt;
&lt;p&gt;
    But we happened to be working in one of those cases where gravity works against you. In our original plan we ran the drip hose straight first at ground level and then snaked it up to end at the top. Unfortunately, this meant that there was higher pressure right at the beginning, which caused all of the water to shoot out before it could get to the top.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-cISCtBOJTmU/XZwXHCPoTII/AAAAAAAAEuk/r9h8QH5TmSANEXHCJmWLl6zHN_vN6sZdwCKgBGAsYHg/s1600/IMG_20190915_143751.jpg&quot; title=&quot;
bottom (gusher)
middle (ok)
top (bone dry)
 &quot;/&gt;
&lt;p&gt;
    The solution was to add a segment of solid hose that first ran to the top of the planter before running back down. With this setup, there was enough time for the water at the top to seep out before it went to lower levels.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-fxaqCnOKa48/XZwXHOGXX4I/AAAAAAAAEuk/gZUYUMTYl8kkOk0CLkPt00ArlUYFo0MCQCKgBGAsYHg/s800/IMG_20190915_151211.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-IQ0LKZ8xD3g/XZwXHBUBajI/AAAAAAAAEuk/oJnZ-2qPcuAmMfpqGI0dzXijcRwbMRCAwCKgBGAsYHg/s1600/IMG_20190915_151253.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We ran the hoses around on the backside and did our best to just tuck them right around the corner, running them low enough that they could be buried with dirt.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-9jbP21BRWeQ/XZwXHOJ9VkI/AAAAAAAAEuk/-arJKaGo58gJgIx8C4b36gjzxQ5RDVX7QCKgBGAsYHg/s800/IMG_20190915_151309.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-vmTydgK8H2w/XZwXHC-3FMI/AAAAAAAAEuk/wPuuCItgpFUidrrz-G41d_Oi1nMtOHG6gCKgBGAsYHg/s1600/IMG_20190915_151405.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Almost not noticeable once its buried.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-v6myJuJpqnI/XZwXHMq4oSI/AAAAAAAAEuk/tP7B0LKu_LgdR1G-SRwL3N70uySKP4i_ACKgBGAsYHg/s1600/IMG_20190915_153120.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Our project was very small so we had a lot of excess hose left over. I just tied off a knot at the end to kink the hose. That way we can extend the project some time in the future.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-BTlAOnOQrRQ/XZwXHEcHAzI/AAAAAAAAEuk/bGqw9m7pTiwZsIDGK_F485DlPcfsa9aqACKgBGAsYHg/s1600/IMG_20190915_151509.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-1n78gLL3zdo/XZwXHOo3JlI/AAAAAAAAEuk/cZnYTsrhptIBCwxKNs3a_09QuZ7URlbrQCKgBGAsYHg/s1600/IMG_20190915_151709.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    From the front, the irrigation system isn't too obvious when it isn't running. We threw a few test plants in that day, but I missed getting a picture of them. I'll just have to wait to go back and get a &quot;results&quot; pic later.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-gqUbDBkDFvE/XZwXHNkHF-I/AAAAAAAAEuk/aBYuL5e-xSIM5Bs8wloQca-Y5QPHdqkHgCKgBGAsYHg/s1600/IMG_20190915_151204.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally, the most important part is getting an automated irrigation timer. This brand was kind of confusing to use, but it was the cheapest one at the store and we didn't have time to comparison shop.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/--7jJRBRuaX8/XZwXHG_5Q_I/AAAAAAAAEuk/2NpuZP89NQgBe2E1ahukhZ_CICVZ8n4kQCKgBGAsYHg/s1600/IMG_20190915_154924.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Results&lt;/h4&gt;
&lt;p&gt;
    I'll update here when I can get a photo of how the plants look after a few months of automate irrigation. My friend has been out of town for multiple weeks already so this will be a good test.
&lt;/p&gt;</description>
        <pubDate>Sun, 20 Oct 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/10/green-wall-irrigation/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/10/green-wall-irrigation/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-2t52RMTXdAU/XaopNS-HFaI/AAAAAAAAE2Q/ekmM-lhYz4sUgY3ZhB_2a41jkuDFOKU0ACLcBGAsYHQ/circuit-20191018-0928.png</image>
        <title>Quantum Coin Flip Device</title>
        <description>&lt;p&gt;
    Over the past few months, I've been working on building tools to connect human decisions with the outcomes of quantum measurements. The goal is to allow people to let their decisions be chosen using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Many-worlds_interpretation&quot;&gt;many-worlds interpretation&lt;/a&gt; of quantum mechanics, which will end up creating parallel realities where all outcomes occur. You can read &lt;a href=&quot;/2019/10/quantum-multiverse-bifurcator.html&quot;&gt;this post&lt;/a&gt; to learn more about the idea and how I built a web-based &lt;a href=&quot;https://quantum-multiverse-bifurcator.appspot.com&quot;&gt;Quantum Multiverse Bifurcator&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    The main drawback of my webapp is that it relies on being connected to the internet to request a quantum measurement from &lt;a href=&quot;https://qrng.anu.edu.au&quot;&gt;an experiment&lt;/a&gt; being run by this &lt;a href=&quot;https://www.cqc2t.org&quot;&gt;quantum computation research group&lt;/a&gt; in Australia. Ideally, I'd like to be able to make such a quantum measurement myself to make it more accessible wherever &lt;a href=&quot;https://journal.burningman.org/2019/10/philosophical-center/the-theme/burning-man-2020-the-multiverse/&quot;&gt;I go&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    There are &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_random_number_generator#Quantum_random_properties&quot;&gt;many examples&lt;/a&gt; of various quantum measurement devices on the web, but most of them are more sophisticated and would be fairly expensive to build. All I need is a device that can make a simple binary measurement from the outcome of a quantum event. So I set about trying to design something cheap and simple that still maintains true quantum randomness.
&lt;/p&gt;
&lt;h4&gt;Concept&lt;/h4&gt;
&lt;p&gt;
    The simplest kind of quantum measurement is probably &lt;a href=&quot;https://www.rp-photonics.com/shot_noise.html&quot;&gt;shot noise&lt;/a&gt;, or the variability in the number of photons detected when measuring light with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Photodetector&quot;&gt;photodetector&lt;/a&gt;. A photodetector is just any device that absorbs light and converts the light it absorbs into an electrical signal. Photodetectors are used in a bunch of things, like if you've ever seen a nightlight that only turns on when its dark, or if you've ever seen your phone/computer automatically adjust its brightness.
&lt;/p&gt;
&lt;p&gt;
    The reason that this is a quantum measurement is that the light field that is being absorbed exhibits quantum fluctuations, which cause the number of photons present to vary. Therefore, the exact amount of electricity generated by the photodetector is also varying slightly even if the average amount of light stays the same. To detect the quantum effect one needs to observe the variability in the electrical signal of the photodetector.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, measuring the exact electrical signal with the kind of sensitivity needed to pick up on the quantum signals normally takes a pretty sophisticated device. That would be costly and make this measurement device a little impractical. So I wanted to simplify the machinery needed to make this measurement.
&lt;/p&gt;
&lt;p&gt;
    Given that I only really need to generate a &lt;a href=&quot;https://www.lexico.com/en/definition/binary&quot;&gt;binary&lt;/a&gt; outcome (a coin flip), I knew that I could get away with a circuit that just goes on when the measurement is beyond some threshold. The catch is that its a little bit difficult to calibrate exactly where the cutoff should be. In addition, it's possible that the source of the variability could be non-quantum if the device isn't set up properly. There are many other sources of apparent randomness that don't come from quantum mechanics and I wanted to make sure to isolate my system from those.
&lt;/p&gt;
&lt;p&gt;
    To alleviate these issues, the design I chose actually creates two quantum measurements of the shot noise from two photodetectors. It then compares the signal from each measurement at a specific point in time and either turns on or off an LED depending on which measurement is greater. This allows for the circuit to really only use 4 components while still transmitting a quantum signal to a binary outcome.
&lt;/p&gt;
&lt;p&gt;
    The last important thing is that you need to be able to control for the variation in the electrical components of the circuit, which could affect the measurement but are non-quantum. To control for this, I can calibrate the amount of light hitting each photodetector to make the measurement go either way with almost exactly 50% probability. And the amount of light can be lowered further and further to turn down the contribution of classical effects on the randomness.
&lt;/p&gt;
&lt;p&gt;
    With this basic concept, the only thing left to do was to try to build it.
&lt;/p&gt;
&lt;h4&gt;Circuit&lt;/h4&gt;
&lt;p&gt;
    After asking both &lt;a href=&quot;https://physics.stackexchange.com/questions/488133/how-to-build-a-circuit-that-generates-a-quantum-coin-flip&quot;&gt;physics&lt;/a&gt; and &lt;a href=&quot;https://electronics.stackexchange.com/questions/445338/circuit-to-randomly-light-one-led-or-another/447272&quot;&gt;electronics&lt;/a&gt; stack exchanges with little results, I came up with the following circuit
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-2t52RMTXdAU/XaopNS-HFaI/AAAAAAAAE2Q/ekmM-lhYz4sUgY3ZhB_2a41jkuDFOKU0ACLcBGAsYHQ/s1600/circuit-20191018-0928.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    To view the circuit in simulation go &lt;a href=&quot;https://www.falstad.com/circuit/circuitjs.html?cct=$%201%200.000005%2010.634267539816555%2050%205%2050%0Aa%20256%20240%20336%20240%208%205%200%201000000%200.7831537737346073%200.7001096127683933%20100000%0AR%20176%20128%20144%20128%200%200%2040%205%200%200%200.5%0At%20144%20192%20176%20192%200%201%20-4.336216318433491%20-0.11937009216809913%20100%0At%20160%20272%20192%20272%200%201%20-4.419260479399706%20-0.11937009216809924%20100%0Aw%20176%20208%20256%20224%200%0Aw%20240%20128%20176%20176%200%0Aw%20240%20128%20240%20240%200%0AR%20144%20192%20128%20192%200%206%2040%200.5%200.5%200%200.5%0AR%20160%20272%20128%20272%200%206%2040%200.5%200.5%200%200.5%0Aw%20192%20288%20256%20256%200%0As%20240%20128%20336%20128%200%201%20false%0Aw%20192%20256%20240%20240%200%0A155%20336%20240%20400%20176%200%205%0Aw%20336%20128%20336%20272%200%0Aw%20240%20128%20176%20128%200%0A162%20432%20240%20512%20240%202%20default-led%201%200%200%200.01%0A162%20432%20304%20480%20304%202%20default-led%201%200%200%200.01%0Aw%20512%20240%20512%20304%200%0Ar%20512%20304%20512%20352%200%20100%0Ag%20512%20352%20512%20368%200%0Ag%20480%20352%20480%20368%200%0Ar%20480%20352%20480%20304%200%20100%0Ax%20120%20316%20336%20319%204%2012%20%5Enoise%5Csto%5Cstransistors%5Cs%5Cq%5Csphotodiodes%0A&quot;&gt;here&lt;/a&gt;. On the simulation site each time you close the switch one of the LEDs should light randomly. Below I will walk through each of the subcomponents in a little more detail.
&lt;/p&gt;
&lt;h6&gt;Step 1. Generate slightly varying voltages from two photodiodes&lt;/h6&gt;
&lt;p&gt;
    The first step is to make a very simple photodetectors using &lt;a href=&quot;https://www.rp-photonics.com/photodiodes.html&quot;&gt;photodiodes&lt;/a&gt;. The photodiodes act like little dams that prevent the flow of electricity (called &lt;a href=&quot;https://en.wikipedia.org/wiki/Electric_current&quot;&gt;current&lt;/a&gt;), but which let more electricity through when light is shined on them.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://www.electrical4u.com/images/2018/november18/characteristics-of-photodiode.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    In the circuit, I connect the photodiode to a between the plus and minus ends of the battery with a resistor after it. This causes there to be a voltage across the resistor, which then fluctuates as the light hitting the photodiode varies. At low enough light, the variation is mostly quantum mechanical in nature.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-vrjicbdG99Y/XaotTVs0WGI/AAAAAAAAE2c/2IiRoRS7Dt4Byzgx1EAgbKr7U9RWYIXrQCLcBGAsYHQ/s800/0b07d078681096482698fbe614ec5890.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    One important point is that there can also be classical noise in this type of circuit, largely due to thermal noise changing the resistivity of the resistor. To overcome this, I got a tip from a physicist friend of mine to use a very large resistor. This should ensure that the thermal variation is small relative to the variation from the quantum effects in the photodiode.
&lt;/p&gt;
&lt;p&gt;
&lt;small&gt;*Note: When I built the circuit simulation on &lt;a href=&quot;http://falstad.com/circuit/circuitjs.html&quot;&gt;falstad's circuit simulator&lt;/a&gt;, I wasn't able to put in a photodiode directly. Instead, I mocked those components using a transistor and random noise source. The rest of the simulation circuit looks like the real prototype though.&lt;/small&gt;
&lt;/p&gt;
&lt;h6&gt;Step 2. Comparing the photodetectors&lt;/h6&gt;
&lt;p&gt;
    The next part of the circuit performs an amplification of the signal difference between the two photodetectors. This is accomplished using an &lt;a href=&quot;https://www.electronics-tutorials.ws/opamp/op-amp-comparator.html&quot;&gt;op-amp comparator&lt;/a&gt;. The comparator is a widely available circuit that works to
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-MNRTKWnK8NY/Xaova_ksN-I/AAAAAAAAE2o/HjwEiXOWY6kYOUlyls_xolP-FtT2zHIfwCLcBGAsYHQ/s1600/opamp-opamp103.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    So whenever the first photodiode's voltage is just slightly higher than the second one's voltage, the output of the comparator is high (+3 volts in my circuit). And whenever the second signal is higher the voltage goes low (0V in my circuit). This signal is varying all the time though as the two detectors vary back and forth. So to persist the measurement we need one more component.
&lt;/p&gt;
&lt;h6&gt;The D-Latch (flip-flop)&lt;/h6&gt;
&lt;p&gt;
    Given a time varying voltage, we need a way to detect whether the voltage is high or low at one instant and then persist that value for a long period of time. There are a number of ways to do this, but one of the simplest is with a &quot;&lt;a href=&quot;https://en.wikibooks.org/wiki/Digital_Circuits/Latches&quot;&gt;latch&lt;/a&gt;&quot; circuit. There are many kinds of latches, but they all take an input and then hold an output value until the circuit is reset.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-mz99UoGkeYc/Xao3fsIh0eI/AAAAAAAAE3A/ovfkl2lejd8OjD58kuJYPqRujPXBuCzzgCLcBGAsYHQ/s1600/dtype01.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I used a &lt;a href=&quot;https://en.wikipedia.org/wiki/Flip-flop_(electronics)#Gated_D_latch&quot;&gt;D-Latch&lt;/a&gt;, which takes an input signal and stores it at the moment a &quot;trigger&quot; input is pushed. Then the D-Latch holds that value and outputs it until the trigger is pushed again. The output is referred to as Q in the diagram. In addition, most D-Latches also output the opposite of Q (called Q') at the same time.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-ZoMUSnQDGR8/XaoxiLzKdoI/AAAAAAAAE20/JTYAPEnFZ4o1bpRlm1FzTYPk9sFeNv5_gCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-18%2B14-41-08.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The signal for my D-Latch was just the output from the comparator. I had a manual switch that set the trigger. If the output from the comparator is high when the trigger is pushed, then the D-Latch will hold Q at high and Q' at low. If the output from the comparator is low, then the D-Latch will hold Q low. The circuit will keep it at that level until the trigger is pushed again, at which point, it will hold the signal based on the output from the comparator at that point.
&lt;/p&gt;
&lt;h6&gt;Output&lt;/h6&gt;
&lt;p&gt;
    To vizualize the output of the D-Latch I just added a pair of LEDs to the end. When the Q output is high, the red LED lights, and when Q' is high, the blue one lights.
&lt;/p&gt;
&lt;h4&gt;Parts List&lt;/h4&gt;
&lt;p&gt;
    I decided to go with a 3.3V design because the parts I could find worked out better that way (price wise). I bought these specific parts for each of the above components. This is not an endorsement of any vendor by the way. Also some of them were NOT the right parts for the reasons listed below, but this should point you in the right direction.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;photodiodes: &lt;a href=&quot;https://www.amazon.com/gp/product/B00M1PMHO4/&quot;&gt;HiLetgo 20pcs 5MM Photodiode Photosensitive Diode Light Sensitive Diode Round F5 Photodiode 3V&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;op-amp: &lt;a href=&quot;https://www.mouser.com/ProductDetail/on-semiconductor/ncs325sn2t1g/?qs=dbuNSGnowt2g9SoYxOxXaw%3D%3D&quot;&gt;ON Semiconductor NCS325SN2T1G&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;flip-flop: &lt;a href=&quot;https://www.mouser.com/ProductDetail/nexperia/74aup1g79gv125/?qs=jquClx72t9COASqZ9WZ81A%3D%3D&quot;&gt;Nexperia 74AUP1G79GV,125&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;leds: &lt;a href=&quot;https://www.mouser.com/ProductDetail/inolux/inl-3ab30/?qs=qSfuJ%252bfl%2Fd4rOSt45g1Ezg%3D%3D&quot;&gt;Inolux INL-3AB30&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;boards: &lt;a href=&quot;https://www.amazon.com/gp/product/B07CJ96ZPW/&quot;&gt;QLOUNI 40pcs PCB Proto Boards SMD to DIP Adapter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.amazon.com/gp/product/B00FO9HQLS/&quot;&gt;3V watch batteries&lt;/a&gt; and &lt;a href=&quot;https://www.amazon.com/gp/product/B01J5FY2GI/&quot;&gt;holders&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Prototype 1&lt;/h4&gt;
&lt;p&gt;
    Since I bought such small components for the D-latch and op-amp, I needed to solder them onto a board to make connections to the other components. The solder work was painstakingly tiny, but you can see that each of the legs connects to a metal strip that would then connect to a through-hole.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-fL8oEk2ahoo/Xao33wOrxuI/AAAAAAAAE3I/pV1DGLzKDnQrFbFRE_47IAKttrpDOczNQCKgBGAsYHg/s1600/IMG_20190728_155527.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I wired up the comparator and D-Latch part of the system as displayed in the diagram above. That way I could isolate those with known signals from the part of the circuit that would be the photodiodes. The D-Latch and LEDs tested and worked correctly.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-bbg5zYbghlE/Xao4leY2xrI/AAAAAAAAE3U/sCWgzEnR7EEZmbGzuVmPFwG6CciGhXR0gCKgBGAsYHg/s800/IMG_20190728_155120.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-bLiAyAkP_GM/Xao4lZaGMkI/AAAAAAAAE3U/Ti_YIQIw6zIIJanmJ30ckw1QVdqkfS7WQCKgBGAsYHg/s800/IMG_20190728_174343.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The next step was to connect the two photodiodes and resistors into the circuit. They sort of look like LEDs but they are photodiodes (LED and photodiodes are very similar materials just with the direction of conversion from light to electricity backwards). I aimed to make the two photodiode segments of the circuit as symmetric as possible to get them close to the similar state. With them wired up, the system is easy to calibrate by just rotating them towards a common light source until the odds of both outcomes is ~50%.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-DU6EqrK1XNM/Xao33_aLvUI/AAAAAAAAE3I/IxgvVzAwIF4okKZH-owmqlzirJjy5SmMgCKgBGAsYHg/s1600/IMG_20191018_134423.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    For the final step, I just soldered in the output LED. The whole circuit is a bit of a mess, but it was functional at least.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-5O4lsbKNg0E/Xao335j77hI/AAAAAAAAE3I/K-0ZvVmq9LYZ95kEodYsv5YL7koknAPSwCKgBGAsYHg/s1600/IMG_20191018_134403.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I am looking to build a couple more iterations that are a little cleaner. When I've built them, I will update here with details of the operation, and how to calibrate them.
&lt;/p&gt;</description>
        <pubDate>Fri, 18 Oct 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/10/quantum-coin-flip-device/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/10/quantum-coin-flip-device/</guid>
        
        <category>physics</category>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-vdKTCTOMcuA/XalW9bhYtoI/AAAAAAAAE1I/mbaN5hrvC1YXGBQDXud0I4Y-wqB7N0Z5wCLcBGAsYHQ/s1600/ezgif-6-15592130e47b.gif</image>
        <title>Quantum Multiverse Bifurcator</title>
        <description>&lt;p&gt;
    &lt;small&gt;Update: by some mind-blowing coincidence the &lt;a href=&quot;https://journal.burningman.org/2019/10/news/brc-news/burning-man-2020-the-multiverse/&quot;&gt;theme of next year's Burning Man&lt;/a&gt; happens to be the Multiverse! Note that what follows was all written before the theme was announced.&lt;/small&gt;
&lt;/p&gt;
&lt;p&gt;
    My partner and I went to Burning Man this year for the first time. It was an overwhelming experience. So much freedom, so much hard work, so little sleep, so many people. There were parts that were forgettable, parts that were frustrating, but overall it was an experience that changed how I thought about the world.
&lt;/p&gt;
&lt;p&gt;
    One of the biggest things that it pointed out to me was &lt;strong&gt;how much f**king stuff to do there is in this world!&lt;/strong&gt; It's hard to imagine how many fun people there are out there just waiting to go on an adventure with you. Unfortunately this presents a problem because as limited humans we can only do one thing at a time. BUT I think I may have solved this problem.
&lt;/p&gt;
&lt;p&gt;
    The method to eliminate all your FOMO requires just a simple piece of quantum mechanical technology and a belief in the many-worlds interpretation of quantum mechanics. If you want to skip ahead, you can &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;try the system out&lt;/a&gt;. It's related to &lt;a href=&quot;/2019/09/partial-identity-suicide.html&quot;&gt;another thought-experiment&lt;/a&gt; that I think I solved a few years ago that allowed me to hack my depression away overnight.
&lt;/p&gt;
&lt;h4&gt;Could parallel universes be real?&lt;/h4&gt;
&lt;p&gt;
    We've all seen the sci-fi (or sitcom) plots where there are parallel highly similar universes, and people cross over from one to the other. This is all-well-and-good for a plot device, but it seems impossible to believe in something so bizarre could really happen. Well, what if I told you there is a legitimate scientific justification for why there would be parallel universes?
&lt;/p&gt;
&lt;h5&gt;The Many Worlds Interpretation of Quantum Mechanics&lt;/h5&gt;
&lt;p&gt;
    A key component of the coolness of my invention relies on the many-worlds interpretation of quantum mechanics. For those unfamiliar, that might sound weird and/or hard to understand, but it's actually pretty simple. I won't go too deeply into the explanation of this since &lt;a href=&quot;https://en.wikipedia.org/wiki/Many-worlds_interpretation&quot;&gt;wikipedia article&lt;/a&gt; already does a pretty good job here. But I'd really like to give a brief explanation to make the next part more clear.
&lt;/p&gt;
&lt;h6&gt;Random things happen&lt;/h6&gt;
&lt;p&gt;
    In our normal everyday life, we generally feel like a lot of things are unpredictable. However, for the vast majority of things, what we really know is that the only reason it is unpredictable is because we just don't know enough to predict it. At least, this was the opinion of the scientific world up until the early part of the 20th century. Basically, physicists were generally convinced that for all things, the laws of classical physics apply (like gravity and electricity) and given enough information, we could calculate everything perfectly. The universe was perfect clockwork.
&lt;/p&gt;
&lt;p&gt;
    Then, something happened that physicists found pretty hard to believe. They found some things they literally could not predict.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fstartswithabang%2Ffiles%2F2017%2F11%2FHydrogen_Density_Plots.jpg&quot; title=&quot;The location of an electron is never exactly predictable &quot; /&gt;
&lt;p&gt;
    These things weren't even complicated. In fact, they were pretty simple. Most of them just looked like firing a subatomic particle at a detector. Supposedly, they had all the information to be able to predict exactly where these particles would go. But as it turned out, the particle would only end up where it was supposed to go half of the time. The other half, it would go someplace different.
&lt;/p&gt;
&lt;p&gt;
    At first, you might imagine that this just meant they were missing something. After much careful work, the scientists eventually concluded that, the truth is, the certain things really do happen in a purely random way. In a way such that no information in the whole universe could tell you what would happen next.
&lt;/p&gt;
&lt;h6&gt;Interpreting Randomness&lt;/h6&gt;
&lt;p&gt;
    So two things can happen, but only one of them does. The followup question for physicists is why? The problem is that there is loss of symmetry when only one thing happens. The universe always has a balance of cause and effect, except for these few totally random things. This isn't impossible, but for some people it is not very satisfying.
&lt;/p&gt;
&lt;p&gt;
    The resolution is to suggest that in actuality &lt;strong&gt;both&lt;/strong&gt; things happened. But then, the question becomes, if we only see one thing happen, how can both have happened?
&lt;/p&gt;
&lt;h5&gt;Universes popping into existence&lt;/h5&gt;
&lt;p&gt;
    The crazy idea behind the many-worlds interpretation is that both things happen in separate universes, and that you only see one. What does this mean? When the experiment takes place, the universe gets duplicated with one where outcome A happens and another where outcome B happens. The reason that you only see one is because your mind's experience also gets duplicated too. But the experience that you are currently experiencing only gets to see one outcome. The other copy of you is off living in a different universe now.
&lt;/p&gt;
&lt;h6&gt;The sci-fi interpretation&lt;/h6&gt;
&lt;p&gt;
    This idea leads directly to the sci-fi plot device of two parallel realities. Often this takes the form of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Mirror,_Mirror_(Star_Trek:_The_Original_Series)&quot;&gt;mirror&lt;/a&gt; universe or a &lt;a href=&quot;https://community-sitcom.fandom.com/wiki/Darkest_Timeline&quot;&gt;darkest timeline&lt;/a&gt;. If you're familiar with these kinds of pop-culture references, you can probably easily imagine how this scenario works. Imagine you are watching a movie of someone approaching a potential lover like in this image.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-PT1529ZfZzE/XaZlg_5jSJI/AAAAAAAAEyk/NnQe1LyrGyIse_xesYHcOLo7SUE3pHofACLcBGAsYHQ/s1600/branching-realities.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    At the moment that the other person responds, the outcome of the universe is undetermined. Then when the decision is made, both outcomes happen in different universes. Reality splits.
&lt;/p&gt;
&lt;h5&gt;The catch: Multiverses don't happen on their own&lt;/h5&gt;
&lt;p&gt;
    But these stories are missing one important detail, without which they remain just stories. The issue is that most of the &quot;random&quot; things that happen in our life are not quantum mechanical events at all. Most quantum events happen on the tiny microscpic scale and when you average a lot of those events together, you end up with a world that behaves really normally. Although it is often unpredictable to us (ie chaotic behavior), it is not necessarily truly random. (There is a difference between chaotic and quantum randomness that I won't get into here, but check &lt;a href=&quot;https://www.quora.com/Chaos-Theory-What-is-the-difference-between-chaotic-behavior-and-random-behavior&quot;&gt;this link&lt;/a&gt; to learn more.) In thhis case, we shouldn't really expect there to be a parallel universe created.
&lt;/p&gt;
&lt;p&gt;
    So to really intentionally split our universe, I figured there should be a way to start connecting the macroscopic outcomes of our lives to quantum mechanical events.
&lt;/p&gt;
&lt;h4&gt;Playing dice with the mother-fucking universe&lt;/h4&gt;
&lt;p&gt;
    Thanks to the hard work of quantum physicists, we now have the power to intentionally harness quantum randomness, and set about making multiple parallel universes. I've previously considered other thought experiments. All we have to do is make macroscopic choices based on random quantum decisions. This is similar to the &quot;Schrodinger's Cat&quot; thought experiment. Except in this case, the cat is us.
&lt;/p&gt;
&lt;p&gt;
    It's an interesting thought, but I wondered how it could work in practice. I recently wrote &lt;a href=&quot;/2019/10/sub-identity-suicide.html&quot;&gt;another post&lt;/a&gt; about how I've another quantum thought-experiment I'd previously toyed with years ago, but this idea seemed like a cool and interesting way to play with the idea in a way that others could access and enjoy. I figured it would be possible to do it manually with a help from proper quantum physicists, but I also wanted to make an interface to make it plain and simple to use for anyone. That eventually led me to build a little app that lets anybody play dice with the universe.
&lt;/p&gt;
&lt;h5&gt;Building The Quantum Multiverse Bifurcator&lt;/h5&gt;
&lt;p&gt;
    To create quantum realities, I needed to do two things
&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Find some way to generate quantum measurements&lt;/li&gt;
    &lt;li&gt;Link quantum measurements to some kind of choice interface&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;h6&gt;Finding Quantum Random Measurements&lt;/h6&gt;
&lt;p&gt;
    Finding &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_random_number_generator#Quantum_random_properties&quot;&gt;quantum random measurements&lt;/a&gt; isn't actually as hard as one might think. It turns out that &quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Shot_noise&quot;&gt;shot noise&lt;/a&gt;&quot; measured from the number of photons emitted from a light source is a quantum event. So in theory, one can use a measurement of the number of photons emitted from a source to create a quantum random outcome.
&lt;/p&gt;
&lt;p&gt;
    I originally tried building my own device for the quantum random measurement using the shot noise principle. I got it working, but it was finicky. I'll write a post on that and link it here when I get time.
&lt;/p&gt;
&lt;p&gt;
    For a more robust measurement, I turned to the real quantum physicists for expertise. Fortunately, there is &lt;a href=&quot;https://anuquantumoptics.org&quot;&gt;a team&lt;/a&gt; at the Australian National University who has built a really effective quantum number generator. The best part is that they put it onto the internet! Their &lt;a href=&quot;http://qrng.anu.edu.au/index.php&quot;&gt;website&lt;/a&gt; explains a lot more about how their system works, check it out if you are interested. Long story short, they measure excitation of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Vacuum_energy&quot;&gt;quantum vacuum energy&lt;/a&gt;, which in-and-of-itself is a trippy concept.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-8ZhC-gKfDVQ/XakWXFHLNyI/AAAAAAAAE0o/p4mUsN8Jyc4x1p8zMed6VSwFLWmRkQzsACLcBGAsYHQ/s1600/quantum-machine.jpg&quot; title=&quot;(not the actual machine used to generate these numbers, but something like it) &quot; /&gt;
&lt;p&gt;
    I found a python package from &lt;a href=&quot;https://twitter.com/paramedoc?lang=en&quot;&gt;Ellie Ragone&lt;/a&gt; that gave an &lt;a href=&quot;https://github.com/EllieRagone/anurandom&quot;&gt;example&lt;/a&gt; of how to use the ANU-Random API. The API just works by loading data from &lt;a href=&quot;http://150.203.48.55/RawBin.php&quot;&gt;this page&lt;/a&gt;, which appear to be rapidly refreshed on the server side rapidly. The data is a sequence of &lt;a href=&quot;https://en.wikipedia.org/wiki/Bit&quot;&gt;bits&lt;/a&gt; representing the outcome of several measurements. To get a quantum coin flip, I just take the first measurement in the string.
&lt;/p&gt;
&lt;h6&gt;Quantum Multiverse Bifurcator App&lt;/h6&gt;
&lt;p&gt;
    After finding the measurement I built a very simple webapp to allow people to interact with the quantum measurement in a more intuitive way. The app works by allowing people to input two choices that they are trying to decide on (Option L and Option R).
&lt;/p&gt;
&lt;p&gt;
    After they submit their form, I pull one quantum measurement (either 0 or 1). If the measurement is 0, the app says do Option L, if it's 1, do Option R.
&lt;/p&gt;
&lt;p&gt;
    I've already started using it to make very important life decisions. You can try it out &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-vdKTCTOMcuA/XalW9bhYtoI/AAAAAAAAE1I/mbaN5hrvC1YXGBQDXud0I4Y-wqB7N0Z5wCLcBGAsYHQ/s1600/ezgif-6-15592130e47b.gif&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    I based the website on this &lt;a href=&quot;https://github.com/petersimeth/basic-flask-template&quot;&gt;minimal template&lt;/a&gt; from &lt;a href=&quot;https://petersimeth.github.io&quot;&gt;Peter Simeth&lt;/a&gt;. As usual, all the code is in &lt;a href=&quot;https://github.com/lots-of-things/quantum-multiverse-bifurcator&quot;&gt;an open source repo on Github&lt;/a&gt;. It's about as bare bones as possible, but it gets the job done.
&lt;/p&gt;
&lt;h4&gt;Making a ton of universes&lt;/h4&gt;
&lt;p&gt;
    That's about everything for the build. After I'd built a rough draft of the app, my partner and I actually asked to do a Burning Man Theme Camp using it. Somehow our application got accepted so, next week, we're going to run this for a bunch of burners. I'm looking forward to creating a whole fuck-ton of parallel realities where people do some crazy stuff. I'll write another post afterward with the details of the camp.
&lt;/p&gt;</description>
        <pubDate>Thu, 17 Oct 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/10/quantum-multiverse-bifurcator/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/10/quantum-multiverse-bifurcator/</guid>
        
        <category>physics</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://1.bp.blogspot.com/-zi73O59MuA4/XZw_Dj9wOpI/AAAAAAAAEvo/D3PsJ82fZLAqnjd7YZ4dN4bbLTD9kiXMgCLcBGAsYHQ/5314782360_f32ff3aab7_c.jpg</image>
        <title>Creating Immediacy</title>
        <description>&lt;p&gt;
    I'm filled with a constant sense of urgency right now. Each day I feel a little more of my time burning away from me.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-zi73O59MuA4/XZw_Dj9wOpI/AAAAAAAAEvo/D3PsJ82fZLAqnjd7YZ4dN4bbLTD9kiXMgCLcBGAsYHQ/s1600/5314782360_f32ff3aab7_c.jpg&quot; title=&quot;source source&quot;/&gt;
&lt;p&gt;
    There is no guaranteed tomorrow so I want to do what I love today: making lots of things. Recently I've been using my spare time to build &lt;a href=&quot;2019/10/creating-immediacy.html&quot;&gt;a modbile app&lt;/a&gt;, &lt;a href=&quot;/2019/10/quantum-coin-flip-device.html&quot;&gt;a quantum measurement apparatus&lt;/a&gt;, &lt;a href=&quot;/2019/10/sub-identity-suicide.html&quot;&gt;philosophical conjectures&lt;/a&gt;, and &lt;a href=&quot;/2019/10/green-wall-irrigation.html&quot;&gt;irrigation systems&lt;/a&gt;. In this post, I wanted to share how I built the Immediacy App. It turns out building Android apps is pretty confusing and also pretty cool.
&lt;/p&gt;
&lt;p&gt;
    If you're interested in the development process, I've tried to lay out the details below. This is mostly a reference for me, but might contain a useful jump-start for anyone looking to do something similar.
&lt;/p&gt;
&lt;h4&gt;Using Firebase&lt;/h4&gt;
&lt;p&gt;
    To build the app, I relied heavily on a free Google Cloud platform called &lt;a href=&quot;https://firebase.google.com&quot;&gt;Firebase&lt;/a&gt;, which serves as an all-in-one real-time NoSQL database with simple APIs to query the database. Using it kept me from having to manage my own server or the database for storage (&lt;a href=&quot;https://np.reddit.com/r/cscareerquestions/comments/6ez8ag/accidentally_destroyed_production_database_on/&quot;&gt;ops scares me&lt;/a&gt;). And more importantly, it has a very generous free usage tier, which should easily cover the handful of people I expect to ever use this thing.
&lt;/p&gt;
&lt;p&gt;
    To learn how to use Firebase, I followed along with this &lt;a href=&quot;https://codelabs.developers.google.com/codelabs/firebase-android/#0&quot;&gt;chat app tutorial&lt;/a&gt;. This covers the setup of a project and connecting it to some Android &lt;a href=&quot;https://github.com/firebase/quickstart-android&quot;&gt;sample code&lt;/a&gt; for a chat app.
&lt;/p&gt;
&lt;p&gt;
    Mostly Firebase is just a fast way to store and retrieve data. The data structure just looks like a nested tree (like json) with a bunch of nonsensical keys used to identify whatever object is interesting.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-GPpYLclBswM/XZv0IN3deyI/AAAAAAAAEuA/Z0mZIYDkJh8dhB6ZoL3G7cmCqv-rNlVowCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-07%2B19-23-48.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    As you can see the database has 4 keys where it stores the users' profiles, conversations, messages and locations. Generally, you call this database with Firebase specific access functions (see below) to traverse the tree and get all the relevant data. Firebase also lets you expand the nodes of the tree to dig down into the data right through their UI, which is pretty convenient.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-omH95lbUKMQ/XZv0Icf_Z2I/AAAAAAAAEuE/CR5g7cGypk0zasLRMynA3z_QxGdJqzjuwCLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-07%2B19-26-07.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Here we can see how a few test messages were stored. Under the userMessages node are all the pairs of users who have had messages. Then under that there is a node to denote the messages. That node houses a list of messages, complete with sender and content.
&lt;/p&gt;
&lt;p&gt;
    One particularly great thing that Firebase does is keep track of all the users on the site and provide login protocols for authenticating them. Having bona fide User objects makes it much easier to access user specific data throughout the application.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-LiJU-AKRoNU/XZv0IUIaduI/AAAAAAAAEuI/ACsyUgzfPwIubsI90S5BtikwLMsjc-yWACLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-07%2B19-27-14.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    With a Firebase database setup and Authentication taken care of, the next step is to get some code to run the Android app on a phone.
&lt;/p&gt;
&lt;h4&gt;Android Programming&lt;/h4&gt;
&lt;p&gt;
    One of the keys to getting shit done in software development these days is to borrow heavily from open-source projects. Or to put it another way, this project started with browsing Github for a couple of hours to find someone else's project to steal outright.
&lt;/p&gt;
&lt;h6&gt;Nearby-Chat&lt;/h6&gt;
&lt;p&gt;
    With a basic understanding of Firebase, I started perusing for open-source Android apps that related to what I was trying to make. I started working with a Github project called &lt;a href=&quot;https://github.com/kshitiz1007/Lets-Chat&quot;&gt;Lets-Chat&lt;/a&gt;, and I adapted it to get something that worked for creating direct messages. Unfortunately, it didn't have anything related to location built-in. Instead of building that from scratch, I found another promising example called &lt;a href=&quot;https://github.com/frinder/frinder-app&quot;&gt;Frinder&lt;/a&gt;, but that one turned out to be mostly just a mockup that didn't quite work right.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-LSYOSMUvD3s/XZw3fbOB0mI/AAAAAAAAEvc/DMQHMoPHMtoHNypYHLLnZ00tE6DzUJYAACLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-08%2B00-14-43.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally, I stumbled on a project by &lt;a href=&quot;https://github.com/kuoa&quot;&gt;Sandu Postaru&lt;/a&gt; called &lt;a href=&quot;https://github.com/kuoa/nearby-chat&quot;&gt;Nearby-Chat&lt;/a&gt; that looked almost exactly like what I was looking for. It used an add-on to Firebase called &lt;a href=&quot;https://github.com/firebase/geofire-java&quot;&gt;GeoFire&lt;/a&gt;, along with Google Maps API to display the location of nearby people to chat with.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-tDUx2h0tQeQ/XZq7KwptmDI/AAAAAAAAEto/780bjfgHGaUfs3aU-_qdof0rzKIfF8c7gCLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-06%2B21-11-56.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This was great because it basically did everything I needed to do. The only downside was that it actually revealed the nearby users' exact location to everybody, which I thought was a little creepy. Fortunately, this meant that all I had to do was remove some functionality and tweak the &quot;Users List&quot; to only include people who were very close.
&lt;/p&gt;
&lt;h5&gt;The Components of the Mobile App&lt;/h5&gt;
&lt;p&gt;
    Android programming is super confusing to me, and I have only scratched the surface of it. In this section, I'm really just jotting introductory notes for myself on the different parts of an Android program. If you don't get Android this section might help explain things, but I'm also likely to be incorrect about some stuff in here. Follow at your own risk.
&lt;/p&gt;
&lt;h6&gt;Activities and Fragments&lt;/h6&gt;
&lt;p&gt;
    In Android parlance, the different main pages of the app are called &quot;Activities.&quot; When there are subsections in a single activity, there are segments called Fragments. In Nearby-Chat, there were four activities:
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MainActivity: activity launched on startup&lt;/li&gt;
&lt;li&gt;OnlineActivity: activity launched after user has logged in&lt;/li&gt;
&lt;li&gt;ProfileActivity: separate activity for editing user's profile&lt;/li&gt;
&lt;li&gt;ChatActivity: separate activity for an individual chat session&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
    The MainActivity had two fragments, one for registering new users and one for logging in. I left both of those untouched. The OnlineActivity also had two fragments: the MapFragment which held the map with nearby users, and the ConversationsFragment, which held a list of all the conversations that were currently ongoing.
&lt;/p&gt;
&lt;p&gt;
    To convert Nearby-Chat into Immediacy, I needed to replace the MapFragment with a NearbyListFragment, which just presented a list of users were close by. Fortunately, the code already had a place in it (OnlineUsersAdapter) that rendered a page that showed the full list of users. So all I needed to do was combine the filtering and fetching of users from the MapFragment with the list functionality of OnlineUsersAdapter.
&lt;/p&gt;
&lt;h6&gt;Adapters?&lt;/h6&gt;
&lt;p&gt;
    I mentioned Activities and Fragments, but there is another part in Android programming called an &lt;a href=&quot;https://abhiandroid.com/ui/adapter&quot;&gt;Adapter&lt;/a&gt; that wasn't clear to me at first. My interpretation is that all your data will come back one item at a time and the adapter is just a way to connect that data to the actual UI. All of th adapters I was working with were extensions of ArrayAdapter, which meant that I was going to get lists of items and convert them into lists of objects in the UI in some way. The way this happens is by adding Callbacks and Listeners
&lt;/p&gt;
&lt;h5&gt;Callbacks and Listeners&lt;/h5&gt;
&lt;p&gt;
    The big thing that's always been hard for me to understand about both web and mobile apps these days is the idea of &lt;a href=&quot;https://codeburst.io/javascript-what-the-heck-is-a-callback-aba4da2deced&quot;&gt;callbacks&lt;/a&gt; and &lt;a href=&quot;https://www.computerhope.com/jargon/e/event-listener.htm&quot;&gt;listeners&lt;/a&gt;. Programming with callbacks means almost none of your code gets called directly by the program when it starts up. Instead on startup you just set the functions to listen for events, and those events then call all these interrelated functions that each trigger each other. It makes sense because you want many things to happen potentially at once, but you still need some way to orchestrate subprocesses to happen after all the things that need to happen first happen. But it still means things are a little confusing—at least to me.
&lt;/p&gt;
&lt;p&gt;
    For my NearbyListFragment, I added a locationCallback function, and set up the fragment to listen for the user's location.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;activity = (NearbyListFragment.OnFragmentInteractionListener) context;&lt;br/&gt;activity.addLocationCallback(locationCallback);&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    When the phone retrieves the location from the device's GPS it send it to my callback's &quot;onLocationResult&quot; function.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;private final LocationCallback locationCallback = new LocationCallback() {&lt;br/&gt;    public void onLocationResult(LocationResult locationResult) {&lt;br/&gt;         for (Location location : locationResult.getLocations()) {&lt;br/&gt;             GeoLocation myLocation = new GeoLocation(location.getLatitude(), location.getLongitude());&lt;br/&gt;             geoFire.setLocation(userId, myLocation);&lt;br/&gt;&lt;br/&gt;             geoQuery = geoFire.queryAtLocation(myLocation, RADIUS);&lt;br/&gt;             geoQuery.addGeoQueryEventListener(geoQueryEventListener);&lt;br/&gt;...&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    This code first sends the location to the geoFire database and then sets up a query based on the current location and the search radius. On the Firebase side, geoFire.queryAtLocation is set up to look for other locations that are within the given RADIUS. Finally, I add a geoQueryEventListener to wait for geoFire to send a location based event back. The code for the GeoQueryEventListener takes this whole &quot;Listener&quot; thing to a new level.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;private final GeoQueryEventListener geoQueryEventListener = new GeoQueryEventListener() {&lt;br/&gt;&lt;br/&gt;        public void onKeyEntered(String key, GeoLocation location) {&lt;br/&gt;            &lt;br/&gt;            LatLng latLng = new LatLng(location.latitude, location.longitude);&lt;br/&gt;            &lt;br/&gt;            DatabaseUtils.getUserProfileReferenceById(key).addListenerForSingleValueEvent(new ValueEventListener() {&lt;br/&gt;            &lt;br/&gt;               public void onDataChange(DataSnapshot dataSnapshot) {&lt;br/&gt;                    UserProfile userProfile = dataSnapshot.getValue(UserProfile.class);&lt;br/&gt;&lt;br/&gt;                    onlineUsersAdapter.add(userProfile);&lt;br/&gt;&lt;br/&gt;...&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    This creates a listener that will wait to run its functions whenever the Firebase database registers an event. Specifically, whenever there is a &quot;KeyEntered&quot; event (ie someone enters within a predefined distance from the user), the onKeyEntered&quot; function will be called. This then generates yet another &quot;ValueEventListener,&quot; which waits for the database to return the data associated with the &quot;KeyEntered&quot; event (ie the UseProfile information for the user that entered the area).
&lt;/p&gt;
&lt;p&gt;
    At this point, the new user is added to the &quot;OnlineUsersAdapter.&quot; As mentioned above this adapter is an ArrayAdapter so for every user in the list, a view is created, which sets the values for the user_name, user_bio, and user_avatar.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;    public View getView(int position, @Nullable View convertView, @NonNull ViewGroup parent){&lt;br/&gt;&lt;br/&gt;        final UserProfile user = userProfileList.get(position);&lt;br/&gt;&lt;br/&gt;        TextView userName = (TextView) convertView.findViewById(R.id.active_user_name);&lt;br/&gt;        TextView userBio = (TextView) convertView.findViewById(R.id.active_user_bio);&lt;br/&gt;        ImageView userAvatar = (ImageView) convertView.findViewById(R.id.active_user_avatar);&lt;br/&gt;&lt;br/&gt;        userName.setText(user.getUserName());&lt;br/&gt;        userBio.setText(user.getBio());&lt;br/&gt;        userAvatar.setImageBitmap(user.getAvatar());&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    The advantage of all of this is that almost all of the work is done by the Firebase server, and your mobile app doesn't really spend any wasted time waiting for data to come back. It just sets up an event listener or a callback and then comes back to life when the event occurs. It's kind of all magic to me.
&lt;/p&gt;
&lt;h5&gt;Models&lt;/h5&gt;
&lt;p&gt;
    The last thing to mention is that all of the data stored in Firebase was basically used to construct Java Objects. The details about these Objects and what variables were associated with them was always stored in the models/ directory. There were model objects for Conversation, Message, OnlineUser, UserConversations, UserMessages, UserProfile.
&lt;/p&gt;
&lt;p&gt;
    The way to then reload these objects from Firebase is by passing the Firebase object the java object's class. As an example, in the above code, I regenerated a UserProfile using the data in the &quot;dataSnapshot&quot; by passing it the UserProfile.class.
&lt;/p&gt;
&lt;pre&gt;UserProfile userProfile = dataSnapshot.getValue(UserProfile.class);&lt;/pre&gt;
&lt;h4&gt;Putting it all together&lt;/h4&gt;
&lt;p&gt;
    A crucial step in all of this is getting the code onto a device where you can test it. Fortunately, you can follow &lt;a href=&quot;https://developer.android.com/studio/debug/dev-options&quot;&gt;these instructions&lt;/a&gt; to set up an Android device for connecting to Android Studio on a Linux machine.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-zkzLTrMW4zg/XZw2jMoeO5I/AAAAAAAAEvI/INL9pKPkwa4X9lnC8bgTkfCrqCxeJ45eACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-07%2B20-02-04.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The Android Studio interface is pretty painful to work with, but it allows you to render your UI components and performs all the code linking for you.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-2If8DyNWfM4/XZw3CcCugUI/AAAAAAAAEvQ/JhFYZABNR2sMg64TveN2fgWhMn0qYE7QgCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-08%2B00-12-57.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Admittedly, Android Studio does a ton of package management that I truly don't understand. Something called gradle is always building things in the background and reorganizing files, and it leaves me feeling totally lost. Honestly, I spent one whole night (probably 4 hours) just trying to get Gradle working again. All it told me was &quot;Input/output error&quot; without any other context. For the record, I eventually figured out I had to delete my ~/.gradle folder. I kind of hate Android programming because it uses such a clunky and black-box tool to generate the entire build process.
&lt;/p&gt;
&lt;p&gt;
    But long story short, the thing gets compiled and pushed over to my phone where I can play with it.
&lt;/p&gt;
&lt;h6&gt;Deployment&lt;/h6&gt;
&lt;p&gt;
    For the final step, I wanted people to actually be able to use this thing. So I plan on spending the cash ($25! wtf) for a developer license, so I can upload my app onto the Google Play store. When I get that finished I'll update here a link and how to
&lt;/p&gt;</description>
        <pubDate>Tue, 08 Oct 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/10/creating-immediacy/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/10/creating-immediacy/</guid>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-GSMO2VFKZGw/XXVt3ILyxDI/AAAAAAAAEZI/a4eiMciIXawuFe1GUYAQvK_ShSM7yIoxgCLcBGAs/112175045_e8d2231042_b.jpg</image>
        <title>Sub-Identity Suicide</title>
        <description>&lt;p&gt;
&lt;i&gt;&lt;small&gt;Epistemic status: In this post, I attempt to describe a thought experiment that allowed me to overcome chronic depression and existential doubts. This is a metaphysical proposition and may not be amenable to a determination of its validity.&lt;/small&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
    For many years, I was experiencing what I later learned to be &lt;a href=&quot;https://psychcentral.com/lib/what-is-existential-depression/&quot;&gt;existential depression&lt;/a&gt;. I remained externally happy and productive, but I had rational doubts about whether there was any purpose to life. As such, I could never commit to the belief that life was worth living. And it followed that I constantly questioned whether living was the right decision for me.
&lt;/p&gt;
&lt;p&gt;
    Then one evening, about three years ago, I figured out how to use a slightly more sophisticated formulation of Pascal's wager to end my depression outright. The result was a thought-experimental procedure that allowed me to remove all suicidal thoughts and tendencies. Now, I'd like to share the procedure that I built.
&lt;/p&gt;
&lt;p&gt;
    Below, I will try to articulate the steps I went through to formulate this idea. I hope that this can be used by others who are in need of something like its recipe for happiness. I'm incredibly nervous and embarrassed to share this story, but I feel it's one of the most useful things I've ever created. Feel free to judge the idea, but please try to avoid judging me personally if you don't sympathize with the sentiment that brought me to this result.
&lt;/p&gt;
&lt;p&gt;
    Thank you
&lt;/p&gt;
&lt;h4&gt;Precursor: Quantum Mechanical Suicide&lt;/h4&gt;
&lt;p&gt;
    During my college and grad school years, I would undertake what my unstable mind considered a terribly clever, though risky, experiment. I would get blind, piss drunk—I mean complete blackout—and I would free climb buildings. One of my favorites was the &lt;a href=&quot;https://chicagodesignslinger.blogspot.com/2015/03/henry-hinds-laboratory-for-geophysical.html&quot;&gt;Henry Hinds Geophysics building&lt;/a&gt; on the UChicago campus. It was incredibly easy to climb because of the bricks on the outside.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-GSMO2VFKZGw/XXVt3ILyxDI/AAAAAAAAEZI/a4eiMciIXawuFe1GUYAQvK_ShSM7yIoxgCLcBGAs/s800/112175045_e8d2231042_b.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Still, for a 6 story building, a misstep near the top could &lt;a href=&quot;https://outdoors.stackexchange.com/questions/8106/how-far-would-you-need-to-fall-for-it-to-be-fatal&quot;&gt;easily have been fatal&lt;/a&gt;. Then once I got to the top, I would perch myself on the edge precariously. I assumed that any tiny miscalculation would send me over the edge.
&lt;/p&gt;
&lt;h6&gt;I know this was stupid&lt;/h6&gt;
&lt;p&gt;
    I'm horribly embarrassed by my actions, but I mention it because some of this early, misguided thinking on this subject eventually led to somewhat more coherent revelations later.
&lt;/p&gt;
&lt;h5&gt;The point of my behavior&lt;/h5&gt;
&lt;p&gt;
    By getting blackout drunk I was attempting to simulate an observerless experiment. I wanted to set up a situation like Schroedinger's cat, but with my drunken self as the cat. The idea was that my brain wasn't really able to record information while I was in a blackout state so I wasn't really &quot;measuring&quot; the outcome of the experiment. Since the experiment was without an &quot;observer,&quot; this would leave me in a superposition of alive and dead. That is, until I sobered up, at which point the experiment would be over, and I would exist in a universe where I didn't fall off the building.
&lt;/p&gt;
&lt;p&gt;
    This was never a true quantum experiment in any scientific sense, however. And I never really committed to this dark experiment in any kind of real way. I just liked the sound of the idea so I played along for a while—until it got boring. And rather than ever &lt;u&gt;really&lt;/u&gt; setting up the quantum experiment where I would kill myself with 50% probability, I faked it with my dramatic little cry for attention.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Rk-Y8-J44dU/XYBbVWPIExI/AAAAAAAAKPg/UqeADdkvtQMtoFyaAFyOBL0qiJ86idsKwCLcBGAsYHQ/s1600/Schrodinger_cat_in_box.jpg&quot; title=&quot;During grad school, I kind of looked like this cat too. During grad school, I kind of looked like this cat too.&quot;/&gt;
&lt;p&gt;
    At any rate, you are currently living in one of the universe's where I survived. So if you read on, you can hear what this line of thinking eventually led to.
&lt;/p&gt;
&lt;h4&gt;My real problem&lt;/h4&gt;
&lt;p&gt;
    Some time later, I came to better understand myself and what was driving me to feel depressed. I realized that I needed my life to have some purpose in order for me to feel like I should continue to exist. This is a personal need. I acknowledge that this isn't an absolute necessity for everyone, but I have recognized that it absolutely is a necessity for me. I've wondered if this is some biological reality of psyche, that my body just doesn't experience the minimum amount of pleasure to make trudging through life worth it. For whatever reason, there is no way for me to feel satisfied without a higher purpose being real.
&lt;/p&gt;
&lt;p&gt;
    Having made this realization, some people will just decide that they must believe in a higher purpose. Unfortunately, try as I might, I couldn't shake my very reasonable doubt. In fact, given the evidence I am shown of the world, I would be more likely to argue that there is actually NO higher purpose to life. This conflict was what left me cycling through frequent periods of depression
&lt;/p&gt;
&lt;p&gt;
    Once I understood this conundrum, I had to believe that even my depression was rational. I needed to maintain my doubt because it was probably correct. I needed to maintain my hope because it was required for my continued existence. I couldn't give up on life entirely and risk failing to find something that truly mattered. But doubt and hope were at constant war with each other. I couldn't use &lt;a href=&quot;https://en.wikipedia.org/wiki/Pascal%27s_wager&quot;&gt;Pascal's Wager&lt;/a&gt; to wish away my true beliefs (I personally don't believe Pascal's Wager is valid because true belief is not something I can choose for the sake of utility).
&lt;/p&gt;
&lt;p&gt;
    Then little by little, a thought experiment crept into my head. It started as something very intuitive and wishy-washy, based loosely on the quantum suicide game I'd played with myself years ago. Then, as I ruminated on it further, I realized it might actually be a valid solution to my problem. Over a few days, I solidified my idea into a fairly cogent procedure with (reasonably) well-defined premises, corollaries, and conclusions. In the following sections, I outline my thinking on this subject and the logical steps required to reproduce my results.
&lt;/p&gt;
&lt;h4&gt;Necessary Premises&lt;/h4&gt;
&lt;p&gt;
    There are a few preliminary assumptions required to make use of this thought-experiment. Each of these can be argued for or against in a number of ways. I'll outline my arguments as I've come to accept them, but I welcome discussion over the truth of these &lt;a href=&quot;https://en.wikipedia.org/wiki/Premise&quot;&gt;premises&lt;/a&gt; as well.
&lt;/p&gt;
&lt;h5&gt;Premise 1: A Personal Need for a Higher Purpose&lt;/h5&gt;
&lt;p&gt;
    This procedure is only useful for those individuals who hold that some higher purpose is required to justify existence. Some people* may not need a higher purpose to their life in order to feel that life is worth living. For those for whom this premise does not hold, the remaining procedure is useless (and probably unnecessary). However, I believe that at least some other people may truly need that type of validation like myself. For those who &lt;strong&gt;know&lt;/strong&gt; that they can't justify their existence without such a higher purpose, we can state
&lt;/p&gt;
&lt;blockquote&gt;Some people cannot justify their existence without believing in a higher purpose. For such people, without certainty of a higher purpose, there is uncertainty about one's justification for existence. &lt;/blockquote&gt;
&lt;h5&gt;Premise 2: Possibility of Purpose&lt;/h5&gt;
&lt;p&gt;
    It is not impossible for there to be a higher purpose to an individual human's existence. That is to say, a higher purpose has not been ruled out by any observation of physical reality. If we assume that any possible underlying real state of the universe that is consistent with our observations may be possible, there are certainly many such states which are also consistent with some higher purpose. As an example, the existence of an all-power deity who declares existence of a soul eternal and purposeful (ie like the Judeo-Christian God) would satisfy this condition. Although this being the true underlying state of the universe is improbable given other explanations for the existence of organized religion (&lt;a href=&quot;https://www.livescience.com/52364-origins-supernatural-relgious-beliefs.html&quot;&gt;social control&lt;/a&gt;), it is not impossible. Many other* theoretically valid possible states also can be proposed. As such, I state as a premise of my argument that
&lt;/p&gt;
&lt;blockquote&gt;A higher purpose to our existence is not impossible.&lt;/blockquote&gt;
&lt;p&gt;
    *&lt;small&gt;Again, my partner asked for a more believable example that could depict a reality where a higher purpose exists. I came up with this simple example. Imagine our experience of physical reality is part of a simulation where the output is fed into the generation of some permanent and knowable universal truth. This truth would then persist indefinitely in a meta-universe that is itself indefinitely sustained by the successful creation of experience from finite universes like our own. This is one not impossible, albeit non-falsifiable, realization of a purpose to our existence.&lt;/small&gt;
&lt;/p&gt;
&lt;h5&gt;Premise 3: Existence of Abstract Ideas&lt;/h5&gt;
&lt;p&gt;
    This premise is required so that we may say that things that are ideas actually &lt;a href=&quot;https://plato.stanford.edu/entries/descartes-ideas/&quot;&gt;exist&lt;/a&gt; in a non-trivial way. I leave this as an exercise for the reader. If you believe that ideas do not exist, ask what that belief is and why you should be allowed to represent that belief to me.
&lt;/p&gt;
&lt;blockquote&gt;Ideas can be said to exist as real things.&lt;/blockquote&gt;
&lt;h5&gt;Premise 4: Composite Identity&lt;/h5&gt;
&lt;p&gt;
    The following is by far the most controversial premise, and it is one that I cannot argue must be true. Instead, this is more of a scientific, or observational premise, meaning one that is derived from experience rather than from abstract notions. So in reading this section, you must accept that this premise may only be intuited from personal experience. Nevertheless, I will describe my reason for this belief, and ask you to consider whether such a belief is congruent with your own worldview.
&lt;/p&gt;
&lt;p&gt;
    I believe that my identity is not monolithic. This means that my overall consciousness can be described using smaller units of consciousness. These smaller units of consciousness can be further subdivided, but, for simplicity, let us assume that we will stop dividing once we reach logically coherent decision making units.
&lt;/p&gt;
&lt;p&gt;
    Why do I hold this belief? I have simultaneously held two disparate thoughts in my mind at once. I have heard my own mind argue both sides of the morality of an action. There are observable underpinnings to this belief, such as the observation of &lt;a href=&quot;https://www.knowablemagazine.org/article/living-world/2018/mind-anthill&quot;&gt;hive minds&lt;/a&gt; or split identities after traumatic &lt;a href=&quot;https://en.wikipedia.org/wiki/Split-brain&quot;&gt;brain injury&lt;/a&gt;. While none of these are full proofs of the assertion, I take as a reasonable premise that
&lt;/p&gt;
&lt;blockquote&gt;Our personal experience of a single unified identity, is a cognitive simplification of the composite of interconnected decision-making units that form our consciousness.&lt;/blockquote&gt;
&lt;h5&gt;Corollary of Premises 3 and 4: Sub-Identities as Independent Actors&lt;/h5&gt;
&lt;p&gt;
    I'm not sure if this is an independent premise or a &lt;a href=&quot;https://en.wikipedia.org/wiki/Corollary&quot;&gt;corollary&lt;/a&gt; of the two previous premises. Although, the constraints of our physical form cause us to only ever take a single physically manifested action on behalf of our identity, our &quot;sub-identities&quot; are still able to act independently in the space of ideas.
&lt;/p&gt;
&lt;p&gt;
    As an example to make this worldview more concrete, say we have two sub-identities that disagree about idea X. They may argue in the abstract space of ideas about idea X. They may build subsidiary beliefs based around their support or lack thereof for idea X. One subidentity may convince the other subidentity of the validity of some argument. This could have effects on other parts of the second subidentities belief system. In order to attain more information (call it datum Y), one or both subidentities would have to manifest the desire for more information into the physical world through action on the unifying identity. Nevertheless, one subidentity may choose to ignore datum Y when they learn it.
&lt;/p&gt;
&lt;p&gt;
    This example is just to illustrate the concept of unbridled independent action of subidentities as long as they are not interacting with the physical world. Or to put it another way
&lt;/p&gt;
&lt;blockquote&gt;The subcomponents of an identity may perform independent actions in the space of ideas.&lt;/blockquote&gt;
&lt;h5&gt;Conclusion: My depression was the existence of multiple conflicting sub-identities&lt;/h5&gt;
&lt;p&gt;
    The above set of premises presented a clear reason to me for why I was depressed. I was made up of disparate well-formed identities that held conflicting opinions about the validity of my existence. In short, I was composed of some set of subidentities that believed there was a purpose to life and therefore I should continue to live. However, I had other subidentities which held the consistent belief that I should not bother continuing to exist.
&lt;/p&gt;
&lt;p&gt;
    I had to find a way to resolve this tension.
&lt;/p&gt;
&lt;h4&gt;The Identity Secession Procedure&lt;/h4&gt;
&lt;p&gt;
    Having established these premises, it is possible to carry out the following procedure.
&lt;/p&gt;
&lt;blockquote&gt;Allow subidentities to self-annihilate in accordance with their own belief system.&lt;/blockquote&gt;
&lt;p&gt;
    Based on my globally held personal beliefs established above, all sub-identities that didn't believe there was a purpose to life also believed that they should act to terminate their existence. Similarly, all sub-identities that believed there was a purpose, should act to self-preserve. Therefore, at the end of this procedure, only the identities that believed in a purpose to life were remaining.
&lt;/p&gt;
&lt;p&gt;
    At this point my complete (composite) identity was now entirely composed of subidentities that truly believed that I should exist. My period of self-doubt and misery could rationally come to an end.
&lt;/p&gt;
&lt;h4&gt;Aftermath (pun intended)&lt;/h4&gt;
&lt;p&gt;
    I can't say I've been purely happy for the three-or-so years since I discovered this procedure. However, I can say with no compunction that I have not thought for one moment that my existence was unwarranted. This system actually worked for me, and I hope that it could work for you too. In the time since then, I have had some other questions cross my mind about the procedure.
&lt;/p&gt;
&lt;h6&gt;Was this fair? What are the implications for the world?&lt;/h6&gt;
&lt;p&gt;
    If I'm taking this procedure seriously, it means that I knowingly let some fractions of a human consciousness commit suicide. If many people try this same plan, then eventually you could posit that we'd be collectively killing the metaphysical equivalent of many persons. So there's an outstanding question about whether this is moral, given your considerations of suicide, and whether this concept of subidentity is truly additive. Taking another approach one could ask, &quot;Is it fair to enter into this procedure, knowing that you are committing some subidentities to kill themselves willfully.&quot; I do not know the answer, but I could imagine arguments either way.
&lt;/p&gt;
&lt;p&gt;
    Another natural question is to apply the &lt;a href=&quot;https://en.wikipedia.org/wiki/Categorical_imperative&quot;&gt;categorical imperative&lt;/a&gt; to this procedure. Would it be a good thing for everyone to do this? If they did, we would be left with a world without doubt about the value of our own existence. Again, I haven't yet comprehended the full morality of this theory. These are incredibly hard ethical concerns for me to argue given that I am so fully invested in the result, but I welcome discussion on the matter.
&lt;/p&gt;
&lt;h6&gt;Who is left?&lt;/h6&gt;
&lt;p&gt;
    Finally, when one of my friends heard my description of this procedure, she asked a particular intelligent question: &quot;Were there strong correlations between personality traits and sub-identities that terminated?&quot; In other words, after the procedure, did my personality have to change because certain traits were possessed only by the &quot;doubting&quot; identities? I don't know for certain unfortunately, but I do certainly feel like a different person now.
&lt;/p&gt;</description>
        <pubDate>Sun, 06 Oct 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/10/sub-identity-suicide/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/10/sub-identity-suicide/</guid>
        
        <category>philosophy</category>
        
        <category>physics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://1.bp.blogspot.com/-Px6r44nrieA/XUdMsVkcWJI/AAAAAAAAET8/UrfNnZ1Ajcs8wFW9Pbq1Axmi-ODdkCNnACLcBGAs/Werewolf-Cell-Phone-User---18386.jpg</image>
        <title>Gmail Auto-Responder for AI Robot Party Game</title>
        <description>&lt;p&gt;
    I'm a big fan of immersive social games! Last fall, I built an &lt;a href=&quot;/2018/10/experiential-puzzle-narrative.html&quot;&gt;escape room&lt;/a&gt; for the engineering social at my company. For the &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;three&lt;/a&gt; &lt;a href=&quot;https://munrolab.uchicago.edu/&quot;&gt;prior&lt;/a&gt; &lt;a href=&quot;https://www.color.com/&quot;&gt;organizations&lt;/a&gt; I've worked for, I've also run a social mystery game similar to &lt;a href=&quot;https://en.wikipedia.org/wiki/Ultimate_Werewolf&quot;&gt;Werewolf&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/Mafia_(party_game)&quot;&gt;Mafia&lt;/a&gt;, but themed around self-aware human-like robots (aka &lt;a href=&quot;https://ideas.4brad.com/everybody-cylon&quot;&gt;everyone is a Cylon&lt;/a&gt;). The game is far more individualized than generic werewolf, including very specific character narratives and powers. I customized each character to have things that only they know how to do, and to create specific connections between characters that need to be uncovered throughout play.
&lt;/p&gt;
&lt;p&gt;
    I'm not going to go into the details of the game because I will definitely run it again someday and I don't want to ruin it. However, I wanted to explain one cool innovation I've made to the game mechanics that modernizes the game and makes it way more interactive. I also want to show the tool I built so I could run the game by myself even with 20 or so people playing at once.
&lt;/p&gt;
&lt;h4&gt;The Problems with Werewolf&lt;/h4&gt;
&lt;p&gt;
    To me, there are three drawbacks to werewolf that make it both unrealistic and a little awkward to play.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;voting requires everyone stopping to close our eyes&lt;/li&gt;
&lt;li&gt;there's no way to verify anything&lt;/li&gt;
&lt;li&gt;only the werewolves have anything to hide&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    When I decided I wanted to adapt the game to have a more immersive take, I knew that I needed to re-imagine some of the central mechanics to fix those problems.
&lt;/p&gt;
&lt;h6&gt;Interruption of gameplay&lt;/h6&gt;
&lt;p&gt;
    As an adult playing werewolf with my friends, I couldn't help but feeling silly when the Game Master intermittently tells everyone to shut their eyes and put their heads down. This brings the entire game to a stop and makes it so that the game has to be played in a tight circle rather than in a dispersed environment where simultaneous conversations and &quot;subplots&quot; can happen.
&lt;/p&gt;
&lt;h6&gt;Nothing but lies&lt;/h6&gt;
&lt;p&gt;
    Really, the biggest problem with Mafia is that the entire structure of the game relies on there being no way to establish definitive facts. For the majority of players, there is no way to &quot;check&quot; if anything someone else says is true. This is actually incredibly unrealistic. In reality, there are almost always external ways to check the validity of someone's alibi, or cross-reference whether they are doing what they say they are doing.
&lt;/p&gt;
&lt;h6&gt;Werewolves under pressure&lt;/h6&gt;
&lt;p&gt;
    Related to the above point, in the original game, most of what everyone is trying to do is just detect the physical characteristics of lying on someone's face. This makes the game easy/boring when you are playing with somewhat honest people. Basically only a crew of stone-faced sociopaths can make the game intriguing.
&lt;/p&gt;
&lt;p&gt;
    The reason it's so basic is because the only people lying are the werewolves. If you have an honest person, it's easy to rule them out early just by directly asking them. If they are uncomfortable about something then they are almost certainly a werewolf. The game would be better if they might be hiding something, but you aren't sure if what they are hiding is good or bad for your team. Furthermore, it would be even better if you aren't sure whether the werewolves know whether you are a werewolf too.
&lt;/p&gt;
&lt;h6&gt;...&lt;/h6&gt;
&lt;p&gt;
    So when I was originally contemplating my redesign, I wanted to break up these three downsides and reinvent them with something new. My goal was to modernize the game both in theme (AI/robots) and in mechanics (modern technologically savvy humans).
&lt;/p&gt;
&lt;h4&gt;A Technological Solution&lt;/h4&gt;
&lt;p&gt;
    I was thinking of ways to both make voting more fluid and come up with ways to introduce &quot;true facts.&quot; Surprisingly, it turned out that introducing the same tool resolved both issues.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Px6r44nrieA/XUdMsVkcWJI/AAAAAAAAET8/UrfNnZ1Ajcs8wFW9Pbq1Axmi-ODdkCNnACLcBGAs/s1600/Werewolf-Cell-Phone-User---18386.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We live within constant connection with our phones to both gather information and inform others of our intentions. Why not leverage our digital extensions to be the primary tool of the game?
&lt;/p&gt;
&lt;p&gt;
    This actually sequentially solved each of my main problems. First, I started by building a way for the werewolves to surreptitiously vote on their phones without interrupting the game. However, if only the werewolves were playing with their phones through the game, the game would be obvious. So next, I introduced another symmetric usage for the non-werewolves.
&lt;/p&gt;
&lt;p&gt;
    As it turned out, the perfect task that I could give non-werewolves was to obtain verified information about the werewolves. Again, I don't want to go into too much detail, but in general, the non-werewolves were able to query a central database that had unambiguous information about who was a werewolf. By limiting how much information they could gather at a time, the game could be tuned to both enforce cooperation and balance the rate of information gain with the rate of werewolf kills.
&lt;/p&gt;
&lt;h4&gt;Implementation: automated email response bot&lt;/h4&gt;
&lt;p&gt;
    To easily incorporate the usage of the phone, I needed to leverage something everyone would have access to. It would have been impossible for me to build a real phone app that would be compatible on everybody's devices. Instead, I leveraged something I knew everyone could use: email.
&lt;/p&gt;
&lt;p&gt;
    I built an automated email response bot that could shuffle information back and forth between players, myself, and a central database full of information that they could use to complete the game. The subject lines of the player's emails had a certain syntax that indicated whether they were trying to gather information or cast a vote to kill. The script I wrote just read the emails and followed some simple logic to direct the information around and keep the game moving along.
&lt;/p&gt;
&lt;h6&gt;Gmail API&lt;/h6&gt;
&lt;p&gt;
    To set up the Gmail API, the &lt;a href=&quot;https://developers.google.com/gmail/api/quickstart/python?authuser=8&quot;&gt;Gmail API Quickstart Tutorial&lt;/a&gt; contains instructions and the link to the spot on Google Cloud where you can activate the API. This will allow 100 sent emails per day, which should be enough if you have 20 or so people playing for an hour.
&lt;/p&gt;
&lt;p&gt;
    I used &lt;a href=&quot;https://gist.github.com/WJDigby/e36203102a195797c712c6cfe5020b21&quot;&gt;this gist&lt;/a&gt; to figure out how to send emails, and &lt;a href=&quot;https://github.com/abhishekchhibber/Gmail-Api-through-Python/blob/master/gmail_read.py&quot;&gt;this code&lt;/a&gt; to figure out how to read subject lines.
&lt;/p&gt;
&lt;p&gt;
    My code is &lt;a href=&quot;https://github.com/lots-of-things/robot-game-emailer/blob/master/robot_game_mailbot.py&quot;&gt;here&lt;/a&gt;, but I'll explain the few bits that are important below.
&lt;/p&gt;
&lt;h6&gt;Code snippets&lt;/h6&gt;
&lt;p&gt;
    This connects to your web browser to allow authentication of the Google account that has Gmail API access.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;creds = flow.run_local_server()&lt;br/&gt;service = build('gmail', 'v1', credentials=creds)&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Next, I grab the unread messages and iterate through them.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;     unread_msgs = service.users().messages().list(userId='me',labelIds=['INBOX', 'UNREAD']).execute()&lt;br/&gt;     mssg_list = unread_msgs['messages']&lt;br/&gt;     for mssg in mssg_list:&lt;br/&gt;            message = service.users().messages().get(userId='me', id=m_id).execute() # fetch the message using API&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    I step through the header items to get the subject and the sender.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;            payld = message['payload']&lt;br/&gt;            headr = payld['headers']&lt;br/&gt;&lt;br/&gt;            for item in headr: # getting the Subject,Time Sent, and Sender&lt;br/&gt;                if item['name'] == 'Subject':&lt;br/&gt;                    msg_subject = str_clean(item['value'])&lt;br/&gt;                elif item['name'] == 'Date':&lt;br/&gt;                    msg_date = item['value']&lt;br/&gt;                    date_parse = (parser.parse(msg_date))&lt;br/&gt;                elif item['name'] == 'From':&lt;br/&gt;                    msg_from = str_clean(item['value'].split('&amp;gt;')[0].split('&amp;lt;')[1])&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    At this point I go through several rounds of custom logic to compare this to the central database. I won't go into the details of the logic, but I want to mention how I access this &quot;central database&quot; in a very cheap and easily editable way.
&lt;/p&gt;
&lt;h6&gt;GSheets makes an easy editable database&lt;/h6&gt;
&lt;p&gt;
    To handle both the emailing permissions and the werewolf feature database, I just pulled the details from a Google Sheet. I already described how to connect to gsheets in a &lt;a href=&quot;/2019/04/visualizing-shared-budgets-and-dividing.html&quot;&gt;previous blog post&lt;/a&gt;. I reused the same credentials to download a sheet and convert into a python dictionary with all the info needed.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;    sheets_service = build('sheets', 'v4', credentials=creds)&lt;br/&gt;    result = sheets_service.spreadsheets().values().get(&lt;br/&gt;        spreadsheetId='game_db_spreadsheet_id', range='db!A:I').execute()&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Finally, I sent emails with the requested information back to the players.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;        message = MIMEText(message_body)&lt;br/&gt;        message['to'] = to&lt;br/&gt;        message['from'] = 'robot-db@gmail.com'&lt;br/&gt;        message['subject'] = subject&lt;br/&gt;        encoded_message = urlsafe_b64encode(message.as_bytes())&lt;br/&gt;        service.users().messages().send(userId='me', body={'raw': encoded_message.decode()}).execute()&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    All of this worked by repeatedly calling the API to get the new unread messages and then running through this over and over again. I used the sent email time to prevent people from repeatedly querying the database in less than the alotted time.
&lt;/p&gt;
&lt;h4&gt;Reaction&lt;/h4&gt;
&lt;p&gt;
    Each time I ran this game, I did it with more and more people. The first time I ran it, I only had about 8 people playing and I just manually responded to the emails they were sending. The last time I ran it, there were more than 25 people playing, and the automation came in really handy. It also allowed me to manage other aspects of the game at the same time.
&lt;/p&gt;
&lt;p&gt;
    Over time, I hope to perfect this game even further. If you are reading this in the SF Bay Area and would like to bring this game to your organization, please leave me a comment and I will get in touch to try to run it for you.
&lt;/p&gt;</description>
        <pubDate>Sun, 08 Sep 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/09/gmail-auto-responder-for-ai-robot-party/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/09/gmail-auto-responder-for-ai-robot-party/</guid>
        
        <category>games</category>
        
        <category>code</category>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-fhRKzpUFnPw/XXVQA7nzpII/AAAAAAAAEYo/zM03M09avR4CLDOa8qcHRW_KF8K53jUdACKgBGAs/IMG_20190618_152054.jpg</image>
        <title>Woodworking, Motor Work, and Head Replacement on Ioni</title>
        <description>&lt;p&gt;
    Claire and I have been refurbishing our sailboat this summer. Our top priorities were to replace our defunct head, and to reseal and treat our wood and recaulk the topside.
&lt;/p&gt;
&lt;h4&gt;Motor Repair&lt;/h4&gt;
&lt;p&gt;
    Soooo, I hate gasoline motors. They are loud and I don't understand them. As such, I'd been putting off fiddling with my noisy, fickle &lt;a href=&quot;https://www.youtube.com/watch?v=_TtZZEmDpro&quot;&gt;six horsepower Mercury four-stroke&lt;/a&gt; for a year. But neglecting things has a way of biting you in the ass.
&lt;/p&gt;
&lt;p&gt;
    The way my negligence got to me this time was in the form of a dead motor in the middle of the &lt;a href=&quot;https://parks.smcgov.org/coyote-point-marina&quot;&gt;Coyote Point Marina&lt;/a&gt; channel on a busy, beautiful Saturday morning. My partner and I were dead in the water for about 10 minutes trying to row ourselves out of the way.
&lt;/p&gt;
&lt;p&gt;
    Eventually we got towed part way back into the harbor, and we were able to set up our backup &lt;a href=&quot;https://en.wikipedia.org/wiki/Trolling_motor#Electric_trolling_motors&quot;&gt;electric trolling motor&lt;/a&gt; to get back to our slip. It was embarrassing to say the least. But it caused me to start the process of fixing the motor back up at least, so there's a bright side.
&lt;/p&gt;
&lt;h5&gt;Oil Change&lt;/h5&gt;
&lt;p&gt;
    After checking that we had decent gas, we decided to change the oil. I followed along with &lt;a href=&quot;https://www.youtube.com/watch?v=7Cxp9Dd42mg&quot;&gt;this BC_Backwaters video&lt;/a&gt;. It's pretty straightforward after you find the drain nut. I refilled with West Marine's default SAE 10W-30 oil.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-9Be0CGQfL9Y/XZ2PnIM-3WI/AAAAAAAAEwE/WbuV-7ya-9k3GywsUiegHVCTwzALG3qowCKgBGAsYHg/s800/IMG_20190919_194851.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    While this did make the engine sound a lot less crunchy, it didn't help with the popping noises from misfires. The engine kept cutting out, and actually we think it might have gotten a little worse.
&lt;/p&gt;
&lt;h5&gt;Gas filter and spark plug&lt;/h5&gt;
&lt;p&gt;
    I was a bit at a loss, but my friend &lt;a href=&quot;https://twitter.com/dannydesloover&quot;&gt;Danny&lt;/a&gt; suggested the next thing we tried should be replacing engine filters and spark plugs. The old ones had gotten a little clogged and crusty.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-8zS7tZiGOJQ/XZ2RgLVabKI/AAAAAAAAEwQ/kD4PyS0RkbEuhmD9LZQPn0X2UV93kNv4wCKgBGAsYHg/s800/IMG_20190928_102112.jpg&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Humming Like A Top&lt;/h5&gt;
&lt;iframe allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/vg9JQVcr9mM&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;
    The motor definitely sounds better and it feels more reliable. Only time will tell how long it holds out. For the next fix, I suspect I'd repack the grease down the propeller shaft. But that will wait for another day.
&lt;/p&gt;
&lt;h5&gt;Update: Oops&lt;/h5&gt;
&lt;p&gt;
    It turns out the above fixes weren't the real culprit after all. Instead, it turns out the fuel line had become clogged with gunk. This resulted in the engine dying about a half-mile away from the marina! Fortunately, we were able to figure out that we could manually pump fuel into the motor by hand, which got us back. In the end, we just had to replace 6 ft of hose and the motor worked perfectly from then on. (knock on wood)
&lt;/p&gt;
&lt;h4&gt;Replacing the head&lt;/h4&gt;
&lt;p&gt;
    Claire's top priority (by a margin) was to replace the head. It seemed like it'd be a very dirty job, but it turned out to be not so bad.
&lt;/p&gt;
&lt;h5&gt;Remove old head&lt;/h5&gt;
&lt;p&gt;
    We removed the old head and drained the old water tanks under the V-berth. Nasty water came out, but I was in my PPE. So it fine.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-PJF2hRCsh-Q/XXVLmA7-LbI/AAAAAAAAEYI/KSenKMbTFacZfH090ok_ONVgPAVNXIqZQCKgBGAs/s1600/20190511_173748.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ZdxZ9F2gcEI/XXVLmMolM0I/AAAAAAAAEYI/DoT8h7h2CA80MUgYMvY2DtmapxyW5dXCQCKgBGAs/s1600/20190511_173758.jpg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Extending the base and mounting the head&lt;/h6&gt;
&lt;p&gt;
    It turns out the replacement head I bought was actually a few inches larger than the old base. I'd thought I'd sized it correctly,, but it seems I was off by about an inch. Since the old base was looking a little rickety anyway, I decided to &quot;augment&quot; the base and extend it by a few inches to fit the new pedestal.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-cimrSSmCAJ0/XXVMDBojRhI/AAAAAAAAEYQ/SXOPmctiTn4G9CPM_imcuSHz6phHO_dFgCKgBGAs/s1600/IMG_20190615_153102.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ssH5ZMpXPZA/XXVMDH2d11I/AAAAAAAAEYQ/s5hCSymOlmceBl5Esoei4G3Dw7aY_r0pACKgBGAs/s800/IMG_20190615_154916.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I mainly just attached two vertical 2x8s to the current vertical plywood, which was glued to the hull. I sawed the angle as best I could to fit the curvature of the inside of the boat.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-ZbVNNi0fs9s/XXVQA3n61uI/AAAAAAAAEYo/7StuJAWREww1zNewWgiYSXFOF5ZnYcM_gCKgBGAs/s800/IMG_20190606_094046.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Then I added a board across the top for mounting to the base of the pedestal.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-CeJu_ouuDww/XXVMDGUg9SI/AAAAAAAAEYQ/w1GN6153nek4XOaVLOfxwNButXN4YAzdgCKgBGAs/s1600/IMG_20190615_155045.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Bit of overhang, but at least it's secured now.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-s4cCOV_I0C8/XXVMDK7wB0I/AAAAAAAAEYQ/1ri5M5sJDnIoUWHhi2CpjDS_O_iyiSHQgCKgBGAs/s1600/IMG_20190615_171833.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-8YBfibXLBBs/XXVMDGc684I/AAAAAAAAEYQ/FAW3QF7Yz1Q-iNUrgWTGWI0HZARQUNd4wCKgBGAs/s1600/IMG_20190615_171845.jpg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Connecting the outlet&lt;/h6&gt;
&lt;p&gt;
    We ran into a bit of a snag when connecting the outlet. No matter how hard we tightened, there was still a tiny leak. Not acceptable when you are talking about piss and shit. So we added a tiny bit of our silicone sealant that we were using to shore up leaks in the topside woodwork. That seemed to do the trick (knock on vinyl).
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-C47leo1-a-k/XXVNFZbpjQI/AAAAAAAAEYc/Dtjpli_uMjQ4bTWDDhHO5hw2mZZSuBXOgCKgBGAs/s800/IMG_20190713_142240.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-y0F1EVsV7qE/XXVNFXDroxI/AAAAAAAAEYc/cWWtXguQ3NcDwv2CXIavzxRkagzKdZZ_wCKgBGAs/s1600/IMG_20190713_142953.jpg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Connecting the inlet&lt;/h6&gt;
&lt;p&gt;
    The last step was to connect the inlet of the toilet to a water source. Originally, the inlet came straight from the ocean through a &lt;a href=&quot;https://www.seamagazine.com/seacock-inspections-2/&quot;&gt;seacock&lt;/a&gt; in the bottom of the hull. That made us a little nervous given the state of the seacock.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-wJE7AiiDPwQ/XXVMDNkHB6I/AAAAAAAAEYQ/GBwnY7V07WIYYTcog4y3sihETeejLuplQCKgBGAs/s800/IMG_20190615_162258.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Instead, we're going to use the old potable water tank as a source. This will require getting more hose to reconnect the potable water tank that I'd previously removed. this project is going to hold off for a bit. For now, we are content to pour water into the top from a gallon jug.
&lt;/p&gt;
&lt;h4&gt;Refurbishing the topside wood&lt;/h4&gt;
&lt;p&gt;
    The last thing we wanted to do before winter was get our wood back in decent shape. This was important because treated and sealed wood prevents water from getting inside the boat in the rainy season.
&lt;/p&gt;
&lt;p&gt;
    We started by resealing the wood with some black silicone that I got from a neighbor. We basically plugged the holes and hoped for the best. Application was messy, but we were able to apply and scrub off the excess after the fact. It's been keeping the water out as we wash it, but we'll see about winter.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-pj9FQ7sVCtc/XXVjCQT7ImI/AAAAAAAAEY8/jc6Qp6496C0q6-rfYmTdxjN0YnmGftTJACKgBGAs/s800/IMG_20190713_114239.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We also replaced the teak oiled all the wood. We were going to pull off the varnish and reapply, but that seemed like a lot of work. Instead, we just decided to let the varnish continue to wear away. We'll keep applying teak oil to keep the wood protected while the varnish wears down. In these photos you can see how he wood started with grey patches, which we'd clean and let dry to get it kind of wood colored again. Then we'd apply teak oil and let dry.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-t-czLwtVj4A/XXcEyeFMdsI/AAAAAAAAEZs/uyxAsGGm89s2gDQpGMN2bm3uFTVy2jLdwCKgBGAs/s1600/IMG_20190714_152917.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    By the end, it looks mostly like the same. The main drawback is that the teak oil will often leave darker patches around the edges of any unfinished area. We're willing to accept this until the point when it's really worn down and we can clean and sand everything to get a nice bright finish.
&lt;/p&gt;
&lt;h6&gt;Recaulking the topside wood&lt;/h6&gt;
&lt;p&gt;
    It turns out caulk is actually pretty tricky to apply. I used masking tape to clearly delineate where the edges of the caulk should be and applied a liberal amount over the top. To smooth and round the caulk (before it dries), I came up with a homebrewed method where I used a rounded piece of wood to spread the caulk with a smooth circumference. It worked OK in most places. I pulled the tape while the caulk was still wet, but there was already some sticking in places.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-d4bbUH2YxJw/XbkNTrBa4RI/AAAAAAAAFAU/moeLtXjNEp0v3Pwlj0Au_LbKIcLF5mG0ACLcBGAsYHQ/s1600/IMG_0022.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-eQJYD_udjns/XbkNUZj94zI/AAAAAAAAFAc/8xb7876F2CwdIlbD1sNxcOEv8e_zyylKgCLcBGAsYHQ/s1600/IMG_0023.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-edEa2fRbzak/XbkNUBcJl_I/AAAAAAAAFAY/0FXABL0XiWYF8Eo4tKX_L7iiY8YSvJqyACLcBGAsYHQ/s1600/IMG_0024.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-KDpJdbo3Wu4/XbkNVcAQ5MI/AAAAAAAAFAg/dXrwvvPDzEQlNsIelN6ztKK2i5PljdZDwCLcBGAsYHQ/s1600/IMG_0025.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-rnXEW7kIyuQ/XbkNVw1dNzI/AAAAAAAAFAk/MzxtuL9-4PkgtXi6TMgvEd_0p-yMbSxxgCLcBGAsYHQ/s800/IMG_0027.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The caulk gun makes a bloody mess, and I was a little late in patching up some areas. I may need to redo a it of this project in the near future.
&lt;/p&gt;
&lt;h6&gt;Fixing some interior wood&lt;/h6&gt;
&lt;p&gt;
    We also found that some of the interior wood drawers were starting to tear apart. I just wood glued and screwed it all back together. Simple fix, but makes it a hell of a lot more livable.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-A9lGhPaDPb4/XXcEUfi_CfI/AAAAAAAAEZk/OUvZDXYxmr4vJUq-uujqbRfGqkOANvo9ACKgBGAs/s800/IMG_20190615_173315.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Budget summary&lt;/h4&gt;
&lt;p&gt;
    In a &lt;a href=&quot;/2019/04/visualizing-shared-budgets-and-dividing.html&quot;&gt;previous post&lt;/a&gt;, I described how much I like keeping track of my expenses, particularly for hobby projects like this. The overall cost of all this was around $250 for the toilet materials, and about $200 for the caulks, the oils, PPE and other miscellaneous tools. This seemed pretty great since a quote from a boatyard was for 3x that for each. Plus, I gotta admit, I feel closer to Ioni every time I work on her.
&lt;/p&gt;</description>
        <pubDate>Sun, 01 Sep 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/09/woodworking-motor-work-and-head/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/09/woodworking-motor-work-and-head/</guid>
        
        <category>boatwork</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://1.bp.blogspot.com/-BN1Su8VptwM/XfGCDzfGpGI/AAAAAAAAFLQ/D5ZMotAq5qso7tUPfbzc4U1LJCPwS2bYwCLcBGAsYHQ/Screenshot%2Bfrom%2B2019-12-11%2B15-47-15.png</image>
        <title>Google Analytics for Scrolling on a Static Website (or Google Analytics is Creepy)</title>
        <description>&lt;p&gt;
    A couple of months ago, I helped one of my friends set up Scroll Tracking with Google Analytics on an experimental website. While working on this I discovered that I could do really cool/creepy stuff like download the scroll event data on a user-by-user basis.
&lt;/p&gt;
&lt;h4&gt;Setting up (free) Google Analytics for Website Usage Tracking&lt;/h4&gt;
&lt;p&gt;
    Because my friend was using a static site on Github Pages, it wasn't possible to set up a database to track the interactions with her website. Instead, we decided to use Google Analytics (GA) to do the storing of all that interaction data. This is great because GA can be used for free, but as we'll see, this can lead to drawbacks.
&lt;/p&gt;
&lt;p&gt;
    The first step in scroll tracking is getting Google Analytics set up to listen in on the activity on your website. This process is pretty straightforward and the steps are covered &lt;a href=&quot;https://support.google.com/analytics/answer/1008015&quot;&gt;here&lt;/a&gt;. At the end of this step, you'll be able to log in and see the number of pageviews and such on the GA site.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-mPJihWJY6FY/XfFneqiZOPI/AAAAAAAAFKA/M7FJ-2O61JgkHa01CatsHuibC1bzSDENACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B14-01-44.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This is an alright overview of the number of people who have visited the site, but we want to get more interesting event level detail like scroll tracking. There are a number of tutorials that explain how to do Scroll Tracking, but &lt;a href=&quot;https://www.lovesdata.com/blog/tracking-scroll-depth&quot;&gt;this one&lt;/a&gt; was a good start that got it working for me. I added a ton more levels to get granularity down to the single percent. After that is set up, you can view the Behavior-&amp;gt;Events tab and see all of the Scroll Tracking events in a timeline.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-E9fhXh5a5oI/XfFogxHcbKI/AAAAAAAAFKM/t8jcGRRHkoUXRizzCQPonAaZXDNWAEO2QCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B14-06-17.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    But we're actually interested in how far people scroll down the page. As explained in the link above, you can get this table by selecting the &quot;Top Events&quot; tab and then setting the primary dimension as &quot;Event Action.&quot;
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-HdQL_RiyaUU/XfFpgO_0uEI/AAAAAAAAFKY/pJnuOwpcQ9Ik2YNM7L6JJN6lK8_Pc3K-QCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B14-10-09.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This table gives a decent overall summary, but it's hard to get down to more detail than this. You can use the &quot;Secondary Dimension&quot; to get it broken down into a little more detail, but it's still pretty high level. Also, if you want to download this data, you can only export the table as it appears, not with any more detail.
&lt;/p&gt;
&lt;h4&gt;Getting User-Event Level Data&lt;/h4&gt;
&lt;p&gt;
    To get down to Event Level Records I did two things:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add custom variables to disambiguate users on each event&lt;/li&gt;
&lt;li&gt;Use google2pandas to download the raw event data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    The first item was necessary to disambiguate multiple users so that I could reconstruct their scroll event history on an individual basis. Otherwise, everyone who scrolled at the same time would be mixed together in the data. The second item just allowed me to get every record directly instead of needing to go through the GA UI and get aggregated data. I break the process of working with those two thins down in the next sections.
&lt;/p&gt;
&lt;h5&gt;Adding User Variables to the Scroll Event Tag&lt;/h5&gt;
&lt;p&gt;
    I think that if you pay for Google Analytics then you can see the user associated with every event pretty easily . But I'm kind of broke so I don't have that luxury. Instead, to add the user's ID, I needed to pull it out of Google's tracking stuff from the inside and past it back in as a custom variable. After I'd done that I could grab those variables to store in the Scroll Event Tag for later use.
&lt;/p&gt;
&lt;h6&gt;Storing Variables&lt;/h6&gt;
&lt;p&gt;
    Google has a way to keep track of the same user across different sessions on your website. It's a little creepy, but it's pretty easy to find a &lt;a href=&quot;https://www.optimizesmart.com/how-to-send-client-id-to-google-analytics-via-google-tag-manager/&quot;&gt;how to&lt;/a&gt; on how to do it. The key part is adding a Custom Javascript variable with the following code.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-RSEUdlZjI4Q/XfF2Re87ZLI/AAAAAAAAFKk/lbVPkwjH7acX__G7qSezgiX_nQyQAlVbQCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-05-08.png&quot; title=&quot; &quot;/&gt;
&lt;pre&gt;function() {
 try {
 var tracker = ga.getAll()[0];
 return tracker.get('clientId').toLowerCase().trim();
} catch(e) {}
return 'false';
}&lt;/pre&gt;
&lt;p&gt;
    Apparently, there is a &lt;a href=&quot;https://www.simoahava.com/gtm-tips/use-customtask-access-tracker-values-google-tag-manager/&quot;&gt;better way&lt;/a&gt; to do this, but I didn't find that until now. The drawback with my method is that the clientId variable will be null if Google hasn't set it yet. To take care of this problem I added a second variable (userId), which I manually populate on the first pageload. That way if Google takes a while to setup the clientId, I can go back and use the userId variable to connect earlier events. Kind of hacky but whatever.
&lt;/p&gt;
&lt;p&gt;
    I added the following javascript to my site to make a random ID and add it to the Google Tag Manager's &quot;&lt;a href=&quot;https://support.google.com/tagmanager/answer/6164391?hl=en&quot;&gt;data layer&lt;/a&gt;.&quot; The data layer is just a way to pass variables from your local javascript to the GTM's variable space. Note that I also added the variable called contentVersion to track which site update the user was viewing.
&lt;/p&gt;
&lt;p&gt;
    After adding this code into the &amp;gt;head&amp;lt; html of my site:
&lt;/p&gt;
&lt;pre&gt;
  function makeid() {
  var text = &quot;&quot;;
  var possible = &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789&quot;;

  for (var i = 0; i &amp;lt; 20; i++)
  text += possible.charAt(Math.floor(Math.random() * possible.length));

  return text;
}
var userID = makeid();
dataLayer = [{'userID': userID,'contentVersion':1}];
&lt;/pre&gt;
&lt;p&gt;
    I added a data layer variable with the same name in GTM.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-GwFkxX7qO3I/XfF4-sXjlZI/AAAAAAAAFKw/pWtR4blYoGkaNwLINLeT3wlOcgNzf0ZKACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-16-29.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Adding variables to Scroll Events Tag&lt;/h6&gt;
&lt;p&gt;
    After I made the variables I just needed to add them to the Scroll Event Tag that I had made before. I just put all of the variables I needed into the &quot;Label&quot; field with colons between them.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-9JLqzB_bcRA/XfF6KU7AQ4I/AAAAAAAAFK8/JubZ8W_bLP4E_AspOkZQIlJPMpWfWO3-QCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-20-02.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    To test I just went back to the GA events table we were looking at above and selected &quot;Event Label&quot; as the primary dimension. This shows the event labels in the specified format {{contentVersion}}:{{userID}}:{{clientId}}.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-T2wnRwrxfvI/XfF6iQQQZXI/AAAAAAAAFLE/kQFXFIVA_-Y2CD79EjjKowDmrUlmHAtNwCLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-12-11%2B15-23-09.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    You might notice that the last item (clientId) is frequently &quot;false.&quot; That's just because it hadn't been set by google yet.
&lt;/p&gt;
&lt;h5&gt;Downloading events with google2pandas&lt;/h5&gt;
&lt;p&gt;
    Now that the data is distinguishable by individual userId, it becomes possible to download it at that level. Rather than using the GA UI, I wanted to write some python scripts. Fortunately, the &lt;a href=&quot;https://github.com/panalysis&quot;&gt;panalysis&lt;/a&gt; group on Github, had the &lt;a href=&quot;https://github.com/panalysis/Google2Pandas&quot;&gt;google2pandas repo&lt;/a&gt; that could connect and return the data in a pretty pandas data frame.
&lt;/p&gt;
&lt;p&gt;
    To download the data I have to send a query structured with the GA viewId, the date ranges, the aggregation dimensions, and the metrics to plot. In this example, I basically just add all the features I have as dimensions and then I get the count of totalEvents as the metric (which should be 1 most of the time anyway).
&lt;/p&gt;
&lt;pre&gt;
  from google2pandas import GoogleAnalyticsQueryV4

  conn = GoogleAnalyticsQueryV4(secrets='attention_service_credentials.json')
  scroll_query = {
  'reportRequests': [{
  'viewId' : '187999039',

  'dateRanges': [{
  'startDate' : '2019-11-26',
  'endDate'   : '2020-05-01'}],

  'dimensions' : [
  {'name' : 'ga:eventCategory'},
  {'name' : 'ga:eventAction'},
  {'name' : 'ga:eventLabel'},
  {'name' : 'ga:pagePath'},
  {'name' : 'ga:pageTitle'},
  {'name' : 'ga:dateHourMinute'}],

  'metrics'   : [
  {'expression' : 'ga:totalEvents'}],
}]
}
df_scrolls = conn.execute_query(scroll_query)
&lt;/pre&gt;
&lt;p&gt;
    I have a working &lt;a href=&quot;https://github.com/lots-of-things/attention-tracking&quot;&gt;jupyter notebook&lt;/a&gt; on this if you want a place to start. You will need to enable the GA API and get your own google_service_credentials.json file by following the instructions &lt;a href=&quot;https://developers.google.com/analytics/devguides/reporting/core/v3/quickstart/installed-py&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;h4&gt;Plotting the scrolling progress&lt;/h4&gt;
&lt;p&gt;
    In my jupyter notebook, I graph the scrolling progress for a few people. The data is clearly messy because some people just scroll straight to the bottom. Still, this gave my friend a pretty clear idea that for people who were actually reading it, it took about an hour to finish.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-BN1Su8VptwM/XfGCDzfGpGI/AAAAAAAAFLQ/D5ZMotAq5qso7tUPfbzc4U1LJCPwS2bYwCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-47-15.png&quot; title=&quot; &quot;/&gt;</description>
        <pubDate>Sun, 30 Jun 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/06/google-analytics-for-scrolling-on/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/06/google-analytics-for-scrolling-on/</guid>
        
        <category>code</category>
        
        <category>data science</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://4.bp.blogspot.com/-UGYDFBT9iTg/XEaClT1EDwI/AAAAAAAADT0/DYfxVt0t790-RsIPku87KJ-l-TQ9TaemQCKgBGAs/20180828_175812.jpg</image>
        <title>Solar Electrical System on Ioni</title>
        <description>&lt;p style=&quot;text-align:center&quot;&gt;&lt;i&gt;Daughters of Nereus, resident in caves, merged deep in sea, sporting through the waves;&lt;br/&gt;whose forms half wide are nourished by the deep, leaping and wandering through the liquid sea.&lt;br/&gt;Bright, watery dolphins, sonorous and gay, well-pleased to sport with Bacchanalian play;&lt;br/&gt;Nymphs beauteous-eyed, whom sacrifice delights, give plenteous wealth, and bless our mystic rites;&lt;/i&gt;
&lt;/p&gt;
&lt;p style=&quot;text-align:right&quot;&gt;Orphic Hymn 24 to the Nereides &lt;i&gt;c. 300 BC&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
    I'm currently in the process of fixing up my vintage Dolphin 24 sailboat, Ioni. This post covers my foray into marine electrical. I'm mostly writing this so I can laugh at myself a year from now, when everything goes horribly wrong. ¯\_(ツ)_/¯
&lt;/p&gt;
&lt;h4&gt;Ioni's Electrical Systems&lt;/h4&gt;
&lt;p&gt;
    There are basically three essential electrical systems on Ioni.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Auto bilge pump&lt;/li&gt;
&lt;li&gt;Running lights&lt;/li&gt;
&lt;li&gt;Radio&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    The bilge pump is to keep any small leaks or rain from sinking her while I'm away. The running lights are needed for any nighttime sailing. The radio is probably not necessary for bay sailing, but it would be a little irresponsible to not set it up. By the end of this all of these will be running off of this 12 volt car battery.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-bqVbi3ZT8Mg/XEZ9heBuBXI/AAAAAAAADS8/oWp-QCbinws1C-fPEDuLSJ3BsTGyRizpgCKgBGAs/s1600/IMG_20180619_195217.jpg&quot; title=&quot;I assure you, it's not as dangerous as it looks. &quot;/&gt;
&lt;p&gt;
    Finally, a battery won't last forever so there needs to be some system to recharge it. I would personally prefer to not need grid electric in my life ever, but as that isn't possible, I at least want to be able to take this small isolated system off of it. Therefore, I'm going to be pursuing solar photovoltaic for recharging the battery.
&lt;/p&gt;
&lt;h4&gt;Basic electrical setup&lt;/h4&gt;
&lt;p&gt;
    Before I set up the solar system, I focused on making sure all the electrical systems were working directly off battery. Ioni's electrical setup is pretty simple. Below is a diagram of all the main electrical equipment I built.
&lt;/p&gt;
&lt;p&gt;
    The wiring itself is set up to run through this junction box. One side is positive and the other negative.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Nl2V_3X3bb8/XEZ_DGyXLBI/AAAAAAAADTU/835E5B8xcMQthFa97Tt5uc_9buuLqXl9ACKgBGAs/s800/IMG_20180619_195203.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Most of the equipment runs through this set of switches, which are hooked up to their own fuses. I also ran a larger breaker across the main battery terminal just in case of short to prevent the auto battery from running hundreds of amps and melting itself.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-yu98CiBrO5Q/XEZ-PkWKdII/AAAAAAAADTM/SyZxZ6Vp2vE55MWADx5--XJIu0hCCM-IQCKgBGAs/s1600/IMG_20180626_221557.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    One component that doesn't run through the set of switches is the automatic bilge pump. I could have run the bilge pump through the switches, but I decided to avoid that since I wanted to make sure no one ever accidentally shut it off. The wiring setup for the bilge pump was particularly easy, and just involved connecting the positive end to the float switch line on the pump. This float switch turns on whenever the bilge pump gets significantly covered in water.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-aXemo4lVHBA/XEZ-PkLW6TI/AAAAAAAADTM/w1jGmMyI9ysqVkqHf6Uk5SkbMXYFbI30gCKgBGAs/s800/IMG_20180626_221744.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Radio&lt;/h4&gt;
&lt;p&gt;
    The radio was the first thing I connected. It was very straightforward. Just connect the black wire to the negative on the battery and the red to the fuse/switch, which connects to the battery positive terminal. The antenna runs up the mast as well.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-o5rLuqEhnhI/XEZ_hE2m1QI/AAAAAAAADTc/76Xwo5p9jBMYmQRbT7TzfIaSOCWfjsssgCKgBGAs/s1600/IMG_20180701_184433.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Lighting&lt;/h4&gt;
&lt;p&gt;
    The lighting was a slightly more complicated setup, but all fairly straightforward once I understood the wiring setup. Fortunately, the wiring for all the lighting was already run, I just had to decipher which lighting element was which. The cabin lights and running lights are each in parallel so that if one goes the rest will work fine. I'd assumed this would mean individual lines for each, but instead, there was just a pair of ground connections and then an individual hot for cabin and running lights. The hots needed to be attached to the switch.
&lt;/p&gt;
&lt;p&gt;
    The light in the V-berth had a broken switch that I needed to open up and break apart from the inside to reattach.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-q1hJ3rFjNRg/XEaAfurVnHI/AAAAAAAADTo/Dpvd5AIQVCsKMR6OwZ3UktRkJNeBOtlVgCKgBGAs/s800/20180725_190631.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Similarly, I had to repair the interior of the main cabin light because the connections were faulty. I dismantled and reconnected it, and then swapped the original bulb with a low power LED. There was also a light in the V-berth that had a jammed switch that needed to be taken apart for repair.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-3mbUxEUSnbs/XEaAfmpNGRI/AAAAAAAADTo/tDBz53k_NzYqDaSA7bxWdP15r6kY-kqGACKgBGAs/s800/20180724_214935.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-b46qdWnJsw0/XEaAfo2vbLI/AAAAAAAADTo/GR8ghn-6sWIIcDvC3qeQaFGgTsNveBcygCKgBGAs/s1600/20180724_183211.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I replaced the running lights with LED bulbs as well. Running lights are designed to be green to starboard, red to port, and white on the stern. The wire leading to the rear white light was cut so I reextended it.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-HnFE-ividFc/XEaAfnrrEgI/AAAAAAAADTo/UFLCS55omy4iW8p39LoPpOF9BtsGTcxhQCKgBGAs/s1600/20180725_190744.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally, the light up the mast was disconnected, which was a good thing, since the casing for that light was missing too. When I bring the mast down for transportation to the drydock for repairs, I'll replace that light. For now, I'll do without.
&lt;/p&gt;
&lt;h3&gt;Solar&lt;/h3&gt;
&lt;p&gt;
    The really interesting part was the setup of the solar system, though again it was surprisingly easy once I got past my fear of lighting something on fire. The truth is the current was limited to about 2 Amps so the chance of a fire is really zero. Still, using too small a gauge wire could have led to some overheating perhaps so it was good that I used 12 gauge stereo installation wire.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-UGYDFBT9iTg/XEaClT1EDwI/AAAAAAAADT0/DYfxVt0t790-RsIPku87KJ-l-TQ9TaemQCKgBGAs/s1600/20180828_175812.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Setup was really just as simple as attaching the voltage regulator to the battery, then to the solar panels, and finally to the load. I really think anyone could set up a solar panel system this simple.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Tzuha2Ku_iw/XEaCt3oJuSI/AAAAAAAADT4/_A0liPqn7dgm26zAXZ79sv2G7VmYWW6RQCKgBGAs/s1600/20180828_184933.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The monitoring on the charge controller is so helpful as it gives an update on the voltage state of the battery as well as input and output currents. Even when quite cloudy the solar panel can bring in 0.1 A and at full brightness 1.8 A.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-6xEBCxXmma4/XEaC2BEq1sI/AAAAAAAADT8/ENTKgfiMn8AINOwW8a7-e1ztsrlKmKMwACKgBGAs/s1600/20180828_173607.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-_MERW8G7w4M/XEaC2OTQc9I/AAAAAAAADT8/Qm05gqYb5kMEQlSoV35gOAlyoPzxT_MoACKgBGAs/s800/20180828_182043.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I ran the wiring to the exterior solar panel through the motor exhaust port at the stern. To begin, I just tested the panel by propping it up in the cockpit of the boat. I wanted to ensure that the charge controller really would limit the voltage when unsupervised to prevent degassing of the battery when overcharged. Indeed after getting up to 14.3 V for a few minutes it would normally top out and move to trickle charge mode, where it held at approx. 13.1 V indefinitely. I left plenty of extra wire to extend the panel where I need it, but I expected to cut that down when I found a more permanent position.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-TwjmvwRTCVE/XEaC-LaSjpI/AAAAAAAADUA/Txsw4gDkD4s8w-AtuizsUO5Fx4c5dO1WgCKgBGAs/s1600/20180828_185959.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I installed the charge controller on the panel near the door so that I could keep an eye on the charging voltages for now. I attached it with one screw so that I can take it off soon and affix it to the top paneling in a less conspicuous place.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-wkkiKdXuCRM/XEaDD8BtnVI/AAAAAAAADUE/beFmNFXUMDgo7ed9Du4-TXHDs5wpETQSACKgBGAs/s800/20180829_081202.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    One great feature of the charge controller is the USB lines, which I can now use to charge small devices.
&lt;/p&gt;
&lt;h6&gt;The Mount&lt;/h6&gt;
&lt;p&gt;
    To allow me to move the panel out of the way and to avoid disrupting woodwork and fiberglass I decided not install the panel. Instead, I simple prop it up on the side whenever I need to charge. Then when we take it out to sail, I place it in the cardboard and slip it back under the cockpit.
&lt;/p&gt;
&lt;h4&gt;Next steps&lt;/h4&gt;
&lt;p&gt;
    There are a few other electrical devices that I might want to add, but at the moment I worry about them drawing too much power for the little battery I have. I have a DC trawling motor that I would love to set up, and I've put together an attachment for a small Peltier cooler. Both of those drain the battery fast so I'll probably need to devise a double battery setup before I can use them. That way even if those drain the energy, I can have a backup to run emergency power for the radio and bilge pumps.
&lt;/p&gt;
&lt;p&gt;
    All in all, the electrical turned out to be quite a bit easier than I thought. It was a good starter before I move onto the next big challenge: plumbing.
&lt;/p&gt;</description>
        <pubDate>Wed, 01 May 2019 21:46:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/05/ionis-solar-electrical-system/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/05/ionis-solar-electrical-system/</guid>
        
        <category>boatwork</category>
        
        <category>energy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://1.bp.blogspot.com/-_tf3KY6IKew/XJsCuBf0TGI/AAAAAAAADmg/hP2k6zaGSokoPBK_4Vhn2Svv2bjpIdz1wCLcBGAs/Screen%2BShot%2B2019-03-26%2Bat%2B9.57.17%2BPM.png</image>
        <title>Visualizing shared budgets and dividing up household expenses fairly</title>
        <description>&lt;p&gt;
        My partner and I have been tracking our finances ever since we moved in together back in 2014. Originally, we started just tracking our shared expenses like rent and groceries in order to make it easier to divide our household contributions &lt;a href=&quot;http://lesswrong.com/lw/ru/the_bedrock_of_fairness/&quot;&gt;*fairly*&lt;/a&gt; (for more, check out the post on our &lt;a href=&quot;/2017/08/the-stedden-constitution.html&quot;&gt;Marriage Constitution&lt;/a&gt;).
    &lt;/p&gt;
&lt;p&gt;
        Figuring out how much we each owed was easy when Claire and I earned the same graduate student stipend and lived in the same place, but eventually we started to have time varying incomes and a more complex expense structure. It was starting to get tricky to sort out who owes what. To solve this, we came up with a more sophisticated way to track and visualize how much we earn and spend. I ended up writing some analysis code into a simple &lt;a href=&quot;http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html&quot;&gt;jupyter notebook&lt;/a&gt; along with a python package for refreshing the data from our records on Google Sheets.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-tDlDpiBZNmE/XJsATOh1E8I/AAAAAAAADmU/nivn8xwtMaIdr_YYYWPKs68DakWf71iOQCLcBGAs/s1600/Screen%2BShot%2B2019-03-26%2Bat%2B9.46.36%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The code is available on the &lt;a href=&quot;https://github.com/lots-of-things/ipy-budget&quot;&gt;lots-of-things GitHub&lt;/a&gt;, and I made some &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1XiSlpguUG_YGU9TQ0b8dJheeCMYNR6xNAg_cluXsrGk/edit?usp=sharing&quot;&gt;dummy budget data&lt;/a&gt; on Google Sheets. Read on for more details and background.
    &lt;/p&gt;
&lt;h4&gt;The Theory&lt;/h4&gt;
&lt;p&gt;
        With our budget, my partner and I are trying to experiment with a small-scale semi-utopian &lt;a href=&quot;https://www.aeaweb.org/articles?id=10.1257/jep.30.1.225&quot;&gt;economy&lt;/a&gt;. Economics is interesting to me because I love the concept of quantizing the costs and benefits of our choices. Of course, money is an imperfect way to quantify all the multitude of factors that go into our definition of value, but I do fundamentally prefer imperfect metrics to fuzzy subjective definitions of value, particularly when trying to define fairness of value in a multi-party situation. I've always thought that keeping things qualitative gives unfair advantage to those who can argue eloquently (or whine loudly). Since I'm interested in an experiment with small organization economics, it's really useful to have a system in place to track, analyze, and experiment with our financial data on the finest grain we can.
    &lt;/p&gt;
&lt;h4&gt;Overview of expenses and income&lt;/h4&gt;
&lt;p&gt;
        When we were first getting started we were only interested in categorizing our expenses into shared and separate to know who was paying for what out of their own pocket. However, we quickly realized that since we were doing all this categorization anyway, it would be really useful to label our expenses a little more granularly so we could analyze what our spending habits looked like over time.
    &lt;/p&gt;
&lt;p&gt;
        Over time, we started incorporating more detail to bin our expenses into the following categories:
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;income&lt;/strong&gt; - gross income from our employers or any side-hustles &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rent&lt;/strong&gt; - our primary housing related expenses and some utilities &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;groceries&lt;/strong&gt; - any essentials bought from the market, includes alcohol purchases from the store &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;household&lt;/strong&gt; - broader category for non-food but still fairly essential things around the house &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;recreation&lt;/strong&gt; - broad category for things we did just for fun, eating and drinking out, throwing parties, etc &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;medical&lt;/strong&gt; - insurance and medical bills &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;transit&lt;/strong&gt; - public transit and rideshares &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;car&lt;/strong&gt; - gas, insurance, repairs &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;boat&lt;/strong&gt; - boat purchase, slip fees &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;flights&lt;/strong&gt; - any airfare (excludes frequent flier miles though) &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;donations&lt;/strong&gt; - charitable organizations &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gifts&lt;/strong&gt; - things we buy to give to others &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;wedding&lt;/strong&gt; - separate category for all of our wedding expenses &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;work expenses&lt;/strong&gt; - things we buy to do our work, often reimbursed &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;taxes&lt;/strong&gt; - tracking tax withholdings and refund &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        In addition, we have two more that are a little different than normal income/expenses. I'll talk more about these categories later and our debate in how to think about them.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;investments&lt;/strong&gt; - treating investments like an expense that will have a future return (hopefully) &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;redistributions&lt;/strong&gt; - transfers from one party to another to help even out the burden &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        At the time when we first started tracking all these categories, it seemed like overkill, but now, years later, I'm glad we did it. This lets us uncover some neat insights into how our spending in each category changed over time. As an example, here we could see our spending on airfare.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-_tf3KY6IKew/XJsCuBf0TGI/AAAAAAAADmg/hP2k6zaGSokoPBK_4Vhn2Svv2bjpIdz1wCLcBGAs/s1600/Screen%2BShot%2B2019-03-26%2Bat%2B9.57.17%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This started to climb in late 2016 when I moved out to California, and we started flying back and forth constantly. It should drop down to nearly zero this year as we start to get our flying habit back under control. We can view this same sort of figure across many different categories of spending too.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-nkcmDZzWkjo/XJsKx2_w7jI/AAAAAAAADm0/4zzZMyFUQhoxhVh73jTQ8wvYcxLlwoCKgCLcBGAs/s1600/Screen%2BShot%2B2019-03-26%2Bat%2B10.31.32%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        One thing that these plots point out is that the spending is not uniform between Claire and myself. Normally, Claire ends up spending a lot more than me. This isn't because Claire is going on shopping sprees or anything; she just ends up taking on a greater proportion of the household and grocery spending. This brings us to the next topic: redistributing money to make up for differences in expenses.
    &lt;/p&gt;
&lt;h4&gt;Splitting Expenses&lt;/h4&gt;
&lt;p&gt;
        As mentioned above, a key reason for doing all this is to determine a fair way to divvy up our money based on income and spending. We've heard that money arguments can lead to failed relationships so we wanted to preempt the arguments by coming up with a reasonable way to discuss things and make fair decisions.
    &lt;/p&gt;
&lt;h6&gt;Why not just divide evenly?&lt;/h6&gt;
&lt;p&gt;
        A lot of couple's seem to suggest the &quot;put equal amounts into a shared account method.&quot; I don't think that method is really adequate for two reasons. First, I think that the person who makes more money should have to pay more of the expenses. This feels justified because the combined lifestyle should be reflected by the combined income. Splitting evenly would mean either the overall money spent is lower than we can afford OR that the person who makes less will have to allocate more of their money to expenses. Either way this is non-optimal and should be prevented with some differential contribution to the shared coffers.
    &lt;/p&gt;
&lt;p&gt;
        The second set of reasons are more about why using a bank account is worse than directly monitoring spending. Just blindly dropping money into a shared account is inefficient and can also can incentivize bad actions. If there is leftover shared money, both parties are incentivized to spend it up rather than reallocate it to savings. Also there is an inherent inefficiency if extra money starts piling up in the shared account rather than being reallocated to investment accounts.
    &lt;/p&gt;
&lt;p&gt;
        So we wanted to come up with a better way to combine our assets, but still keep autonomy and flexibility.
    &lt;/p&gt;
&lt;h6&gt;From each according to his ability, to each according to his needs&lt;/h6&gt;
&lt;p&gt;
        The most reasonable method we could come up with was to split our expenses based on our proportion of income. This method makes perfect sense both in the limit where one person is making all the money and when everyone makes the same amount. And it seems like the most reasonable starting place for a fair division.
    &lt;/p&gt;
&lt;p&gt;
        Initially, we figured it would be easy to just add up our monthly or quarterly income along with our expenses and divide evenly. However, a simple thought experiment shows why it makes more sense to use our cumulative income and expenses.
    &lt;/p&gt;
&lt;h6&gt;The Lottery&lt;/h6&gt;
&lt;p&gt;
        Imagine that in a relationship, one partner makes all of the money, while both partners spend about the same amount month to month. Clearly, the partner that makes all the money needs to reimburse the other or else the non-earning partner will not have any money to spend! That is just fair. Now imagine that the non-earner were to buy a lottery ticket and win a million dollars on one day. If they were basing their split on that month then clearly the lottery-winner/normally-non-earner would have to pay for almost everything that month. However, compared to the monthly expenses their would still be tons of cash left over, which the non-earner would get to bank at the end of the month. Then, the next month the non-earner's income would go back to zero, and the earning partner would have to go back to supporting both parties. Clearly this would be unfair. A similar argument explains the unfairness if the couple have time-varying expenses too. Hence, it is more fair to divvy up the total cumulative expenses based on the partners cumulative income.
    &lt;/p&gt;
&lt;p&gt;
        This might not be a huge difference in practice though, so it made sense to compare the two methods using our real data.
    &lt;/p&gt;
&lt;h4&gt;Local vs Global Income and Expenses&lt;/h4&gt;
&lt;p&gt;
        I wanted to compare the method of using the short-term (local) and cumulative (global) expenses and incomes for the split of money. Because I already have all the data in an unaggregated form, it's easy to use pandas to get a cumulative sum of the expenses.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;income['total quarterly income'] = income['c']+income['w']&lt;br/&gt;income['total cumulative income'] = income['total quarterly income'].cumsum()&lt;br/&gt;income['Claire\'s local share of income'] = income['c']/income['total quarterly income']&lt;br/&gt;income['Claire\'s global share of income'] = income['c'].cumsum()/income['total cumulative income']&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        As a first step, we can plot these two methods of breaking down our income. In the graph below, I plot the share of our total income that Claire brought in as a proportion of our total. We expected that we'd look roughly equal up to the start of 2017 and then Claire would make up about one third of the income.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-JtIZmatjR3c/XJulGNnVqsI/AAAAAAAADnM/exbQu1otpLgXiRCKVckgNXIGQoi3LtNtwCLcBGAs/s1600/shareincome.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        That turns out to be the case for the local method, but for the global method she slowly shifts from 50% toward ~30%. This smooths out the step change in my income because over a long enough time, fluctuations in income become less important.
    &lt;/p&gt;
&lt;p&gt;
        In Q1 2019, Claire stopped working as she transitioned between grad school and her first job. Clearly with the local method, Claire's income drops to zero, and so her share of expenses should be zero. However, using the global method, her income in prior periods still counts, though less and less over time.
    &lt;/p&gt;
&lt;p&gt;
        Similarly our local split of expenses zig-zags also all over the place, but that is smoothed out in the global method.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-GGw49_19mzw/XJuoDWjN5JI/AAAAAAAADnY/5j3ANMg-G8AehnlE7_Z2f2uO-AkwIgkLACLcBGAs/s1600/shareexpense.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        So with the aggregated income and expense data, we can calculate what we each should have paid and what we ended up paying.
    &lt;/p&gt;
&lt;h4&gt;Calculating the overpayment&lt;/h4&gt;
&lt;p&gt;
        Using the local and global methods, I can calculate the fair allocation of Claire's expenses by multiplying Claire's fair share of expenses by the true expenses. I can then perform another cumulative sum to see the gap between what Claire has really paid to date and what she should have paid. Finally, the difference between those lines is the overpayment by Claire (ie the money I owe her).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-pn5saTsKb9c/XJuo-NFVAyI/AAAAAAAADnk/yIOQGK_N6rka9ULuthU8_SqY9rVuYEn6gCLcBGAs/s1600/payment.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Right around the beginning of 2017 was the last time that Claire and I redistributed money. It was also when I started my post-grad job and started earning more. You'll notice that the global method actually means Claire is owed more money from me. It comes to about $1000 dollars which is real money. I guess that's what I get for trying to do things more fairly!
    &lt;/p&gt;
&lt;h6&gt;Counting Investments?&lt;/h6&gt;
&lt;p&gt;
        One thing that we are still trying to figure out is how investments should be tracked. There are basically two ways to think about them.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ignore investments&lt;/strong&gt; - Investments are really just moving your income around between accounts&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Investments as expenses&lt;/strong&gt; - Investments are treated as expenses until they are withdrawn &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        It's hard to decide which way to think about investments. I personally like the idea of thinking about them as current expenses. This makes investments similar to other large capital purchases that might pay off later. For example, buying a car means an expense today with a possible payout later (though less than the initial value probably). Investments are just the same except that they can earn more money.
    &lt;/p&gt;
&lt;p&gt;
        The issue is that then all one partner has to do is invest all of their money to make it look like they have no income. That could lead to bad behavior, but realistically, the same could be said for any expenses (spending all your money on things that go to yourself means you don't have to share anything). The point of the budget is to identify where one partner is over-spending or over-investing and to allow a debate about whether that is wise. Importantly, if one partner makes a bad investment they probably shouldn't be penalized by having to count the investment as their personal income without being able to count the loss. Furthermore, either partner can decide that they want to take on investing more money and there can be a redistribution of income to compensate. It all just comes down to a negotiation and an ability to justify the expense for the good of the team.
    &lt;/p&gt;
&lt;p&gt;
        This, to me is the argument for treating investments like normal expenses until withdrawn. However, Claire and I still need to work out whether that is a reasonable way to think about it.
    &lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;
        In the end, all of this just goes to remind me how lucky I am that I've been able to have stable finances in my adult life. Going through this exercise was really important for seeing how our spending habits are evolving as our lifestyle changes, and it's been useful in articulating our goals for our financial future. We will continue to use this method to redistribute income in the future, and I will update if we arrive at any new methodologies that are worthy of note. I can also see this paradigm working in a larger coop-like organization, and I'm curious to see if Claire and I ever get to incorporate these ideas into something like that.
    &lt;/p&gt;
&lt;h4&gt;Appendix: Securely querying Google Sheets data in python&lt;/h4&gt;
&lt;p&gt;
        One of the things that made this so easy was the ability to get the data out of google sheets and into a jupyter notebook where we could more cleanly perform the analyses we needed for this project. It would have been very messy to do all this work directly in the spreadsheet. &lt;a href=&quot;https://www.stitchdata.com/blog/google-sheets-stitch-easy-sync-to-redshift/&quot;&gt;Many&lt;/a&gt; &lt;a href=&quot;https://blog.usejournal.com/how-to-use-google-sheets-as-a-cms-or-a-database-f9d8e736fdce&quot;&gt;others&lt;/a&gt; have found this separation of data entry and front-end/analysis to be really effective too.
    &lt;/p&gt;
&lt;p&gt;
        I also built a little &lt;a href=&quot;https://github.com/lots-of-things/ipy-budget/blob/master/ipy_budget_api.py&quot;&gt;wrapper python package&lt;/a&gt; for the gsheets api that is specifically designed for grabbing data in this format. The package calls up the &lt;a href=&quot;https://developers.google.com/sheets/api/guides/authorizing&quot;&gt;Google Authentication flow&lt;/a&gt; to securely allow connection to your own GSheets. This greatly reduces friction from downloading and manually storing files all over.
    &lt;/p&gt;
&lt;p&gt;
        If you like this project and want to replicate the workflow for yourself feel free to fork the repo and make modifications. I could imagine this could be a start to a really lightweight DIY budgeting analysis toolkit. In future editions I hope to build some piping for automated download of financial statements and import into gsheets and maybe even auto classification and analysis. This seems really preferable to shopping this out to a third party like mint for the security and privacy reasons.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 03 Apr 2019 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2019/04/visualizing-shared-budgets-and-dividing/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/04/visualizing-shared-budgets-and-dividing/</guid>
        
        <category>data science</category>
        
        <category>philosophy</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://4.bp.blogspot.com/-BWDJKx2T98s/XHoHhskJ7II/AAAAAAAADdg/Pq0bXqvX5JQlK0k3BE7WU03U43wnylRXwCKgBGAs/20181210_083237.jpg</image>
        <title>Redwood Planter Cabinet</title>
        <description>&lt;p&gt;
    My &lt;a href=&quot;https://www.instagram.com/mysfmountain/&quot;&gt;friend&lt;/a&gt; had really been wanting to build his own &lt;a href=&quot;https://www.pinterest.com/pin/72972456436478855&quot;&gt;green wall&lt;/a&gt; in his back yard in the Mission in SF. So this winter, we took a weekend, planned it out, and built it. Here's the haphazard, meandering process we went through.
&lt;/p&gt;
&lt;h4&gt;Planning&lt;/h4&gt;
&lt;p&gt;
    We didn't really know what we could pull off on this project. We started by mapping out a few sketches.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-VdRrf5EznCk/XHoGwrXbzVI/AAAAAAAADdM/BJIAmNy-IZ8fjzatEyH_G7IoCzYTx3ZLgCKgBGAs/s1600/20181208_205806.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Although the &quot;floating boxes effect&quot; seemed really cool, we ultimately figured it'd be too tough to implement. We also toyed with doing almost closed sides sort of like a moving pallet, but thought it might be too much wood and look too shabby if it were reclaimed material. We went with a basic shelf-trough sort of design instead.
&lt;/p&gt;
&lt;p&gt;
    I grabbed a few native plants from the nursery at the Presidio after a &lt;a href=&quot;https://www.facebook.com/events/874448542679077/&quot;&gt;planting day&lt;/a&gt;, which we assumed would be generally resilient to weather in the area. The backyard area wasn't going to be getting much light so I picked a some strawberries that the Presidio naturalist had selected for a shadier area.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-lSDLyTI3qL0/XHoGwnhVJWI/AAAAAAAADdM/1mh6Oaa9wQk0q0PIsCf_uEVR3GIswjHyACKgBGAs/s1600/20181208_122620.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Breaking ground&lt;/h4&gt;
&lt;p&gt;
    With a rough plan in hand, we started stitching things together. We dug out the post holes to be filled with 4x4 posts and dropped them in to size approximately.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-E5r_mrmxwFA/XHoHKcJCdrI/AAAAAAAADdU/gY3KEoxyc2Qpx5nmaOeIPP777fID4UecwCKgBGAs/s800/20181209_094816.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We did the entire project without any power tools. Here is Sam sawing away. I found it pretty exhausting. I think we needed about 12 cuts, but we obviously ended up doing a lot more. Fortunately, all the cut surfaces were interior.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-f_lbed6ftq4/XHoG-LDVIhI/AAAAAAAADdQ/w_qB2fFrpiMEgJ4rEdL_XcH1MYkvRQztwCKgBGAs/s800/20181208_181937.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Assembly&lt;/h4&gt;
&lt;p&gt;
    During planning, we didn't think about how flimsy the connections were going to be between the posts and the bottom 2x4 of the shelves. Fortunately, the interior of the shelves would be filled with dirt and wouldn't be visible so we could add some ugly reinforcements to the corner of the shelves on the inside.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ObzxCQ1UITU/XHoHKUZ-N9I/AAAAAAAADdU/79FOF9u6fSkkzkBgMock0GvilFbJNFwKQCKgBGAs/s800/20181208_203332.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    That made the frame much more sturdy so we could afford to move it around without fear of completely tearing out the ends of the 2x4s.
&lt;/p&gt;
&lt;p&gt;
    We assembled 3 shelves straight across for simplicity and structural support. /p&amp;gt; &lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-LgxIXSOoKUc/XHoHKbRV3MI/AAAAAAAADdU/CiGruuuMcQgLdJpWze2hz8PpIyTH0AhsQCKgBGAs/s1600/20181209_094042.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        After the frame was assembled we finished out the post holes (using a spoon!) and dropped the frame inside. Well, we almost did. Except that we were off by about a half inch and ran into a sliver of foundation concrete. We chipped it back so the posts could just slide in.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-4azjRkj0w6Y/XHoG-Clb8GI/AAAAAAAADdQ/WjMsXt0OW_8tuPQeQli5kShEAR0EXfwlACKgBGAs/s1600/20181208_175451.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Finally, we started screwing the redwood slats onto the outside to make the soil troughs.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-tXFPZ90WT7o/XHoHKcJW5LI/AAAAAAAADdU/J-9ByG-aH3Y6kjt5khQi9MEdXTDd9CGKwCKgBGAs/s800/20181209_110746.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        By some miracle when all was said and done both the posts and all the shelves were somehow perfectly level. We didn't actually use a level until the posts were set in the gravel!
    &lt;/p&gt;
&lt;h4&gt;Planting&lt;/h4&gt;
&lt;p&gt;
        We filled with a bit of soil and fertilizer and then we planted.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-isYwAyTCFig/XHoHT7qItQI/AAAAAAAADdY/2Nr2RBAdFFcNuePK8nPbFIF3a-EgrsUoACKgBGAs/s800/20181209_220704.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Sam looks happy with the process.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-hYyGLGwdVEA/XHoHb_kY4TI/AAAAAAAADdc/-uOuARWe-T0GdxKE1biBmXZf2so7tVyrACKgBGAs/s800/20181209_214541.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Result&lt;/h4&gt;
&lt;p&gt;
        The vegetation is still a little less than filled out. I will update as we roll on through the year and hopefully get a bit more sunlight. Still, it already adds a lot to the ambiance of the backyard, in my humble opinion. Perhaps, I'll grab a few more plants soon.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-BWDJKx2T98s/XHoHhskJ7II/AAAAAAAADdg/Pq0bXqvX5JQlK0k3BE7WU03U43wnylRXwCKgBGAs/s800/20181210_083237.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Update 1&lt;/h4&gt;
&lt;p&gt;
        They made it through the rest of winter at least!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-TnbQNHBe0DM/XH3v4ufb1vI/AAAAAAAADeQ/vmI1xoUeT-8lXOU_g3AfULei7NOyPQ_XQCKgBGAs/s800/20190302_082724.jpg&quot; title=&quot; &quot;/&gt;&lt;/p&gt;</description>
        <pubDate>Mon, 04 Mar 2019 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2019/03/redwood-planter-cabinet/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/03/redwood-planter-cabinet/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-qTlakxg1tSI/XEZ7ycNPETI/AAAAAAAADSw/LoxKdWkuP38S3ohYzk6nlPtHPfubg0yBwCLcBGAs/20181218_191642.jpg</image>
        <title>Human Ivory Earrings</title>
        <description>&lt;p&gt;
    Ever since working on my partner's &lt;a href=&quot;http://www.makeloft.org/2017/04/engagement-ring-from-found-smoky-quartz.html&quot;&gt;engagement ring&lt;/a&gt; last year, I've become more and more interested in making custom jewelry for people. Recently, I happened upon another interesting raw material, and I decided to see what I could make.
&lt;/p&gt;
&lt;h3&gt;Sustainable Ivory&lt;/h3&gt;
&lt;p&gt;
    Mammal teeth and tusks are made of the same thing, &lt;a href=&quot;https://en.wikipedia.org/wiki/Ivory&quot;&gt;dentine&lt;/a&gt;. So, when I had my wisdom teeth removed, I kept them to try to fabricate some &quot;sustainable ivory&quot; jewelry from them.
&lt;/p&gt;
&lt;p&gt;
    I'll spare showing you my cavity filled wisdom teeth in their raw form.
&lt;/p&gt;
&lt;p&gt;
    I grabbed my Dremel and started carving a spiral groove around the edges. After cutting away a bit of that and turning the shape a little, I had the following.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-cmYifuWlGsg/WslIToIma2I/AAAAAAAABc4/GIxJxvHwXNoaNj7hn_jTaIH32Ar1ENw0wCKgBGAs/s800/IMG_20171223_100539.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I continued thinning down that shape for a while, until I accidentally took it just a bit too far, and one of them shattered into multiple pieces. Kind of sad, but on the other hand, they were a little large for earrings. Instead, I ended up wrapping the remaining one in a bit of steel wire, to be used as a necklace pendant.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-qTlakxg1tSI/XEZ7ycNPETI/AAAAAAAADSw/LoxKdWkuP38S3ohYzk6nlPtHPfubg0yBwCLcBGAs/s1600/20181218_191642.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I found &lt;a href=&quot;https://majeruslucie.eu/H-U-M-A-N-I-V-O-R-Y&quot;&gt;another artist&lt;/a&gt; who did &lt;a href=&quot;https://www.treehugger.com/sustainable-product-design/human-ivory-lucie-majerus.html&quot;&gt;something similar&lt;/a&gt; before. Hopefully people aren't too weirded out by the idea as it seems a hell of a lot more reasonable than poaching ivory or sending people into mines for stupid shiny shit.
&lt;/p&gt;</description>
        <pubDate>Mon, 21 Jan 2019 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2019/01/human-ivory-earrings/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2019/01/human-ivory-earrings/</guid>
        
        <category>art</category>
        
        <category>design</category>
        
        <category>craft</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-k7IGUdP6QFE/XJGdGWRt_0I/AAAAAAAADkQ/NBd_jknvCxcIo_HMZqkWvSGYNu1GdkfSgCLcBGAs/Screen%2BShot%2B2019-03-19%2Bat%2B6.52.54%2BPM.png</image>
        <title>@rtifice Website Revamp</title>
        <description>&lt;p&gt;
    A few months ago, a non-profit I volunteer for &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;@rtifice tech education&lt;/a&gt;, needed to get its digital face revamped. I spent a few weeks working on a full website and blog revamping.
&lt;/p&gt;
&lt;h4&gt;Page loads and information&lt;/h4&gt;
&lt;p&gt;
    There were two main problems with the non-profit's web presence. First off, the website looked totally amateur and was filled with out of date information. This is, of course, completely normal for most non-profits, but it wasn't a great face for an after-school computer coding program. The second problem was that the blog was really slow to load. It was implemented with a very hacky &lt;a href=&quot;https://www.blogger.com/&quot;&gt;Blogger template&lt;/a&gt;, which also looked pretty unprofessional. For that one, I have to take &lt;a href=&quot;https://www.makeloft.org/&quot;&gt;full responsibility&lt;/a&gt;.
&lt;/p&gt;
&lt;h4&gt;Website update&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-T5rzXljjES0/XJGa9Tz3GBI/AAAAAAAADj8/sTYEihTjRjwyqL62S6rAgsV4VfgVpHy9ACLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.43.16%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The former admins had switched the whole codebase to reside in &lt;a href=&quot;https://pages.github.com/&quot;&gt;Github Pages&lt;/a&gt;, so I could easily make updates and we all could review remotely. Much simpler than the old days of SCPing your code onto a server somewhere.
&lt;/p&gt;
&lt;h6&gt;Jekyll&lt;/h6&gt;
Originally, the admins had been using totally static pages. I could have kept the same, but I've found that whenever there are changes to things in the nav menu, people (including me) inevitably forget to update them across all pages. That makes for an impossible navigation experience as users try to get to places that can only be gotten to from 1 of your pages.

&lt;p&gt;
    Instead, I decided to switch to using a &lt;a href=&quot;https://talk.jekyllrb.com/t/jekyll-theme-showcase-share-your-jekyll-themes/1382&quot;&gt;jekyll template&lt;/a&gt;, which would allow me to make site wide edits in one location. I based it on a template from a company called &lt;a href=&quot;https://cloudcannon.com/&quot;&gt;CloudCannon&lt;/a&gt; that released their template for open reuse with modification.
&lt;/p&gt;
&lt;p&gt;
    I was really happy with the main landing page. It used a lot of images, but also had good space for us to put our mission front and center.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-r0jFvaC6-r4/XJGesiq_z0I/AAAAAAAADkc/ec5uwUML5boZa8QxCwEY-vRgyVsIuWU1wCLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.52.54%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I also added two additional pages that were mostly implemented in the template already. One was a community page that allows us to show how many amazing people work together to make our projects happen. The second was a lightweight CMS for big news in the organization. That was really cool to write up the little blurbs about all the big milestones we'd had over the years.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-kkWs6Wbl7_s/XH39Jlnl6gI/AAAAAAAADfM/KJSlazp3KWApuxdPPHm3CbhIsnQdU8DLACLcBGAs/s800/Screen%2BShot%2B2019-03-04%2Bat%2B8.34.14%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    These were all relatively minor stylistic changes. It took a lot to design the flow of the website and figure out what content to surface, but the engineering challenges were minor. The main technical improvement came on the class signup page.
&lt;/p&gt;
&lt;h6&gt;Class Signup&lt;/h6&gt;
&lt;p&gt;
    The coolest new feature that I built was the ability to signup for classes on the website. On the old site, I'd added a page to add donations using Paypal's built in &lt;a href=&quot;https://www.paypal.com/donate/buttons&quot;&gt;donate button feature&lt;/a&gt;. Then when we needed to pay for classes we just directed them there and had them set the payment amount as their donation. I was pretty ashamed of how hacky that made the organization look.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-YhOAUkfBfqM/XJGaf1G4esI/AAAAAAAADjw/Fi9T3hPK7ZABL-rBzg29Cff3ykJS49IEgCLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.41.59%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;div style=&quot;text-align:center&quot;&gt;That was totally lame.&lt;/div&gt;
&lt;p&gt;
    So for this update, I wanted to make a clean form that allowed people to sign-up before being sent to a legitimate paypal payment page. It was technically very interesting because I had to do all of this without using a true database. So the record keeping had to be done entirely on the frontend with javascript, without any backend code.
&lt;/p&gt;
&lt;p&gt;
    To do this, I actually hijacked Google Forms, using some &lt;a href=&quot;https://blog.webjeda.com/google-form-customize/&quot;&gt;incredibly insightful info&lt;/a&gt; that I found from &lt;a href=&quot;https://twitter.com/webjeda&quot;&gt;webjeda&lt;/a&gt;. Basically, google's forms are just basic webforms, but they try to obfuscate a few fields, making it difficult to just create any customization of style. But if you figure out the real names of the form fields, you can simply make your form submit those fields to Google's backend. It's pretty brilliant.
&lt;/p&gt;
&lt;p&gt;
    The second big hurdle
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-esXp14lfrSE/XH389MIrasI/AAAAAAAADe8/wpH2vTZLjSg4BFssO3W3SM4JCBBnP25xwCLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.35.45%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I described all of our in-class programs in detail. And built CTAs (Calls to Action), that hopefully helped people see what they needed to do. Obviously, a more thoughtful designer to make improvements, but I worked with what I had here.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Hl8aAgIXbRo/XH389AYtqFI/AAAAAAAADe4/JjhKVoLosNAVlkZOdpkW4eh487CuwjzogCLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.35.58%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    But the real mindf**k came when I tried to combine this off-label usage of Google Forms with another off-label usage of Paypal form submission. And to do something that you aren't supposed to be able to do with HTML at all: use the same form fields in multiple form submissions! (The things that get me excited, I tell you.)
&lt;/p&gt;
&lt;p&gt;
    I found &lt;a href=&quot;https://blog.webjeda.com/google-form-customize/&quot;&gt;this writeup&lt;/a&gt; on how to customize Google Forms along with piecing together a few &lt;a href=&quot;https://pressupinc.com/blog/2014/03/easy-hacks-paypal-purchase-buttons/&quot;&gt;examples&lt;/a&gt; of hacking Paypal buttons into forms. Check out &lt;a href=&quot;https://github.com/artificechicago/artificechicago.github.io/blob/master/enroll.html&quot;&gt;the code&lt;/a&gt; for more detail, but basically I overrode the generic form submission to allow the forms to swap info back and forth between submissions.
&lt;/p&gt;
&lt;h6&gt;the gory details&lt;/h6&gt;
&lt;p&gt;
    The only way to make the submit occur from another form is for the submit button on the main form to be hidden, and to have it's label actually function as the button on another form.
&lt;/p&gt;
&lt;p&gt;
    This line hides the submit button on the main (Google) form
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;input type=&quot;submit&quot; id=&quot;submit-form&quot; style=&quot;display:none;&quot; value=&quot;Enroll In Course&quot; /&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Then here, I add the label to the second (Paypal) form with the &lt;bold&gt;for&lt;/bold&gt; keyword referencing it back to the submit button for Google.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;label id=&quot;enroll_button&quot; class=&quot;special_button&quot; for=&quot;submit-form&quot; tabindex=&quot;0&quot;&amp;gt;Enroll In Course&amp;lt;/label&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Everything in the Paypal form is actually hidden so that form just grabs a bit of info from the other form using javascript jQuery and passes it on (securely) to the Paypal authentication site. The code below is run because the forms submit action is overridden to run a custom function:
&lt;/p&gt;
&lt;pre&gt;onsubmit=&quot;submitPay()&quot;&lt;/pre&gt;
&lt;pre&gt;&lt;br/&gt;function submitPay() {&lt;br/&gt;    $( &quot;#name_paypal&quot; ).val( $( &quot;#name&quot; ).val() );&lt;br/&gt;    $( &quot;#paypal_return&quot; ).val( &quot;http://www.artificechicago.org/enroll/?transaction=&quot; + $( &quot;#secret_paypal&quot; ).val() );&lt;br/&gt;    $( &quot;#paypal_opened&quot; ).val( 'Yes' );&lt;br/&gt;    $( &quot;#enroll_button&quot;).css('background-color','#4182e4');&lt;br/&gt;    $( &quot;#paypal_button&quot;).css('background-color','rgba(120,120,120,.5)');&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    And after finishing on Paypal the user just returns to submit the Google form and it will include the payment confirmation info automatically.
&lt;/p&gt;
&lt;p&gt;
    I won't explain too much more because this is kind of mildly vulnerable to exploitation (though don't worry not in terms of any payment information leaking*). Basically the paypal and google forms pass some confirmation numbers back and forth so that the &lt;a href=&quot;https://www.linkedin.com/in/clairestedden/&quot;&gt;Treasurer&lt;/a&gt; can confirm the transactions went through in the account.
&lt;/p&gt;
&lt;p&gt;
    Overall, the new main site is much more user friendly and professional.
&lt;/p&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Blog update&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-LUhhb2Fqz7A/XJGbdRNBFDI/AAAAAAAADkE/aLNdA8uTEo4GZ4BhITRuSUO2ymNCuNJggCLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.46.01%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The blog update was less interesting because it was similar to things I had done before. I simply nabbed a free-to-use template from &lt;a href=&quot;https://www.templateism.com/&quot;&gt;Templateism&lt;/a&gt;, and started making my own tweaks.
&lt;/p&gt;
&lt;p&gt;
    I did spend a good bit of time trying to think of the best way to make the info on the website explorable too though. I made a few easily navigable landing pages that helped to highlight some of our favorite work over the years.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-5RP-DKocMJI/XH34I1W9gyI/AAAAAAAADeg/8aLXnx2FmJITShtoQjPvMLj0PQ46cvXDACLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.14.41%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-LMzxEcaM_zA/XH34I7cyObI/AAAAAAAADec/rW65up6ItlsV8XPL_iWeCylqC3nc8nQ-ACLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.15.14%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-VBPJ9qI3Srg/XH34I5L77xI/AAAAAAAADek/8cwgPG48df4o7smM0WTKf_PTI9TxzjtDQCLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.15.47%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I tried making the content more highly visible, and I think it paid off. Hopefully, the website helps to add some credibility to the organizations coding expertise and brings them more volunteers and students in the future.
&lt;/p&gt;
&lt;p&gt;
    * The vulnerability is that someone could figure out how to pass a boolean that says that the payment is confirmed even though it isn't. Still, part of @rtifice's ethos is that if you can figure out how to hack our systems you actuallyf deserve whatever tiny spoils you get.
&lt;/p&gt;</description>
        <pubDate>Sun, 02 Dec 2018 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2018/12/rtifice-website-revamp/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/12/rtifice-website-revamp/</guid>
        
        <category>design</category>
        
        <category>code</category>
        
        <category>infra</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://1.bp.blogspot.com/-3l5FjSZn1Ew/W7bsXFQuUyI/AAAAAAAAC3E/cHx_ncuyizkxbMEUF4i154hyodMWWUVwgCLcBGAs/abacus.png</image>
        <title>Experiential Puzzle Narrative</title>
        <description>&lt;p&gt;
        I recently completed a long-time dream of building my own experiential puzzle narrative, also known as an &lt;a href=&quot;https://en.wikipedia.org/wiki/Escape_room&quot;&gt;escape room&lt;/a&gt;. I ran it as an engineering social (not &lt;a href=&quot;https://en.wikipedia.org/wiki/Social_engineering_(security)&quot;&gt;this&lt;/a&gt;) at my current place of employment, &lt;a href=&quot;https://www.color.com&quot;&gt;Color&lt;/a&gt;. Below is some documentation on both the narrative and the mechanics that went into building the puzzles.
    &lt;/p&gt;
&lt;h4&gt;Be forewarned. Herein lieth a plethora of philosophical musings on storytelling and the nature of existence. Also spoilers.&lt;/h4&gt;
&lt;h3&gt;A Narrative&lt;/h3&gt;
&lt;p&gt;
        In actuality, the story that tied the game together came at the very end of production. But for the meta-narrative purposes of an expository blog post, I'm going to explain the game elements as they played out.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/--X_zBA-USyU/W7keM7mqe7I/AAAAAAAAC5g/Z8a5HYeLztsEkkUp30iw8KbsANi2Ki01gCLcBGAs/s1600/Westworld10HopkinsBeach.0.jpeg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The main delivery for the game mechanics was the tool &lt;a href=&quot;https://medium.com/@frank_meehan/slack-just-significantly-changed-their-home-page-b226769667bd&quot;&gt;&quot;Where work happens&quot;&lt;/a&gt;, Slack (yeah, right). I built a very simple &lt;a href=&quot;https://github.com/lots-of-things/the-game/blob/master/lurker.py&quot;&gt;message bot&lt;/a&gt; using &lt;a href=&quot;https://twitter.com/kn&quot;&gt;Katsuya Noguchi's&lt;/a&gt; &lt;a href=&quot;https://github.com/kn/slack&quot;&gt;slack API python wrapper&lt;/a&gt; to deliver a series of timed messages.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-1Y9g3rlF_TE/W7Ll_ayDPYI/AAAAAAAAC1A/21jcDci-I4U7k0ljCnfsW7mPYBgd1ZhwACLcBGAs/s800/Screen%2BShot%2B2018-10-01%2Bat%2B8.28.36%2BPM.png&quot; title=&quot;code found here &quot;/&gt;
&lt;p&gt;
        The game started by spitting out an urgent message sent by a mysterious DrF...
    &lt;/p&gt;
&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/PQ-r1U3Jvsw&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt; &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Consumer Rereation Services&lt;/h4&gt;
&lt;p&gt;
        In the story, a mysterious Dr F is warning our protagonist engineering team about an autonomous AI, named CRS, that has gone out of the creators control. This is the first cultural reference I embedded. CRS is the abbreviation of Consumer Recreation Services from the 90's David Fincher film, &lt;a href=&quot;http://screencrush.com/the-game-20th-anniversary/&quot;&gt;The Game&lt;/a&gt;—a fun little mindf*** for my 12 year old brain and a serious inspiration to me both in terms of this escape room and the general game of life that I frequently assume I am playing. Even though it's been mostly forgotten, it still sits right there next to &lt;a href=&quot;https://www.newsweek.com/2018/06/15/truman-show-jim-carrey-reality-show-delusion-960250.html&quot;&gt;The Truman Show&lt;/a&gt; and &lt;a href=&quot;https://geekprank.com/matrix-code-rain/&quot;&gt;The Matrix&lt;/a&gt; for keeping me looking over my existential shoulder. Interestingly, all three films start with &quot;The&quot; by coincidence (hmm?).
    &lt;/p&gt;
&lt;p&gt;
        Dr F alerts the team that her AI has left a note referencing a &quot;start sequence&quot; that Dr F just can't figure out.
    &lt;/p&gt;
&lt;h5&gt;GCCACC___G&lt;/h5&gt;
&lt;p&gt;
        Recognizable to the biologist or anyone with Google as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kozak_consensus_sequence&quot;&gt;Kozak consensus sequence&lt;/a&gt;, completed with an ATG. The first puzzle lead from main staging area to the smaller rooms each named after the nucleic acids Adenine, Thymine, and Guanine.
    &lt;/p&gt;
&lt;p&gt;
        Importantly, I specifically wanted this challenge to involve as much Google as the players wanted to use. I think that's crucial to making a game much more immersive. Phones are now extensions of our consienciousness so why cut someone off artificially during the game. What's more, it forces you to build something novel so no one can just google the answer directly. Finally, it embeds the puzzle inside of the whole universe, rather than cutting it off to just the silly arbitrary toys in the room around the players. Much preferable for my liking.
    &lt;/p&gt;
&lt;h4&gt;Haystack&lt;/h4&gt;
&lt;p&gt;
        After a basic misdirect for the password (&quot;the answer's right under your nose&quot;), I built a very software developer centric puzzle for the next challenge using just a computer &lt;a href=&quot;http://ask.xmodulo.com/boot-into-command-line-ubuntu-debian.html&quot;&gt;booted into command line&lt;/a&gt; to keep the mechanics simple and to the point. A full user interface might have made it easier to get lost on dead ends. Also, using the terminal makes for a great &quot;hacking the matrix&quot; vibe.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-rO97AzW6DQY/W7b3cMVWJDI/AAAAAAAAC3c/MxhVRP9VTj8kQdHi-PIhceD7Fkq-SZQhgCLcBGAs/s1600/Screen%2BShot%2B2018-10-04%2Bat%2B10.32.10%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The mechanic involves a single file on a computer. The file contains the names of hundreds of books. The only hint is the message &lt;em&gt;check the diff&lt;/em&gt;. This is a hint to the computer savvy that this file has had its changes tracked with a tool called git, allowing you to see each change recorded using the command
    &lt;/p&gt;
&lt;pre&gt;git diff &amp;lt;sha&amp;gt;&lt;/pre&gt;
&lt;p&gt;
        where &amp;lt;sha&amp;gt; refers to a long string of characters (e.g. 9427ce9792636fba8ddc9488dcf484e6afac982f) that refers to a unique change. Using a two way video chat between two rooms and a transparency revealed the location of the &quot;needle&quot; for this haystack. The diff between the &lt;em&gt;HEAD&lt;/em&gt; and the needle, suggested the book titled &lt;strong&gt;The Man in The High Castle&lt;/strong&gt; would lead to the next puzzle.
    &lt;/p&gt;
&lt;h4&gt;Multi-threaded&lt;/h4&gt;
&lt;p&gt;
        Simultaneous with the previous puzzle in another room, another subset of participants were discovering this puzzle box. Inside, there were allusions to a mysterious AH as well as the transparency needed for finding the needle, required in the other room.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-UO-Rea8CSZA/W7b6lcj7C4I/AAAAAAAAC3o/gP8GRAh9YuI4ECfATny3pL7f56ncjj6LACKgBGAs/s1600/20181002_221946.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In a third room, another group was discovering a seemingly unrelated set of three mathematical puzzles.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-FUsZV8AP5cA/W7kgbVTMvfI/AAAAAAAAC5s/Lpc6lifHmIEXM8CATyq4ztdv4SqshnAMACKgBGAs/s800/20180929_113755.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The parallelization was necessary due to the large number of participants in this game, but also served another purpose which surprised me. Since each individual had to discover non-overlapping information, the game could only proceed with significant communication. Also, in the post-game recapitulation, there was way more opportunity for cross-communication of sub-puzzles that weren't visible to everyone the entire time.
    &lt;/p&gt;
&lt;h4&gt;Surprise Guest Star&lt;/h4&gt;
&lt;p&gt;
        As a device to enable Slack based triggering of the plot resolution, I needed to work into the narrative an excuse for communicating with a third party over Slack. To do so without incurring the assumption of a real person on the other end, I expanded my cast of sentient robots. As a scientific laboratory we have a fair share of real robots carrying out various tasks around the company. One of our more charismatic bots happens to be named Alexander Hamilton.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-zhxe13a8MWU/W7b0_soEYXI/AAAAAAAAC3Q/Aw6ASCkf_VAmmpXicO1tJzfOiZ5RDM31ACLcBGAs/s1600/Screen%2BShot%2B2018-10-04%2Bat%2B10.21.27%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Having established the mechanism for game completion early, the participants now had to navigate the remaining clues.
    &lt;/p&gt;
&lt;h3&gt;Recursion&lt;/h3&gt;
&lt;p&gt;
        Inside the book they found a pair of sheets that led to the next puzzle. Also inside the book were numerous references to the I Ching. The I Ching (sometimes called just the Oracle) is an ancient Chinese text, used to perform some divination in conjunction with some random element (tossed sticks or coins).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-qjzFVu1H_z0/W7b78O1DCyI/AAAAAAAAC38/FtxkciYC3lUsd3z1g4sCPwSslxcZCyErACKgBGAs/s800/20180929_113948.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I find the The Man in the High Castle to be pretty brilliant at one of my favorite things in all of fiction: &lt;a href=&quot;https://en.wikipedia.org/wiki/Metafiction&quot;&gt;metafiction&lt;/a&gt;. I'll try to summarize succinctly. In the novel, Dick describes a parallel universe where Japan and Germany won WWII. Also in the novel, a man (living in Japan controlled Colorado) writes a novel about a parallel universe where the Allied Powers won WWII. In the novel, it is revealed that the author composed the narrative using the I Ching as his guide. In &quot;real&quot; life, PK Dick also utilized the I Ching to guide his own narrative decisions.
    &lt;/p&gt;
&lt;h5&gt;Spoilers...&lt;/h5&gt;
    Now I spoil the ending: the author learns from the I Ching that the story he wrote is actually the truth. By my reading, we can see the I Ching functioning accurately throughout the novel. I believe (not crazy: I found &lt;a href=&quot;https://blog.brian-fitzgerald.net/blog/2015/10/24/meta-fiction-story-and-philip-k-dicks-man-in-the-high-castle/&quot;&gt;others&lt;/a&gt;) we are supposed to interpret the I Ching as a revelatory voice of a true author (maybe Dick) transmitting to the characters in this story. Depending on your perspective on the nature of reality, one might conclude that the I Ching in our universe would then be a voice from the author of our universe. Of course, if the author from another universe were transmitting to the author in our universe what happened in his own universe, which looks a little more like that in the book, well, that would then introduce a lovely recursive &lt;a href=&quot;http://www.crystalinks.com/ouroboros.html&quot;&gt;Ouroboros&lt;/a&gt;.

&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-EgDqHosxmCk/W7cEjhYfoZI/AAAAAAAAC4U/B1BbGiyZhuYjMRg9jm8Pk4CqL3oqSmABACLcBGAs/s1600/birthday_card_by_paivatar-d68r562.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Also, I actually stumbled upon adding I Ching references to my narrative by accident with a later puzzle. That inclusion led me to the Man in the High Castle through a &lt;a href=&quot;https://thoughtcatalog.com/christine-stockton/2014/01/the-10-best-wikipedia-black-holes-for-curious-people-who-have-no-impulse-control/&quot;&gt;wikipedia black hole&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The slip of paper inside the book pointed to a sequence of numbers underneath the engineering teams' desks forming a 3 by 3 grid of numbers. A previous clue had led to an Android phone that could be unlocked by swiping the lock screen in the order of this pattern.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-yCVkHK8eiXs/W7cCH2sqY9I/AAAAAAAAC4I/E28VHilz-cYA2Mokyeg3jlB0tVOOxi1EQCLcBGAs/s1600/android_p_dp1_pattern.gif&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h3&gt;CAGE&lt;/h3&gt;
&lt;p&gt;
        On the phone, there are three icons. The first is a &lt;a href=&quot;https://github.com/lots-of-things/the-game/tree/master/cage_lock/ComboLock&quot;&gt;custom combo lock app&lt;/a&gt; that shows three tumblers. The other two icons are audio files. The first, titled &lt;a href=&quot;https://raw.githubusercontent.com/lots-of-things/the-game/master/cage_lock/John.mp3&quot;&gt;John.mp3&lt;/a&gt;, is 4 pure musical tones. The second, titled &lt;a href=&quot;https://raw.githubusercontent.com/lots-of-things/the-game/master/cage_lock/hint.mp3&quot;&gt;hint.mp3&lt;/a&gt;, consisted of 4'33&quot; of silence.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-z7FT9qviLCQ/W7cJcwDdTjI/AAAAAAAAC4g/Q_kBafqilrYzC1NWNTSfIvj3oBQ22-nXwCLcBGAs/s800/718fd0a08a06836728b3d512e31bf31e.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The solution to the combo was 4-3-3, a reference to John Cage's &lt;a href=&quot;https://www.npr.org/2000/05/08/1073885/4-33&quot;&gt;famous piece of silence&lt;/a&gt;. Interestingly, the desire for a musical clue was what spawned this puzzle and the subsequent discovery of the I Ching (and it's culminating puzzle). The choice of CAGE as the solution came about because I was trying to generate a topical solution that used the letters A through G. The connection between an escape room and the word &quot;cage&quot; is obvious, but I was pleasantly struck by the parallel strand connecting John Cage and the entire idea of &lt;a href=&quot;https://www.theartstory.org/movement-happenings.htm&quot;&gt;experiential artwork&lt;/a&gt;. Cage's &quot;happenings&quot; focused on removing artist control by forcing involvement by an unpredictable audience. This is, of course, the beauty of any experiential narrative—even the campy robot infused ones.
    &lt;/p&gt;
&lt;p&gt;
        It was this &lt;a href=&quot;https://en.wikipedia.org/wiki/Music_of_Changes&quot;&gt;wikipedia tryst with Cage&lt;/a&gt; that led me to the I Ching and later the High Castle. The solution to the puzzle drops the first big hint about the usage of the I Ching for the final stage of the puzzle.
    &lt;/p&gt;
&lt;pre&gt;John Cage was noted for his development of 'happenings' or experiential artwork. &lt;br/&gt;In addition to increasing audience participation, his work frequently relied on chance to determine the outcome.  &lt;br/&gt;He heavily utilized the hexagrams of King Wen's I Ching in his compositions.&lt;/pre&gt;
&lt;p&gt;
        I took a bit of inspiration from this turn of events:
    &lt;/p&gt;
&lt;h4&gt;After this point, all the puzzles I wrote were generated through a randomization process.&lt;/h4&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h3&gt;The Arousing Thunder&lt;/h3&gt;
&lt;p&gt;
        The mathematical puzzles allowed access to the last clue. A sheet of letters and numbers in a 10 by 14 grid.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-haoSofL-rDk/W7cO3Y7HfbI/AAAAAAAAC4s/bijOSSQpJd0LF2oNyNdASNfBafhiItrLgCKgBGAs/s1600/20180929_113845.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This grid could be combined with a color coded abacus that sits in our office to uncover a four character sequence of characters on each line.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-Wp_VYFzCUhs/W7khguV1hVI/AAAAAAAAC54/I1nkxYOsU9kL8FE19zSyvHcdlhJILrc5ACKgBGAs/s800/20180928_162616.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        A hint from Alexander Hamilton mentioned Unicode characters, which the software developers understood as being composed of 4 character hexadecimal codes like the ones they were looking at.
    &lt;/p&gt;
&lt;p&gt;
        At around this time, CRS made her appearance. As it turns out, &lt;a href=&quot;https://knowyourmeme.com/memes/the-cake-is-a-lie&quot;&gt;DR F was a lie&lt;/a&gt;.
    &lt;/p&gt;
&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/WCe7KT1kq2M&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;
        The I Ching and a random number generator helped me write this quite interesting poem.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-_KHNp0ViTyI/W7cPZAsoEpI/AAAAAAAAC40/1ouSgSY6Rf0RJoky1IKeZK9xcXqtBxxKQCLcBGAs/s1600/poem.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I won't reveal anymore except to say that the team discovered what CRS was missing. You can click this link to hear the finale audio.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lots-of-things/the-game/master/end.mp3&quot; style=&quot;font-family:'PT Sans';font-size:2em;background:#CCC;padding:10px;border-radius:10px&quot;&gt;Click for Finale Audio&lt;/a&gt;&lt;/div&gt;
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt; &lt;a href=&quot;https://tvtropes.org/pmwiki/pmwiki.php/Main/Denouement&quot;&gt;dénouement&lt;/a&gt; &lt;/h4&gt;
&lt;p&gt;
        Endings are hard. I felt let down by this one. I wish the game could continue. Maybe it does?
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-peQESzYxHWY/W7kh5xEJ6qI/AAAAAAAAC6A/vuS83Tp098UvpZz8vfQv6alm7wwKGWUygCKgBGAs/s1600/20180928_161306.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h3&gt;Puzzle Elements&lt;/h3&gt;
&lt;p&gt;
        Below are some notes on building a couple of the game elements.
    &lt;/p&gt;
&lt;h5&gt;Building Audio &amp;amp; Video Assets&lt;/h5&gt;
&lt;p&gt;
        The part of the production that really put this whole deal over the top was adding some movies to tie the narrative elements together. The audio was just a generic text to speech generator. I experimented with several until discovering the &quot;Emma&quot; voice on &lt;a href=&quot;http://www.fromtexttospeech.com/&quot;&gt;fromtexttospeech.com&lt;/a&gt;. It was understandable and wonderfully creepy. I layered this in on top of some &lt;a href=&quot;https://www.videezy.com/elements-and-effects/242-tv-static-hd-stock-video&quot;&gt;generic static&lt;/a&gt; that got even weirder when I compressed and downsampled it.
    &lt;/p&gt;
&lt;p&gt;
        for reference, I used the following ffmpeg functions to build the assets/
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://video.stackexchange.com/questions/12905/repeat-loop-input-video-with-ffmpeg&quot;&gt;loop input video static video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/11779490/how-to-add-a-new-audio-not-mixing-into-a-video-using-ffmpeg&quot;&gt;mix mp3 audio over video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://video.stackexchange.com/questions/12105/add-an-image-overlay-in-front-of-video-using-ffmpeg&quot;&gt;add image overlay to video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;Combo Lock App&lt;/h5&gt;
&lt;p&gt;
        I also built the combo lock app from scratch since I couldn't find anything that quite fit my needs. I used Android Studio, which I'd only used once before. The following links have all the info needed.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://developer.android.com/training/basics/firstapp/creating-project&quot;&gt;Start a project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/33053765/how-to-make-a-wheel-picker&quot;&gt;Wheel Picker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.zoftino.com/android-number-picker-tutorial&quot;&gt;More Number Picker Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://android--examples.blogspot.com/2015/05/how-to-use-numberpicker-in-android.html&quot;&gt;Add text on change&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://developer.android.com/reference/android/widget/NumberPicker#NumberPicker(android.content.Context)&quot;&gt;NumberPicker Object&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt; &lt;br/&gt;
</description>
        <pubDate>Sat, 06 Oct 2018 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2018/10/experiential-puzzle-narrative/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/10/experiential-puzzle-narrative/</guid>
        
        <category>games</category>
        
        <category>code</category>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-GjSpEzzqqlw/Wy6pybYkEBI/AAAAAAAACPA/tRxkLdkX4PcXN34Xgjo2J9GxAjNMgWZJQCKgBGAs/IMG_20180606_075423.jpg</image>
        <title>Introducing Ioni</title>
        <description>&lt;p&gt;
    I recently purchased a beautiful Dolphin 24 sailboat. The boat was manufactured in 1968 and has a &lt;a href=&quot;http://www.dolphin24.org/san_jose_dolphin.html&quot;&gt;great history&lt;/a&gt; compiled by Ron at &lt;a href=&quot;http://www.dolphin24.org/&quot;&gt;dolphin24.org&lt;/a&gt;. I'm honored to be a part of her story, and I hope to take great care of her over the next few years.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-GjSpEzzqqlw/Wy6pybYkEBI/AAAAAAAACPA/tRxkLdkX4PcXN34Xgjo2J9GxAjNMgWZJQCKgBGAs/s1600/IMG_20180606_075423.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    She came without a name so I plan to call her &lt;a href=&quot;http://greekmythology.wikia.com/wiki/Ione&quot;&gt;Ioni&lt;/a&gt;, after a Graecian &lt;a href=&quot;http://www.theoi.com/Pontios/Nereides.html&quot;&gt;sea nymph&lt;/a&gt; known for riding a dolphin, and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Ionians&quot;&gt;Ionian people&lt;/a&gt;—seafaring nation in the ancient Aegean, credited with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Ionian_Enlightenment&quot;&gt;founding of science&lt;/a&gt;. It also is a reference to the origin of the word &lt;a href=&quot;https://en.wikipedia.org/wiki/Ion&quot;&gt;ion&lt;/a&gt;. Claire came up with the idea to use a particle as a nod to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Wave%E2%80%93particle_duality&quot;&gt;wave-particle duality&lt;/a&gt;, which seems pretty appropriate for a sailboat.
&lt;/p&gt;
&lt;h4&gt;Rigged and Ready&lt;/h4&gt;
&lt;p&gt;
    The boat was in decent condition for sailing when I bought it, though it does need a bit of maintenance. Most of the issues are cosmetic though fortunately.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-C9qgUOJXJJM/Wy6snlZXlLI/AAAAAAAACPc/jDZgcjc61lAGFSkN7raveBWt7pDC2CwAACKgBGAs/s1600/IMG_20180511_191827.jpg&quot; title=&quot;
Sails rigged

Sails rigged
    &quot;/&gt;
&lt;div&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-sZ-oZ5uLKBs/Wy6snl321fI/AAAAAAAACPc/RhjwV4e38wACQTyHels0qsxWREwjwL1twCKgBGAs/s1600/IMG_20180511_184103.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://4.bp.blogspot.com/-sZ-oZ5uLKBs/Wy6snl321fI/AAAAAAAACPc/RhjwV4e38wACQTyHels0qsxWREwjwL1twCKgBGAs/s200/IMG_20180511_184103.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-kc-sNOPsuvw/Wy6snvpdQ8I/AAAAAAAACPc/aIUYw1WEjjoWdHesaFgwfZi5BDuSLZf0QCKgBGAs/s1600/IMG_20180511_184045.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://3.bp.blogspot.com/-kc-sNOPsuvw/Wy6snvpdQ8I/AAAAAAAACPc/aIUYw1WEjjoWdHesaFgwfZi5BDuSLZf0QCKgBGAs/s200/IMG_20180511_184045.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-KK_I-uTrtsI/Wy6snvdGRaI/AAAAAAAACPc/Xco0bb6aeK46KlXlqrHt1dPu7reVeJWrQCKgBGAs/s1600/IMG_20180511_184023.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://2.bp.blogspot.com/-KK_I-uTrtsI/Wy6snvdGRaI/AAAAAAAACPc/Xco0bb6aeK46KlXlqrHt1dPu7reVeJWrQCKgBGAs/s200/IMG_20180511_184023.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-Jbfcbjp3RDA/Wy6snnsXgjI/AAAAAAAACPc/j9-RCoRLjAc6q1Irrc_sHXFdqyFGPJkPwCKgBGAs/s1600/IMG_20180511_184014.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://2.bp.blogspot.com/-Jbfcbjp3RDA/Wy6snnsXgjI/AAAAAAAACPc/j9-RCoRLjAc6q1Irrc_sHXFdqyFGPJkPwCKgBGAs/s200/IMG_20180511_184014.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-tqC-_Jm5eKs/Wy6snlmLKSI/AAAAAAAACPc/Cuy2pOcuI98SaIsZmS9BCaneI6kvp_qmACKgBGAs/s1600/IMG_20180511_183905.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://2.bp.blogspot.com/-tqC-_Jm5eKs/Wy6snlmLKSI/AAAAAAAACPc/Cuy2pOcuI98SaIsZmS9BCaneI6kvp_qmACKgBGAs/s200/IMG_20180511_183905.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-yymqkc-AsIs/Wy6sni5Z6oI/AAAAAAAACPc/p9PS7eaPRJoe8tzWNaIckC7XQ1ZuIkbtgCKgBGAs/s1600/IMG_20180511_183837.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://4.bp.blogspot.com/-yymqkc-AsIs/Wy6sni5Z6oI/AAAAAAAACPc/p9PS7eaPRJoe8tzWNaIckC7XQ1ZuIkbtgCKgBGAs/s200/IMG_20180511_183837.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;br/&gt;Topside hardware, some needs a little TLC&lt;/div&gt;
&lt;br/&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-OLXSWLIcvuc/Wy6snrVD8CI/AAAAAAAACPc/9MDJPZdnxgYUdtA-bbHIgx2bFaYbvuYNwCKgBGAs/s1600/IMG_20180512_134531.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;150&quot; src=&quot;https://2.bp.blogspot.com/-OLXSWLIcvuc/Wy6snrVD8CI/AAAAAAAACPc/9MDJPZdnxgYUdtA-bbHIgx2bFaYbvuYNwCKgBGAs/s200/IMG_20180512_134531.jpg&quot; width=&quot;200&quot;/&gt;&lt;/a&gt;&lt;br/&gt;Interior, without paneling between cabin and under-cockpit
&lt;p&gt;
    A little messy, but I can take care of that.
&lt;/p&gt;
&lt;h4&gt;The Big Worry&lt;/h4&gt;
&lt;p&gt;
    Supposedly, 50% of boats sink because of &lt;a href=&quot;https://www.boats.com/reviews/five-common-mistakes-that-might-sink-your-boat/#.Wy6oDRJKgWo&quot;&gt;failure to repair equipment&lt;/a&gt; below the waterline. For me, the big fear comes from my old &lt;a href=&quot;https://en.wikipedia.org/wiki/Seacock&quot;&gt;seacocks&lt;/a&gt;.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-Jq6yoUtHODw/Wy6o_hktxVI/AAAAAAAACO4/y71tUGlACiEStygHeoJp52cLFesho3zHACKgBGAs/s800/IMG_20180522_180114.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-WBsFAz0qyOQ/Wy6o_rNR3qI/AAAAAAAACO4/EoE82C6743E1NECYM0FsOEJFMvavgyGtACKgBGAs/s1600/IMG_20180606_075534.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    As you can see they have significant corrosion. I plan to replace these soon, but it's quite difficult since removal has to take place when the boat is out of the water. I'll assess them more carefully during my first bottom paint job later this summer. I don't want to turn the handle now because I've read horror stories of corroded seacocks crumbling apart during their test.
&lt;/p&gt;
&lt;h4&gt;Bilge Pump Electrical&lt;/h4&gt;
&lt;p&gt;
    As a backup plan, in the event that one of those seacocks starts to leak, I want to make sure that the bilge pump will be able to run to keep the boat from filling. I'll link to that in an upcoming post.
&lt;/p&gt;
&lt;h4&gt;Cleanup and Repaneling&lt;/h4&gt;
&lt;p&gt;
    In the short term, I just needed to get the boat slightly more livable since I will be staying on her a few nights per week to commute to work.
&lt;/p&gt;
&lt;p&gt;
    The first step was to clean up. This mostly consisted of removing the gas tanks from the interior of the boat and cleaning up a few spots, particularly the head.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-3Y3V0gJPTXI/Wy6v14ydNYI/AAAAAAAACQE/3SQWfSKJG489u5uB4I7xibNxPoNRFXbewCKgBGAs/s1600/IMG_20180511_180707.jpg&quot; title=&quot;Gas tanks inside the boat = unhealthy fumes everywhere &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-tH8u6mHZsok/Wy6v1yKbXlI/AAAAAAAACQE/JOmBnvlG9-EgORKnq0XOfaSO6XPxvzJaACKgBGAs/s1600/IMG_20180511_180653.jpg&quot; title=&quot;Before, after  &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-YeVPG8UCUGY/Wy6v1ybsQJI/AAAAAAAACQE/9a1iMpvlcb4u8ro0_XtFOn8lRFvNKaz-wCKgBGAs/s800/IMG_20180516_073633.jpg&quot; title=&quot;Much nicer once the paneling separated the bilge &quot;/&gt;
&lt;p&gt;
    I also had to add back some panels that had been removed and stored under the bilge. The wood was a bit spotty so I repaired with wood glue and bits of wood.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-s20E-zAzpeE/Wy6y31N9P0I/AAAAAAAACQw/zDrm-LxwYTkJUw_nJCsNzGCmitGn8OEbgCKgBGAs/s1600/IMG_20180518_070230.jpg&quot; title=&quot;wood glue and sticks &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-aU4MHjgAGLg/Wy6y36refQI/AAAAAAAACQw/SQJmZVNZ0mwTiuhAF5v3Jp6AwWHwMWKAwCKgBGAs/s1600/IMG_20180518_071305.jpg&quot; title=&quot;fill the hole so the screw has something to grab &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-3UGWu-j5HIU/Wy6y3z0su8I/AAAAAAAACQw/kKRZApFV0xMMc0CFPGCtIUsoZGWdWKYbQCKgBGAs/s1600/IMG_20180518_182459.jpg&quot; title=&quot;Panels added &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Next Steps&lt;/h4&gt;
&lt;p&gt;
    There are still tons of things to do. The next big project will be a haul out and repaint of the bottom with biocidal paint. At that time, I'll assess the seacock situation and any issues with the exterior of the hull. After that, I need to attach new pulleys to the boom for the outhaul. After that, I'll reconnect the electrical for the mast lights and radio. I also suspect that I'll need to caulk some parts of the topside of the boat and woodwork. Eventually, I'd like to get some system so I can keep the sails on the outside of the boat (just so I have more room inside). The last thing to do is rehab the wood on the interior and exterior before it deteriorates too much. Probably around the end of the year, I'll need some new lines too.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Q_QKPbzZXIE/Wy6zt-ZckRI/AAAAAAAACQ8/XZNdTeCqcfs5MadGMe0PlDfCkskJZVQWwCKgBGAs/s800/IMG_20180516_073633.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    It does already start to feel like home though. There's a lot of work to do, but I'm excited (and terrified) for it.
&lt;/p&gt;</description>
        <pubDate>Wed, 27 Jun 2018 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2018/06/introducing-ione/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/06/introducing-ione/</guid>
        
        <category>boatwork</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://4.bp.blogspot.com/-n-IaIEjZ7dI/Wy6jECSF6II/AAAAAAAACOI/ljGqaAqk3PgriDnaX9fz5Zw6EYYWaK6DgCLcBGAs/14117166008_3817a7bd9f_z.jpg</image>
        <title>Skylight Chapters 3 &amp;amp; 4</title>
        <description>&lt;p&gt;
    Another two chapters from my novel. &lt;a href=&quot;/2018/05/03/skylight-chapters-1-2/&quot;&gt;Click here&lt;/a&gt; to read the first two chapters.
&lt;/p&gt;
&lt;hr/&gt;
&lt;iframe height=&quot;800px&quot; src=&quot;https://docs.google.com/document/d/e/2PACX-1vTjfVtSDoVCI9APvUq9YxmvZLjw0fvqRRALRq7euEvZ-0O9p7pMa9g4r_TYFDGchfRJ1kP2FUWe8822/pub?embedded=true&quot; style=&quot;border:1px solid black; height: 800px&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt;</description>
        <pubDate>Sat, 23 Jun 2018 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2018/06/skylight-chapters-3-4/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/06/skylight-chapters-3-4/</guid>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-jd0H8cvT3Ps/WuvELaKIVWI/AAAAAAAABvQ/j1Yjr-EE1KUDJNcJbjqHpuP9_VbHSBXMgCLcBGAs/Screen%2BShot%2B2018-05-03%2Bat%2B7.22.55%2BPM.png</image>
        <title>Skylight Chapters 1 &amp;amp; 2</title>
        <description>&lt;p&gt;
    I've been working on a novel for what feels like a really long time. I usually don't like to let projects drag on like this so I'm gonna start releasing bits to keep me moving. I feel pretty solid about the first two chapters so here they are for public consumption. Enjoy...
&lt;/p&gt;
&lt;div&gt;&lt;iframe height=&quot;800px&quot; src=&quot;https://docs.google.com/document/d/e/2PACX-1vQ29U0iqCXJu16Jk6tiXmknr-r_UDYnZ3DtAFsli0txTrWRd7Q6nSKtAafYakpiNgup3VSrG_Wi_YwD/pub?embedded=true&quot; style=&quot;border:1px solid black; height: 800px&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;</description>
        <pubDate>Thu, 03 May 2018 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2018/05/skylight-chapters-1-2/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/05/skylight-chapters-1-2/</guid>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://4.bp.blogspot.com/-Wd6UtSuoGAk/Wtz6vam3vmI/AAAAAAAABnY/DrxxLEr5Z1IZlv8VZERWB8OGHcKx3v7DgCKgBGAs/IMG_20180418_195658.jpg</image>
        <title>Notes on Bike Fixes</title>
        <description>&lt;p&gt;
    I've been hanging out at &lt;a href=&quot;http://bikekitchen.org/&quot;&gt;Bike Kitchen&lt;/a&gt; in SF for the past couple of weeks. I previously wrote a little something about &lt;a href=&quot;http://www.makeloft.org/2018/04/replacing-bottom-bracket.html&quot;&gt;replacing a bottom bracket&lt;/a&gt;. Below are my notes on a few more key fixes.
&lt;/p&gt;
&lt;h4&gt;Front Derailleur&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-N3ch0I3qkfg/Wtz6ifN8unI/AAAAAAAABnU/7Jl9v7-1H8EJBhFBBvsVV-Yh9a2_d6gYQCKgBGAs/s800/IMG_20180418_194303.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    With the new derailleur, you first need to get it in the right place on the tube. You want it lined up with only a few millimeters of clearance above the largest gear. The derailleur I used had the shifter line wrap around from the underside. It fastened at just one spot despite the oddly shaped nut.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-gPFQupgvkeA/Wtz6iSrdhrI/AAAAAAAABnU/4L0gfZ0D1RUMK7SCMMl8ozM_zxhxIanEACKgBGAs/s800/IMG_20180418_194514.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Afterward it was attached I just had to align the derailleur as normal.
&lt;/p&gt;
&lt;h4&gt;Chain Replacement&lt;/h4&gt;
&lt;p&gt;
    My chain had been jumping hard for a while, so this was the next most important change needed. I was pretty sure the chain was shot, but the way to check for sure is to use a &lt;a href=&quot;https://www.parktool.com/blog/repair-help/when-to-replace-a-chain-on-a-bicycle#article-section-1&quot;&gt;CC-32 chain checker&lt;/a&gt;, or a ruler. Since the chain checker passed through on 0.75, I needed to replace.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-F_1UO_-uaEA/Wtz6vafTVbI/AAAAAAAABnY/r_KXHHnzImMTbUUafmqWqx8rvWHt3xETgCKgBGAs/s1600/IMG_20180418_201057.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I honestly had never though about how chains get on and off of bikes. It didn't really even occur to me that they had to be taken apart. Getting it off requires a specialized tool, aptly called a chain remover, but isn't that difficult once you have it. You line the tip of the remover up with the pin in the middle of one of the links and turn the handle. The pin remover applies pressure and the pin starts to slide.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-9-WgX_Z6LCs/Wtz6vSsnYLI/AAAAAAAABnY/tdj5l9C3WvES7Y4nsW7TyJ0eoyt4K7TagCKgBGAs/s800/IMG_20180418_195611.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Keep in mind that it's incredibly important not to let the pin come all the way out on a part of the chain you really want to keep. Once the pin is all the way out it's very hard to get back in, and you normally end up needing to remove that link entirely and starting on the next one.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-H0tQc3ykE5s/Wtz_bM3eaEI/AAAAAAAABn0/57G7puBd0HII7J4pOiu3i6rp81dmpkYdQCKgBGAs/s800/IMG_20180418_195838.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    You need to put the new one back together on the bike because it has to thread through the frame and derailleurs.
&lt;/p&gt;
&lt;h4&gt;Hub Overhaul: Cup and Cone&lt;/h4&gt;
&lt;p&gt;
    The most interesting and satisfying fix came from a relatively minor problem. The hub of my back wheel had a little more play than it should have . To fix this I needed to perform a hub adjustment (aka cone adjustment), but since I was taking the hub apart anyway, I decided to do a full &lt;a href=&quot;https://www.parktool.com/blog/repair-help/hub-overhaul-and-adjustment#article-section-4&quot;&gt;overhaul&lt;/a&gt; at the same time.
&lt;/p&gt;
&lt;p&gt;
    I started by popping the nuts on one side of the hub off. I took them off of the side with the gearset, but either works as long as you only take off one. Inside you can see the bearings along with some filthy grease.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-_NM8KWKyLls/Wtz6-Bj6K7I/AAAAAAAABnc/DwWeuhrrm2UoYsnP9jqpFjSF6Vxgk3qQACKgBGAs/s1600/IMG_20180421_121652.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I cleaned the bearings and cup and cones from both sides, making sure to replace any bearings that had significant wear. Basically bearings with any obvious dent in the surface got switched out.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-PkiDuSXxuOs/Wtz6-N8GLWI/AAAAAAAABnc/7xmD2KrrU2UvQG2iF16YCifE6wBW_UBLgCKgBGAs/s1600/IMG_20180421_125241.jpg&quot; title=&quot; &quot;/&gt;
With everything clean, I reapplied gobs of grease and reinserted the bearings. The grease held the bearings in pretty well while I reinserted the shaft through the wheel and resealed them. &lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-e4iyHEKZmns/Wtz6-AUz8TI/AAAAAAAABnc/63zONLm9E6sv9748JqmjjDlmyC0u7_HigCKgBGAs/s800/IMG_20180421_130007.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The big trick is when you close up the hub. You want to adjust the cone to be just tight enough to stop any play, but still loose enough that the bearings don't jam up. If you tighten it all the way down you can feel the bearing rubbing against each other. I backed off a little and then held the cone in place while tightening the outside bolt. The external bolt and the cone should lock together to keep the cone from moving.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-nDOF9Qju2lE/Wtz6-LnG5yI/AAAAAAAABnc/VBx7DjAcRfkUQe3sJSrQ8iV1rhBJDhkLwCKgBGAs/s800/IMG_20180421_130705.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;That's a rack&lt;/h4&gt;
&lt;p&gt;
    The bike was running smoothly at this point. But I've been having fun so I also threw a rack on the back for good measure. I'll just need to turn one of my bags into some panniers next!
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-OSlfQ08vYUw/Wt0CKrGaHYI/AAAAAAAABoM/29hWgFyI-dMe_91WiTTX0YpNWPkzwtN8ACKgBGAs/s800/IMG_20180421_141308.jpg&quot; title=&quot; &quot;/&gt;</description>
        <pubDate>Sun, 22 Apr 2018 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2018/04/notes-on-bike-fixes/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/04/notes-on-bike-fixes/</guid>
        
        <category>bikes</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-yRriFPg6uK8/Wsk_c9sNdZI/AAAAAAAABb4/rtnl4uAIqo4D0GPRix05w08Oh9mjDhNhQCKgBGAs/IMG_20180405_191331.jpg</image>
        <title>Replacing a Bottom Bracket</title>
        <description>&lt;p&gt;
&lt;strong&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Bottom_bracket&quot;&gt;bottom bracket&lt;/a&gt; is one of the most fundamental parts of the bike. Like many highly important things, it's also one that gets totally overlooked. That is until it starts to break.&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;
    For several months my &lt;a href=&quot;https://en.wikipedia.org/wiki/Crankset&quot;&gt;crankset&lt;/a&gt; has been wobbling worse and worse. I ignored it as long as I could, but when an elderly man on a mountain bike leisurely pedaled past me on flat ground, I realized there had to be something slowing me down.
&lt;/p&gt;
&lt;p&gt;
    But even though I knew there was something up with the crankset, I didn't actually know what to do. Even googling was a little tricky because I really wasn't sure that the bottom bracket was actually called the bottom bracket. Fortunately, I had recently heard about this place called the &lt;a href=&quot;http://bikekitchen.org/&quot;&gt;Bike Kitchen&lt;/a&gt;. Bike Kitchen is really cool because for a membership you can use all the tools there and ask questions to really knowledgeable people hanging around the shop.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://bikekitchen.org/wp-content/uploads/2012/08/394273_10150470289569506_192847620_n.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    So I'm planning to overhaul the rest of my bike in the next weeks, but for now, I've got my number one priority.
&lt;/p&gt;
&lt;h3&gt;Replacing a Bottom Bracket&lt;/h3&gt;
&lt;p&gt;
    You can fix a bottom bracket in two ways: you can overhaul it and put in new bearings manually or you can put a sealed bottom bracket in it. Sealed bottom brackets cost a little more, but they last a lot longer because it's harder for junk to get inside and start to wear them down. At Bike Kitchen, they've got a whole bin of sealed ones so I decided to put one of them in.
&lt;/p&gt;
&lt;p&gt;
    To get the old one out, you have to use the aptly named &lt;a href=&quot;https://www.youtube.com/watch?v=60wtyyXvtOs&quot;&gt;crank-puller&lt;/a&gt; which basically pushed the cranks out from the bottom bracket.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-U3SRKK2BS1I/Wsk9udyJo3I/AAAAAAAABaw/5CWe1S2_mi4Bo9OsrUfiB7rz5mBgDXjQgCKgBGAs/s800/IMG_20180405_183417.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    afterwards you can see just the end caps and the spindle of the bottom bracket are left.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-MhUIcyd7mZQ/Wsk9uYMcXZI/AAAAAAAABaw/t6HNag24cQ0TqolVJzR7dvthbzxVpZLRgCKgBGAs/s800/IMG_20180405_183402.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    After removing the end caps, a fairly destroyed set of bearing came tumbling out afterwards. And inside you can see that the interior looks pretty roughed up.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-3Vln1ONbUqQ/Wsk-zY1EKwI/AAAAAAAABbc/ByaJ-xKh4Uw7DlBEiYt8Msc6ZyLuIF5HACKgBGAs/s800/IMG_20180405_184014.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    After I cleaned up the inside, the sealed bottom bracket definitely looked a lot healthier sliding in there.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-yRriFPg6uK8/Wsk_c9sNdZI/AAAAAAAABb4/rtnl4uAIqo4D0GPRix05w08Oh9mjDhNhQCKgBGAs/s800/IMG_20180405_191331.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Now the wobble and the friction are both gone! On to the next fix.
&lt;/p&gt;</description>
        <pubDate>Sat, 07 Apr 2018 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2018/04/replacing-bottom-bracket/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/04/replacing-bottom-bracket/</guid>
        
        <category>bikes</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-lFaEVQJrE2s/WhJ1L0-weqI/AAAAAAAAA74/OR1DLky2mEs8gD6rp8wAvpDtitTflFxYwCKgBGAs/IMG_20171114_080512.jpg</image>
        <title>Sailboat Light Covers</title>
        <description>&lt;p&gt;
    Starting in November 2017, I began renting a boat at Coyote Point Marina in Burlingame, CA. I'm using it as a crashpad near my work so that I don't have to commute from SF every day.
&lt;/p&gt;
&lt;p&gt;
    It's a fine little Tanzer 22, and the owner has done a decent job of repairing and maintaining it. Now that it's in my care, I've gotten to work on some little fixes to spruce it up a bit.
&lt;/p&gt;
&lt;h4&gt;Raising the boom and replacing the tarp&lt;/h4&gt;
&lt;p&gt;
    After giving her a quick clean last week, it became clear that the tarp covering the boat was nearing its last legs. For the replacement, I figured I could get a slightly larger tarp and extend my headspace a bit. There was about six inches available to raise the boom, and I could drape the tarp over the edges of the grab rails on the foredeck.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-0aa-NafYl4o/WkwY7dA6YHI/AAAAAAAABI0/08OKmiJcXbACBISdkwEzH9WKZgwe3GWdACKgBGAs/s800/IMG_20171223_090700.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This made the boat much more livable and made me feel better about showing it off to people. Plus who knows what all those frayed bits of fiberglass were doing to my lungs :(
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-_e4MK52T-pQ/WkwZjVH1Z1I/AAAAAAAABJA/Xoohtz4oy3QMLGJ3mz8nVMXpcRu86BH1ACKgBGAs/s1600/IMG_20171120_165751.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Covering the lights&lt;/h4&gt;
&lt;p&gt;
    The owner had replaced the internal cabin lights with some really awesome bright LED bulbs. Unfortunately, he didn't have any covers to cover the internals of the light fixture, which leaves the cabin looking a little shabby and unfinished.
&lt;/p&gt;
&lt;p&gt;
    My friend Pete (a sailor from the Land of 10,000 lakes) came over, and we measured the fixture at 5' by 5' even, estimating that a depth of probably a half inch would give plenty of clearance. There were also 4 gaps on the sides where tabs in the plastic could fit in, but I figured that I'd see if the plastic would hold in place without the tabs. Anything simple would do to start.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-lFaEVQJrE2s/WhJ1L0-weqI/AAAAAAAAA74/OR1DLky2mEs8gD6rp8wAvpDtitTflFxYwCKgBGAs/s1600/IMG_20171114_080512.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    At first, I thought I'd try making a clear transparent acrylic casing, but realized that wouldn't help much in masking the bulb and prettifying my cabin. Also, after living there, I realized that the light was plenty bright and that I could do with a more opaque material. In fact, I figured that could be helpful in &lt;a href=&quot;https://en.wikipedia.org/wiki/Hard_and_soft_light&quot;&gt;diffusing the light&lt;/a&gt; a little so it wasn't so jarring.
&lt;/p&gt;
&lt;p&gt;
    As a quick prototype, I just cut out and bent a thin sheet of plastic that I found in the scrap pile at the &lt;a href=&quot;https://noisebridge.net/&quot;&gt;Noisebridge hackerspace&lt;/a&gt; in San Francisco's Mission District.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-5NIsyj3zTTU/WhJ2sDh3veI/AAAAAAAAA8E/PQaXRfkcX683q70H6xl4XAIFOK1eXelugCKgBGAs/s800/IMG_20171118_135351.jpg&quot; title=&quot;nothin' fancy &quot;/&gt;
&lt;p&gt;
    I just cut some simple notches and bent them out to fit in the holes.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Z_1trGJ5mK8/Wkwa10nKspI/AAAAAAAABJQ/sUz-pRggd0AJ4a2ExJvQ-FeP2BgMrtNMQCKgBGAs/s1600/IMG_20171120_171855.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The device is simple, but did a decent job at making the lights less noticeable.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-TqrC2GdPfk0/WkwaoYZlprI/AAAAAAAABJM/T8kgQBIEXg8IPSHo4iYQnekOQva9qxM1ACKgBGAs/s800/IMG_20171120_170154.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Next step, rainbow lights&lt;/h4&gt;
&lt;p&gt;
    While I was first playing around with that material, it suddenly reminded me of a similar thin film I'd played around with before. If you've ever taken apart an LCD monitor then you probably have run into some shiny colorful plastic material like this before.
&lt;/p&gt;
&lt;p&gt;
    Basically it's just polarizer film, or a film that only let's light through when it's &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_polarization&quot;&gt;linearly polarized&lt;/a&gt; in a particular direction. &lt;a href=&quot;https://physics.stackexchange.com/questions/155391/what-happens-if-you-remove-the-polarization-filter-from-a-computer-monitor&quot;&gt;This Physics StackExchange post&lt;/a&gt; will explain why polarizer film is required for LCDs to work. One cool bonus feature is that this film has the optical effect of generating nifty rainbow colors as you bend it. You can see another effect of that in this cool GIF from the &lt;a href=&quot;https://www.exploratorium.edu/&quot;&gt;exploratorium&lt;/a&gt;.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://www.exploratorium.edu/sites/default/files/PolarizedLightMosiac_DSC_7232.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I should be able to cut out an identical shape if I wanted to through some technicolor light around the boat. I'll update with the new version once I get a chance to try it.
&lt;/p&gt;
&lt;h4&gt;Sailing&lt;/h4&gt;
&lt;p&gt;
    Unfortunately, the owner hasn't yet let me sail it, but I'm hoping that these cool modifications along with a trial run or two with him this winter will have me sailing that beauty around the Bay by spring. Fingers crossed.
&lt;/p&gt;</description>
        <pubDate>Tue, 02 Jan 2018 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2018/01/sailboat-light-covers/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2018/01/sailboat-light-covers/</guid>
        
        <category>boatwork</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-4ZgtsQLJgpw/WWJq8wDEgAI/AAAAAAAAIpQ/mPvZHgPxLwgQg6owh8Zvxg1qDlSwekfAQCLcBGAs/IMG_20170709_103715.jpg</image>
        <title>Making Better Eyes</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: Currently engaging in exploratory experiments to determine validity of hypothesis. 10% confidence of success, but experiment is low risk, which makes it worth pursuing.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        In May 2017, I had an eye exam with my new optometrist. During that visit, my optometrist made a passing remark about a quirk that he noticed in my old glasses. That tiny remark completely changed my perspective on optometry and near-sightedness. And I'm hoping that it might just change my life.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-4ZgtsQLJgpw/WWJq8wDEgAI/AAAAAAAAIpQ/mPvZHgPxLwgQg6owh8Zvxg1qDlSwekfAQCLcBGAs/s1600/IMG_20170709_103715.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Why had I never thought of that before?&lt;/h4&gt;
&lt;p&gt;
        All this started when my new optometrist asked me nonchalantly whether my previous optometrist had ever mentioned putting a prism in my glasses. I'm severely myopic (or near-sighted) with a prescription of around -7.5 diopters in my glasses. This means I need to take my prescriptions pretty seriously because getting the wrong glasses means I can't see much farther than 12 inches in front of me.
    &lt;/p&gt;

    Now, as it just so happened, I had taken my prior prescription to the online eyeglasses retailer, &lt;a href=&quot;https://www.reddit.com/r/malefashionadvice/comments/3yowqq/how_is_the_quality_of_warby_parker_glasses/&quot;&gt;Warby Parker&lt;/a&gt;, so I knew very well that there was no mention of &quot;prism&quot; anywhere on my prescription. Moreover, even though I've been going to the optometrist for more than 20 years, I had never heard about prism before. Since I didn't know what prism was, I asked what it meant for glasses to have prism.

&lt;p&gt;
        Essentially, as my doctor explained, prism means that the center of the focus of the lens is not aligned with the center of your eye. In other words, it means the lens of the glasses are offset. This is normally done intentionally when a person has a misaligned eye that needs to be corrected. But since I knew that my old prescription didn't mention prism, I told the optometrist that it must have been a mistake, and that I remember having a really hard time adjusting to my glasses when I got them. And then he responded with a statement that completely took me by surprise.
    &lt;/p&gt;
&lt;blockquote&gt;It must have just been lucky then because you actually need exactly the same amount of prism that is in your glasses.&lt;/blockquote&gt;
&lt;p&gt;
        I could tell by the way that he said it that he wasn't questioning the arrow of causation, but to me, the following painfully obvious question instantly sprung loose in my imagination:
    &lt;/p&gt;
&lt;h6&gt;Could my new-found prism have been caused by my glasses?&lt;/h6&gt;
&lt;p&gt;
        Knowing what little I knew about biology, it seemed more likely to me that my eye would have adapted to an erroneous prism than that the accidental prism and the &lt;strong&gt;never before diagnosed&lt;/strong&gt; prism happened to just perfectly counterbalance. So if I assume that my glasses were able to retrain my eye to adjust for a prism, it isn't too difficult to jump to the next obvious question:
    &lt;/p&gt;
&lt;h6&gt;Could other vision problems be induced by glasses, specifically, my progressive myopia?&lt;/h6&gt;
&lt;p&gt;
        I was floored. How had that thought never occurred to me? I feel pretty stupid for never thinking about it, but once the idea was in my head, I had to get an answer.
    &lt;/p&gt;
&lt;h4&gt;What causes myopia?&lt;/h4&gt;
&lt;p&gt;
        To explain why I'd never thought of this before, we have to understand my previously &lt;i&gt;correct&lt;/i&gt; yet &lt;i&gt;limited&lt;/i&gt; understanding of the cause of myopia. In short, myopia is caused by &lt;a href=&quot;http://www.allaboutvision.com/conditions/myopia.htm&quot;&gt;the lens of the eye being unable to properly focus&lt;/a&gt; a distant image on the retina of the eye. If we look at a picture of light coming into a simple convex lens (like the one in our eye), we would see all the light being redirected to focus down to a single point, called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Focus_(optics)&quot;&gt;focal point&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-PrqqPeldvQ4/WU3hrjtR_1I/AAAAAAAAIhM/3ookaYm6z6wg68djAWn4KDdleOZ_OD4qACLcBGAs/s1600/convex_lens.jpg&quot; title=&quot; How light is redirected through a lens. source  How light is redirected through a lens. source&quot;/&gt;
&lt;p&gt;
        The exact shape of the lens determines how much the light rays are redirected, which sets the &lt;a href=&quot;http://www.nikonusa.com/en/learn-and-explore/a/tips-and-techniques/understanding-focal-length.html&quot;&gt;focal length&lt;/a&gt; or how far away the focal point occurs. This occurs in a camera, a telescope, and most importantly our eyes. In our eyes, this means that light coming from an object will focus down to a little miniature image at the focal point on the other side of our lens. Basically, if you want the mini image to always appear at the same location (your retina), but the real object is at a different location, you will need a different thickness of lens. The eye provides this ability by giving us muscles that quite literally &lt;i&gt;squeeze&lt;/i&gt; our lens to &lt;a href=&quot;https://www.sciencelearn.org.nz/resources/50-how-the-eye-focuses-light&quot;&gt;change its thickness&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-06VX6JEA8sg/WU3hrt50E8I/AAAAAAAAIhQ/TKmxO6zA8eAX7uQxHS_5Mkir-w3Of9IRQCLcBGAs/s1600/Eye-focus-final-3000X2000.jpg&quot; title=&quot;The eye squeezes the lens to adjust focus. source The eye squeezes the lens to adjust focus. source&quot;/&gt;
&lt;p&gt;
        The problem with myopia is just that the lens in your eye can't get thin enough to turn a far away object into an image at the exact location of your retina. Instead, &lt;a href=&quot;https://www.virginiaeyeconsultants.com/procedures/eye-conditions/myopia/&quot;&gt;the image is focused a little bit in front of the back of the retina&lt;/a&gt;, which causes the image at the retina to be fuzzy. The underlying reason can either be due to the lens being too thick or from the eyeball being too elongated.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-9_9840U2Vmk/WU3g_jrIjuI/AAAAAAAAIhE/uyllbGSOBewyMnLMQAeSx7N0U-qc6D6VQCLcBGAs/s1600/myopia.jpg&quot; title=&quot;Distance glasses adjust the accessible focal range of the eye. source Distance glasses adjust the accessible focal range of the eye. source&quot;/&gt;
&lt;p&gt;
        Either way, you should note that &lt;strong&gt; myopia doesn't come from an inability of your muscle to squeeze the lens hard enough, but, rather, a failure of the muscle to release the lens far enough. &lt;/strong&gt; The corrective lens actually is making up for a mismatch between the minimum thickness of your lens and the elongation of the eyeball.
    &lt;/p&gt;
&lt;p&gt;
        Most people with a technical degree will be introduced to this information around their freshmen or junior year of college. Since I felt like I knew a little about optics, I felt like I perfectly understood the problem. However, this still leaves the question of why some eyes are able to stay functional, while others come out of alignment.
    &lt;/p&gt;
&lt;h6&gt;The mechanics of short-sightedness&lt;/h6&gt;
&lt;p&gt;
        The next question one has to ask is &lt;i&gt;Why is a myopic person's eyeball elongated&lt;/i&gt;?
    &lt;/p&gt;
&lt;p&gt;
        I'd heard that the cause for the misalignment was genetic, due to some deficiency in the formation of the eye. The explanation that I remember hearing from my early optometrists only informed me that my eye was somehow too elongated. This is true relative to the minimum thickness of my lens, since my eye is literally too elongated for even my most relaxed focal point to reach it. This means that there is nothing I can do to get that focal point to my retina because any amount that I squish my lens to get thicker only moves the point of focus further toward the center of the eye and away from my retina at the back.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-FuRLCSN9mY4/WU3m_Oq13vI/AAAAAAAAIhg/0z9l1qmYGlITIpvVLOPRNqeOLGycrYMXgCLcBGAs/s1600/Ciliarymuscles.jpg&quot; title=&quot;Closeup on the muscles that are squeezed to adjust focus point. source Closeup on the muscles that are squeezed to adjust focus point. source&quot;/&gt;
&lt;p&gt;
        Although my optometrists accurately explained this immediate cause of my failure to focus, they never went into specifics of how my eye got to be that way, only suggesting that I had a genetic problem. But I can remember thinking how strange it was that so many people could be so blind so suddenly if this was an underlying genetic problem. About 30% of people in the United States are near-sighted today so, logically, then shouldn't approximately 30% of people have needed glasses 200 years ago too? That's just how genetics work. But 200 years ago glasses were a rare luxury for the rich so 30% of the country would have been effectively blind! At the time, I explained it away to myself by saying, &quot;Well my grandparents were all farmers; maybe on the farm no one noticed that they were going blind.&quot;
    &lt;/p&gt;
&lt;h4&gt;The biological case for vision adaptation&lt;/h4&gt;
&lt;p&gt;
        As far as I know, no one can state for sure what is truly the causing the sudden epidemic of progressive myopia. In 2015, the journal Nature posted &lt;a href=&quot;http://www.nature.com/news/the-myopia-boom-1.17120&quot;&gt;this article&lt;/a&gt;, suggesting that the myopia boom was due to children not being exposed to enough sunlight. The evidence they cite (pun intended) is that children who spend more time outside tend to have lower levels of myopia.
    &lt;/p&gt;
&lt;p&gt;
        However, a more parsimonious explanation, and one that is more widely accepted than the outdoor light theory, is simply that being outside means you are spending more time focusing on things that are far away. Being inside probably means you are looking at nearby objects, like books or computers more often. In short, it's possible that myopia is nothing more than the eye trying to adapt to the environment it is put into day after day.
    &lt;/p&gt;
&lt;p&gt;
        There are many hundreds of complex feedback mechanisms that our bodies have in place, tuning our various physiological processes to fall into homoeostasis (&lt;a href=&quot;https://www.albert.io/blog/positive-negative-feedback-loops-biology/&quot;&gt;here's a tiny handful of examples&lt;/a&gt;). From our kidneys nearly instantly setting the osmolarity, pH or ion concentration of our blood, to our muscles slowly adapting to the toll of the labor, to the development of the size of our fingers and toes, the body almost magically tunes itself to function properly. Why should vision be any different?
    &lt;/p&gt;
&lt;p&gt;
        I'm not alone in my belief that myopia is really just an adaptation to keeping the eye focused close up. Many research studies &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0042698998002296&quot;&gt;in animals&lt;/a&gt; and &lt;a href=&quot;http://journals.lww.com/optvissci/Abstract/1969/09000/THE_TRANSMISSION_OF_REFRACTIVE_ERRORS_WITHIN.5.aspx&quot;&gt;on many&lt;/a&gt; &lt;a href=&quot;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0080361&quot;&gt;different populations&lt;/a&gt; suggest that close work is a &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/20592235&quot;&gt;plausible cause of myopia&lt;/a&gt;, and that &lt;a href=&quot;http://www.bmj.com/content/324/7347/1195&quot;&gt;close-up focus along with genetic factors&lt;/a&gt; is what is causing the &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/20008719&quot;&gt;increase in myopia&lt;/a&gt; today. I don't have time to enumerate all the details of these studies, but if you'd like a high level overview of the research, I suggest you listen to the first half of &lt;a href=&quot;myhttps://www.youtube.com/watch?v=x5Efg42-Qn0&quot;&gt;this excellent talk&lt;/a&gt; by &lt;a href=&quot;http://gettingstronger.org/the-author/&quot;&gt;Todd Becker&lt;/a&gt;. &lt;h6&gt;The glasses problem&lt;/h6&gt;
&lt;p&gt;
            Of course, the issue isn't just that there are more myopic people. The issue is really that there are &lt;a href=&quot;https://www.theatlantic.com/health/archive/2016/02/in-2050-half-the-world-will-be-nearsighted/468606/&quot;&gt;so many more people with an advanced level of myopia&lt;/a&gt;. In fact, the levels of severe myopia are measurably &lt;a href=&quot;https://www.theatlantic.com/health/archive/2014/05/nearsightedness-and-the-indoor-life/361169/&quot;&gt;higher among young people&lt;/a&gt; than they are among the elderly. This leads to the question about what could be causing the pandemic worsening degree of myopia, and to one conclusion: that our increased reliance on glasses is making myopia worse.
        &lt;/p&gt;
&lt;p&gt;
            This point is more controversial than the issue of near-work causing myopia. However, it is very clear that myopia can be &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/cxo.12312/abstract;jsessionid=326E7CC5287AF8D06E34055FB9D9D4EC.f03t02&quot;&gt;intentionally induced in animals&lt;/a&gt; through the use of corrective lenses. In these studies, scientists put a pair of glasses onto chickens who presumably have pretty good eyesight.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/--rHz-s1F4p4/WVAR6fHU2zI/AAAAAAAAIiM/wTe-hl-C9RMuWTk7RKV6BXmEf98IUIz6QCLcBGAs/s1600/Chicken%2Beyes.png&quot; title=&quot;source source&quot;/&gt;
&lt;br/&gt;
&lt;p&gt;
            They wait a while and then measure the chicken's eyes and find, lo and behold, that the chicken with glasses have a &lt;strong&gt;much&lt;/strong&gt; longer eyeball. In short, the chicken's that wore glasses are now myopic even thought their peers without glasses are still just fine. Recently, researchers have proposed the &lt;a href=&quot;http://www.computersinbiologyandmedicine.com/article/S0010-4825(06)00192-2/fulltext&quot;&gt;incremental retinal defocus theory&lt;/a&gt; as a way to explain this phenomenon, which basically suggests that defocus releases chemicals that affect eye growth. If the same effect works in humans (and why shouldn't it), this would explain why people with glasses end up needing a higher prescription later on.
        &lt;/p&gt;
&lt;p&gt;
            On the other hand, I find it hard to believe that something this obvious wouldn't have been noticed and addressed a long time ago. If glasses were so obviously making us go blind, why wouldn't we have enacted measures to reduce our dependence on them. In fact, there have been several studies that dissuade me from believing in the validity of this mechanism. For starters, &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0042698902002584&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;http://www.journalofoptometry.org/en/under-correction-human-myopia-is/articulo/S1888429613000885/&quot;&gt;studies&lt;/a&gt; have shown that undercorrection of myopia can lead to &lt;i&gt;worsening&lt;/i&gt; myopia in youth and adolescents (though counteracting the effects of near work with plus lenses &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/10806444&quot;&gt;has been shown to prevent myopia progression&lt;/a&gt;). And it appears that there are probably &lt;a href=&quot;http://newsroom.cumc.columbia.edu/blog/2015/08/31/gene-leads-to-nearsightedness-when-kids-read/&quot;&gt;genetic factors that increase one's susceptibility&lt;/a&gt; to &lt;a href=&quot;https://www.sciencedaily.com/releases/2016/04/160421133905.htm&quot;&gt;near work causing myopia&lt;/a&gt;.
        &lt;/p&gt;
&lt;h5&gt;Is bad vision correctable?&lt;/h5&gt;
&lt;p&gt;
            All of this is well and good if it can be shown that developing eyes are harmed by the introduction of glasses. However, that doesn't do me much good other than showing me that I should keep my kids as far away from the optometrist as possible. The big question I need to answer is if there is anything that I can do today to undo the harm that may have occurred thanks to a misguided public health policy.
        &lt;/p&gt;
&lt;p&gt;
            I still do not know if vision is correctable through training. It's very clear from published research that adult and juvenile eyes will respond adaptively to stimuli. In addition, there are &lt;a href=&quot;http://gettingstronger.org/2010/07/improve-eyesight-and-throw-away-your-glasses/&quot;&gt;many&lt;/a&gt;, &lt;a href=&quot;https://www.facebook.com/endmyopia/&quot;&gt;many groups&lt;/a&gt; and &lt;a href=&quot;https://endmyopia.org/&quot;&gt;blogs&lt;/a&gt; online that swear they have been able to achieve improvements in eyesight through various regimens. However, conventional optometrists don't acknowledge any of this as even borderline legitimate. I admit my ignorance on this subject, but I also admit I'm more than a little optimistic that I'll soon find out.
        &lt;/p&gt;
&lt;h4&gt;An experiment in vision correction&lt;/h4&gt;
&lt;p&gt;
            Before I bought new glasses I decided I wanted to see if I could start to push my vision back in the direction of 20/20. I figure there isn't that much to lose: My vision is already so bad that &lt;a href=&quot;https://www.fda.gov/MedicalDevices/ProductsandMedicalProcedures/SurgeryandLifeSupport/LASIK/ucm061366.htm&quot;&gt;LASIK is a dangerous bet&lt;/a&gt;, &lt;a href=&quot;http://www.allaboutvision.com/contacts/orthok.htm&quot;&gt;Ortho-K&lt;/a&gt; isn't possible, contact lenses will continue to leave me with dry, fatigued eyes by sundown, and my increasingly heavy glasses will forever limit my ability to maintain an active, healthy life. At -7.5 diopters, I'm on the road to blindness if I don't do something.
        &lt;/p&gt;
&lt;h5&gt;Trying to be scientific&lt;/h5&gt;
&lt;p&gt;
            I'm not the best scientist, but that doesn't mean I don't want to try to be as systematic as possible in my approach to improving my eyesight. Towards that goal, I'm writing this blog post for a couple of reasons. First, I want to make sure I had a relatively decent understanding of the basic science that underpins the justification for the possibility of vision correction. Writing a post always makes me double check my research so I don't say something stupid. But beyond this, I want to document in a reasonably reproducible manner the approach I'm taking to improve my vision. I want to make it clear what I'm trying to do up front, and then, after a few years, I can fairly evaluate whether I've seen any improvement and what led to such improvement.
        &lt;/p&gt;
&lt;p&gt;
            Stating &lt;a href=&quot;https://www.nature.com/articles/s41562-016-0021&quot;&gt;the goal and the methods before the study&lt;/a&gt; is a valuable approach in &lt;a href=&quot;https://osf.io/&quot;&gt;Open Science&lt;/a&gt; for two reasons. First, if I am successful, after the fact there can be no accusation that I fudged something or that I misrepresented my approach. On the other hand, if it doesn't work, I will have a record that I tried and failed. If everyone records their failed attempts too, then we'll start to get some grassroots confirmation that this really isn't possible. There's always the possibility that the field of optometry isn't deluding us, and I would like to reveal in an unbiased way what proof my experience can offer.
        &lt;/p&gt;
&lt;h5&gt;My experimental technique&lt;/h5&gt;
&lt;p&gt;
            Although many different forms of vision remedy exist on the internet (and some are &lt;a href=&quot;https://www.youtube.com/watch?v=WEetWYtLCFQ&quot;&gt;just plain quackery&lt;/a&gt;), I've tried to pick a very simple routine.
        &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;When doing all near work (reading or working on the computer) wear weaker glasses (approximately +1.25 diopters relative to my most recent prescription) or reading glasses with contacts.&lt;/li&gt;
&lt;li&gt;Whenever I notice blur, practice focusing on things just &lt;i&gt;a little too far&lt;/i&gt; outside my easily visible range.&lt;/li&gt;
&lt;li&gt;When outside, use regular prescription, but be sure to keep focus on far away objects whenever possible.&lt;/li&gt;
&lt;li&gt;When possible, rest my eyes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
            This is based on the suggested routine from &lt;a href=&quot;http://gettingstronger.org/wp-content/plugins/wordpress-toolbar/toolbar.php?wptbto=http%3A%2F%2Fgettingstronger.org%2Frehabilitation%2F&amp;amp;wptbhash=aHR0cDovL2dldHRpbmdzdHJvbmdlci5vcmcvMjAxMC8wNy9pbXByb3ZlLWV5ZXNpZ2h0LWFuZC10aHJvdy1hd2F5LXlvdXItZ2xhc3Nlcy88d3B0Yj5JbXByb3ZlIGV5ZXNpZ2h0ICYjODIxMTsgYW5kIHRocm93IGF3YXkgeW91ciBnbGFzc2VzPHdwdGI%2BaHR0cDovL2dldHRpbmdzdHJvbmdlci5vcmc8d3B0Yj5HZXR0aW5nIFN0cm9uZ2Vy&quot;&gt;gettingstronger.org&lt;/a&gt;, but I have simplified it so that I can state clearly what methods I am employing. This will enable me to better describe &lt;i&gt;exactly&lt;/i&gt; the patterns of behavior that led to vision improvement (or lack thereof).
        &lt;/p&gt;
&lt;h4&gt;Preliminary data&lt;/h4&gt;
&lt;p&gt;
            As a baseline starting point, I am including my prescription as of May 2017. My goal is to continue just getting annual prescriptions, and using that as my official record. I'm hoping to see about a half diopter improvement per year since that was approximately the rate at which my myopia progressed. Of course, that will mean that it'll take 10 years before I can see without glasses, but better late than never.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Aey91VVwFJg/WVAVEsd6HKI/AAAAAAAAIig/3_YZxmPQFwUcvtR6bfTfVZK7KGoYI-SIACKgBGAs/s1600/IMG_20170616_182411.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            Fortunately, I was able to convince my optometrist to give me a pair of glasses for working on the computer. I had been wearing reading glasses with contacts anyway so we figured I could just get a prescription with +1.25 diopters added and use that so I wouldn't dry my eyes out with the prescription. In theory, I should switch back to my regular prescription any time I walk away from the computer, but I've effectively started wearing these glasses when I was away from the computer too. I now spend about 70% of my day wearing my -6.25 glasses.
        &lt;/p&gt;
&lt;p&gt;
            For the first three days with the computer glasses, I had an intense headache and I couldn't see further than my computer screen. It was truly painful, but I persisted, remembering how painful it was when I originally received my erroneous prescription from Warby Parker. I quickly grew accustomed to the changes, and any eye strain was completely unnoticeable after the first week.
        &lt;/p&gt;
&lt;p&gt;
            I've now been following this program for about a month. As the month has progressed, I have seen an immediate and quite obvious improvement, but I don't want to overstate the results. I feel that this immediate improvement could just be due to my adjustment to this new set of glasses, and my brain getting used to perceiving somewhat fuzzy images better than I was used to before.
        &lt;/p&gt;
&lt;p&gt;
            To get some early quantitative results, I've tried two different online &lt;a href=&quot;http://www.personaleyes.com.au/online-eye-test/index.php&quot;&gt;eye&lt;/a&gt; &lt;a href=&quot;https://www.zeiss.com/vision-care/en_us/better-vision/better-vision-with-zeiss/zeiss-online-vision-screening-check.html&quot;&gt;tests&lt;/a&gt; to estimate my &lt;a href=&quot;https://en.wikipedia.org/wiki/Visual_acuity&quot;&gt;visual acuity&lt;/a&gt; . Both claim that I am 20/20 when wearing my -6.25 lenses. I actually think I'm probably closer to 20/40, based on how well I can see street signs around me (&lt;a href=&quot;https://www.aoa.org/patients-and-public/eye-and-vision-problems/glossary-of-eye-and-vision-conditions/visual-acuity?sso=y&quot;&gt;20/40 is worse than 20/20&lt;/a&gt;). To put that in perspective, &lt;a href=&quot;https://www.reddingmedical.com/documents/Spot%20VS100%20Vision%20Screener,%20Conversion%20Chart%20&amp;amp;%20Instructions.pdf&quot;&gt;this conversion chart&lt;/a&gt; (derived from &lt;a href=&quot;http://www.hicsoap.com/publications/TheRelationshipofVisualAcuity.PDF&quot;&gt;this paper&lt;/a&gt;), suggests that my -1.25 of uncorrected vision should equate to approximately 20/70. Clearly I am seeing better than that even if these tests aren't perfectly accurate. I don't think this is necessarily so dramatic though, and I can't really be sure that this change in visual acuity isn't just a an early effect of my brain getting comfortable with fuzzier images. To really be sure, I will have to wait for my next official eye exam sometime next year. &lt;i&gt;Note, I don't want to measure my vision too often because I believe this could effectively train my eyes to get better at beating Snellen charts, which could bias my results.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
            A conservative interpretation is that my eyes had the ability to adjust to the sensation of wearing a weaker prescription, and I've been able to compensate for the weaker prescription in a short time by focusing better even in the presence of some blur. I do not expect this rapid improvement to persist in the coming months though. Instead, I am hoping that over the next year or so I will slowly adapt to being able to see further and further with my -6.25 lenses.
        &lt;/p&gt;
&lt;p&gt;
            I will check back in with an update on my vision at the 6 month point. If I've improved to the point that my -6.25 glasses are truly 20/20 and I have no difficulty viewing things at moderate distance, I may order an even weaker pair of glasses online for computer work.
        &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;</description>
        <pubDate>Sun, 19 Nov 2017 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2017/11/making-better-eyes/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2017/11/making-better-eyes/</guid>
        
        <category>science</category>
        
        <category>biology</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-8Ztl7NFEjQw/WTo4DMnOYnI/AAAAAAAAIY0/Q_i-Cws8TbwfnkxKB06EBGjm7rAw1aSJQCLcB/Screenshot%2Bfrom%2B2017-06-08%2B22-52-11.png</image>
        <title>hope you dance (alone)</title>
        <description>&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-8Ztl7NFEjQw/WTo4DMnOYnI/AAAAAAAAIY0/Q_i-Cws8TbwfnkxKB06EBGjm7rAw1aSJQCLcB/s1600/Screenshot%2Bfrom%2B2017-06-08%2B22-52-11.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        For the past couple of months, I've been obsessed with &lt;a href=&quot;http://neilcicierega.com/&quot;&gt;Neil Cicierega&lt;/a&gt;'s amazing &lt;a href=&quot;mashup of marshmello Alone and early 2000s maudlin smash hit i hope you dance&quot;&gt;mashups&lt;/a&gt;. Basically, he does an unbelievably amazing job of squeezing tons of irony and kitsch out of a bunch of 90s and 2000s songs. His work has a very DIY feel, and it very much comes out of the internet culture, but the work is really impeccable and just sooo funny.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://images.genius.com/7748ece5191c0a368b5ea02112649286.800x800x1.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;i&gt;btw, I just looked up the links for Neil Cicierega and ended up spending the last two hours listening to his music again.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        Anyway, &lt;a href=&quot;http://www.phrases.org.uk/meanings/imitation-is-the-sincerest-form-of-flattery.html&quot;&gt;imitation is the sickest form of flattery&lt;/a&gt; so I decided I would play around with mashing up a couple of tunes myself. I've always liked the idea of merging dance music with country music because the only famous example is the &lt;a href=&quot;http://mentalfloss.com/article/82584/long-history-behind-song-cotton-eye-joe&quot;&gt;notably horrible Cotton Eye Joe&lt;/a&gt;. After deciding to do a country tune merged with a dance songe, the obvious choice for me was the classic &lt;a href=&quot;http://www.chicagotribune.com/news/columnists/chi-schmich-sunscreen-column-column.html&quot;&gt;wear your suncreen&lt;/a&gt; of the south: &lt;a href=&quot;http://www.greatamericanthings.net/music/songs-music/song-i-hope-you-dance/&quot;&gt;Hope you dance&lt;/a&gt; by appropriately triple named &lt;a href=&quot;https://en.wikipedia.org/wiki/Lee_Ann_Womack&quot;&gt;Lee Ann Womack&lt;/a&gt;. For the dance track, I decided to just mash it up with an instrumental of Marshmello's Alone for the sole reason that I just think that track is great.
    &lt;/p&gt;
&lt;p&gt;
        Here's my mashup on youtube dubbed over clips from the original music video. It's not great, but I kind of like it in a weird way. Read below for more on how to make a track like this.
    &lt;/p&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/UnhhmN9PJGk&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;h3&gt;The Audacity of Dope&lt;/h3&gt;
&lt;p&gt;
        All the music editing took place using the &lt;a href=&quot;http://www.audacityteam.org/&quot;&gt;Audacity&lt;/a&gt; open source music editor. The community surrounding this software is great and there are already a ton of tutorials to get you started. I'm going to focus primarily on the process for grabbing a bunch of music that you like off of youtube and putting it together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-iWerQHgB8iA/WTo34SWZIUI/AAAAAAAAIYw/pmq0Z4aeKHgPDVMERkuKsa7iqJ-BxOg7QCLcB/s1600/Screenshot%2Bfrom%2B2017-06-08%2B22-51-12.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;downloading some audio&lt;/h6&gt;
&lt;p&gt;
        The first step is to download music. I got all of mine off of youtube using &lt;a href=&quot;https://www.onlinevideoconverter.com/mp3-converter&quot;&gt;this site&lt;/a&gt;. Since this was just a fun project, I didn't fuss too much with getting really good audio. My primary focus was trying to get music with audio and instrumental separated so that I could merge them without having the instruments conflict. I was able to do that for Alone, but old country songs don't have a very wide remixing community so I had to make due on my own.
    &lt;/p&gt;
&lt;h6&gt;removing instrumentals&lt;/h6&gt;
&lt;p&gt;
        I played around with a couple of the examples in &lt;a href=&quot;http://manual.audacityteam.org/man/tutorial_vocal_removal_and_isolation.html&quot;&gt;this tutorial&lt;/a&gt; from Audacity. They worked to a certain degree, but there are still fragments of instruments in the background of the Womack track. I just went with it and tried to incorporate them in a musical way.
    &lt;/p&gt;
&lt;h6&gt;beat matching&lt;/h6&gt;
    Once I had the music and vocals more or less isolated, there was one crucial step called beat matching. basically, the two songs were in very different tempos so I tried to get them close to the same speed so that I could merge them without the two tracks getting out of sync. To do this, I first estimated the bpm of the songs by tapping to the beat on an &lt;a href=&quot;http://www.all8.com/tools/bpm.htm&quot;&gt;online bpm tool&lt;/a&gt;. This gave me a relative difference in tempo, which I could use to adjust one of the tracks using Audacity's &lt;a href=&quot;http://manual.audacityteam.org/man/change_tempo.html&quot;&gt;change tempo feature&lt;/a&gt;. &lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-2KRmZpY6twg/WTowqENdMzI/AAAAAAAAIYg/z_JlyQx7DM8HxsPV9pIHx7WSqdLyypZ3gCLcB/s1600/change_tempo_w10.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;slice and dice&lt;/h6&gt;
&lt;p&gt;
        After this, basically all I did was slice audio clips, and copy and paste them into an Audacity project with the instrumental running in the background. I &lt;a href=&quot;http://manual.audacityteam.org/man/change_pitch.html&quot;&gt;changed the pitch&lt;/a&gt; of the clips in different ways in different places, but I just adjusted the pitch by ear until it sounded sort of OK. Occasionally, I'd just start throwing random effects onto clips, but I never really kept track of what I was doing so I can't really describe what I did there.
    &lt;/p&gt;
&lt;p&gt;
        Long story short, you just have to play around for a long time to massage the clips into the surrounding beat track. This took me about 4 nights of continuous work and then another maybe three or four where I would just poke around for 15 minutes. I suspect that the next time I do this it will take significantly less time, but I will end up with a significantly better project. I didn't have too high of hopes so the product I ended up with was good enough for me to finalize the project and move on.
    &lt;/p&gt;
&lt;h3&gt;Throwing together a video&lt;/h3&gt;
&lt;p&gt;
        Finally, I really wanted to see this weird new song stitched back in with the original music video. So I went about getting a copy of the video from youtube. If you don't know already, all you have to do to download a youtube video is add ss to the url as described &lt;a href=&quot;http://www.nairaland.com/1934159/how-download-youtube-videos-using&quot;&gt;here&lt;/a&gt; (and a moillion other places online.
    &lt;/p&gt;
&lt;p&gt;
        After you download the mp4, you can edit in any video editor. I used this really janky program called &lt;a href=&quot;https://www.shotcut.org/&quot;&gt;ShotCut&lt;/a&gt;, but I would not recommend it. It served its purpose for me, but I'm sure there must be better video editing packages out there.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-8Ztl7NFEjQw/WTo4DMnOYnI/AAAAAAAAIY0/Q_i-Cws8TbwfnkxKB06EBGjm7rAw1aSJQCLcB/s1600/Screenshot%2Bfrom%2B2017-06-08%2B22-52-11.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I won't describe how to slice and dice a video up, but I will give you a few suggestions if you want to upload a copyrighted video to youtube. After you do all the editing, just add a ton of crazy filters so that none of the original video appears in its original condition in your final product. Otherwise youtube will block it automatically.
    &lt;/p&gt;
&lt;p&gt;
        Note: I think this is all legal because it falls under fair use, but then again, I'm not a lawyer so if anybody cease and desists you, just take it down and don't fight them. That probably won't happen if you make something as crappy as the music I made, but keep it in mind.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Fri, 17 Nov 2017 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2017/11/hope-you-dance-alone/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2017/11/hope-you-dance-alone/</guid>
        
        <category>music</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-2ktRD2ZG9C8/Waj7MWjgbNI/AAAAAAAAI8w/PDn4EYAwgdE7QP2k0gpsAi3DR3US3Tj0ACKgBGAs/IMG_20170830_181342.jpg</image>
        <title>Indiana Jones and the Elusive Promo Code</title>
        <description>&lt;p&gt;
        In a lot of ways, my brother and I share a lot of the same opinions, but there are a few subjects where we disagree vehemently. One of the places where our difference of opinion has led to conflict has been on the subject of gift giving. To explain the paradox of our situation, I wrote the following allegory.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;h5&gt;The paradox of the brothers’ gifts:&lt;/h5&gt;
&lt;p&gt;
            Once there were two brothers who had to buy each other gifts. Brother Will believed that the value of the gift lay in the utility that it brought to the receiver. He believed it was the benefit that counts. As such, he would even go so far as to ask the receiver what it is they wanted, rather than risk a mistake.
        &lt;/p&gt;
&lt;p&gt;
            Brother Andrew believed that the value of the gift lay in the effort the giver exerted in trying to pick the gift. He believed it was the thought that counts. As such, he would be pleased with a gift that the receiver immediately threw away as long as the receiver believed that Andrew had thought long and hard to pick it out.
        &lt;/p&gt;
&lt;p&gt;
            When the brothers came to give each other gifts, they were doomed to fail.
        &lt;/p&gt;
&lt;p&gt;
            If Brother Andrew aimed to search his soul for what Brother Will would truly want, he would inevitably come to the realization that he must give up being thoughtful and directly ask Brother Will, even if it meant that his gift didn’t truly represent his feelings.
        &lt;/p&gt;
&lt;p&gt;
            If Brother Will aimed to give a gift that Brother Andrew would value highly, he would have to forgo his philosophy of directly ascertaining the gift of highest value, and instead project his feelings about Andrew into his selection of a gift, even though he might be wrong.
        &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5&gt;&lt;/h5&gt;
&lt;p&gt;
        Long story short, I am the utilitarian, and my brother is the romantic. This dichotomy has been largely fine from my viewpoint for many years: I just ask my brother what he needs and then ship it; my brother gets me gifts I don't need, and I give them away to other people. However, earlier this month my brother actually managed to nail it with his gift and get me something that I really liked that I didn't even know I needed, which made me reconsider my approach. I suddenly found a new respect for the contemplation required in his style, so for his best man's gift, I decided I'd to try something different.
    &lt;/p&gt;
&lt;h3&gt;The Backstory&lt;/h3&gt;
&lt;p&gt;
        Both my brother and I grew up loving &lt;a href=&quot;https://en.wikipedia.org/wiki/Indiana_Jones_(franchise)&quot;&gt;Indiana Jones&lt;/a&gt;, as every kid should. My brother has dressed up as Indiana on many occasions, and our mother even somehow let us buy bullwhips when we were kids.
    &lt;/p&gt;
&lt;p&gt;
        When I got my PhD from the University of Chicago, my brother wanted to commemorate it with something that acknowledged that Dr. Jones and I are &lt;a href=&quot;http://indianajones.wikia.com/wiki/University_of_Chicago&quot;&gt;both alumni of the same institution&lt;/a&gt;. He thought long and hard on the gift, and decided to get me a &lt;a href=&quot;http://indianajones.wikia.com/wiki/Indiana_Jones%27s_Satchel&quot;&gt;WWII gas mask bag&lt;/a&gt; like the one Indiana uses to carry his stolen loot (I mean archaeological findings). Although I didn't realize it at first, this turned out to be a very practical and useful gift. Having this satchel is a great way to carry just a few things while going on hikes without having to lug a whole backpack. Plus it's just inherently really cool to walk around with a piece of Indiana Jones gear on.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-NX_kUpncASg/WagYceTakjI/AAAAAAAAI8I/5-s7ldd5TkE1C_ymfuclkXcAmAjmDERDwCKgBGAs/s800/IMG_20170829_223632.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When I got my brother a gift for being my best man and officiating my wedding, I wanted to make it something practical, but I also wanted to continue the adventurous spirit. Importantly, I wanted to make sure the delivery was part of the gift itself. The best thing I could think of was to get something that would enable my brother to finish a project that he's been wanting to execute on for a while now. He has a good idea for a board game, but he has never gotten around to finishing it and building it. To help him get it made, I got him credits with &lt;a href=&quot;https://www.thegamecrafter.com/&quot;&gt;Game Crafter&lt;/a&gt; to get all the pieces printed and delivered as soon as he finalizes the plans.
    &lt;/p&gt;
&lt;p&gt;
        Traditionally, I would have just emailed him the promo code, but for this delivery, I decided to make a little mystery and see if he could follow the clues to discover his gift...
    &lt;/p&gt;
&lt;h3&gt;The Setup&lt;/h3&gt;
&lt;p&gt;
        I thought it would be too hard to get someone to figure out both a website and complex 16 character promo code so instead I just created a fake Indiana Jones themed email and had the promo code sent there. For the puzzle he has to figure out to check gmail and the username and password from the hints I give. As an added bonus, I'm not going to directly reveal to him that there's a puzzle at all. I'm just going to hint at it with my clues a couple of times during my wedding weekend.
    &lt;/p&gt;
&lt;h4&gt;Clue 1: Map of the West Indies&lt;/h4&gt;
&lt;p&gt;
        For the first clue, I'm trying to be subtle enough that he could still doubt whether there is anything going on at all. To do this, I'm pretending that the first clue was actually hidden in the gift that he gave me. He bought it online so there's some chance that he'll believe that it was an &lt;a href=&quot;http://www.huffingtonpost.com/2012/12/18/uchicago-indiana-jones_n_2322098.html&quot;&gt;easter egg from the person selling it&lt;/a&gt;. I know it's a long shot, but even if he only has the tiniest momentary sensation that I didn't put it there, then that will make it just a little bit mysterious.
    &lt;/p&gt;
&lt;p&gt;
        The clue is a pretty basic map of the Caribbean that I found a few days ago on the sidewalk. To make it look more &quot;authentic,&quot; I stained it with coffee folded it up and ripped one edge. The symbolism of this token is that another name for the Caribbean is the West Indies, and Indy is Dr. Jones' abbreviated nickname.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-2ktRD2ZG9C8/Waj7MWjgbNI/AAAAAAAAI8w/PDn4EYAwgdE7QP2k0gpsAi3DR3US3Tj0ACKgBGAs/s800/IMG_20170830_181342.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        On the back, I'm adding the text:
    &lt;/p&gt;
&lt;blockquote&gt;Summer 1943,&lt;br/&gt;Island two miles south of Terre Rouge, Haiti&lt;/blockquote&gt;
&lt;p&gt;
        I didn't want to make it too obvious so I used a reference from a fairly obscure &lt;a href=&quot;http://indianajones.wikia.com/wiki/Indiana_Jones_and_the_Army_of_the_Dead&quot;&gt;Indiana Jones novel&lt;/a&gt;, &lt;i&gt;Indiana Jones and the Army of the Dead&lt;/i&gt;. The Island that Indiana and crew visit in the book is Called Zile Muri-yo, which is more ore less a transliteration of the French, Isle de Mort, or Island of the Dead. This is essentially the only reference I could find that put Indy somewhere in the West Indies so I kind of had to use it. From this, hopefully my brother can deduce that &lt;i&gt;zilemuriyo@gmail.com&lt;/i&gt; is the email address he'll be looking for. Of course, at this point he doesn't know anything about an email account. That clue comes later.
    &lt;/p&gt;
&lt;p&gt;
        As a premature setup, I also sent him a text mentioning that I found a map at the bottom of the bag he gave me. Of course, his text response shows that he isn't that gullible.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-OnAlmJ6PCIo/Waj7je6yb1I/AAAAAAAAI80/nKRlGHqeFrAPWYDmUfKUSH8WhJQ2Bcj8ACKgBGAs/s1600/Screenshot_20170831-064407.png&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Clue 2: Morse Code Belt&lt;/h4&gt;
&lt;p&gt;
        Next up we have the red herring, specially equipped with a classic coded puzzle. My brother will expect a best man gift so I'm going to need to give him something early on to throw him off the trail.
    &lt;/p&gt;
&lt;p&gt;
        The item I've chosen is an odd leather belt that I got a few years back. It says made in India so I'm going to suggest that it was fashioned in the region of India where &lt;i&gt;Temple of Doom&lt;/i&gt; is set. This is another subtle clue because encoded in the belt is a message that comes from that film.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-C4Xl75W6yzI/Waj7pll6ooI/AAAAAAAAI84/es37Sgl1bnIDIFEgO0c-m8k-GotdoRC9ACKgBGAs/s800/IMG_20170830_181508.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The belt has those weird holes poked through it all along the edge. The secret is that I'm stringing thread in a Morse code pattern between and among the holes. I'm using two types of thread. Presumably, this is hideous enough that my brother will notice there must be something up with the strings randomly strewn across a weird looking belt.
    &lt;/p&gt;
&lt;p&gt;
        The two colors each encode a different word. One is &lt;strong&gt;fortune&lt;/strong&gt;, the other is &lt;strong&gt;glory&lt;/strong&gt;. From this, hopefully my brother will guess that &lt;i&gt;fortuneandglory&lt;/i&gt; is the password. &quot;Fortune and glory&quot; is famously what Indiana (and everyone) is seeking on adventures.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-WAqGdbSdIF4/Waj8JwmnkRI/AAAAAAAAI9A/5LFfljRPgAkaZgYdcv9_0wcRV4wZTka9ACLcBGAs/s800/fortune-and-glory.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Still, he probably won't know at this point that he's looking for an email address, but he and I have both used that trick before so he might see it coming. Anyway, just in case, that is where the last clue comes in.
    &lt;/p&gt;
&lt;h4&gt;Clue 3: Lincoln Log Message&lt;/h4&gt;
&lt;p&gt;
        The last clue is going to be hidden in a gift I give to my brother's daughter, Penny. I got her several boxes worth of Lincoln Logs because she likes building things. I'll be giving her the bulk of the toys on Sunday at her birthday party, but, on Friday night before my wedding, I'm going to give my brother a little teaser of 5 lincoln logs and a figurine that looks a bit like Indiana.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-V_der9_HS9U/Waj6eu3UxPI/AAAAAAAAI8k/BkzSQCuy3KwLd6DLhY30-60UZVzD6MtIACKgBGAs/s800/IMG_20170830_181547.jpg&quot; title=&quot;Note that the thread is the same as used in the belt &quot;/&gt;
&lt;p&gt;
        The trick is that on some of the flat faces of the logs, there are little letters carved in: A, I, L, and M.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-EXomLziaRSo/Waj6PlrVpsI/AAAAAAAAI8g/Ko5qa0FrFuwKCbVuY5yfeo8KczgNoWeNgCKgBGAs/s800/IMG_20170830_203309.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Since each letter appears twice, the puzzle can be solved by constructing them together such that the same letters overlap.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-2zZK9nv6zI8/Waj6KPsrIKI/AAAAAAAAI8c/T1qBJ5AwCW0lIgg9ydMEWGipysW2xiJZQCKgBGAs/s800/IMG_20170830_203346.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When he does that, he should hopefully see that the logs form the shape of a capital G.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-sxMN4thpARY/Waj616VcF4I/AAAAAAAAI8s/kaa9yRPAUm0aQQ1J6IFeK5KK8dkJrDcngCKgBGAs/s800/IMG_20170830_203535.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        That along with the letters MAIL, should presumably help make it clear how to use the other two clues in some combination. Then, if everything goes according to plan, he'll log in and get the &lt;i&gt;Elusive Promo Code&lt;/i&gt;.
    &lt;/p&gt;
&lt;h3&gt;The Delivery&lt;/h3&gt;
&lt;p&gt;
        Overall, the delivery didn't go as well as I expected. The big issue was that I didn't make it obvious enough that there was a puzzle to solve. I went out of my way to make it seem like finding the map was an accident, and that the belt came that way. This led to some confusion. Even after my brother knew, he felt too pressured having to work on the problems while visiting family.
    &lt;/p&gt;
&lt;p&gt;
        There was also a technical problem with the construction of the Morse code belt that hampered the puzzle solving. Many of the threads came untied when transporting the belt around so there was an incomplete message by the time my brother was ready to solve the puzzle. In the end, I had to give that clue away because it was just to hard to solve with some threads missing.
    &lt;/p&gt;
&lt;p&gt;
        But in the end, I think my brother was really happy with the effort I put into both gift selection and delivery. And although it took a lot more work, I had a lot of fun building the puzzle. I think I'll try to keep this up with the next gift I give him, and maybe carry it over to my niece when she's old enough.
    &lt;/p&gt;
&lt;p&gt;
        The best part is that since we're brothers, I know that sooner or later the temptation to one-up each other will kick in. I'm looking forward to my brother coming up with something even more clever for my next gift.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 17 Sep 2017 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2017/09/indiana-jones-and-elusive-promo-code/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2017/09/indiana-jones-and-elusive-promo-code/</guid>
        
        <category>games</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-S0wDJ8pgbIA/WZkQ5QRKtQI/AAAAAAAAI4Q/UPX824oNWMksuOjYVPyabVJdTE7194eGwCLcBGAs/Screen%2BShot%2B2017-08-19%2Bat%2B9.32.15%2BPM.png</image>
        <title>The Stedden Constitution</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: Strongly convinced of personal utility, haven't fully considered all ramifications of broader adoption.&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;In order that we might form a more perfect union, we aim to adopt this constitution as a set of guiding principles for our partnership. &lt;br/&gt;--&lt;i&gt;Preamble to the Stedden Consitution&lt;/i&gt;&lt;/blockquote&gt;
&lt;h3&gt;The founding of a partnership&lt;/h3&gt;
&lt;p&gt;
        On September 2nd, 2017, Claire Grace Stevenson and William Michael McFadden are going to enter into formal partnership. Oftentimes, this type of partnership is called a marriage, but Claire and I are trying to think of our marriage differently. We want to look at this tradition with fresh eyes, and commit to using this opportunity to meet our own highest aspirations as companions for each other and as human beings.
    &lt;/p&gt;
&lt;p&gt;
        Toward this goal, we have decided to draft a set of guidelines that we will commit to in order to improve our marriage. Since we're both changing our last names to Stedden when we get married (a combination of our last names) and since this is in many ways the founding document of our partnership, we've nicknamed it the Stedden Constitution.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-S0wDJ8pgbIA/WZkQ5QRKtQI/AAAAAAAAI4Q/UPX824oNWMksuOjYVPyabVJdTE7194eGwCLcBGAs/s1600/Screen%2BShot%2B2017-08-19%2Bat%2B9.32.15%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h3&gt;Motivation&lt;/h3&gt;
&lt;p&gt;
        There have been &lt;a href=&quot;https://www.nytimes.com/2017/06/23/style/modern-love-to-stay-in-love-sign-on-the-dotted-line-36-questions.html&quot;&gt;several&lt;/a&gt; great &lt;a href=&quot;http://www.nytimes.com/2012/09/30/fashion/marriage-seen-through-a-contract-lens.html&quot;&gt;pieces&lt;/a&gt; over the past couple of decades based on the idea of setting up some kind of formal document. The main idea is that by putting something in writing, everyone has to think hard about why they feel the way they do, and they can't arbitrarily change their principles when it suits them.
    &lt;/p&gt;
&lt;p&gt;
        Other &lt;a href=&quot;https://waitbutwhy.com/2014/02/pick-life-partner.html&quot;&gt;things&lt;/a&gt; that Claire and I have been &lt;a href=&quot;http://www.slate.com/articles/arts/everyday_economics/1997/09/the_marriage_contract.html&quot;&gt;reading&lt;/a&gt; lately showcased the value of thinking about marriage as a negotiation for mutual benefit and thinking deeply about the cost-benefit of marriage. Ultimately, we are two people who like thinking about our actions and reaching mutually agreeable decisions so we thought this would be a great exercise for us.
    &lt;/p&gt;
&lt;h5&gt;Formalizing our highest aspirations&lt;/h5&gt;
&lt;p&gt;
        We really liked the idea of taking an opportunity to write out our aspirations for ourselves and each other. One of the main reasons for formalizing our relationship with marriage is to attain shared and individual goals that we really wouldn't be able to accomplish without being able to count on each other. But to accomplish those goals, we decided it was important to describe the goals we think are the most important.
    &lt;/p&gt;
&lt;p&gt;
        Here is a brief list of examples of aspirations that we are hoping to attain with each other's help. The full list is in the document below.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Develop understanding of and exercise faculties in diagnosing and treating patterns of irrational conflict inducing behavior&lt;/li&gt;
&lt;li&gt;Fairly allocate resources, despite living in an unfair world&lt;/li&gt;
&lt;li&gt;Ensure that each member of the partnership has all of the communicative and caring personal support they need&lt;/li&gt;
&lt;li&gt;Generate more value for the universe than is consumed by the members of the partnership as well as the additional activities that come about as a direct result of the partnership &lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;
&lt;h5&gt;A just and equitable relationship is by definition a negotiation&lt;/h5&gt;
&lt;p&gt;
        Claire and I both believe that any decisions in a relationship need to look like fair negotiations, with give and take so that both parties can be happy. I will go further with my own opinion: I believe that freedom to choose is truly the most fundamental human right one can give to another. If I had to pick one principle above all it would be that individual freedom should never be impinged without the consent of the individual. From this, it follows that all compromises and resolutions would need to be free negotiations between empowered individuals.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-DRwiRQzZg3E/WZkPGxu_WTI/AAAAAAAAI4E/aR-x7RC8pRQnW80BnP6r9VeGLs-aD2PXwCLcBGAs/s1600/7.jpg&quot; title=&quot;Note: Claire would never use that nail polish &quot;/&gt;
&lt;p&gt;
        Our agreement is putting in place the first formal ground rules for how we would negotiate our most fundamental decisions as our relationship progresses. We treat each other as equal partners and therefore we should write our founding constitution with that in mind.
    &lt;/p&gt;
&lt;h4&gt;Implementation&lt;/h4&gt;
&lt;p&gt;
        It can be tough to get the details right on an agreement like this. We couldn't find too many physical examples of real written marriage agreements despite many people talking about them, which meant we were largely on our own for how to structure it. Obviously, there are a million different ways that this could be done so the task can seem a little daunting.
    &lt;/p&gt;
&lt;p&gt;
        One thing was for sure, we definitely wanted to write all of this down and not count on our memories to keep our agreement in tact! Documentation tends to make us both feel more accountable. I cannot tell you how much more has gotten done in my life thanks to the existence of the TO-DO list. And beyond that, in terms of polishing things and following through, this blog has resulted in me finishing so many projects that otherwise would have sat at 95% done.
    &lt;/p&gt;
&lt;p&gt;
        We also wanted to keep this a living document since we are quite sure that we haven't perfected it yet. In some ways, just the exercise is valuable for helping us to understand each others needs better. Nevertheless, we did get some insight into what we thought would be best for our writing.
    &lt;/p&gt;
&lt;h5&gt;Avoiding obligations&lt;/h5&gt;
&lt;p&gt;
        We don't want this to be the place where we list our pet peeves and household chores. This document is more of a framework for the big picture items that will help us sort out all the smaller things day-to-day.
    &lt;/p&gt;
&lt;p&gt;
        To make sure we didn't get bogged down in too many small issues, I started by basing the outline around the concept of the &lt;a href=&quot;http://felipecastro.com/en/okr/what-is-okr/&quot;&gt;OKR&lt;/a&gt;. OKR stands for Objective and Key Result, and it's a framework developed at Google and used at my current company to keep us focused on our objectives and the key measurable outcomes that will help us determine if we're meeting our objectives. This methodology doesn't perfectly apply to what we were trying to attain with our constitution, but it did help to set the tone for what we wanted. We wanted to make sure we maintained focus on our top objectives and that we included specific actions that would immediately benefit those goals.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-wKw9CfJcunU/WZkbwSykI0I/AAAAAAAAI4g/Jju5gHTCt4EhAixEC6T4wM4MRyU5COQ2QCLcBGAs/s1600/MBO-and-OKR.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Based on this framework, we set up a short list of goals for five topics. Then we added activities and decisions that we will monitor to make sure we are keeping up with our objectives. So for example, one goal of our constitution was to make sure we fairly share our resources, and one action related to that objective was to maintain separate accounts and utilize a system of shared payments and gifts to formalize redistribution of finances. All of these goals and actions were kept at a high level without implementation details so that we could adapt our methods without having to ignore our constitution's guiding principles.
    &lt;/p&gt;
&lt;h5&gt;A political, legal, and economic microcosm&lt;/h5&gt;
&lt;p&gt;
        I like to think that there is an analogy that our partnership is more like the founding of a state than a contract of two business parties. We tried to ensure that we covered all the most important sections of life, and it was interesting to see that they had some interesting parallels with branches of real governments. The main sections that we focused on were:
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the resolution of conflicts in the relationship&lt;/li&gt;
&lt;li&gt;On the division of labor and capital&lt;/li&gt;
&lt;li&gt;On intimacy and emotional support&lt;/li&gt;
&lt;li&gt;On respecting the individuality of the members of the union&lt;/li&gt;
&lt;li&gt;On promoting ethical, engaged, valuable interactions with society&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        The first two can really be likened to our own little legal and economic systems, and the rest form the main different dimensions of the political issues that we've found ourselves trying to navigate already. We may someday find other broad areas that need to be incorporated, but for now, we've defined the scope of what our marriage tries to regulate.
    &lt;/p&gt;
&lt;h5&gt;Is this binding?&lt;/h5&gt;
&lt;p&gt;
        Uhhh, probably not. It seems like the only thing in a normal pre-nup is the money stuff. Our agreement on money stuff is that we will keep separate accounts and keep a careful budget to allow us to share expenses fairly. In the event of a divorce, we'll probably be able to use the budget to show how we managed our money during the marriage.
    &lt;/p&gt;
&lt;h5&gt;Timeframe&lt;/h5&gt;
&lt;p&gt;
        We want to make sure this document stays current as our needs and our understanding changes. Therefore, we've set the specific content of this document to be binding only until our first anniversary with the expectation that we will modify and reinstate next year and (hopefully) every year thereafter.
    &lt;/p&gt;
&lt;p&gt;
        For a bit, we considered designing both our constitution and our marriage to become fully optional for continuation after 30 years. The reason we considered this was so that we could plan our lives together for 30 years without expectations or pressure to stay together after that time. Of course, we both firmly believe today that we'll want to continue our marriage for the rest of our lives, but we want to be able to be able to reevaluate the situation without either of us feeling like it would be a betrayal at that time. I liked the idea of 30 years because that is about how long we've lived up to now so it's kind of more sincere to commit ourselves to each other for as long as our current lifetime. Also, this is just enough time for us to raise our family according to our current plan.
    &lt;/p&gt;
&lt;p&gt;
        I personally think that it would be highly logical to start making marriages intentionally optional after child-rearing is over. I know that divorce already makes this the practical outcome for a lot of marriages, but, to me, it would be better if we just made temporary marriage the default state. One factor to consider is that we now live much, much longer than anyone did back when marriage was first invented, and the need to keep two people pinned together indefinitely seems cumbersome as the populace ages. Plus, this would make it even more special when people actively decide to stay together after all that time.
    &lt;/p&gt;
&lt;p&gt;
        Unfortunately, there isn't really any legal way to make a marriage end after a set time period (though I assume that will become standard soon enough). However, we plan to maintain active communication as we approach September 2nd, 2047, to make sure that we want to keep our marriage on the books.
    &lt;/p&gt;
&lt;p&gt;
        It can be a little uncomfortable to talk about these kinds of things just as we're on the cusp of getting married, but on the other hand, these are the realities of the world we live in. It's sort of similar to my job in that no one wants to think about their risk of getting cancer in 10 years, but to me it seems sensible to address this head on and proactively. Based on &lt;a href=&quot;https://www.bls.gov/opub/mlr/2013/article/marriage-and-divorce-patterns-by-gender-race-and-educational-attainment.htm&quot;&gt;statistics for our demographic&lt;/a&gt;, Claire and I have set ourselves up to have a long and happy marriage, with only a 23% chance of being divorced after 15 years together. It's sad that 23% is surprisingly much better than other populations, but we're hoping that makes it all the more special when we succeed.
    &lt;/p&gt;
&lt;h4&gt;The Stedden Constitution - Year 1&lt;/h4&gt;
&lt;p&gt;
        And now without further ado, here is the document in its entirety.
    &lt;/p&gt;
&lt;iframe height=&quot;400&quot; src=&quot;https://docs.google.com/document/d/1ibN5nGRMWRl8JhEBFDqGGvocRhOYD3wT_R9a-eVIO6U/pub?embedded=true&quot; style=&quot;border:1px solid black&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt; &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Reflections&lt;/h4&gt;
&lt;p&gt;
        For the most part this document is meant to be a reflection on our personal values and our future goals. It's also a reflection on the state of marriage in this world. I believe that an exercise like this would prevent a large portion of failed marriages and broken homes. A few things stand in the way of a good idea like this from catching on in our culture.
    &lt;/p&gt;
&lt;p&gt;
        First, for some reason we culturally seem to have decided that it's distasteful to carefully think about the principles behind their relationships. Rather we spend vast quantities of time thinking about the shallow details of our wedding ceremony decorations, and who needs to be invited. Theoretically, I guess most people should have thought about the underpinnings of their reason for marriage before it gets to this point, but something tells me that it's rarer than one would think.
    &lt;/p&gt;
&lt;p&gt;
        It was a challenge to get this written with the absurdly onerous minutia involved in planning a wedding ceremony. But I'm so thankful that we took the time to draft this carefully and I firmly hope that we can inspire a few others to do the same.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 27 Aug 2017 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2017/08/the-stedden-constitution/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2017/08/the-stedden-constitution/</guid>
        
        <category>writing</category>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-aExL4L6pT8g/WTgYr_JKqhI/AAAAAAAAIXE/Cye57SqPgKIwsrX_-gjW-Dh5ANiFTQtOgCLcB/Embryo.gif</image>
        <title>Theseus and the Cell (a PhD dissertation story)</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: High confidence in technical validity of model, low confidence in biological applications.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        The main reason I haven't been very active on this blog for the past year is that I've been finishing up my PhD thesis. Since it was a big project, I think it deserves a little real estate on this blog of mine, but I don't want to rehash my whole thesis here since that was the point of publishing the dissertation. What I want to do in this blog post is outline the big idea behind my thesis and a couple of the fun things that I did to illustrate it.
    &lt;/p&gt;
&lt;h4&gt;How does an organism change its shape?&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-aExL4L6pT8g/WTgYr_JKqhI/AAAAAAAAIXE/Cye57SqPgKIwsrX_-gjW-Dh5ANiFTQtOgCLcB/s800/Embryo.gif&quot; title=&quot;Zebrafish developing from 1 cell into an early embryo &quot;/&gt;
&lt;p&gt;
        Imagine you had a shed filled with the most basic tools that you could use for constructing houses, say it just had a ton of hammers and saws. Now, lets say that every day you deliver more raw materials like lumber and nails to that shed. Would you ever imagine that you could come back nine months later and see that that shed had turned into a one bedroom house with a garage? What if you came back twenty years later and that shed had turned itself into a three story mansion with a pool out back? Would you think that's just impossible?
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-wgY_Pxh54es/WTgZm7Mi0yI/AAAAAAAAIXQ/sErKYz5yIOk6NiarvH0StNFGibaE0nZJACLcB/s1600/animation-full-home-remodel1-1.gif&quot; title=&quot; &quot;/&gt;
&lt;hr/&gt;
&lt;p&gt;
        Well that's basically exactly what happens every time a human embryo develops into a newborn baby and then, later, a fully grown adult. You start just with the basic tools for life in a simple package, and over time that simple embryo gets remodelled piece by piece into the person reading this blog post right now.
    &lt;/p&gt;
&lt;p&gt;
        Now, if you are a tinkerer like me, you might guess that all this would take place kind of the same way humans build stuff. We might start with something simple, but when we want to change something, we'll knock down a wall and put up a newer, better one in its place. Or we'll build a separate free-standing building next to the old one and then connect them together after you have both structures made. There are a lot of ways to build things, but the point is at the human scale of construction, we normally work by building something from the ground up with tools from the outside. Then when we want to revise, we build something new and attach it to the old thing or knock the old thing down when it isn't useful anymore.
    &lt;/p&gt;
&lt;blockquote&gt;Reference: &lt;a href=&quot;https://www.google.com/search?q=Dilbert&amp;amp;tbm=isch&quot;&gt;all of Dilbert&lt;/a&gt;&lt;/blockquote&gt;
&lt;p&gt;
        But what's amazing is that cells don't work this way. In fact, they pretty much can't for a couple of reasons:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There are no &quot;outside tools&quot; or an independent construction crew because the organism &lt;em&gt;is simultaneously&lt;/em&gt; the tools, the builders, and the structure being made.&lt;/li&gt;
&lt;li&gt;An individual cell can never totally knock something down and build a new version all at once because that would compromise its current function.&lt;/li&gt;
&lt;li&gt;When we are talking about individual molecules it is really hard to coordinate building things separate from the current cell. On that scale anything you tried to build would quickly float away from the construction site.&lt;/li&gt;
&lt;/ol&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-1_pVNxp68bQ/WTgZ-7lNjeI/AAAAAAAAIXU/6hd7kuprKSESorvZN0KOuUopoTjCTlhpACLcB/s800/roofon.jpg&quot; title=&quot;No giant construction workers for cells :( &quot;/&gt;
&lt;p&gt;
        So how do organisms overcome these obstacles to grow and change their form? Well, basically they do it by constantly making minimal modifications to their own structure, molecule by molecule, until they wind up with all these incremental changes adding up to large scale development. The analogy with builders is if you would move a wall by taking out one nail at a time, slipping the board as far as you can, and then renailing it before moving on to the next nail.
    &lt;/p&gt;
&lt;p&gt;
        We'll see how this works in a minute, but to understand just how they manage to rearrange their own internal parts without any outside help, we have to take a look at the basic building materials of the cell.
    &lt;/p&gt;
&lt;h4&gt;What's a cell made of?&lt;/h4&gt;
&lt;p&gt;
        The structure of almost all the interesting cells in the human body is a big, disordered cage-like web of tiny, molecular fibers made of a protein called &lt;em&gt;actin&lt;/em&gt;. I like to compare it to a messier version of a Zeppelin frame. In this vizualization I made as part of my dissertation defense, I take you on a little tour inside an egg shaped cell to see the orange actin filaments holding the cell together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-HYLaD555oGk/WTa_kUWEfeI/AAAAAAAAIVQ/l-4Sv8gF_MIM0guWbUZAqJ2Wu_JtJLcEQCLcB/s1600/cell_zoom.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The outside coating of this Zeppelin-like cell is a layer of oily goo, called the plasma membrane. On it's own, this oily layer isn't capable of providing much structure at all. Ultimately, if this was all that was holding cells together, a cell (or a Zeppelin) would just flop over in a little puddle of mushy goo (or a deflated blimp).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-pG4jSe0RScI/WTYu-uJpedI/AAAAAAAAITs/l2ImAcyKjms2apZiYoQ0snCWoXS7BCaWgCLcB/s1600/mn_goodyear.jpg&quot; title=&quot;Not the Best Year Not the Best Year&quot;/&gt;
&lt;p&gt;
        What makes the cell strong and able to hold its shape is the cage of molecular fibers that get stuck together by other small sticky proteins to create something like a disordered version of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Geodesic_dome&quot;&gt;geodesic dome&lt;/a&gt;. Inside this cage of actin filaments, the rest of the cell's machinery, like DNA, ribosomes, and mitochondria are free to do their work, largely protected from outside forces.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-GaatGYC44sk/WTYxDu1P1eI/AAAAAAAAIUA/zisPh0_dXQcFsmU8N_Nk8MJODZJO0k2BQCLcB/s1600/3320963272_93c60d29a7_z.jpg&quot; title=&quot;One of Fuller's Geodesic Dome - A mouse cell with actin fibers in green &quot;/&gt;
&lt;p&gt;
        As you can probably guess, it is by rearranging this web of actin filaments that organisms are able to grow, divide, and generally change their shapes. But before we get to describing how the cell does that, lets take a quick trip into an ancient philosophical discussion that helps to illustrate this basic physical system.
    &lt;/p&gt;
&lt;h4&gt;The Ship Of Theseus&lt;/h4&gt;
&lt;p&gt;
        If you know your ancient Greek mythology, you might remember Theseus as the smarter-than-your average hero of ancient Athens. What made Theseus interesting was that he often had to rely on a little cleverness to make his way through (as compared to that dumb jock Hercules). He was most famous for navigating the &lt;a href=&quot;http://www.creativitypost.com/arts/myth_and_creativity_ariadnes_thread_and_a_path_through_the_labyrinth&quot;&gt;labyrinth at Knossos&lt;/a&gt; and slaying the Minotaur&lt;a href=&quot;https://www.youtube.com/watch?v=2aoIs-5zqoI&quot;&gt;&lt;/a&gt;, and he's generally considered to have set up Athens into the &lt;a href=&quot;http://blog.amaliadillin.com/2011/01/theseus-as-father-of-athenian-democracy.html&quot;&gt;ancient model of democracy&lt;/a&gt;. But anyway, this story isn't so much about Theseus as much as it is about &lt;a href=&quot;https://en.wikipedia.org/wiki/Ship_of_Theseus&quot;&gt;his boat&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-zqjzUEG7zco/WTgbY2eV_PI/AAAAAAAAIXg/WZAoGOKdkD4cCneoRxm1NETf0fCiMmsXgCLcB/s1600/ancient-greek-boat.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You see, since Theseus was such a celebrity around Athens, after he died, people kept up maintenance on his ship and sold tickets to go sailing on it. But as time went on, one or two of the boards would get rotten, and so someone would see that those boards were going to cause the boat to sink and they'd replace them. Then a couple of years later, a few different boards would start to rot and somebody else would go and replace them. And every couple of years, this would continue so that there were always a few old boards being removed and a few fresh boards being added.
    &lt;/p&gt;
&lt;p&gt;
        Now this continued for centuries, until eventually somebody noticed that only one of the boards on the boat was actually original anymore. And what's even worse, they noticed when they looked at some old drawings that the layout of the boat wasn't even the same anymore because each time they brought on new wood they would slightly alter how it fit onto the boat.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-FssfV97-NmI/WTgdxn7ytbI/AAAAAAAAIXs/qoCTOJVxOZw48FhgxNIh3GOvDeo-__iZwCLcB/s1600/KOnQ8x.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Now this was ancient Greece so there were a ton of philosophers around (I'm pretty sure philosophy was, like, a quarter of Athens' GDP). And the philosophers liked to point out that pretty soon nobody should be wasting money to go see that boat because it &lt;em&gt;wouldn't be the same boat anymore&lt;/em&gt;. Now everybody understood that philosophers are generally kind of &lt;a href=&quot;http://www.denisdutton.com/bad_writing.htm&quot;&gt;pretentious&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Ethics&quot;&gt;buzz-kills&lt;/a&gt; anyway, but they also had to admit that they were kind of right.
    &lt;/p&gt;
&lt;p&gt;
        The people selling tickets to sail on the ship of Theseus were bummed because this started to hurt ticket sales so they tried to hatch a plan to get the philosophers to agree that it was still the same boat. Fortunately, they'd taken all the old rotting boards and piled them up in the same place over the centuries. On that spot, the boards had already decomposed back into soil, and a bunch of new trees had sprouted up and grown. So the people selling tickets to ride Theseus' ship took the wood from the trees that grew from the ground where the original boards rotted and started to incorporate those boards back into the modern ship.
    &lt;/p&gt;
&lt;p&gt;
        And so they asked the philosophers, &quot;Now since, it's all the same material*, wouldn't you agree that this is still the same ship?&quot; And some of the philosophers agreed and some didn't and this led to a philosophical conundrum about the nature of being... but that is a problem for another kind of &lt;a href=&quot;http://thoughtcatalog.com/maria-noelle/2015/04/the-meaning-of-life-as-explored-by-a-communications-major/&quot;&gt;blog&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The reason I brought this story up was to illustrate the way in which cells remodel themselves over time. Cells break down their actin fibers one at a time and then use the broken down material to build new fibers which they incorporate in different locations. This leads to a slow remodelling of the whole structure without ever losing the overall integrity.
    &lt;/p&gt;
&lt;h4&gt;My computational model of the actin network&lt;/h4&gt;
&lt;p&gt;
        My whole PhD was basically dedicated to using a computer simulation to recreate the molecular processes that cause cells to morph from one shape to another. Although writing the model itself involved a lot of math and computer code, the basic principles underlying the model are pretty simple to explain.
    &lt;/p&gt;
&lt;h6&gt;The structure&lt;/h6&gt;
&lt;p&gt;
        We already went over how the structure of the cell comes from actin filaments &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-covalent_interactions&quot;&gt;sticking together&lt;/a&gt; with other &lt;a href=&quot;https://www.mechanobio.info/topics/cytoskeleton-dynamics/actin-filament-bundle-assembly/&quot;&gt;smaller, sticky proteins&lt;/a&gt;. To get a clearer view of how this actually looks in a real cell here are a few electron microscopy images.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-xTxi9zzUoSQ/WTa9CQV7CuI/AAAAAAAAIVA/ayUf_RE8e7sWEG2T9743NO7azOo2Saa0QCLcB/s1600/309fbe1e5c14522cfa6d3924dc918ff5.jpg&quot; title=&quot;Actin filament network electron microscope images &quot;/&gt;
&lt;p&gt;
        In reference to our analogy of moving one board around at a time to change the structure, the next question that arises is how would the cell move these structural actin filaments around in the first place.
    &lt;/p&gt;
&lt;h6&gt;The movers&lt;/h6&gt;
&lt;p&gt;
        The way these filaments get moved around is ridiculously amazing. Every cell is teaming with nanoscale molecular motors called myosins. These myosins are tiny clumps of protein that burn chemical energy in the cell to generate little tiny tugs on actin filaments. This GIF shows what it looks like for one motor to pull against an individual actin filament. The colorful thing that is moving around is the myosin.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-6-pmB6QKC1Y/WTbUl-5S7gI/AAAAAAAAIV8/735jSANWAsUgFWyEyS632Yg3__-L0hI-QCLcB/s1600/myosin.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        By adding up hundreds of little tugs in different places around the cell, we end up with cellular scale motions. These motions can pull larger protein complexes around the cell or they can even pull against the surface of the cell to cause the cell to pinch in the center for dividing. In this video you can see the actin filaments in white all get pulled into a central ring, and that ring is pulled by the myosins toward the center to pinch the sides of the cell inward.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-EfEXuJXDafc/WTeA6a1PtyI/AAAAAAAAIWU/bzZKt-ykeFMWY7L-HQkIFIBhLY0oVbCVACLcB/s1600/contract_ring.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        What's even more crazy is that this microscopic system for moving around molecular components in the cell is actually evolutionarily conserved with our larger scale system for moving our muscles. Over time, multi-cellular organisms repurposed the function of actin and myosin to generate specialized muscular tissues. Every time we move, it's thanks to the sum activity of billions of actins and myosins working together to produce the macroscopic contractions in our muscles .
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-l_LRsVEi7W8/WTbVMtObn-I/AAAAAAAAIWA/GzNpCUey9tAcL5ke2fSAYkzgR_lqNHSQACLcB/s1600/muscle-contraction-o.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But back on the molecular scale of the cell, all these tiny tugging motions produce highly localized contractions within the cell. In my thesis research, I simulated the mechanical properties of actin filaments and myosin motors to reproduce local contractions of patches of simulated cellular material. In thee next animation, you can see one of the many thousands of simulations I ran to test the model and make predictions about how these cellular materials might behave with different concentrations of motors and filaments.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-0LRpOdmdbvs/WTbEDcIFxfI/AAAAAAAAIVc/vigPRb90Qmc8Ln1xnqDCN9ksSzePGelogCLcB/s1600/contract.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        So (after proving that the simulation makes sense and works right) the next question I asked was whether this model was enough to explain a significant amount of biological information? Could I predict how the cell would move around its structure just by employing my equations for simulated motors and filaments. Well it turns out it isn't quite that simple. If we just left these motors to their own devices, they would eventually either lock up the structure or tear it apart. To show this some of my colleagues, actually mixed purified myosin and actin together an recorded what happened under the microscope. As you can see in this next movie, the patch starts to deform a little bit, but before long, it winds up ripping itself into little chunks.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-BpT9-v3M3jc/WTbLWIfXV1I/AAAAAAAAIVs/Q3om4VQBsoYEDhoGQWuXiuw2c1urTxRPwCLcB/s1600/tearup.gif&quot; title=&quot;Actin and Myosin reconstitution tearing itself apart from Murrell et al. Actin and Myosin reconstitution tearing itself apart from Murrell et al.&quot;/&gt;
&lt;p&gt;
        To keep the cell alive and able to change shape, we have to introduce one more property that lets the actin network refresh itself as it is being moved around.
    &lt;/p&gt;
&lt;h6&gt;Recycling material&lt;/h6&gt;
&lt;p&gt;
        We find that as the motors move filaments around they end up wearing the filaments out so that they can't be moved around too much before they start to break down. So to solve this problem, just like in the ship of Theseus up above, the cell intentionally removes the old actin filaments and uses the material to rebuild fresh filaments that can be used to reconstruct. And also like in the ship of Theseus, the cell is doing this one filament at a time.
    &lt;/p&gt;
&lt;p&gt;
        To actually see this breakdown occur, my colleagues and I developed a method that allowed us to measure how long these filaments lasted before being broken down. We used single-molecule particle tracking movies like this one to watch individual pieces of actin get incorporated into the actin web, sit in the structure for a little while, and then get broken down and disbursed. In this video, you can see the flickering molecules as they get added and removed from the structure.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-ZE-bZYO0Y_c/WTeFeyg7BdI/AAAAAAAAIWg/AFF2kPkv7EAecWfu-uFD1-PwE0OZGfBYACLcB/s1600/tata.gif&quot; title=&quot;Single molecules of actin from Robin et al. Single molecules of actin from Robin et al.&quot;/&gt;
&lt;p&gt;
        I started calling this phenomenon filament recycling because, to me, it seems like the perfect analogy. The cell is actively breaking down its old structural material into its constituent parts and then reassembling those parts in order to rebuild its structure. The name still hasn't caught on (filament turnover seems to be the more popular jargon), but I'm hopeful that I'll be able to check back in on the field in a couple of years and see that they adopted my name.
    &lt;/p&gt;
&lt;h6&gt;Putting it all together&lt;/h6&gt;
&lt;p&gt;
        One of the most interesting things about doing a PhD is that you get to be the first to try something. For my thesis, I got to be &lt;a href=&quot;https://www.nature.com/articles/ncomms10323&quot;&gt;one of&lt;/a&gt; the first people to incorporate this recently discovered biological process of filament recycling into my mathematical model. This movie shows what my simulations looked like when I added in recycling.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-L5ZG2QM7xhQ/WTgeqtHn4SI/AAAAAAAAIX4/JuQbz61R9oUR2Rd9HSb4T0rvnCmggYQzwCLcB/s1600/act_rec.gif&quot; title=&quot;Wibbly wobbly filaments in simulation &quot;/&gt;
&lt;p&gt;
        This bears a striking resemblance with how the actin and myosin look in real cells.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-9JJjh981rXE/WTgf2RQt3gI/AAAAAAAAIYE/EQLG8l6uVV8ZMfQSoOkwISiKEzG40X92wCLcB/s1600/actin_seq.gif&quot; title=&quot;Wibbly wobbly filaments in living cells &quot;/&gt;
&lt;p&gt;
        The main takeaway of this work was that adding recycling prevented the cell from tearing itself to shreds. Beyond the basic observations, using a mathematical model allowed me to make a ton of predictions about how cells work, and it provided the field with some worthwhile ideas to explore in designing new experiments. You can view the &lt;a href=&quot;https://arxiv.org/abs/1612.07430&quot;&gt;preprint of the paper&lt;/a&gt; I wrote with my colleagues describing this research if you are interested to learn more.
    &lt;/p&gt;
&lt;p&gt;
        But most importantly, that wrapped up the body of work that my thesis committee decided was enough to qualify me for a PhD.
    &lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;The Seventh Labor - Writing the thesis&lt;/h4&gt;
&lt;p&gt;
        Like Theseus or any hero, just when you thought it was over, there's always a little more to be done. The final step in getting a PhD is to write a massive document and then stand up and give a talk about the work you have done over the years. The talk wasn't that hard for me, but, man, writing the paper was impossible. For some perspective, writing up this blog post took me about 5 hours split up over two nights. Writing up my dissertation took me over two years and I don't even want to think about the number of hours. It was gruelling and &lt;a href=&quot;https://thesiswhisperer.com/2014/09/17/im-writing-a-book-no-one-will-read-and-other-reasons-the-phd-can-get-you-down/&quot;&gt;arguably not really worth it&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        Fortunately, I version controlled the whole thing &lt;a href=&quot;https://github.com/wmcfadden/theseus&quot;&gt;on GitHub&lt;/a&gt; to keep track of the process. Using the &lt;a href=&quot;https://github.com/lots-of-things/git-pdf-viz&quot;&gt;Git PDF Visualizer code&lt;/a&gt; that I &lt;a href=&quot;http://www.makeloft.org/2016/06/git-versioned-pdf-visualizer.html&quot;&gt;wrote about on this blog&lt;/a&gt; last year, I was able to make a cool little video showing the progress.You can see a couple of big lulls when I worked on &lt;a href=&quot;https://www.usenix.org/node/195133&quot;&gt;analyzing datacenter efficiency&lt;/a&gt; and building an &lt;a href=&quot;http://sexpertise.makeloft.org/&quot;&gt;automated doctor&lt;/a&gt;.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/970OKVFPxQQ&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        The finished document was published on some completely ridiculous &lt;a href=&quot;http://www.proquest.com/&quot;&gt;basically inaccessible website&lt;/a&gt;, but you can get a copy &lt;a href=&quot;https://github.com/wmcfadden/theseus/raw/master/theseus/theseus.pdf&quot;&gt;here&lt;/a&gt; if you're dying to read it. Enjoy.
    &lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;
&lt;i&gt;*I know that most of the material in trees comes from CO2 in the air, and not decomposed material in the soil, but we'll just pretend that ancient Athenians didn't know that so the story still works.&lt;/i&gt;
&lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Mon, 14 Aug 2017 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2017/08/theseus-and-cell-phd-dissertation-story/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2017/08/theseus-and-cell-phd-dissertation-story/</guid>
        
        <category>science</category>
        
        <category>analysis</category>
        
        <category>modeling</category>
        
        <category>biology</category>
        
        <category>physics</category>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-1IVZ3gQl6Mw/WWLffNqxr2I/AAAAAAAAIrw/rqxcHrOLbiUboUlFBuNVThYCCp9J1y6VQCLcBGAs/WPS%2BDiscipline.png</image>
        <title>Analyzing Edge.org forum data - Experiences with Crowdsourcing Analysis</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: First foray into this type of analysis, expecting a 33% chance of at least 1 major technical error.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        I recently signed up to take part in an &lt;a href=&quot;https://docs.google.com/document/d/1fXQBLdWydISskOKhoq8gl5unuwsv7VA3pkKY4IWFS6o/edit&quot;&gt;experiment&lt;/a&gt; on crowdsourcing data analysis run by &lt;a href=&quot;https://www.esmt.org/martin-schweinsberg&quot;&gt;Martin Schweinsberg&lt;/a&gt; out of &lt;a href=&quot;https://www.esmt.org/&quot;&gt;ESMT Berlin&lt;/a&gt;. For this project, a bunch of analysts are going to try to determine independently whether a hypothesis is true using the same data set. Then we'll get back together at the end to see how variable our conclusions were. What we really hope to get out of this is some understanding of whether independent analysts can produce reliable reproducible results or if the many different ways of analyzing any complex data source will inevitably lead to discrepancies in interpretation.
    &lt;/p&gt;
&lt;p&gt;
        I'm very interested to be part of this study to promote reproducible and open scientific practices. After seeing the &lt;a href=&quot;https://osf.io/preprints/psyarxiv/qkwst/&quot;&gt;preprint&lt;/a&gt; of the previous round of crowdsourced analysis and Martin's &lt;a href=&quot;https://osf.io/hj9zr/&quot;&gt;crowdsourcing science course&lt;/a&gt;, I feel like this will be an interesting experience. I'm hoping to learn a lot about social science research and statistical inference techniques.
    &lt;/p&gt;
&lt;p&gt;
        I'll be writing more about the collaboration experience in a followup post once I get feedback on my contribution, but here, I wanted to write up my initial analysis of the data. I should point out that I'm not that experienced with social science research so this just a novice's attempt at using some statistical methods. Hopefully, it doesn't turn out that I've made too many mistakes.
    &lt;/p&gt;
&lt;h3&gt;The Edge.org Data Set&lt;/h3&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Uc2ASFAtzV8/WX00JBh5aqI/AAAAAAAAIu0/LVxu5syh8IoFIAM3FbG0tyjxvEeTRZxCgCLcBGAs/s1600/Screen%2BShot%2B2017-07-29%2Bat%2B6.19.08%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        For this study we are going to be trying to answer a few questions about how scientists and technologists communicate. To do this we're going to be looking at communications from an online forum dedicated to scientific discussions called The Edge. I had never heard of it but from what I can gather, Edge.org is designed facilitate important intellectual discussion about the &quot;edge&quot; of what science has concluded about reality.
    &lt;/p&gt;
&lt;blockquote&gt;To arrive at the edge of the world's knowledge, seek out the most complex and sophisticated minds, put them in a room together, and have them ask each other the questions they are asking themselves. &lt;/blockquote&gt;
&lt;p&gt;
        Importantly, the forum isn't open to anyone and the contributors are selected by Edge based on their creative work. These contributors include Daniel Kahneman, Marissa Meyer, Craig Venter, and many other academics as well as writers, entrepreneurs, business leaders, and more. These individuals are supposed to make up a class called the third culture, which I think is in contrast to the two culture mentality of science &lt;i&gt;vs.&lt;/i&gt; &quot;literary intellectuals.&quot; This is how the website describes the third culture:
    &lt;/p&gt;
&lt;blockquote&gt;The third culture consists of those scientists and other thinkers in the empirical world who, through their work and expository writing, are taking the place of the traditional intellectual in rendering visible the deeper meanings of our lives, redefining who and what we are. &lt;/blockquote&gt;
&lt;p&gt;
        To read more about the background on The Edge, you can read &lt;a href=&quot;https://www.edge.org/about-edgeorg&quot;&gt;this historical account&lt;/a&gt; by the creator. But perhaps the easiest way to get acquainted (and the way I first approached it) was to look at a few sample threads.
    &lt;/p&gt;
&lt;h4&gt;Example forum thread&lt;/h4&gt;
&lt;p&gt;
        As a quick example of what conversational threads really end up looking like, I randomly selected a post titled &lt;strong&gt;&lt;a href=&quot;https://www.edge.org/conversation/mirror-neurons-and-imitation-learning-as-the-driving-force-behind-the-great-leap-forward-in-human-evolution&quot;&gt;Mirror neurons and imitation learning as the driving force behind the great leap forward in human evolution&lt;/a&gt;&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;
        From the &lt;a href=&quot;https://www.edge.org/conversation/frank_schirrmacher-wake-up-call-for-europe-tech&quot;&gt;few&lt;/a&gt; &lt;a href=&quot;https://www.edge.org/conversation/paul_davies-time-loops&quot;&gt;other&lt;/a&gt; &lt;a href=&quot;https://www.edge.org/conversation/david_gelernter-the-second-coming-%E2%80%94-a-manifesto&quot;&gt;examples&lt;/a&gt; I looked up, I get the sense that, most of the time, the conversation looks kind of like one person going on a rant about their personal project or promoting a book, and then a bunch of academics debating at length who really deserved credit for that idea.
    &lt;/p&gt;
&lt;p&gt;
        While Edge and the third culture ideal is a cool idea, people are people I guess. Fortunately, the content being stuffy academic jibber-jabber makes it easier to analyze the data without getting caught wasting time reading the articles.
    &lt;/p&gt;
&lt;h4&gt;The Edge.org community&lt;/h4&gt;
&lt;p&gt;
        The data table provided for the analysis consists of about 7975 comments provided by 728 users across 522 threads. About half of these threads are actually live recorded discussions, but I removed those to focus down on just online discussion in 3657 comments from 681 users across 344 threads. Some threads were more popular than others, and some users were more prolific than others. To get a sense of the data and the structure of the community generating the data, I started with some basic preliminary plots.
    &lt;/p&gt;
&lt;p&gt;
        One cool thing about the data set is that they have categorized all the community members based on their job title and academic discipline (if they are academics). This gives a pretty clear insight into what kinds of people are making contributions. There are actually a lot of people with non-academic jobs on the forum, though professors do make up the bulk of the population. For those who have a discipline, there seems to be an overabundance of those who focus on social sciences. Of course, I'm not sure if that is due to there actually being more social scientists in the world or if they just are more drawn to this forum, though I suspect the latter.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-lg2ykXC-BYI/WWKOugW2ZuI/AAAAAAAAIps/X6uffXODC90TF_CphAVymOsxILf19X2VQCLcBGAs/s1600/Discipline%2BCount.png&quot; title=&quot; Counts of Users based on Job Title and Discipline. &quot;/&gt;
&lt;p&gt;
        Next, to get a sense of engagement, I plotted the number of contributions coming from each community member as a function of how many years they had been active in the community. The result showed that there were a few members who had been contributing since the forum began, and those few individuals were very active. However, the vast majority of users only made a small number of contributions during 1 year.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-aaVIk_SHwjk/WWKPnrGjRgI/AAAAAAAAIp0/8kleJpBM1e0lxmSteIS2D5CeX8kTY4ccACLcBGAs/s1600/YearsContrib%2Bvs%2BTotal%2BContribs.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Finally, this last set of figures shows that certain threads were more popular than others, and that the number of threads created has varied by quite a bit over the years.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-M1X5O7CYA0g/WWKPs31_xjI/AAAAAAAAIqE/bkHwg5fr91goze6PQjicOrwWogqs-Z3XQCLcBGAs/s1600/DebateSize%2BCount.png&quot; title=&quot;Thread contribution stats &quot;/&gt;
&lt;p&gt;
        Fortunately, the forum data hasn't offered too many surprises up to now. So I feel a little more comfortable using it to address the hypotheses that I've been tasked with investigating.
    &lt;/p&gt;
&lt;h3&gt;Testing hypotheses&lt;/h3&gt;
&lt;p&gt;
        The aim of this project is to test two hypotheses provided by the project organizers.
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A woman’s tendency to participate actively in the conversation correlates positively with the number of females in the discussion.&lt;/li&gt;
&lt;li&gt;Higher status participants are more verbose than are lower status participants.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        By the end, I know I'm supposed to provide some type of effect size to display the significance of any finding. I normally don't work in the language of formal effect sizes (folks at the company I work for glaze over when I toss around p-values) so I'm going to try to keep my analysis simple. Hopefully if I just follow the basic guidelines on linear models, I can justify my usage to any reviewers.
    &lt;/p&gt;
&lt;p&gt;
        I'm personally much more interested about the question of female participation in science. From personal experience, I've noticed differences in communication styles between men and women and I thought it would be interesting to see if there were signals of those differences in the online forum data. At the same time I also like the idea of comparing the verbosity of academics, particularly comparing how verbose individuals from different disciplines and job descriptions might be.
    &lt;/p&gt;
&lt;p&gt;
        In the following two sections, I'll go through my analysis of each hypothesis separately.
    &lt;/p&gt;
&lt;h4&gt;Contributions from Women&lt;/h4&gt;
&lt;p&gt;
        I find that a lot of the nuance of which direction I'm going to pursue comes down to how I'm interpreting the hypothesis.
    &lt;/p&gt;
&lt;blockquote&gt;A woman’s tendency to participate actively in the conversation correlates positively with the number of females in the discussion. &lt;/blockquote&gt;
&lt;p&gt;
        To flesh out the first hypothesis, I needed to specify what participation means. I'm going to interpret the hypothesis as valid if I can detect whether a woman joining in on a conversation depends on how many other women are in the conversation.
    &lt;/p&gt;
&lt;h5&gt;Female contributions across threads&lt;/h5&gt;
&lt;p&gt;
        To begin, I wanted to test the simplest evidence that would point to the hypothesis being true. Can I detect whether women self-segregate into certain threads? In other words, are there some threads with a lot more women than we would guess.
    &lt;/p&gt;
&lt;p&gt;
        The easiest way to see this would be to just visually check if there are lots of crazy outlier threads in terms of female contribution. We can plot the fraction of women in each thread along with a confidence interval to see if there. I used a Wilson confidence interval to determine the significance of the discrepancy from the expected proportion given the sample size in each thread. Because the confidence intervals on very small samples are too large to be meaningful, I've filtered out the threads that have fewer than 5 people.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-pwLX-PJch9c/WWKYJnX3C0I/AAAAAAAAIqQ/a8y7Us9-ZAwPMbB1vDxtp7363QgkqrbFACLcBGAs/s1600/Female%2BFraction%2BDiscrepancy.png&quot; title=&quot;Confidence intervals for each thread shows that most threads have a fair distribution of women. &quot;/&gt;
&lt;p&gt;
        It looks like there are basically only 3 threads that don't overlap with the expected proportion (solid lines). So at the simplest level, it seems that women are participating in all threads about as much as we would expect.
    &lt;/p&gt;
&lt;p&gt;
        We can also perform a statistical test of the female proportion of contributors in each thread using a chi squared test of homogeneity. This can be performed easily with R's prop.test function. The results of my prop test (below) show that the differences between female proportion are not significant enough to conclude that women are segregating into groups and only talking with one another. The p-value on the prop test was 0.12, which is widely accepted as &lt;a href=&quot;http://blog.minitab.com/blog/understanding-statistics/what-can-you-say-when-your-p-value-is-greater-than-005&quot;&gt;not significant&lt;/a&gt;.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;span style=&quot;color:brown&quot;&gt; prop.test(thread_info$UniqueFemaleContributors,thread_info$UniqueContributors) &lt;/span&gt;&lt;br/&gt;&lt;br/&gt; 93-sample test for equality of proportions without&lt;br/&gt; continuity correction&lt;br/&gt;&lt;br/&gt;X-squared = 107.96, df = 92, p-value = 0.1224&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        At this point, I'm thinking that I would feel pretty comfortable concluding that female participation is largely unbiased across threads. However, this is a rich data set so I wanted to continue with some more exploratory analysis.
    &lt;/p&gt;
&lt;h6&gt;Digging deeper: female demographics by discipline and job, effects of time, and total contributions&lt;/h6&gt;
&lt;p&gt;
        There is some concern that different covariates could influence the rates of female participation. Particularly, I was interested in the gender skew among different disciplines and jobs. Plotting the community size as well as the female makeup of each community showed that female job titles and disciplines were not evenly distributed.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-HQZyi6AXKz8/WWKscPWpgbI/AAAAAAAAIqk/0HhH0ltECE4OunmkYSC4NWDDYY2PhzCvwCLcBGAs/s1600/fraction%2Bfemale%2Bdiscipline.png&quot; title=&quot; Line is Female Fraction (apologies for being same color) &quot;/&gt;
&lt;p&gt;
        The result is largely what you'd expect. Natural science and math is underrepresented in their share of women compared to humanities and social sciences. And the more prestigious professions also show a lower proportion of women. However, the effects are not as severe as you might think. The groups all mostly overlap, but you can tell that there are trends that would probably shake out if we had more participants.
    &lt;/p&gt;
&lt;p&gt;
        A much bigger issue is that female participation hasn't been constant over time. In fact, the outlying threads from the previous analysis were all from 2010 onward. Obviously, that will be a potential confounding variable in the analysis. As you can see from the following figure, the fraction of contributions from women grew considerably over the past 20 years.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-IWZyetk5r_E/WWKtyACHlaI/AAAAAAAAIqw/dStR3ZFVBWgonE2SXGg90mrNZznvlbo_QCLcBGAs/s1600/Female%2Bby%2Byear.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Related to this, there is also one other interesting quirk in the number of contributions made by individuals relative to how long they have been in the community. This last plot basically shows that for recent users the number of contributions made by men and women is approximately the same. However, for users who have been involved for more than 10 years or so, the men seem to have been much more active.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-uvFu8rtx51s/WWKvKmw6xVI/AAAAAAAAIrA/EHi-f20G_7ccqnyFfyhINeAYUIyz27JBACLcBGAs/s1600/Rplot01.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This shouldn't really affect our results, but it's interesting, and it might be useful to keep it in mind.
    &lt;/p&gt;
&lt;p&gt;
        Taking all of this into account, I wanted to attempt a slightly more sophisticated methodology for modeling female participation.
    &lt;/p&gt;
&lt;h5&gt;Predicting the gender of the next contributor&lt;/h5&gt;
&lt;p&gt;
        As a final test, I wanted to see whether there was any information about a thread that could be used to predict whether the next person to enter the thread would be a woman. My reasoning behind this was that any variable that would be shown to significantly affect the prediction would meet some definition of significance. Therefore, if the fraction of women participating was predictive, we could conclude that women must be using that information to influence whether they enter the conversation. I believe this is generally how people do &lt;a href=&quot;http://www.pitt.edu/~wahed/teaching/2083/fall10/Lecture610.pdf&quot;&gt;statistical inference&lt;/a&gt; from linear models, but I could be wrong. In the past, I've mostly always used fitting techniques like this to infer &lt;a href=&quot;http://courses.washington.edu/matlab1/ModelFitting.html&quot;&gt;error estimates on parameter values&lt;/a&gt; (I used to be a physicist after all).
    &lt;/p&gt;
&lt;p&gt;
        The way I will operationalize this is to try to predict the gender of each new contributor to a thread given the information about the thread up to the point before this contributor joined. I chose this metric specifically because I didn't want to include any influence from that participant having already joined in the conversation. Therefore, what I'm looking at is the probability that given a new person enters the conversation, what is the probability that that participant is a female.
    &lt;/p&gt;
&lt;p&gt;
        The main variable I want to test to see if it affects this probability is the fraction of previous contributions in a thread that came from women. To test this variable I had to construct it by using a running sum of the number of unique participants and thread responses from both men and women.
    &lt;/p&gt;
&lt;p&gt;
        In addition to this primary metric of interest, I also wanted to include a few covariates that I thought might be of interest. In particular, I wanted to see if the thread year, and the overall thread progress (i.e. what fraction of the total length of the thread has already occurred before the participant under question joins the converstaion.)
    &lt;/p&gt;
&lt;p&gt;
        Without controlling for thread year, I found a very slight effect of the cumulative fraction of comments that came from women.
    &lt;/p&gt;
&lt;p&gt;
        Additionally, I also found an effect from the thread progress. Women seemed to be less inclined to enter a conversation as it was nearing it's end.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-t3fViz9NUdk/WWK8UIzcAzI/AAAAAAAAIrU/imVQj5jm_CMWsohTG5vvgDyFmZ7sMjX6QCLcBGAs/s1600/thread%2Bprogress.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I used the &lt;a href=&quot;https://stat.ethz.ch/R-manual/R-devel/library/stats/html/glm.html&quot;&gt;R glm function&lt;/a&gt; to &lt;a href=&quot;http://www.ssc.wisc.edu/sscc/pubs/RFR/RFR_RegInference.html&quot;&gt;infer the significance&lt;/a&gt; of the two contributions. The code below produces a summary of the model, with the estimated coefficients and the their test statistic (see wikipedia for more details on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Wald_test&quot;&gt;Wald test&lt;/a&gt;).
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;span style=&quot;color:brown&quot;&gt;&amp;gt; model = glm(Female ~ OtherFemale_CumFrac + ThreadProgress, family = 'binomial', data_th1 )&lt;br/&gt;&amp;gt; summary(model)&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Call:&lt;br/&gt;glm(formula = Female ~ OtherFemale_CumFrac + ThreadProgress, &lt;br/&gt;    family = &quot;binomial&quot;, data = data_th1)&lt;br/&gt;&lt;br/&gt;Coefficients:&lt;br/&gt;                    Estimate Std. Error z value Pr(&amp;gt;|z|)    &lt;br/&gt;(Intercept)          -1.9450     0.1233 -15.774  &amp;lt; 2e-16 ***&lt;br/&gt;OtherFemale_CumFrac   1.4296     0.4605   3.104  0.00191 ** &lt;br/&gt;ThreadProgress       -0.4739     0.1946  -2.436  0.01485 *  &lt;br/&gt;---&lt;br/&gt;Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        In the last column, Pr(&amp;gt;|z|), a p-value is computed for that variable given all the information from the rest of the model. Thus both ThreadProgress and OtherFemale_CumFrac show some correlation with the outcome in question even when taking the other variable into account. From this we could conclude that there is some significant correlation between women joining the conversation and the percent of comments thus far that came from women.
    &lt;/p&gt;
&lt;p&gt;
        I submitted the above result because I was in a rush to meet the deadline, BUT the story isn't quite over. Long story short, I missed a BIG issue that basically invalidated my result!
    &lt;/p&gt;
&lt;h5&gt;OOPS! Adding Thread Year as a Covariate&lt;/h5&gt;
&lt;p&gt;
        I mentioned in my analysis abover that female participation varied with thread year. Unfortunately, I forgot to include that as a covariate when performing the regression above. When taking year into account, the significance of the above result evaporated.
    &lt;/p&gt;
&lt;p&gt;
        Basically, all I had to do to fix the problem was add thread year back into the equation for the glm. Had I done that in the beginning I would have found the following result.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;span style=&quot;color:brown&quot;&gt;&amp;gt; model = glm(Female ~ OtherFemale_CumFrac + ThreadProgress + Year, family = 'binomial', data_th1 )&lt;br/&gt;&amp;gt; summary(model)&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Call:&lt;br/&gt;glm(formula = Female ~ OtherFemale_CumFrac + ThreadProgress + &lt;br/&gt;    Year, family = &quot;binomial&quot;, data = data_th1)&lt;br/&gt;&lt;br/&gt;Coefficients:&lt;br/&gt;                      Estimate Std. Error z value  Pr(&amp;gt;|z|)    &lt;br/&gt;(Intercept)         -101.33251   23.40287  -4.330 0.0000149 ***&lt;br/&gt;OtherFemale_CumFrac    0.60656    0.52847   1.148    0.2511    &lt;br/&gt;ThreadProgress        -0.49821    0.19466  -2.559    0.0105 *  &lt;br/&gt;Year                   0.04958    0.01167   4.248 0.0000216 ***&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        From the last column, Pr(&amp;gt;|z|), we can see the significance p-value is well below 0.05 for the Year variable, whereas the OtherFemale_CumFrac variable is now at 0.25 and thus not significant. Therefore, I have to reject the hypothesis that female participation has been influenced by anything other than time at this point.
    &lt;/p&gt;
&lt;h6&gt;Takeaway: no evidence for the hypothesis &lt;/h6&gt;
&lt;p&gt;
        Although, I did find a slight effect, the confounding variable of thread year appears to be the real predictor. Therefore, we should accept the null hypothesis that women's participation is not influenced by the participation of other women.
    &lt;/p&gt;
&lt;p&gt;
        Unfortunately, I didn't double check my work until I started writing this blog post! That means the answer I submitted has a MUCH higher significance that I really found. Oh well, I suppose these are the growing pains of trying to learn how to use an online collaborative data analysis framework. At least I learned, that I need to write up my analysis BEFORE I submit it to make sure my thinking is clear.
    &lt;/p&gt;
&lt;h4&gt;Verbose Academics?&lt;/h4&gt;
&lt;p&gt;
        There was a second hypothesis to be tested as part of this project.
    &lt;/p&gt;
&lt;blockquote&gt;Higher status participants are more verbose than are lower status participants. &lt;/blockquote&gt;
&lt;p&gt;
        I was significantly less interested in this question so I won't speak to as much detail on this problem as I did above. But there were some interesting points which I'll highlight quickly.
    &lt;/p&gt;
&lt;h5&gt;What specifically should we test&lt;/h5&gt;
&lt;p&gt;
        This problem is kind of hard because there are lots of reasonable ways to operationalize &quot;verbosity,&quot; and answering this hypothesis really requires picking a definition. I actually tested three related measurements before getting to one that had a very weak observable effect. The forum post data included precomputed text analysis of the &lt;a href=&quot;http://liwc.wpengine.com/&quot;&gt;LIWC metrics&lt;/a&gt;. These metrics basically try to boil down complex properties of text into simpler metric(see &lt;a href=&quot;http://liwc.wpengine.com/wp-content/uploads/2015/11/LIWC2015_LanguageManual.pdf&quot;&gt;this manual&lt;/a&gt; for lots of details). I just used three simple metrics that I thought would be good measures of verbosity:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;total word count per post (WC),&lt;/li&gt;
&lt;li&gt;word count per sentence (WPS),&lt;/li&gt;
&lt;li&gt;and the LIWC metric for usage of words that are six letters or longer (Sixltr).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        For the dependent variable I tried a couple of metrics all of which related to the total citations of the user up to the point of their last contribution on the forum. They all showed basically the same thing so, in the interest of brevity, I'll just report results in terms of the total number of citations. Basically my less ambiguous hypothesis ended up being:
    &lt;/p&gt;
&lt;h6&gt;Does a users word usage relate to the number of citations they've had?&lt;/h6&gt;
&lt;p&gt;
        I figured the main confounding variables for this study would be the discipline and job title of the contributor so I decided to do a little exploration to see how those related.
    &lt;/p&gt;
&lt;h5&gt;How discipline and job affected verbosity&lt;/h5&gt;
&lt;p&gt;
        This was one of the things I wanted to know the most. After having lived with three anthropologists for about 6 months, I had a pretty solid preconceived notion about how verbose people in the humanities were. Just plotting the WPS and Sixltr metrics showed that there was some pretty noticeable discrepancies between the disciplines, with social science and humanities coming in at the high end for word length, and social science and natural science coming in at the high end for the Sixltr score.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-OUO5bWa1eIw/WWLffONo6nI/AAAAAAAAIr0/a4YFQnvUKcUnMJSIX5Ifw1RiCDifcP6AQCLcBGAs/s1600/Sixltr%2BDiscipline.png&quot; title=&quot;  Different disciplines write differently (not that surprizing) &quot;/&gt;
&lt;p&gt;
        Likewise, when looking at the effect of job title on word count (WC), it seemed pretty clear that the academic job titles were more inclined to writing longer posts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Wvw15DFVC1Y/WWLhm-rufUI/AAAAAAAAIr8/Iot7L_sES-Yv9uSf5nWPDDGMl1B2YX3qACLcBGAs/s800/job%2Btitle%2BWC.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Clearly, with the large, significant effects that these variable imparted, I figured it might be hard to pick up much signal from the impact of citations.
    &lt;/p&gt;
&lt;h5&gt;Impact of citations on verbosity&lt;/h5&gt;
&lt;p&gt;
        Interestingly, any effect of citations on verbosity seemed to be at best discipline and job specific. As an example, we can look at the effect of citations on a user's mean Sixltr score, while comparing only members of the same discipline. In the following figure, I group and color users by discipline so that you can follow a colored line to see what the average effect citations had on the Sixltr score.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-BhuPN7abqok/WWLbdSiYtTI/AAAAAAAAIrk/gq_ubjJg94UBbG0XFnUeH1lc22CZhTacACLcBGAs/s1600/citation%2Bsixltr%2Bdiscipline.png&quot; title=&quot;Effect of citation count varies across disciplines &quot;/&gt;
&lt;p&gt;
        As you can see most of the disciplines actually have a negative correlation between citations and number of six letter words used. However, the natural sciences seems to show a positive correlation. Likewise, we can look at the same measurement while comparing among members of the same academic hierarchy (1 being assistant professor and 6 being chaired professor).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-yQQhouV2BZ0/WWLcBRolc9I/AAAAAAAAIro/gOi2q1yys7cdk7A9Kv3wInBaNAXBeQRhwCLcBGAs/s1600/citation%2Bsixltr%2Bhierarchy.png&quot; title=&quot;Effect of citation count varies across echelons of academia &quot;/&gt;
&lt;p&gt;
        Again, the results are all over the place, with higher academic rank showing a positive correlation while a lower academic rank has a negative correlation. However, the folks with a low academic rank and few citations appear to be just as verbose as those with a high academic rank and many citations. It almost looks like there is a &lt;strong&gt;valley of verbosity&lt;/strong&gt; among the middle of the pack.
    &lt;/p&gt;
&lt;p&gt;
        To make a long story short, this is the kind of data where you can slice any story out of it that you want. I chose to keep my tests simple and linear so I had a pretty good feeling that I wasn't going to find any strong effect in this data set.
    &lt;/p&gt;
&lt;h6&gt;Results of the modeling&lt;/h6&gt;
&lt;p&gt;
        Finally, I tested the hypothesis using the same glm formula as before, though this time I was predicting a &lt;a href=&quot;https://en.wikipedia.org/wiki/Normal_distribution&quot;&gt;gaussian&lt;/a&gt; variable rather than a &lt;a href=&quot;https://onlinecourses.science.psu.edu/stat200/node/37&quot;&gt;binomial&lt;/a&gt;. It turned out that WC and WPS had almost no effect so I will just show the results for Sixltr since that was more interesting.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;Call:&lt;br/&gt;glm(formula = Sixltr ~ Total_Citations, family = &quot;gaussian&quot;, &lt;br/&gt;    data = user_wc)&lt;br/&gt;&lt;br/&gt;Coefficients:&lt;br/&gt;                    Estimate   Std. Error t value Pr(&amp;gt;|t|)    &lt;br/&gt;(Intercept)     28.492929260  0.510552842  55.808   &amp;lt;2e-16 ***&lt;br/&gt;Total_Citations -0.000008705  0.000014841  -0.587    0.559    &lt;br/&gt;---&lt;br/&gt;Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        Again, if we analyze the printout, we can see that the p-value for Total_Citations is well above the minimum for significance of 0.05. Thus we would reject that Total_Citations has much of an impact on Sixltr. I repeated this modeling exercise for a bunch of different citation related variables and seeing if they had an impact on WC, WPS and Sixltr. None of them showed significant results. I also tried a few &lt;a href=&quot;http://www.public.iastate.edu/~alicia/stat328/Multiple%20regression%20-%20higher%20order.pdf&quot;&gt;second order models&lt;/a&gt;, where I looked at whether citations could have a different impact given combinations of other variables (e.g. did citations matter if we controlled for tenured professors in the social sciences). I started to see a few significant results (p &amp;lt; 0.05), but by that time I had been testing so many hypotheses that I was going to need some serious effect sizes to believe anything. &lt;/p&gt; &lt;h6&gt;Takeaway: basically no evidence for the hypothesis. &lt;/h6&gt;
&lt;p&gt;
                I had to conclude that citations as a measure of academic status wouldn't map directly to usage of six letter words. But at this point in the project, I was running low on time, and every code rerun correlated with me uttering four letter word. Eventually, I had to give up even though I wasn't totally satisfied with my results.
            &lt;/p&gt;
&lt;p&gt;
                As usual, all my code is on the lots-of-things Github for you to tear into should you so desire. Best of luck, and hope you can get further on it than I did.
            &lt;/p&gt;
&lt;i&gt;
&lt;h6&gt;* A note on dataexplained.org&lt;/h6&gt;
&lt;p&gt;
                    As part of this project, we were initially supposed to do all of our analysis using the website &lt;a href=&quot;http://dataexplained.org&quot;&gt;dataexplained.org&lt;/a&gt;. This site had an &lt;a href=&quot;https://www.rstudio.com/&quot;&gt;RStudio&lt;/a&gt; console that recorded every line of code that was executed. Based on &lt;a href=&quot;https://www.youtube.com/watch?v=Do3bQ7TvDcM&quot;&gt;the video instructions&lt;/a&gt;, the analysts were then supposed to group their code into logical blocks and document why they chose that line of reasoning. Initially, I thought this was an awesome idea, and I was excited to try to use it to record and document my analysis process. Unfortunately, the website was poorly designed and I quickly started to experience performance problems that made it impossible to use it. The IT team eventually fixed the issues but by then I had already started doing a fair bit of work locally. I manually reproduced the majority of the work in the interface, but I'm disappointed that the interface wasn't really built well enough to make it useful. In particular a lot of the questions they ask are poorly worded, which just leads skipping the question. Hopefully in future rounds, there will be a better method to record every step of the process.
                &lt;/p&gt;
&lt;/i&gt;&lt;br/&gt;
</description>
        <pubDate>Sat, 29 Jul 2017 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2017/07/experiences-with-crowdsourcing-analysis/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2017/07/experiences-with-crowdsourcing-analysis/</guid>
        
        <category>data science</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://1.bp.blogspot.com/-FEZWAlMmtRk/WPGKsWYHewI/AAAAAAAAH9g/037ZKdxEiSUOLBbK6dS8No0WEsk6O1dQgCLcB/IMG_4928.jpeg</image>
        <title>Engagement Ring from Found Smoky Quartz</title>
        <description>&lt;img border=&quot;0&quot; height=&quot;480&quot; src=&quot;https://1.bp.blogspot.com/-FEZWAlMmtRk/WPGKsWYHewI/AAAAAAAAH9g/037ZKdxEiSUOLBbK6dS8No0WEsk6O1dQgCLcB/s640/IMG_4928.jpeg&quot; style=&quot;display:none&quot; width=&quot;640&quot;/&gt;
&lt;p&gt;
        Sometimes you try something that you're just sure will never work, yet somehow, even though you almost can't believe it, things work out just perfectly. When my fiancee, Claire, and I talked about getting engaged, we dreamed about how cool it would be to make the engagement ring from scratch from a gem we found ourselves. We never really thought that it was possible, but for some crazy reason, Claire let me plan a trip to &lt;a href=&quot;http://academic.emporia.edu/aberjame/student/rice1/CMB.htm&quot;&gt;Colorado's mineral belt&lt;/a&gt; to see what we could find. This is the story of how we just got plain old lucky despite not knowing what the heck we were doing.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-CMwyQbs4kWg/WM7msXQA_KI/AAAAAAAAHpc/Er2v5B6ajBcnbqpJuYfwlmHQakkBuitkQCKgB/s1600/Image.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In a lot of ways it's a perfect way to sum up just how lucky we've been to have found each other too, even though we never could have believed it would happen.
    &lt;/p&gt;
&lt;h4&gt;Finding our treasure&lt;/h4&gt;
&lt;p&gt;
        Believe it or not, there's still an abundance of gemstones just waiting to be found out there. As an example, just the other day I found this beauty while I was out on my run on a trail around Burlingame, CA.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-coxKnXgMAvk/WM84r2-sp9I/AAAAAAAAHqU/bxBW9285HyAs6aK42ykq4zsFei5F38ZTQCLcB/s1600/IMG_20161202_092350.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;strong&gt;Just kidding.&lt;/strong&gt; That &quot;gem&quot; was plastic, and truth be told it's a heck of a lot harder to find a gem than going for a jog in a crowded suburb. But then again, that's kind of the point: rockhounding is a great way to get into the less travelled parts of the great outdoors.
    &lt;/p&gt;
&lt;h5&gt;Rockhounders are we.&lt;/h5&gt;
&lt;p&gt;
        Rockhounding is another word for &lt;a href=&quot;https://en.wikipedia.org/wiki/Amateur_geology&quot;&gt;amateur geology&lt;/a&gt;. Yes that's right, regular people are capable of finding interesting rocks and gems. Toward the middle of the 20th century, there was a surge in the popularity of recreational rock and gem collecting in the US. There are still &lt;a href=&quot;https://www.gemsociety.org/article/mined-in-america/&quot;&gt;many areas&lt;/a&gt; in the US where amateurs will try their luck, but the widespread popularity of gem collecting seems to have ebbed substantially since its heyday.
    &lt;/p&gt;
&lt;p&gt;
        Because minerals are a fundamentally limited resource, it can be tough to find the best spots. Most material on the internet is fairly sparse and tough to interpret, but the Bob Loeffler's &lt;a href=&quot;http://www.peaktopeak.com/&quot;&gt;peaktopeak website&lt;/a&gt; has done a really great job of collecting and mapping many &lt;a href=&quot;http://www.peaktopeak.com/colorado/index.php3&quot;&gt;mine sites around Colorado&lt;/a&gt;. Another great resource for rockhounding sites was the &lt;a href=&quot;https://books.google.com/books/about/Colorado_Rockhounding.html?id=7EJavgAACAAJ&amp;amp;source=kp_cover&amp;amp;hl=en&quot;&gt;Colorado Rockhounding&lt;/a&gt; by Stephen M. Voynick. In addition to ultimately leading us to the sites where we had the most luck, this book also gave us some context to understand the history of Colorado's mineral belt.
    &lt;/p&gt;
&lt;h5&gt;Treasure Falls&lt;/h5&gt;
&lt;p&gt;
        Yes, it sounds too good to be true, but we found the gem that I proposed with at Treasure Falls. We were up in the clouds looking in the rock piles below this area where road crews had blasted through the side of the mountain. Our rockhounding book suggested that these were really great places because they offered freshly exposed rock that hadn't been picked through already.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-HscuaQ0wUwQ/WNnIrC3jneI/AAAAAAAAH4E/wHwB2ApZGqo9h1rtvb3RWg2zMKOgpwYyACLcB/s1600/IMG_4190.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This was basically the first site that we spent a lot of time investigating. From the beginning, we found many pretty rock in the rock piles where the rubble was collected, but none of them really seemed to be gemstones at all. Claire stayed in the rock piles while I ventured out closer to the exposed side of the mountain nearer the road. As I was looking through that region a lot of small rocks kept falling down towards where I was searching, which was a little nerve racking. Eventually, I found what looked like a black meteor, broken into three parts, with a little purplish-clear nugget right in the center.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-gN1h151CD_M/WNnKyM_TceI/AAAAAAAAH4g/RvzfhSlTA-QpF_x1Koab_aXuzFy9h1yEACLcB/s1600/IMG_4205.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-opKDiuwtH7o/WNnK12JQKqI/AAAAAAAAH4k/ilhD3_KRLPQRJjyBk5OGFwafn7MIkw-lACLcB/s1600/IMG_4212.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I rushed back over to Claire carrying the rock. I knelt down in the mud around the rock piles she was searching in and presented her with 15 lbs. of rock with a golf ball-sized smoky quartz in the center. Then I asked her to marry me, and she said yes!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-tx46PfwBXe4/WM9HHG6qw0I/AAAAAAAAHrE/AE84mFi5DLkIs7_naaukoarZkzLtHFXGgCLcB/s1600/IMG_2977.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        She was blown away that I'd found something. To tell the truth, she had kind of been doubting that this little adventure would turn up anything. I thought we'd find something, but I never thought we'd find something quite that large and beautiful. After spending the whole rest of trip trying to find any more interesting rocks and gems, we never topped that first find.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-sNTRQ4CnYrg/WNnJpT0pKzI/AAAAAAAAH4Q/iKlYLRUHcTg_Pr7M339zsNLvrMm2SyUFACLcB/s800/IMG_4188.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Claire and I have decided we're hooked on rockhounding. Searching for something really focuses your senses and helps you to take in the details of your surroundings to a level that you sometimes lose during a long day of hiking. Collecting rocks (or plants for that matter) can be a great way to motivate you to keep going that next little stretch of trail. I'll never forget one of our best hikes at high elevation surrounded by these old abandoned mine shafts. We didn't find much other than a little silver, but we kept going up and up the mountain in a chilly rain, carrying heavy chunks of rock until we just couldn't make it another step... and then we had to get back before dark. Rockhounding is really an adventure, and I suggest it if you're into hiking off-the-beaten-path kinds of places.
    &lt;/p&gt;
&lt;h5&gt;Learning what we had&lt;/h5&gt;
&lt;p&gt;
        To be honest, when collecting, Claire and I really just looked for shiny things and carried back anything that looked pretty and interesting. To learn what we had, we brought our haul into the &lt;a href=&quot;http://www.mines.edu/Geology_Museum&quot;&gt;Colorado School of Mines Geology Museum&lt;/a&gt; in Golden, CO. The museum curator was nice enough to go through our minerals and gems with us. This was where we learned that the geode I'd proposed with had been an &lt;a href=&quot;https://en.wikipedia.org/wiki/Agate&quot;&gt;agate&lt;/a&gt; or a &lt;a href=&quot;http://www.quartzpage.de/gen_types.html#CQ&quot;&gt;cryptocrystalline quartz&lt;/a&gt;. Being a quartz means that it is composed of silicon and oxygen. Cryptocrystalline refers to the fact that the silicon oxide doesn't form a perfectly repetitive crystal, but instead there are many mini-crystals that aren't quite perfectly aligned. It's relatively common and not normally considered a precious gemstone, but that doesn't diminish it in our hearts any.
    &lt;/p&gt;
&lt;h4&gt;Cutting the Stone&lt;/h4&gt;
&lt;p&gt;
        At first, I was pretty sure that I could shape a part of the geode into the faceted stone for Claire's ring myself. We found a smallish section with some oblong agate-like rings that we chiselled away from the darker stone to make the ring.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-RalG2WbInrg/WNnM8mhwIlI/AAAAAAAAH5E/pU_tKifu6j4oz6R8TumW3r7SK7FpmuPPACLcB/s800/IMG_4309.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        With the chunk that came out ther was still a lot of work to do to remove the excess debris and shape it into a decent chunk for faceting and polishing. I spent a whole weekend with a diamond edged Dremel slowly carving down the piece to get it close to the right size.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Pl0K_mqPglk/WNnM7oNDM4I/AAAAAAAAH5A/aRO38-GIP_8O1UeEqNfdxvlIKFHoCgM4wCLcB/s1600/IMG_4321.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Based on a few &lt;a href=&quot;http://www.thriftyfun.com/tf49873458.tip.html&quot;&gt;mediocre&lt;/a&gt; &lt;a href=&quot;http://www.howtodothings.com/fashion-personal-care/how-to-cut-quartz-crystal&quot;&gt;references&lt;/a&gt; I could find online, I held the stone in place just with a pliers and cut into the gem surface at right angles to keep it from slipping. I used mineral oil for the lubricant to keep the dust down and make the cuts cleaner. I was a little bit over-the-top paranoid about silicosis. In general, exposing yourself to quartz dust is a bad idea, but in all honesty for a project this size, it really wasn't any big deal.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/CJZNXaxTUaI&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-zq55A9NA8JA/WNnNCY1yvXI/AAAAAAAAH5M/CyO15172PVEQjDU39QKXhdXtbWmSOZGSwCLcB/s1600/IMG_4331.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        With the main chunks off, I started carving off the last bits of black rock with the edge. This also worked well for getting a roughly rounded circumference at the size we wanted.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/DZOU0egc-wc&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        At this stage, we spent a bit wondering whether we wanted to keep the stone in this sort of natural state. We liked how the stone had naturally broken to produce that interesting little peak, but ultimately, we decided we'd want to get the glossiness that could only come with a polish. And that just wouldn't be possible without getting the surface faceted.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-YkrVnoE7cBE/WNnNHXHIPnI/AAAAAAAAH5c/hKKF8swOvoQgrdvYkpmssjLw8xbR0kywQCLcB/s1600/IMG_4339.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Just for fun, I tried cutting a flat little piece of the excess off as an experiment to see what the material looked like in thin segments. I smoothed it down as much as possible. It ended up looking like a little glass (which it is) with some interesting swirling imperfections in it.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-GxpQBJkOM0Y/WNnMrtwuZaI/AAAAAAAAH44/RDMp0bClIg4IASSC5JY7oq53DuxDm0uNACLcB/s1600/IMG_20160905_105308.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-PAPBByfM_8g/WNnMqPAYa8I/AAAAAAAAH40/sLUXjgqKCJER7HyJi0uM61at-jKzvrTQQCLcB/s800/IMG_20160905_112111.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6&gt;Bringing in the Professional&lt;/h6&gt;
&lt;p&gt;
        Ultimately, I wasn't able to get a good enough polish on the stone surface to really make the stone shine. Claire also wanted a rose-cut facet, which is generally considered to be a fairly difficult cut. I was nervous that my faceting wouldn't be quite good enough since I'd never had any practice before. Ultimately, we decided it would be better to let a professional do the final cut and polish.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Glx90c1rvKg/WNH42c4_swI/AAAAAAAAHr4/g2YBArFwumsZCbwjlWNapldVzdezgNf5QCLcB/s800/Apr-2015-f1-e1480986144969-225x300.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        There aren't that many lapidaries who will take custom jobs from individuals anymore. Fortunately, we were able to track down a nice gentleman from Kentucky named &lt;a href=&quot;https://gemsbyjohn.com/&quot;&gt;John Wright&lt;/a&gt;. We sent the part of the stone that I had shaped down to a rough cut, and John sent back a polished rose-faceted gem just a little over a week later.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-itfYyJjq9d8/WNnZAB1lZTI/AAAAAAAAH6A/fN2IYwEK8bUkbuHwdPt1dAxqQghmhgnqACLcB/s800/IMG_4463.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Mounting the Ring&lt;/h4&gt;
&lt;p&gt;
        Claire had found some inspiration from &lt;a href=&quot;http://www.mineralogydesign.com/&quot;&gt;Mineralogy Studios&lt;/a&gt; in Chicago's Ravenswood neighborhood. We went and met with the owner and jeweller, Theresa Cowan, there to find out what kind of mounting we could do.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://assets.dnainfo.com/generated/chicago_photo/2015/07/mineralogydoorway-1436320075.jpg/extralarge.jpg&quot; title=&quot; &quot;/&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;338&quot; mozallowfullscreen=&quot;&quot; src=&quot;https://player.vimeo.com/video/144520365?title=0&amp;amp;byline=0&amp;amp;portrait=0&quot; webkitallowfullscreen=&quot;&quot; width=&quot;640&quot;&gt;&lt;/iframe&gt;&lt;a href=&quot;https://vimeo.com/144520365&quot;&gt;Mineralogy&lt;/a&gt;
&lt;p&gt;
        Theresa was wonderful to work with. She was very knowledgeable about gemstones and totally game to work with us on our unusual project. Claire liked the look of some of Theresa’s rings, so she gave us the exact measurements of the stones in them (length, width, height etc) to make sure we could tell the lapidary exactly what we wanted.
    &lt;/p&gt;
&lt;p&gt;
        Then Claire brought in the final stone and Theresa worked her magic to produce the perfect ring. Claire was thrilled with the final product. It was the classy without being over-the-top.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-PnGQ_QLR1so/WPGK1hjm4QI/AAAAAAAAH9o/iIbcTvwJG9IC0AwKZoWniQkk1Cb12-y_wCLcB/s800/IMG_4920.jpeg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;The finishing touches &lt;/h6&gt;
&lt;p&gt;
        We also asked Theresa to make Claire’s wedding band with diamonds from her Great Aunt. We can’t wait to make it official this fall!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-FEZWAlMmtRk/WPGKsWYHewI/AAAAAAAAH9g/037ZKdxEiSUOLBbK6dS8No0WEsk6O1dQgCLcB/s1600/IMG_4928.jpeg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Bonus: Earrings&lt;/h4&gt;
&lt;p&gt;
        Collected some fragments from the original stone and turned them into earrings for Claire's mom.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-jlI1cNWnLy0/WM8zZM1BKuI/AAAAAAAAHp8/11hZ4GfF83gCqvRT6vvglGWhNCdN68UVwCLcB/s800/earrings2.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Fri, 14 Apr 2017 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2017/04/engagement-ring-from-found-smoky-quartz/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2017/04/engagement-ring-from-found-smoky-quartz/</guid>
        
        <category>design</category>
        
        <category>craft</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://4.bp.blogspot.com/-eDtnSA_LrOk/V_6IY2EOMLI/AAAAAAAAHDE/cqVsQMqK4PQT5H720zmOrH-3aw-R6Tw8wCLcB/png%253Bbase64de1231217d364075.png</image>
        <title>Text Mining and Natural Language Processing on Health Forums</title>
        <description>&lt;p&gt;
        As part of the &lt;a href=&quot;http://insighthealthdata.com/&quot;&gt;Insight Health Data Science Fellowship&lt;/a&gt;, I just got to spend the last 3 weeks working on a pretty fun project applying natural language processing to medical health forums. The goal is to curate health forums so that people can get instant advice on sexual health problems and then see the most relevant forum posts on those issues.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-eDtnSA_LrOk/V_6IY2EOMLI/AAAAAAAAHDE/cqVsQMqK4PQT5H720zmOrH-3aw-R6Tw8wCLcB/s1600/png%253Bbase64de1231217d364075.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The web app is up and running. To try it out, hop on over to &lt;a href=&quot;sexpertise.makeloft.org&quot;&gt;sexpertise.makeloft.org&lt;/a&gt; (maybe use an incognito tab if you're skiddish about your search history). I'll eventually do another post all about the AWS backend API and the D3 frontend stuff, but for this post I want to focus in just on the text mining and analysis that went into building the condition suggester. To jump straight to the code you can check out &lt;a href=&quot;https://github.com/lots-of-things/health-forum-analysis&quot;&gt;my Github repo&lt;/a&gt;.
    &lt;/p&gt;
&lt;h3&gt;Health Forum Datasets&lt;/h3&gt;
&lt;p&gt;
        At least &lt;a href=&quot;http://www.pewinternet.org/fact-sheets/health-fact-sheet/&quot;&gt;4 out of 5 internet users&lt;/a&gt; ask health related questions online and google says &lt;a href=&quot;https://googleblog.blogspot.com/2015/02/health-info-knowledge-graph.html&quot;&gt;1 in 20 searches are for medical info&lt;/a&gt;. Clearly, online information is an integral part of the healthcare pipeline in this day and age. Providing better information to users up front can change their whole medical experience downstream.
    &lt;/p&gt;
&lt;p&gt;
        Nowhere is this more important than in sexual health information because social taboos can prevent people from feeling comfortable seeking medical help. As many as &lt;a href=&quot;http://healthdecide.orcahealth.com/2012/11/20/survey-finds-people-turn-to-internet-over-doctor-for-health-questions/#.V_5u_7Uy3qM&quot;&gt;63% of people who go online for medical advice&lt;/a&gt; say they turn to the internet to talk about sensitive issues like sex and STDs. Fortunately, the internet is helping to alleviate some of these constraints.
    &lt;/p&gt;
&lt;p&gt;
        To get advice on these issues many users turn to online &quot;Ask a Doctor&quot; forums found on &lt;a href=&quot;http://exchanges.webmd.com/default.htm&quot;&gt;WebMD&lt;/a&gt;, &lt;a href=&quot;http://www.doctorslounge.com/forums/&quot;&gt;DoctorsLounge&lt;/a&gt; or &lt;a href=&quot;http://ehealthforum.com/&quot;&gt;eHealthForum&lt;/a&gt;. All of these sites offer free anonymous questions with medical professionals. On these sites, typically an &quot;Asker&quot; poses a question in a public forum, which can then be answered by a doctor.
    &lt;/p&gt;
&lt;p&gt;
        As an example let's look at the following interaction between an asker and a doctor, which can be found at &lt;a href=&quot;http://www.doctorslounge.com/forums/viewtopic.php?f=61&amp;amp;t=43266&quot;&gt;this doctorslounge.com post&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-Yeold6n9Mbs/V_5qqMS5OCI/AAAAAAAAHCM/Tx31LffyQpEE31jUZfhvqZNcD2wXNUO8QCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B09-53-25.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The asker normally talks about symptoms that he or she is experiencing (blue), while the doctor responds with suggestions and, importantly, mentions different likely conditions (green). Unfortunately, it can take as much as a week for a doctor to respond, and this can cause the asker to wait unnecessarily rather than seeking medical help at a clinic.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-z9yFUe9O8Hc/V_5xx2cUQPI/AAAAAAAAHCc/SWd4whSfyPYoCn3rdYktAkb1vVFcYFq0wCLcB/s1600/waittime.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        It would be great to be able to mine the text so that we could map those symptoms to conditions automatically. At the same time, it's clear that there's a lot of extra information in the posts. Without any further analysis, it's basically impossible to tell what's important in these messages and how to extract meaning from them. But fortunately, there is a process for working with textual data known as NLP that will help us make sense of this.
    &lt;/p&gt;
&lt;h6&gt;Scraping forum data&lt;/h6&gt;
&lt;p&gt;
        In order to analyze these forums I needed to download many forum conversations from multiple websites. To do this I used BeautifulSoup to crawl the webforus and store the text from the asker, the doctor, and any other respoonders. I ended up getting data from WebMD, eHealthForum, DoctorsLounge, and ScarletTeen sexual health forums. Others that I could add would be reddit and stackexchange as well as medhelp.
    &lt;/p&gt;
&lt;p&gt;
        I downloaded 150,000 posts in 60,000 threads and about half of them had a response from a medical professional (either a doctor or a registered nurse). Identifying medical professionals was always specific to each forum, and the best one can do is get a sense of the heuristics each site uses to identify their &quot;official&quot; responses. To view the scrapers that I used to download the data check out my &lt;a href=&quot;https://github.com/lots-of-things/insight-health-scraper&quot;&gt;insight-health-scraper&lt;/a&gt; repo on GitHub.
    &lt;/p&gt;
&lt;h4&gt;Filtering on writing style&lt;/h4&gt;
&lt;p&gt;
        One of the first things I noticed when perusing my dataset was the wide disparity in the quality of Asker questions and their writing style. I also noticed that the doctors tended to sound a lot smarter than the askers as you might expect. This led me to wonder whether I could detect the quality of the writing style. To do this I calculated the Flesch-Kincaid Grade Level of each post in my corpus using &lt;a href=&quot;https://github.com/mmautner&quot;&gt;mmauter&lt;/a&gt;'s &lt;a href=&quot;https://github.com/mmautner/readability&quot;&gt;readability package&lt;/a&gt; for python. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests&quot;&gt;Flesh-Kinkaid readability tests&lt;/a&gt; are a system to estimate the reading ease of paragraphs. The Grade Level tries to map someone's writing onto the equivalent educational Grade Level in the American school system. I applied it to my corpus and was able to get a nice plot of the frequency of reading levels for both the asker and doctor texts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/--JWKUmh_ekM/V_5yhhrh7-I/AAAAAAAAHCk/26dMNj4-wzsZgwhNl9OAhYmrIW_FEWXXQCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B10-27-19.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        As you can see, using this metric, doctor texts score significantly higher than asker texts. Flesch-Kincaid mainly takes into account the number of syllables in words and the number of words in sentences. Ernest Hemingway would probably disagree that those are good metrics for the quality of writing, but it's a fair proxy short of any other information about the text. For example, one asker posed the following thought provoking health question:
    &lt;/p&gt;
&lt;blockquote&gt;Should I have sex with some random guy?&lt;/blockquote&gt;
&lt;p&gt;
        This sentence actually scores negative on the Flesch-Kinkaid grade level. To me it seems like it should score negative on pretty much every level.
    &lt;/p&gt;
&lt;p&gt;
        At any rate, the Flesch-Kincaid metric gave me a method to establish which asker questions were just unfit to be displayed. At the end of the project, this helped in filtering the responses that I showed to end users. However, I still left that data in during the modelling part.
    &lt;/p&gt;
&lt;h3&gt;Finding Conditions in Doctor Responses&lt;/h3&gt;
&lt;p&gt;
        After the dataset is downloaded and tidied, you have to ask what you are going to do with the dataset. At the moment, the whole dataset just consists of pairs of unstructured text, one for asker and one for doctor. You could try to map from asker text to doctor text (see below for that problem), but first it would be better to get a simpler set of labels to map to. In the end, what I really wanted was just a list of all the recognizable conditions that the doctor mentions.
    &lt;/p&gt;
&lt;p&gt;
        So to turn this into a more cleanly labelled dataset, I needed to generate a list of condition labels directly from the doctor text. This turns out to be not a trivial task with lots of ways to tweak the final result. I can't offer a perfect answer, but I can offer the solution I used to detect conditions in doctor text.
    &lt;/p&gt;
&lt;h4&gt;Generating condition synonym list from CDC and Mayo clinic websites&lt;/h4&gt;
&lt;p&gt;
        To get recognizable conditions to label, I needed to build a list of text strings that could be construed to represent &quot;diseases&quot;. Fortunately, both the &lt;a href=&quot;http://www.cdc.gov/diseasesconditions/&quot;&gt;CDC&lt;/a&gt; and &lt;a href=&quot;http://www.mayoclinic.org/diseases-conditions&quot;&gt;Mayo Clinic&lt;/a&gt; have lists of diseases and conditions which were easy enough to scrape using my &lt;a href=&quot;https://github.com/lots-of-things/insight-health-scraper&quot;&gt;insight-health-scraper package&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        After I had the raw list, I realized that there were lots of conditions that were pretty similar to each other. I decided I needed to collapse this list down to a shorter list of truly unique entries for two reasons: 1) I didn't want an overwhelming array of conditions to display at the end, and 2) I wanted to enhance the predictive ability of my model by increasing the number of occurrences of each condition I was trying to model. To do this I used a technique called &lt;a href=&quot;https://en.wikipedia.org/wiki/Approximate_string_matching&quot;&gt;fuzzy matching&lt;/a&gt; to see which strings were more than 90ish% similar to each other.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://autoaudit.com/wp-content/uploads/2013/10/services-fuzzy-matching-logic.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I relied on a cute python package called &lt;a href=&quot;https://github.com/seatgeek/fuzzywuzzy&quot;&gt;fuzzywuzzy&lt;/a&gt;, which worked great for identifying close partial matches of strings. Specifically, I could just use the extractOne() method to find the closest match out of the diseases I've already seen. If the match was better than 90%, just add it as a synonym to the original disease, creating a way to map all of the similar strings to one term.
    &lt;/p&gt;
&lt;h4&gt;The many ways to match a string&lt;/h4&gt;
&lt;p&gt;
        Once I had the disease synonyms, I needed to look into the doctor text to see when they were mentioned. There were a number of different ways to do this, and I explored several permutations of the following techniques.
    &lt;/p&gt;
&lt;h6&gt;Multiple &quot;synonyms&quot;&lt;/h6&gt;
&lt;p&gt;
        I already had multiple different terms that mapped to the same disease so I had a long list of somewhat similar terms that could be compared against (e.g. 'ehrlichiosis' and 'human ehrlichiosis' both map to the same disease).
    &lt;/p&gt;
&lt;h6&gt;Spelling correction&lt;/h6&gt;
&lt;p&gt;
        Another cool package called &lt;a href=&quot;https://pypi.python.org/pypi/pyenchant/&quot;&gt;PyEnchant&lt;/a&gt; can make spelling corrections. It is slow so I didn't use it on the whole dataset, but it could offer another way to correct spelling errors for diseases.
    &lt;/p&gt;
&lt;h6&gt;Fuzzy matching&lt;/h6&gt;
&lt;p&gt;
        As I mentioned above, fuzzy matching allows similar strings that are not exact matches to be compared. Again, this technique is much slower than a simple string comparison, but I decided to use it anyway in this case to make sure I didn't miss any similar text.
    &lt;/p&gt;
&lt;h6&gt;Marking negation&lt;/h6&gt;
&lt;p&gt;
        Finally, it's possible that a mention doesn't necessarily mean the text is relevant. In particular, a doctor could be saying that she &lt;i&gt;doesn't&lt;/i&gt; think you have a condition (e.g. &quot;You probably don't have an STD&quot;). Using negation marking in nltk.util allows you to mark every word in a sentence that comes after a negation (i.e. not, no, etc). I stored the results of this, but it only reduced the number of identified conditions by 1% so I didn't bother using it for simplicity of explanation. Nevertheless, it can be a good idea if you're trying this on a different dataset.
    &lt;/p&gt;
&lt;h4&gt;Disease labelling results&lt;/h4&gt;
&lt;p&gt;
        I searched for 200 diseases across the 30,000 doctor texts. Of those, only 80 occurred more than 100 times so I decided to just focus on those. The following diagram shows some of the most and least frequently mentioned diseases./p&amp;gt; &lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-dcoWntZNXq4/V_6GaYj5Q2I/AAAAAAAAHC4/cBM40kOXEZEpm-BAGH8cBUQQXwMHVPwUwCLcB/s1600/occurence.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            I also repeated this with the asker comments to see which conditions were mentioned by them. In addition I queried the top disease-related wikipedia articles to see how many times they were viewed and I compiled some CDC data to see which diseases occurred the most. Combining these, it was interesting to see what the most commonly mentioned issues were from these disparate datasets
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-px90z-NSk6c/V_6F39Js8bI/AAAAAAAAHC0/z7JJtUIrdM4KK9iPtOHoShgmU4lY-i2XgCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B11-46-58.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            Clearly different things are on different people's minds.
        &lt;/p&gt;
&lt;h3&gt;Predicting Conditions from Questions&lt;/h3&gt;
&lt;p&gt;
            With a labelled dataset, I could generate a model that predicted conditions using input text. However, the asker text was still just an unprocessed string, which isn't really easy to model without to measure the occurrence of important words. Unfortunately, there is no obvious way to extract the most important words from the text &lt;i&gt;a priori&lt;/i&gt;. Instead, I had to use some natural language processing techniques to extract the features of the text into a numerical form that could be fit with a model.
        &lt;/p&gt;
&lt;h4&gt;Term Frequency Inverse Document Frequency (TFIDF)&lt;/h4&gt;
&lt;p&gt;
            The most traditional way to convert text into a vector of features is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bag-of-words_model&quot;&gt;&quot;bag of words&quot; model&lt;/a&gt;. In this model, you lose all information about the ordering of the words and you basically just end up with counts of occurrences of each word. I used a slight adaptation of this called &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&quot;&gt;TFIDF&lt;/a&gt;, where you normalize the word counts by the frequency of those words across all the documents in your corpus. This has the effect of making it so that your representation has values much larger than 1 whenever a word is over-represented compared to the average document.
        &lt;/p&gt;
&lt;p&gt;
            You can find a lot of information about &lt;a href=&quot;http://aimotion.blogspot.com/2011/12/machine-learning-with-python-meeting-tf.html&quot;&gt;TFIDF on the web&lt;/a&gt;. It is the standard and most obvious way to deal with this problem. Just to briefly make it clear what we got out of this. Basically after converting your text into TFIDF form, you'll have a vector of numbers where each element in the vector represents how over-represented a certain word is in that text. One consequence is that two identical documents will have identical vector representations. Similarly documents with similar word frequencies will have simimilar vector representations.
        &lt;/p&gt;
&lt;h6&gt;Stop Words, Stemming, and Ngrams&lt;/h6&gt;
&lt;p&gt;
            There are three additional techniques that extend the usefulness of TFIDF. First, removing &lt;strong&gt;stop words&lt;/strong&gt; filters out the most common English words that don't really convey meaning. Words like 'I', 'in' and 'the' get dropped so they aren't wasting space in your vectorized representation. Second, &lt;strong&gt;stemming&lt;/strong&gt; drops inferred suffixes off of words. Thus, 'running,' 'runs,' and 'run' will all map to 'run,' which further reduces your feature space. Finally, generating &lt;strong&gt;ngrams&lt;/strong&gt; creates new words out of continuous segments of words. So for example, without ngrams you would have a count of 'bus' and a count of 'driver' in your document, but you wouldn't know if the term 'driver' was ever associated with 'bus.' If you use a bigram (or 2-gram) then you would also have the count of 'bus driver' in your text. This can give you more meaning if t turns out to be an important feature.
        &lt;/p&gt;
&lt;h6&gt;Restricting feature frequency&lt;/h6&gt;
&lt;p&gt;
            I also filtered out words and phrases that were too common and too rare. To do this I clipped out the least frequent 1% and the most frequent 40% of words. This was something where I really wanted to explore the effect on my model systematically, but due to time constraints I had to move on after finding a &quot;good enough&quot; restricting condition.
        &lt;/p&gt;
&lt;h6&gt;Experiments with Doc2Vec&lt;/h6&gt;
&lt;p&gt;
            In addition to the classic TF-IDF, I also experimented with the state of the art &lt;a href=&quot;https://radimrehurek.com/gensim/models/doc2vec.html&quot;&gt;gensim Doc2Vec&lt;/a&gt; for extracting features from my text. Doc2Vec (and its basis &lt;a href=&quot;https://en.wikipedia.org/wiki/Word2vec&quot;&gt;Word2Vec&lt;/a&gt;) is a complicated algorithm that &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/3wu7di/how_does_doc2vec_work/&quot;&gt;many&lt;/a&gt; other people have attempted &lt;a href=&quot;https://www.quora.com/How-does-word2vec-work&quot;&gt;to explain&lt;/a&gt; better than me. In a nutshell, it attempts to look at the context.
        &lt;/p&gt;
&lt;p&gt;
            One great thing about it is that it maps different words into a &quot;meaning&quot; space. This means that you can map synonymous words to the same feature space with lower dimensionality. As such different words can be have their nearby regions inspected and you can see which words are the most similar in meaning. Here I display 3 different Doc2Vec implementations, and which words they find closest in meaning to ovulation.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-o1SvnRhJKt4/V_6Ih_SLo7I/AAAAAAAAHDI/udZY11Dvr2AOS_ho95Lx4mWIT7FyHfTkwCLcB/s1600/png%253Bbase649f9c19b5fbaf1495.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            In truth, Doc2Vec is a family of algorithms, each with its own pluses and minuses. As you can see the one on the left looks to be the most informative. That one uses the &lt;a href=&quot;https://www.quora.com/What-are-the-continuous-bag-of-words-and-skip-gram-architectures-in-laymans-terms&quot;&gt;skip-gram model&lt;/a&gt;, which you can look into if you are interested in the details. All in all, I'm impressed with Doc2Vec, and with a little more fiddling I'm sure I could change my implementation to include this more elegant vectorization procedure. However, the current Doc2Vec implementations do not enable you to directly map a text to a unique vector representation. Instead, they infer a &quot;good enough&quot; representation with some random noise, which is not guaranteed to be the same every time you query. I didn't have time to fix this issue so I left the TFIDF in production.
        &lt;/p&gt;
&lt;h6&gt;Results of the vectorization&lt;/h6&gt;
&lt;p&gt;
            To get a better idea of what comes out of the vectorization process take a look at this text from the example above.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/--wqIFOHhBrc/V_6jvlAKvhI/AAAAAAAAHEM/mqgqtM2H8F0oDEqFrP23saOTJB91XPIKwCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-57-14.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            As you can see, many of the words have been truncated by the stemming. Also, even though there are many possible ngrams in this example, none of them are in the final vectorization. That just means that they were either too frequent or not frequent enough to make the cut. All in all, a lot of information has been lost, but we don't know if we've kept enough until we've tried to make a model.
        &lt;/p&gt;
&lt;h4&gt;Modelling sparse data with multiple labels&lt;/h4&gt;
&lt;p&gt;
            For this model, I didn't have a lot of data, but I had a lot I had to predict. In the end, I was trying to predict 80 diseases, and many of those diseases didn't even have many more than 100 examples in the dataset. That leaves a lot of room to get things wrong.
        &lt;/p&gt;
&lt;p&gt;
            For example, using the &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F1 score&lt;/a&gt; I only had actual predictive power over a handful of conditions. This was universally true with any model that I used (random forests, SVM, logistic regression, and naive bayes) which is a good indication that I just didn't have enough samples to get a predictive model.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/--9fAgxwLBsg/V_6UeACyzxI/AAAAAAAAHDc/tUVFFjy39vkFvdp48LvXlwNmIJ_-3MGngCLcB/s1600/png%253Bbase64a41082f67ebe75a4.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            Fortunately, after a little while I realized that my problem was actually way easier than trying to predict the diseases. Really, all I needed was to identify the 10-or-so most probable diseases associated with a given disease. Doing that with some fidelity isn't anywhere near as hard, and I found that I could be pretty successful even with my small dataset. The resulting conditions definitely passed the gut test and matched with pretty good fidelity to my expectations.
        &lt;/p&gt;
&lt;p&gt;
            To be more systematic, I used an ROC area under the curve to score my models and found that I could get 0.85 (1 being the best) using a moderately sized random forest. So that was the model that ended up going into production.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Svlsu3cCewo/V_6WszpbtQI/AAAAAAAAHDo/l8AUaY5kKpoHYFLPaN2aZjitP9oyUmG_wCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-01-44.png&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Viewing the most predictive words for each condition&lt;/h4&gt;
&lt;p&gt;
            One interesting thing that falls out of this modelling is the ability to see which words are most important for predicting a given condition. I built an &lt;a href=&quot;http://sexpertise.makeloft.org/analysis&quot;&gt;interactive analysis tool&lt;/a&gt; to visualize the words that are best at predicting a given condition. One of the coolest predictions is for appendicitis.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-W_i-MCj1eE4/V_6ZSE__ZvI/AAAAAAAAHD4/SgBpIUBzpwsjHnN3H-PkKHL8OmfGqzK0QCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-06-24.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            As you can see, two of the most closely related phrases are 'right' and 'abdominal pain.' To me it's absolutely incredible that this ended up working so perfectly. Feel free to explore the &lt;a href=&quot;http://sexpertise.makeloft.org/analysis&quot;&gt;analysis tool&lt;/a&gt; to find more cool patterns like this.
        &lt;/p&gt;
&lt;h3&gt;Bonus: Disease Connectivity Map&lt;/h3&gt;
&lt;p&gt;
            As a cool little additional analysis, I also found that I could infer the connections between diseases based on their co-occurrence in doctor responses. Using this connection map I was able to build a little &lt;a href=&quot;https://bl.ocks.org/mbostock/4062045&quot;&gt;D3 force graph&lt;/a&gt; to visualize the connectivity.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-AK0lHBPssqU/V_6ZNh_v26I/AAAAAAAAHD0/KDvyLCfs-kcyjdic01CtTF6dYA4olW4cgCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-09-22.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            You can definitely see clusters amongst some obviously related conditions. Women's health issues like pregnancy, breastfeeding, and back pain; flu, sore throat, and cold; and all the stds clump together. Some things are less explainable. If you want to explore first hand you can go to the &lt;a href=&quot;http://sexpertise.makeloft.org/analysis&quot;&gt;analysis page&lt;/a&gt;. Have fun and be safe.
        &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;</description>
        <pubDate>Wed, 12 Oct 2016 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2016/10/text-mining-and-natural-language/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2016/10/text-mining-and-natural-language/</guid>
        
        <category>data science</category>
        
        <category>machine learning</category>
        
        <category>code</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://1.bp.blogspot.com/-VKPf9qgeyLY/V2hP1oPA9zI/AAAAAAAAGYk/K3C78Q2_9joKCPEIR9lA_uRYFh1N6YzugCLcB/hqdefault.jpg</image>
        <title>Git Versioned PDF Visualizer</title>
        <description>&lt;a href=&quot;https://github.com/lots-of-things/git-pdf-viz&quot;&gt;jump to the code&lt;/a&gt;
&lt;p&gt;
    I've been writing a &lt;a href=&quot;https://github.com/wmcfadden/theseus&quot; title=&quot;my PhD thesis&quot;&gt;very long document&lt;/a&gt; over the past couple of years. Because I love tracking my own behavior and &lt;a href=&quot;https://en.wikipedia.org/wiki/Open_science&quot;&gt;Open science&lt;/a&gt;, I decided to version control the whole editing process of my thesis on GitHub. Because I've been keeping track of all my updates with git, that means I can monitor all the changes that have gone into my thesis over time. This can also be useful for &lt;a href=&quot;http://danaernst.com/using-github-to-coauthor-papers/&quot;&gt;collaborating on writing papers&lt;/a&gt; too (though my prototypical Luddite advisor would rather do things by emailing &lt;a href=&quot;http://www.apple.com/mac/pages/&quot;&gt;Mac Pages&lt;/a&gt; documents).
&lt;/p&gt;
&lt;h4&gt;Git PDF movie maker&lt;/h4&gt;
&lt;p&gt;
    As a cool way to visualize all the changes, I wrote a series of a couple of scripts that checkout each version and make a movie out of all the .pdfs in the repo over time. Here's the current state (note that the thesis isn't even close to finished yet; I'll update when I get more on it.)
&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/mWvQ1Y5uaGc&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
    If you think you'd like to use this, you can bounce over to the &lt;a href=&quot;https://github.com/lots-of-things/git-pdf-viz&quot;&gt;git-pdf-viz GitHub repo&lt;/a&gt; and download it now. Read on below for more info on how it works, how to modify it, and to see the results of running git-pdf-viz on my thesis.
&lt;/p&gt;
&lt;h4&gt;A Real Bash!&lt;/h4&gt;
&lt;p&gt;
    Writing bash scripts is a party, I know. This entire project is comprised of just a few bash scripts that are meant to be run sequentially (with some editing maybe).
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;save_all_pdfs&lt;/li&gt;
&lt;li&gt;pdfs_to_ims&lt;/li&gt;
&lt;li&gt;ims_to_montage&lt;/li&gt;
&lt;li&gt;montage_to_frame&lt;/li&gt;
&lt;li&gt;frame_to_movie&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Save All PDFs&lt;/h4&gt;
&lt;p&gt;
    The first script really takes care of the core of this program. There's lots of extra details but the key piece of save_all_pdfs.sh is &quot;git rev-list master,&quot; which gives you all the commit ids for your repo. This pseudo-bash shows the general idea:
&lt;/p&gt;
&lt;pre&gt;
for commit in $(git rev-list master)
do
    git checkout $commit
    ...copy all pdfs to somewhere safe...
done
&lt;/pre&gt;
&lt;p&gt;
    &quot;git checkout&quot; updates all the files that are sitting in the project directory locally. So with the list of revisions from &quot;git rev-list master&quot; I can reset the state of my file system to reflect the state at each committed phase of the project. After that, I just need to copy all the files I need (in this case my pdfs) somewhere safe for use later. (&lt;strong&gt;Caveat:&lt;/strong&gt; I'm currently only copying pdfs if they have a corresponding latex file because I wanted to ignore any figures that weren't included. You can modify the script accordingly if you need all your pdfs copied.)
&lt;/p&gt;
&lt;h4&gt;Playing with pdfs and images&lt;/h4&gt;
&lt;p&gt;
    The next three scripts rely on &lt;a href=&quot;http://ghostscript.com/doc/current/Devices.htm&quot;&gt;GhostScript&lt;/a&gt; and &lt;a href=&quot;http://www.imagemagick.org/script/index.php&quot;&gt;ImageMagick suite&lt;/a&gt; to jockey our pdfs into a composite image that will eventually be turned into movie frames. You can view the scripts themselves for more details about implementation, but I'll explain the idea behind each script for reference.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=merged.pdf *.pdf &lt;/strong&gt; uses ghostscript to merge all the saved pdfs together&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;convert merged.pdf im/i_%03d.png&lt;/strong&gt; converts the merged pdf to a sequence of individual pngs&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;montage -mode concatenate -tile 10x i_* ../final.png&lt;/strong&gt; stitches all the individual png &quot;pages&quot; into a &quot;montage&quot; panel with 10 columns&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;convert &quot;${now}/final.png&quot; -resize 1000x -gravity northwest -background white -extent 1000x700 -colorspace RGB &quot;PNG32:bydate/${now}.png&quot;&lt;/strong&gt; rescales each montage and ensures that all images are the same size and colorspace&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mogrify -gravity southeast -pointsize 26 -annotate +10+10 %t *.png&lt;/strong&gt; adds a little timestamp (based on the title) in the southeast corner&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    At the end of this process there will be a folder named bydate/ with an image for every frame of a movie that's about to get made.
&lt;/p&gt;
&lt;h4&gt;Lights, Camera, Action&lt;/h4&gt;
&lt;p&gt;
    As the final step we use &lt;a href=&quot;https://ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt; to convert all of the images into an mp4 movie. This requires two lines because ffmpeg is made to work with numerically sequential files, and my files are named based on their date.
&lt;/p&gt;
&lt;pre&gt;
ls *.png | sort -V | xargs -I {} echo &quot;file '{}'&quot; &amp;gt; list.txt
ffmpeg -r 2 -f concat -i list.txt -r 30 -c:v libx264 -pix_fmt yuv420p ../git_pdf_viz.mp4
&lt;/pre&gt;
&lt;p&gt;
    This is a good example of how compicated ghostscript, ImageMagick, and ffmpeg can be to use. Through all of this there are about 20 extra parameters that have to get passed to each of these programs to make them work properly. I can't explain all of them in detail, so I recommend the individual software's documentation if you find you need to modify these extensively. These are &lt;strong&gt;amazingly&lt;/strong&gt; powerful programs that make life so much easier for any kind of batch audiovisual project so I highly encourage getting acquainted with them at some point in your life.
&lt;/p&gt;
&lt;p&gt;
    Have fun, and I hope that this encourages you to use open source version control whenever you write/edit any large document project.
&lt;/p&gt;</description>
        <pubDate>Mon, 20 Jun 2016 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2016/06/git-versioned-pdf-visualizer/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2016/06/git-versioned-pdf-visualizer/</guid>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-IP2Dr2Tqd8c/VzuMv7lD59I/AAAAAAAAGNw/u1r8hWqeKx4pexG-dLyuDH3OfJL9CKrGACLcB/Screenshot%2Bfrom%2B2016-05-17%2B16%253A27%253A04.png</image>
        <title>Parallel IPython with Jupyter Notebooks on a SLURM cluster</title>
        <description>&lt;p&gt;
        I figured it would be such a piece of cake to get my Jupyter IPython notebooks to run parallel on my work cluster, but in the end, I had so much trouble trying to find the simple steps for setting it up. After much fiddling, I offer you an explanation of what is sort of working.
    &lt;/p&gt;

&lt;h4&gt;Running a remote ipython notebook server&lt;/h4&gt;
&lt;p&gt;
        The first part of this is actually incredibly simple: you need to connect your local browser to a remote Jupyter notebook server. Essentially, all you need is some port forwarding or ssh &quot;tunnelling&quot; to connect your local web browser to an ipython notebook server that is being run through a batch system on the cluster. Sound simple enough? Well unfortunately, I couldn't find any single tutorial that clearly stated the necessary steps outright. I did manage to find two similar examples where the &lt;a href=&quot;https://wiki.scinet.utoronto.ca/wiki/index.php/IPython_Notebook_on_GPC&quot;&gt;first&lt;/a&gt; works correctly but looks overly complicated while the &lt;a href=&quot;https://github.com/tnarihi/wiki/wiki/Jupyter-notebook-on-TTIC-clusters&quot;&gt;second&lt;/a&gt; looks like it should work, but for some reason doesn't.
    &lt;/p&gt;
&lt;p&gt;
        To make it work I created an sbatch job named ipy_srv.sbatch which launched the server somewhere on a machine in the cluster and then printed the serving machine's ip and port number to the log file. I could then use those values with the ssh tunnel.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;#!/bin/sh&lt;br/&gt;#SBATCH --part=westmere&lt;br/&gt;#SBATCH --reservation=energy&lt;br/&gt;#SBATCH --ntasks=1&lt;br/&gt;#SBATCH -t 04:00:00             # max runtime is 4 hours&lt;br/&gt;#SBATCH -J  ipy_server    # name&lt;br/&gt;#SBATCH -o log/ipy-%J.out&lt;br/&gt;&lt;br/&gt;let ipnport=($UID-6025)%65274&lt;br/&gt;echo ipnport=$ipnport&lt;br/&gt;&lt;br/&gt;ipnip=$(hostname -i)&lt;br/&gt;echo ipnip=$ipnip&lt;br/&gt;&lt;br/&gt;module load python&lt;br/&gt;ipython notebook --ip=$ipnip --port=$ipnport --no-browser&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I don't know where &quot;($UID-6025)%65274&quot; came from, but it seems to get the job done so I just left it. After launching this with &lt;strong&gt;sbatch ipy_srv.sbatch&lt;/strong&gt;, I can check in the most recent file under log/ipy-* to get the ip and port number at the top of the file.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-rxiSDUa7Kbw/VzOXXp8duQI/AAAAAAAAGNI/HfqjnmTc6_YsaUGx2TXiY8PrsrW-uOsPACLcB/s1600/Screenshot%2Bfrom%2B2016-05-11%2B15%253A13%253A34.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Next simply ssh into the cluster of your choice while using the tunnelling flag -L. You'll probably need to add your credentials
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;ssh -N username@midway.rcc.uchicago.edu -L &amp;lt;local port&amp;gt;:&amp;lt;server ip&amp;gt;:&amp;lt;server port&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I just used &amp;lt;local port&amp;gt;=8888 so that I could connect to http://localhost:8888/tree like I normally do when serving the notebook on my local machine. And voila... the ipython notebook interface pops up when you navigate your web browser to that address.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-BhI3eAPd-dY/VzOU7TTJy_I/AAAAAAAAGM8/EpuLq7IIaI8ptUZjMOO8qkN81mQ1b-hkACLcB/s1600/Screenshot%2Bfrom%2B2016-05-11%2B15%253A23%253A47.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You can stop here if you only want to host your notebooks on a cluster as a server, but of course using a cluster means you can do so much more because you can run things in parallel. Keep going to see how that works.
    &lt;/p&gt;
&lt;h4&gt;Running the cluster with parallel jobs&lt;/h4&gt;
&lt;p&gt;
        To make things slightly more confusing, but also much more useful, I wanted to run a parallel cluster for my ipython notebooks. This really broke down to two steps:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;#ipcluster&quot;&gt;Setting up an ipcluster to run on a set of nodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#connections&quot;&gt;Getting ipython notebook server to send jobs to the ipcluster&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;ipcluster&quot;&gt;Setting up an ipcluster&lt;/h4&gt;
&lt;p&gt;
        This part can theoretically be carried out in a number of ways, but in practice I found that only one way actually works with SLURM as your backend. In particular, I found it very troublesome to use any of the &quot;automatic&quot; setup systems, like ipcluster or ipython_cluster_helper. They didn't play nicely with the SLURM configurations that I was working with so I wrote a script that directly launched the underlying tools, ipcontroller and ipengine.
    &lt;/p&gt;
&lt;p&gt;
        The script I used based largely on examples I found from &lt;a href=&quot;http://k-d-w.org/node/96&quot;&gt;Sebastian Pölsterl&lt;/a&gt;, &lt;a href=&quot;http://twiecki.github.io/blog/2014/02/24/ipython-nb-cluster/&quot;&gt;twiecki&lt;/a&gt; and &lt;a href=&quot;https://rcc.fsu.edu/docs/parallel-ipython-programming-hpc-and-spear&quot;&gt;FSU's RCC&lt;/a&gt;. After the SBATCH setup info, it accomplishes three things:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Delete all old ipython profiles and create a new one for this ipcluster &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;rm -r ~/.ipython/profile_job*&lt;br/&gt;profile=job_${SLURM_JOB_ID}&lt;br/&gt;&lt;br/&gt;echo &quot;Creating profile ${profile}&quot;&lt;br/&gt;ipython profile create ${profile}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Launch an ipcontroller that can connect to any IP using this profile &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;ipcontroller --ip=&quot;*&quot; --profile=${profile} &amp;amp;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Launch as many ipengines as needed (60) that will connect to the ipcontroller at $(hostname) &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;srun ipengine --profile=${profile} --location=$(hostname)&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        After you run this script using &lt;strong&gt;sbatch run_ipcluster.sbatch&lt;/strong&gt;, SLURM will return a job number that you will need to use later. To see what this is doing behind the scenes you can view the output in the appropriate log/ipc-* file. You'll essentially see the ipcontroller come online and then you'll see a bunch of updates as each ipengine makes contact with the ipcontroller. However, at this point we really haven't accomplished anything because all those ipengines are still waiting for work to do.
    &lt;/p&gt;
&lt;h4 id=&quot;connections&quot;&gt;Connecting to your parallel ipcluster&lt;/h4&gt;
&lt;p&gt;
        To actually use the ipengines we set up, we have to use the special parallel programming utilities housed in IPython.parallel. Technically, we're supposed to use &lt;a href=&quot;https://github.com/ipython/ipyparallel&quot;&gt;ipyparallel&lt;/a&gt; now, and I recommend using that if you know how. At the time of writing this though, ipyparallel needs to be installed separately and most of the examples I've found used IPython.parallel so I didn't feel like crossing those hurdles for my set up.
    &lt;/p&gt;
&lt;p&gt;
        IPython.parallel doesn't have to be used with Jupyter notebooks, and, in my opinion, combining the two makes things a little difficult to understand at first. To make things easier, I'll introduce the script based method first and then show the tricks for using it in a notebook.
    &lt;/p&gt;
&lt;h6&gt;Running a standalone script&lt;/h6&gt;
&lt;p&gt;
        For a quick test to make sure that the cluster is actually functioning at all, you can run the &lt;a href=&quot;https://github.com/lots-of-things/ipynb-par-slurm/blob/master/pypar.py&quot;&gt;pypar.py&lt;/a&gt; test. This code generates an estimate of Π from a &lt;a href=&quot;http://interactivepython.org/runestone/static/thinkcspy/Labs/montepi.html&quot;&gt;large &quot;dartboard&quot; simulation&lt;/a&gt; so the accuracy should increase with more machines being used.
    &lt;/p&gt;
&lt;p&gt;
        To run this using the parallel cluster, pass the profile name to the script.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;$ module load python&lt;br/&gt;$ python pypar.py -p job_&amp;lt;jobn&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        &amp;lt;jobn&amp;gt; is the job number returned by SLURM when you submitted run_ipcluster.sbatch earlier. When the script finishes there should be a file called result-job.txt, which will include a pretty OK estimate of Π. I'm not going to get too deep into how how to actually do parallel programming in Ipython, but here are some tutorials and examples to get you started working with that.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;https://ipython.org/ipython-doc/3/parallel/parallel_demos.html&lt;/li&gt;
&lt;li&gt;http://nbviewer.jupyter.org/github/minrk/IPython-parallel-tutorial/blob/master/examples/Parallel%20image%20processing.ipynb&lt;/li&gt;
&lt;li&gt;http://minrk.github.io/scipy-tutorial-2011/basic_remote.html&lt;/li&gt;
&lt;/ul&gt;
&lt;h6&gt;Connecting your notebooks to the cluster&lt;/h6&gt;
&lt;p&gt;
        Using IPython.parallel inside the Jupyter notebook isn't that much trickier than in a python script. There are a few tricks that are covered in &lt;a href=&quot;http://twiecki.github.io/blog/2014/02/24/ipython-nb-cluster/&quot;&gt;twieki's post&lt;/a&gt;, but I'm not sure if that's exhaustive. Just as an example, I've included the somewhat useless dummie_notebook.py to get you started. It performs some calculations and outputs to the file to simpleoutput.txt. To make it work, you'll have to update the profile referenced when setting up the parallel.Client() so that it matches the job name of returned when you launched run_ipcluster.sbatch.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-IP2Dr2Tqd8c/VzuMv7lD59I/AAAAAAAAGNw/u1r8hWqeKx4pexG-dLyuDH3OfJL9CKrGACLcB/s1600/Screenshot%2Bfrom%2B2016-05-17%2B16%253A27%253A04.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        If everything is set up correctly you should just get the range of numbers from 1 to 10,000 in the simpleoutput.txt file. You can make sure that the job actually ran in parallel by checking the corresponding log/ipc-* file to make sure that a ton of communications started getting printed to file.
    &lt;/p&gt;
&lt;h4&gt;Future directions and get the code&lt;/h4&gt;
&lt;p&gt;
        This setup should prove to be very useful to me and I hope it will be to you too. You can get all the code from my &lt;a href=&quot;https://github.com/lots-of-things/ipynb-par-slurm&quot;&gt;ipynb-par-slurm&lt;/a&gt; repo on Github. In the future, I think it should be possible to extend this method to work with other libraries that support parallelism, but I'm just scratching the surface of those challenges right now. I may update the github repo to include other examples that work with more packages if that turns out to be possible. Happy parallelizing,
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 11 May 2016 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2016/05/work-in-progress-parallel-ipython-from/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2016/05/work-in-progress-parallel-ipython-from/</guid>
        
        <category>data science</category>
        
        <category>infra</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://3.bp.blogspot.com/-XWaEhvNkWMI/VxUDQrKEcpI/AAAAAAAAGBE/v_GPtW_YD3g0D00sVyaHbNwniVz8uzkHQCKgB/IMG_20160418_103145.jpg</image>
        <title>Bluetooth controlled Redbot construction</title>
        <description>&lt;p&gt;
        For part of the Ray elementary after school electronics and robotics club (R-ASER), I'm prototyping a robot that can be remotely controlled via a serial connection through bluetooth. The following is the rough draft of the classroom instructions. (PS, volunteering with kids is fun so go out and do it.)
    &lt;/p&gt;
&lt;h4&gt;Adding the Bluetooth module&lt;/h4&gt;
&lt;p&gt;
        This lesson starts with a fully assembled and functional Redbot chassis. You can find more info abut the robot kit and instructions on &lt;a href=&quot;https://learn.sparkfun.com/tutorials/redbot-assembly-guide&quot;&gt;sparkfun's tutorial website&lt;/a&gt;, and you can see more of our Redbot based projects once we have them online. This is what our original Redbot looks like before we start construction.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-XWaEhvNkWMI/VxUDQrKEcpI/AAAAAAAAGBE/v_GPtW_YD3g0D00sVyaHbNwniVz8uzkHQCKgB/s1600/IMG_20160418_103145.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We'll be modifying this basic robot with an a bluetooth module that doesn't come from sparkfun so we'll get all the excitement of working with non-kit electronics. We're going to be adding an HC-05 BT module like the one pictured below.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ureRUngkG68/VxUooNgWmiI/AAAAAAAAGCY/tzU378CqnooU82_6p3AxYYe7BadBnQaLgCKgB/s1600/IMG_20160418_103201.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This device contains a fully functional bluetooth transmitter and receiver so we don't have to worry about building the parts that transmit data through the air. That means all we will have to do is listen to the serial data coming from the device as if it were coming from the USB cable.
    &lt;/p&gt;
&lt;h4&gt;Connecting through a voltage divider&lt;/h4&gt;
&lt;p&gt;
        The big trick with this device is that it communicates using only 3.3 V while the Arduino usually uses 5 V. This means that if we send information to the using 5V we will overload the circuit and burn the chip up. This cause us to need to use a &lt;a href=&quot;https://en.wikipedia.org/wiki/Voltage_divider&quot;&gt;voltage divider&lt;/a&gt; to decrease the voltage going to the bluetooth module. We'll put together a circuit based on &lt;a href=&quot;http://www.instructables.com/id/Cheap-2-Way-Bluetooth-Connection-Between-Arduino-a/?ALLSTEPS&quot;&gt;this excellent Instructable&lt;/a&gt; from techbitar
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FSK/AI30/HMMFE6UO/FSKAI30HMMFE6UO.MEDIUM.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To start we'll connect black, red, yellow, and green wires to the bluetooth module like in the image.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-hhOEchGO0dA/VxUDQj-omjI/AAAAAAAAGBE/xxBRx0Vtbdkz7S9jJoVkJ7H-68FcbE5pgCKgB/s1600/IMG_20160418_103759.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The black and red wires will just connect the bluetooth module to the power and ground of the Arduino microcontroller. The yellow and green wires will connect to analog ports on the Arduino in order to transmit and receive signals. Serial signals work by having each connected device transmit information from a port labeled TXD and receive signal from a port labeled RXD. So we're going to use the green wires to receive signals from the Arduino (RXD) to the bluetooth module, and we're going to use the yellow wires to transmit signals to the Arduino (TXD).
    &lt;/p&gt;
&lt;h6&gt;The voltage divider&lt;/h6&gt;
&lt;p&gt;
        The signal that is going into the bluetooth module needs to be at 3.3v so we will need to connect that wire through a voltage divider. A voltage divider just causes some voltage to be lost directly to ground without going through another part of the circuit.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Impedance_voltage_divider.svg/220px-Impedance_voltage_divider.svg.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In our circuit that means we need to add two resistors connected to the yellow lead coming out of the RXD pin.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-k974hT3hAmg/VxUobvFKDLI/AAAAAAAAGCQ/5i4xEP3xI0s1mbOsX6FluNJQnAHOaGcGQCKgB/s1600/IMG_20160418_103846.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We'll use a 1 kOhm resistor on the line to the Arduino input and a 2 kOhm resistor on the line to the ground. This will cause most of the voltage to be on the Arduino input with only a little being divided away. What would happen if we had used 2kOhm on both?
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-pe5KXXeO_ws/VxUDQqvwcYI/AAAAAAAAGBE/MVdcat5kge8MoqArk7USNjhoY5q5iOZYACKgB/s1600/IMG_20160418_103858.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To make things more clear I used a black wire coming off the 2 kOhm resistor (going to ground) and a white wire off the 1 kOhm resistor (going to the inputs).
    &lt;/p&gt;
&lt;h4&gt;Connecting to the board&lt;/h4&gt;
&lt;p&gt;
        The final step for connecting the module is to plug it into the board itself. You can figure out how to connect our wires from the diagram above and using your logic. The important thing to know is that A0 is going to be doing the receiving from the bluetooth module while A1 is going to be doing the sending to the module. Can you figure out which color wires should connect even without looking? &lt;strong&gt;IMPORTANT: Two of the wires in the next image are reversed so you have to figure out which color goes where!&lt;/strong&gt;
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-TNl0oI6tGK0/VxUDQvqxLJI/AAAAAAAAGBE/vf7lQGaqlu4Y-HKWiHVZ3chg0KrvXDLgwCKgB/s1600/IMG_20160418_104051.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The board has a switch that you'll have to change too. This switch changes the Arduino circuitry so that now analog ports A0 and A1 will work just like the Serial USB works. This is called SoftwareSerial and we'll talk more about it next time, but for now just make sure that the switch points to &quot;XBEE SW SERIAL&quot;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Wykpn_3f1eE/VxUMhB-KZMI/AAAAAAAAGB0/texGL8Nz6uAy-my0T-wHH_lsC-6b4WxyQCKgB/s1600/IMG_20160418_113003.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Renaming the Bluetooth Module&lt;/h4&gt;
&lt;p&gt;
        If you are working with more than one bluetooth module in the same area, you will need to rename your module so that you don't get it confused with any of the other ones in the area. To do this you will need to upload some special code to your Arduino that'll let you write from your USB serial to the modules serial line.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;#include &amp;lt;RedBot.h&amp;gt;&lt;br/&gt;#include &amp;lt;RedBotSoftwareSerial.h&amp;gt;&lt;br/&gt;&lt;br/&gt;RedBotSoftwareSerial swsp;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  Serial.println(&quot;Arduino is ready&quot;);&lt;br/&gt;  swsp.begin(9600);&lt;br/&gt;  Serial.println(&quot;BTserial started at 9600&quot;);&lt;br/&gt;  delay(50);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  if (swsp.available())&lt;br/&gt;    Serial.write(swsp.read());&lt;br/&gt;&lt;br/&gt;  // Keep reading from Arduino Serial Monitor and send to HC-05&lt;br/&gt;  if (Serial.available()){&lt;br/&gt;    char c = Serial.read();&lt;br/&gt;    Serial.write(c);&lt;br/&gt;    swsp.write(c);&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        After this code is uploaded you should power on the bluetooth module. Next open the Serial Monitor and you should see the text &quot;Arduino is ready&quot; and &quot;BTSerial started at 9600&quot;. At this point, if you type in the Serial Monitor nothing special should happen. You need to activate the module's AT mode, which will allow you to change internal programming of the module. To do this you need to press and hold the tiny button sitting next to the EN line on the module.
    &lt;/p&gt;
&lt;p&gt;
        IMPORTANT: In the bottom right of the Serial Monitor, you need to make sure you have selected &quot;Both NL and CR&quot; and &quot;9600&quot;. This ensures that every time you press enter, the message is sent with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Newline&quot;&gt;New Line&lt;/a&gt; character. The Bluetooth module requires new lines at the end of every command.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-CTsSPHDBE9Y/Vz5g3mMsFaI/AAAAAAAAGOI/T2-ydewCf7Q_Mjc_KV-oRSONoZXkVcrlwCLcB/s1600/serial_nlcr.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        While holding down that button you can type &quot;AT&quot; and the serial monitor should respond &quot;OK.&quot; Next type &quot;AT+NAME&quot; to see the current name of the module(which should be &quot;HC-05&quot;). Finally type &quot;AT+NAME=####&quot; where you should put a unique name in place of #### so that you can identify your module when you try to pair with it. After you've done that, simply turn the Arduino back off and back on to reset the Bluetooth module.
    &lt;/p&gt;
&lt;h4&gt;Connect bluetooth device&lt;/h4&gt;
&lt;p&gt;
        Again connecting will be different on every machine, but we'll show the steps for Windows.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-fMqFoxy7M0I/VxUyXB7QHfI/AAAAAAAAGCw/wDy8YmUnWz8uM_XuRyIF4NiOGVYBllwXwCLcB/s1600/icon-bluetooth.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You'll start by making sure that the bluetooth module is powered on and blinking. Next, right click on the little bluetooth icon in the corner and select &quot;Connect Devices&quot; or something similar. This will open a dialog that let's you search for the bluetooth module. There's no guarantee on the name but it might say HC-05 if you're lucky.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/F4D/GW1B/H1JUIZBK/F4DGW1BH1JUIZBK.MEDIUM.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You'll have to move through a few more steps until you need to add a pairing code to make the devices talk to each other. This is just how bluetooth makes sure that you aren't accidentally connecting to the wrong device. For me the pairing code was 1234, but this is not guaranteed to be correct.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FHS/ORJ6/H1JUIZBJ/FHSORJ6H1JUIZBJ.LARGE.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You'll have to figure out which serial port the device is talking to. That can be found in the device properties.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FWZ/8AGB/H1JU5CJD/FWZ8AGBH1JU5CJD.LARGE.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Write to Serial Bluetooth with Tera Term&lt;/h4&gt;
&lt;p&gt;
        Next, we have to set up Tera Term to talk to that port. Tera Term is pretty much the same thing as the Serial Monitor, but it works slightly better. Importantly, we can use it with the COM port that the Bluetooth is talking to.
    &lt;/p&gt;
&lt;h6&gt;Install Tera Term&lt;/h6&gt;
&lt;p&gt;
        The first thing we're going to do is get Tera Term onto our machines. Installing Tera Term will be different on every system, but for Windows machines, you can simply download the latest .exe file from their website.
    &lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://en.osdn.jp/projects/ttssh2/releases/&quot;&gt;https://en.osdn.jp/projects/ttssh2/releases/&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
        Once Tera Term is installed, open it. After you open Tera Term you just have to select he same COM Port connected to the Bluetooth. The trick here is that our Bluetooth modules actually connect to two COM Ports, but only one of them works. It appears to be totally random which COM port is selected so you have to guess. If you guess correctly, the blinking pattern on the Bluetooth chip will change to two short flashes. If you guess wrong, you just have to reopen Tera Term and select the other port.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FSH/QADB/H1JU5CJC/FSHQADBH1JU5CJC.LARGE.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Once you think you're connected you need to get some code on your Arduino to really see if it's working.
    &lt;/p&gt;
&lt;h4&gt;Checking for connectivity&lt;/h4&gt;
&lt;p&gt;
        As a simple test case we can use the following code from techbitar to blink code over the serial port once we have the computer connected to the Arduino.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;#include &amp;lt;RedBot.h&amp;gt;&lt;br/&gt;#include &amp;lt;RedBotSoftwareSerial.h&amp;gt;&lt;br/&gt;&lt;br/&gt;int counter =0;&lt;br/&gt;RedBotSoftwareSerial swsp;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  swsp.begin(9600);&lt;br/&gt;  delay(50);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  counter++;&lt;br/&gt;  swsp.print(&quot;Arduino counter: &quot;);&lt;br/&gt;  swsp.println(counter);&lt;br/&gt;  delay(500); // wait half a sec&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The part where we define swsp relies on using Software serial to make a &quot;software&quot; version of the regular serial port (i.e. the one we use when we write Serial.println()). We don't have to worry about how this works under the hood (unless something doesn't work).
    &lt;/p&gt;
&lt;h4&gt;Challenge: Drive the car&lt;/h4&gt;
&lt;p&gt;
        You now have swsp working just like a regular USB serial port. So use it just like you would to control the Redbot! If you can't figure it out, you can cheat and click in the box to see the code to drive the car.
    &lt;/p&gt;
&lt;input name=&quot;answer&quot; onclick=&quot;showDiv()&quot; type=&quot;button&quot; value=&quot;Click to Cheat&quot;/&gt;

&lt;br/&gt;

&lt;script&gt;
function showDiv() { document.getElementById('welcomeDiv').style.display = &quot;block&quot;; }
&lt;/script&gt;</description>
        <pubDate>Mon, 18 Apr 2016 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2016/04/bluetooth-controlled-redbot-construction/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2016/04/bluetooth-controlled-redbot-construction/</guid>
        
        <category>electronics</category>
        
        <category>robots</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://4.bp.blogspot.com/-uz-UeIv9vhc/Vz54Bh5sTtI/AAAAAAAAGOo/UIHzIL2AglwfrH_ks9BnkDmK5ohzc7vxACKgB/CAM00041.jpg</image>
        <title>Connecting the Artifice Center with a Shared NAS Drive</title>
        <description>&lt;p&gt;
        These are some quick instructions for anybody interested in connecting a NAS to Linux computers on a closed local network. In particular, this guide will help to reconnect the NAS drive to the computers at the &lt;a href=&quot;www.artificechicago.org&quot;&gt;Artifice Tech Center&lt;/a&gt; in Woodlawn.
    &lt;/p&gt;
&lt;h4&gt;The NAS drive&lt;/h4&gt;
&lt;p&gt;
        A NAS (&lt;a href=&quot;https://en.wikipedia.org/wiki/Network-attached_storage&quot;&gt;Network attached storage&lt;/a&gt;) device allows you to essentially connect hard drives directly to your network without needing them to be associated with a &quot;real&quot; computer. If you have a wireless router, you can just plug the device straight into the router.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-uz-UeIv9vhc/Vz54Bh5sTtI/AAAAAAAAGOo/UIHzIL2AglwfrH_ks9BnkDmK5ohzc7vxACKgB/s1600/CAM00041.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        From the hardware end there isn't really much more to it than that. The device should have it's own IP address that you can communicate with from any other device on the network.
    &lt;/p&gt;
&lt;h4&gt;Making a Shared folder on the NAS&lt;/h4&gt;
&lt;p&gt;
        To let other computers modify the disk drives in the NAS, you need to set up a shared folder on it. The machine case itself should have it's access point IP address printed somewhere on it. If for some reason it doesn't, you'll need to use other information printed on it to search the web or the address.
    &lt;/p&gt;
&lt;p&gt;
        Once you have the IP, you can connect to the NAS simply by typing that address into the browser on any computer in your local the network. To connect to mine, I navigated to &lt;a href=&quot;http://192.168.1.32&quot;&gt;http://192.168.1.32&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        You can find the specific instructions for making network shares on &lt;a href=&quot;http://www.dlink.com/uk/en/support/faq/network-storage-and-backup/nas/dns-series/dns-320l/uk_create-users_groups-and-folder-sharing-in-dns-320l&quot;&gt;dlink's help site&lt;/a&gt;. The process is mostly self-explanatory. I made a directory called Artifice_Share, and set the permissions so that anybody could read or write anything.
    &lt;/p&gt;
&lt;h4&gt;Mounting a drive to a Linux machine (Mint)&lt;/h4&gt;
&lt;p&gt;
        The more mysterious step is how to get a machine to automatically connect to the shared drive. Fortunately, the instructions that I got from &lt;a href=&quot;http://forums.dlink.com/index.php?topic=7848.0&quot;&gt;this post on the dlink forums&lt;/a&gt; are actually quite easy. In the technical jargon we are setting up our &quot;fstab&quot; file to &quot;mount&quot; the directory. In practice that just looks like adding a line to our &quot;/etc/fstab&quot; file:
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;.... a bunch of other junk ....&lt;br/&gt;&lt;br/&gt;//&lt;span style=&quot;color:red&quot;&gt;192.168.1.32&lt;/span&gt;/Volume_1/Artifice_Share /home/artifice/Desktop/Artifice_Share cifs guest,rw,uid=1000,gid=1000,nounix,iocharset=utf8,file_mode=0777,dir_mode=0777 0 0&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        You'll have to adjust the IP (in red) to match with the device ID for your particular NAS. After you restart the computer there should be 2 folders on the Desktop both named Artifice_Share. I don't know why two show up, but it doesn't seem like it's causing any harm.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 30 Mar 2016 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2016/03/connecting-artifice-center-with-shared/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2016/03/connecting-artifice-center-with-shared/</guid>
        
        <category>infra</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-63w9Rl8tGLI/Vrgh8uWuEjI/AAAAAAAAF4o/dKeaPCS_mOQ/IMG_20160207_225952.jpg</image>
        <title>Star Wars Themed Settlers of Catan</title>
        <description>&lt;p&gt;
        I have been wanting to get a Settlers of Catan game for ourselves ever since I played it for the first time a few months ago. It looked like an incredibly simple game setup so my girlfriend and I figured it would easy enough to build the game ourselves.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-63w9Rl8tGLI/Vrgh8uWuEjI/AAAAAAAAF4o/dKeaPCS_mOQ/s1600/IMG_20160207_225952.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Of course, since we were making it ourselves this was a prefect opportunity to make the game theme just the way we wanted. Amid the hype surrounding &lt;a href=&quot;http://www.imdb.com/title/tt2488496/&quot;&gt;The Force Awakens&lt;/a&gt;, we decided to go for a Star Wars theme. Prepare for the nerdy, folks.
    &lt;/p&gt;
&lt;p&gt;
        There are &lt;a href=&quot;http://www.starwars.com/databank&quot;&gt;nearly infinite possibilities&lt;/a&gt; provided by the &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_Star_Wars_books&quot;&gt;thousands of stories&lt;/a&gt; set in the &lt;a href=&quot;http://starwars.wikia.com/wiki/List_of_planets&quot;&gt;many planetary systems&lt;/a&gt; of the &lt;a href=&quot;http://www.swgalaxymap.com/&quot;&gt;Star Wars Galaxy&lt;/a&gt;. Not to mention that you can choose from any period in the galaxy's &lt;a href=&quot;http://starwars.wikia.com/wiki/Timeline_of_galactic_history/Legends&quot;&gt;roughly 1 billion year history&lt;/a&gt; as your setting&lt;a href=&quot;#/footnote&quot;&gt;*&lt;/a&gt;. Needless to say, this leaves you with a lot of choices to make in designing a game's backdrop.
    &lt;/p&gt;
&lt;p&gt;
        Other people have made Star Wars Settlers games before. The two that we could find were Settlers of the Old Republic and Settlers of the Empire. Both of them look great, especially Settlers of the Empire, so we wanted to make sure we approached it differently so that we could have our own
    &lt;/p&gt;
&lt;h4&gt;Settlers of the Outer Rim&lt;/h4&gt;
&lt;p&gt;
        Ultimately, we decided on a theme based on the time period around Episode VII. The game is set in the most distant reaches of the galaxy, known as the Outer Rim. The basic premise is that after the fall of the Empire and the rise of the New Republic, new traders and settlers will try to expand the influence of the Republic to systems in the so called Outer Rim. I think this is a fairly reasonable concept, and it steers the game's focus away from more established periods of &lt;a href=&quot;https://en.wikipedia.org/wiki/Star_Wars_canon&quot;&gt;Star Wars Canon&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The gameplay is still exactly identical to the original Settlers of Catan. Only the names and faces of the cards have been changed to reflect the new storyline. When we play it, I like to kind of pretend we're really in this storyline with its grand theme of galactic economics.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-r4KSiXOMmNA/VrgjXxxAQAI/AAAAAAAAF5A/7ruINkl9ArE/s1600/building_panel.png&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h6&gt;The Story&lt;/h6&gt;
&lt;p&gt;
        You're a galactic pioneer of the New Republic, looking to find new resources in the Outer Rim of the galaxy. The main hurdle for trade in this sector is the establishment of new and secure hyperspace routes, landing pads, and space stations. Of course, for such a lucrative opportunity there's obviously a lot of competition. Your challenge is to reach economic dominance of the Outer Rim before any of your opponents.
    &lt;/p&gt;
&lt;p&gt;
        To build your hyperspace routes and resupply stations you'll need to extract resources from the star systems in this region. You can also trade with the Bank of the New Republic or you can look for better deals with smugglers at the edges of the galaxy.
    &lt;/p&gt;
&lt;p&gt;
        In addition, to help you control more territory, you can also invest in development of your trade network. These investments can pay off with exclusive Republic contracts, captured smugglers, free hyperspace routes, or any of a number of valuable ships and droids. Finally, you can also attain abandoned lightsabers, which help you gain influence over a confederation of Outer Rim bounty hunters.
    &lt;/p&gt;
&lt;p&gt;
        At each turn, you roll a dice to find out which systems have resources ready for extraction. Then you proceed to trade, or to purchase equipment and development cards.
    &lt;/p&gt;
&lt;p&gt;
        For every space port or space station you will receive 1 or 2 Victory Points, respectively. The Republic will reward you with extra points if you provide the longest hyperspace route, or if you recover the largest number of lost lightsabers. The game ends when one player attains 10 Victory Points.
    &lt;/p&gt;
&lt;h4&gt;Game Components&lt;/h4&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Outer Rim Gameboard&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-cwRdoN-GzMs/VrgcWi35s0I/AAAAAAAAF3U/ROnufWxP2V4/s1600/IMG_20160207_222522.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Game Pieces&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-dKfqIIngOWg/Vrgcla728UI/AAAAAAAAF3k/Iq218v-WSwQ/s1600/IMG_20160207_222135.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Galactic Resources&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-NnlWcNx0amE/VrgcpSaV4-I/AAAAAAAAF3s/BSpvJLTxnBk/s1600/IMG_20160207_221604.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Development Cards&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-YK3EwaQSays/VrgiBPdo0hI/AAAAAAAAF4w/hVCKIcw6l7E/s1600/IMG_20160207_224717.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Gameplay&lt;/h6&gt;
&lt;p&gt;
        As mentioned above, the gameplay follows the original &lt;a href=&quot;http://www.catan.com/service/game-rules&quot;&gt;Settlers of Catan rules&lt;/a&gt;. If you've played Settlers before, you'll see the parallels immediately. Otherwise I suggest &lt;a href=&quot;https://www.youtube.com/watch?v=mco5SL4-y-c&quot;&gt;this video&lt;/a&gt; to get you more acquainted with how to set up and play.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Graphics for Download&lt;/h6&gt;
&lt;p&gt;
        If you like the idea of the game and would like to recreate it for yourself, we've put the &lt;a href=&quot;https://github.com/lots-of-things/settlers-outer-rim&quot;&gt;svg files&lt;/a&gt; on the &lt;a href=&quot;https://github.com/lots-of-things/&quot;&gt;MakeLofT Github&lt;/a&gt;. I've just embedded all the images directly and I haven't rerasterized or compressed anything so some of the files are a little big. Hope you have fun if you put it together, and may the Force be with you.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-xR4w_yMiK2k/VrglVD3UOBI/AAAAAAAAF5M/xCLD7ReUn7E/s1600/bacta.png&quot; title=&quot; &quot;/&gt;
&lt;p id=&quot;footnote&quot;&gt;*&lt;sub&gt;I know that the possibilities have technically been drastically slashed by Disney's &lt;a href=&quot;http://www.dailydot.com/geek/star-wars-expanded-universe-not-canon/&quot;&gt;decanonization of the Expanded Universe&lt;/a&gt;, but I still believe that the Legends are real.&lt;/sub&gt;
&lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 07 Feb 2016 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2016/02/star-wars-themed-settlers-of-catan/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2016/02/star-wars-themed-settlers-of-catan/</guid>
        
        <category>games</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://3.bp.blogspot.com/-f-a5ltIGHv0/Vni1dxc9W0I/AAAAAAAAFpI/svbf1BgmCaA/IMG_20151218_172725.jpg</image>
        <title>The Plexi+Rock Boot Tray Accident</title>
        <description>&lt;p&gt;
        Over the holidays, I always end up with new projects to make for gifts for my friends and family. This time for Christmas my gf's mom asked me to make a boot tray for her new apartment. She specifically said, &quot;use any materials you want,&quot; so I took her up on that by combining left-over plexiglass and tumbled gravel to make a classic, &lt;a href=&quot;https://www.google.com/search?q=rock+shoe+tray&amp;amp;source=lnms&amp;amp;tbm=isch&amp;amp;sa=X&amp;amp;ved=0ahUKEwjIvvu4t-7JAhXDKx4KHWlQANoQ_AUICCgC&amp;amp;biw=1319&amp;amp;bih=671&quot;&gt;rock boot tray&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-f-a5ltIGHv0/Vni1dxc9W0I/AAAAAAAAFpI/svbf1BgmCaA/s1600/IMG_20151218_172725.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This projecct was quite funny because really nothing went expected, but the result still looks pretty impressive in my opinion At the very least this is another example that muddling through will &lt;strong&gt;almost always&lt;/strong&gt; get you what you want. That should probably be the official slogan of this blog.
    &lt;/p&gt;
&lt;h5&gt;The plexiglass tray&lt;/h5&gt;
&lt;p&gt;
        The tray is the main endeavor in this project. Once you have a tray, the rest is just cleaning up some rocks. But there are so many ways to make a tray, I didn't know what I wanted to do. I thought originally I'd go with simple bent sheet metal, but that was too much like what I made for Claire's &lt;a href=&quot;http://www.makeloft.org/2014/12/introducing-daves-grill-it-all.html&quot;&gt;dad last year&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        Instead, I stumbled on some simple clear plastic that was left over from an experiment at work. Most people would probably call this plexiglass, but it's actually technically Lexan (polycarbonate), not plexiglass (acrylic).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-o1cdCP3oWhU/Vni4FamMBvI/AAAAAAAAFpU/JBQp0MHz7gc/s1600/IMG_20151216_194043.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To mold polycarbonate, you only need to heat it to &lt;a href=&quot;http://www.instructables.com/answers/Is-it-safe-to-melt-polycarbonate/&quot;&gt;somewhere just above 150°&lt;/a&gt;. So I threw a test piece into the oven to see what it would do. I slowly heated to 200° but it was still stiff. Then I went to 250° and finally, 300° before it started to bend.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-9yAsrKMm1hY/Vni5HkazydI/AAAAAAAAFpg/gLatHIYxtd4/s1600/IMG_20151216_194104.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The results weren't amazing, but the edge was moldable so I figured I'd toss in the main piece and see what I could make of it. However, for this piece the oven was already warmed up to 300° and this had some pretty crazy (but pretty) results!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-R_TpCiU7ak4/Vni6KrSPOZI/AAAAAAAAFps/g8WtrRPRyww/s1600/IMG_20151216_213301.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;a href=&quot;http://bbs.homeshopmachinist.net/archive/index.php/t-30224.html&quot;&gt;As it turns out&lt;/a&gt;, polycarbonate has a high water content in the plastic so if you rapidly ramp the temperature up past the boiling point, the water inside the material starts to boil out. In this case, this caused the plastic to turn white with tiny bubbles and for the edges to turn up.
    &lt;/p&gt;
&lt;p&gt;
        But amazingly that was exactly what I wanted anyway! So... I just decided to keep it like that (not that I had much choice at that point). The edge wasn't perfectly symmetric along the back side, but I figured that part could go against the wall.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-NvGgUGT2eaI/Vni6-6bDNYI/AAAAAAAAFp0/FoemmhWj8C0/s1600/IMG_20151216_213326.jpg&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Cleaning rocks&lt;/h5&gt;
&lt;p&gt;
        For rocks I just gathered pebbles from vacant lots and trails around my neighborhood. I tried to pick prettier sets, but once I realized how many I need I just started grabbing handfuls.&lt;p&gt;
&lt;p&gt;
                I did want them to shine a little though. After I cleaned them, I tried to &quot;cure&quot; them (or something) by putting them through an oil bath followed by a soap bath.
            &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-P9v_iJDZItw/Vni7a7NSRHI/AAAAAAAAFp8/_qFXUh60b6E/s1600/CAM00440.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                This led to a significant improvement in shininess (at least temporarily).
            &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-M91SKhxlvVQ/Vni8Rcqv_sI/AAAAAAAAFqI/bwDGgCC1Sjw/s1600/IMG_20151218_172628.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                After, piling the rocks on the tray, all that was left was to add shoes. And I think it made for a cute and practical little outdoorsy themed home furnishing.
            &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-gjf0sss2iE8/Vni8j3TsVuI/AAAAAAAAFqQ/sI2nGfewNmc/s1600/IMG_20151218_172705.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                I almost wanted to keep it for our house.
            &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;&lt;/p&gt;</description>
        <pubDate>Tue, 22 Dec 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/12/the-plexirock-boot-tray-accident/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/12/the-plexirock-boot-tray-accident/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://3.bp.blogspot.com/-vLP4HuiJA6A/Vm95iCkSAKI/AAAAAAAAFcY/cMtPnk43kQg/routecrime.png</image>
        <title>Q&amp;amp;A on the Route Crime Calculator</title>
        <description>&lt;p&gt;
        I've recently built a cool little web app that helps evaluate the number of crimes occurring along a person's travel route in the City of Chicago. To elaborate a little on the rationale and methodology, I've written this blog post where I answer some plausible questions.
    &lt;/p&gt;
&lt;h6&gt;How safe is travelling around in Chicago?&lt;/h6&gt;
&lt;p&gt;
        That's hard to say, but hopefully I've made it a little easier to evaluate that. Obviously both native Chicagoans and visitors to the city have often find themselves travelling on public transit through neighborhoods that can make them feel unsafe. I wanted to explore this question and give some way to compare different routes and parts of the city so I started analyzing some of the city's open crime data for answers. This led to some interesting results so I decided to try to open that data up to the public in some reasonable way by making a little webapp.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-vLP4HuiJA6A/Vm95iCkSAKI/AAAAAAAAFcY/cMtPnk43kQg/s1600/routecrime.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;So what can it do?&lt;/h6&gt;
&lt;p&gt;
        To help prevent exposure to crime and to make everybody feel more safe, this tool evaluates the likelihood of criminal activity based on your transit route. It shows a few options and let's you see whichever one is the &quot;safest.&quot;
    &lt;/p&gt;
&lt;h6&gt;So it's like minority report or something?&lt;/h6&gt;
&lt;p&gt;
        The problem of predicting crime has been tackled before in &lt;a href=&quot;http://www.theverge.com/2014/2/19/5419854/the-minority-report-this-computer-predicts-crime-but-is-it-racist&quot;&gt;Chicago&lt;/a&gt; and &lt;a href=&quot;http://thinkprogress.org/justice/2015/02/12/3622235/police-departments-use-big-data-predict-crime-will-hit-next/&quot;&gt;elsewhere&lt;/a&gt;. However, it seems like most of the focus I've seen on this matter focused on its relation to policing strategies rather than public awareness. I don't intend to predict crimes, and I certainly don't want to build a tool that could be used to unfairly target citizens. I'd prefer that everybody just be aware of the real dangers (or lack of dangers) presented to them. I wanted to make something that helps the average person better evaluate exactly what they are facing when they take to the street every day.
    &lt;/p&gt;
&lt;h6&gt;So then what exactly does it do?&lt;/h6&gt;
&lt;p&gt;
        This tool is really just a fancy database query that looks up the past crimes that have occurred at any block in the city. I break the data up based on time of day, day of the week, and month of the year to make the prediction as accurate as possible. With that data, I can compute the average number of crimes that occur at that time and place over the past couple of years, which gives me a rate for crime occurrence.
    &lt;/p&gt;
&lt;p&gt;
        Now from good old &lt;a href=&quot;https://developers.google.com/maps/documentation/directions/?hl=en&quot;&gt;Google Directions API&lt;/a&gt;, I can find out for each route how long you're going to spending in a given region. And from that I can simply add up the total number of crimes that will happen in an area during the time that you will be there. I repeat that for all the areas that you will pass through on your route and that's the total number of crimes that will happen in your vicinity during your trip.
    &lt;/p&gt;
&lt;h6&gt;So you present some big number of crimes?&lt;/h6&gt;
&lt;p&gt;
        Surprisingly no. The number of crimes is actually pretty darn small, so I present a relatively tiny &lt;a href=&quot;https://en.wikipedia.org/wiki/Probability&quot;&gt;probability&lt;/a&gt; of a crime occurring, in the form of classic &lt;a href=&quot;https://en.wikipedia.org/wiki/Odds&quot;&gt;betting odds&lt;/a&gt;. &lt;h6&gt;And you're satisfied with that?&lt;/h6&gt;
&lt;p&gt;
            Actually I'm pretty disappointed with the final result because there's a huge half of the story missing. To really present how likely a crime is to happen to &lt;strong&gt;you&lt;/strong&gt;, I need to know how many people are on the street when a crime occurs. That means I need to have some idea about street traffic, which is harder to find than you'd think. This is my quiet plea for somebody to make that data available somewhere.
        &lt;/p&gt;
&lt;h6&gt;Where did you get that data?&lt;/h6&gt;
&lt;p&gt;
            Since 2000, the city of Chicago has been tracking all of their criminal activity using their &lt;a href=&quot;https://portal.chicagopolice.org/portal/page/portal/ClearPath/Online%20Services/ICLEAR&quot;&gt;CLEAR database&lt;/a&gt;. The majority of the data on crime type and location has been &lt;a href=&quot;https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2&quot;&gt;put online&lt;/a&gt; to allow the public to have open access to it. This has been used in &lt;a href=&quot;http://blog.spotcrime.com/2015/07/impacts-of-open-crime-data.html&quot;&gt;other projects&lt;/a&gt; to &lt;a href=&quot;http://chicagocrimeviewer.roosdesignconsulting.com/&quot;&gt;visualize local crime maps&lt;/a&gt;, &lt;a href=&quot;http://&quot;&gt;report recent crimes&lt;/a&gt;, and &lt;a href=&quot;http://www.crimeinchicago.org/&quot;&gt;display other trends&lt;/a&gt;.
        &lt;/p&gt;
&lt;h6&gt;So is that it?&lt;/h6&gt;
&lt;p&gt;
            I hope not. I really want other people to pick this up and work on it so I've put it all up in a &lt;a href=&quot;https://github.com/lots-of-things/route-crime-calculator/blob/master/analysis/crime_maps_viz.ipynb&quot;&gt;GitHub project&lt;/a&gt; for someone else to run with. Anyone is free to modify it any way they want, and I'll push their mods to the original if they work. So please help and have fun.
        &lt;/p&gt;
&lt;/p&gt;</description>
        <pubDate>Mon, 14 Dec 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/12/route-crime-calculator/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/12/route-crime-calculator/</guid>
        
        <category>data science</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://2.bp.blogspot.com/-YHdCwZrollQ/Vm-K1o3JEjI/AAAAAAAAFc8/QF2LTMuCzmk/CNrF-7aWsAAqvLM.jpg%253Alarge.jpeg</image>
        <title>ARFI: A Robotic Dog</title>
        <description>&lt;p&gt;
        Over the past couple of months, me and my friends at &lt;a href=&quot;http://blog.artificechicago.org/&quot;&gt;Artifice Tech Education&lt;/a&gt; have been building our very own robot dog mascot, &lt;a href=&quot;http://blog.artificechicago.org/p/arfi-robotic-dog.html&quot;&gt;ARFI&lt;/a&gt;. He's been a lot of fun to build, and although we really don't have much in the way of &lt;a href=&quot;https://github.com/lots-of-things/arfi-the-kionoid&quot;&gt;plans&lt;/a&gt; or intricate design specs, I thought I'd share some of the production experience here. Hope you enjoy...
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-YHdCwZrollQ/Vm-K1o3JEjI/AAAAAAAAFc8/QF2LTMuCzmk/s1600/CNrF-7aWsAAqvLM.jpg%253Alarge.jpeg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Preliminary Construction&lt;/h4&gt;
&lt;p&gt;
        My friends from &lt;a href=&quot;http://blog.artificechicago.org/&quot;&gt;Artifice&lt;/a&gt; went into the machine shop with me to try to piece together the basic aluminum frame to assemble. Eventually we settled on a pretty simple design equipped with rolly chair wheels that we had lying around.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-WqTeBOAwJeU/Vm-E2LPokEI/AAAAAAAAFco/UQn7GAucpjk/s1600/CAM00224.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We brought it down to the center where Jeice had a fun time putting it together for us. He got it looking pretty slick for us.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-QIU3ijVL0BU/Vm-E2OiTHZI/AAAAAAAAFco/q_hOpUKRYzI/s1600/CAM00233.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-tnOv_k1oSuE/Vm-E2JqkGpI/AAAAAAAAFco/-vD-juIwgJQ/s1600/CAM00234.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But unfortunately, our design skills were not so clean and our little puppy ran amok and hurt himself.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/nMDIItKs4bw&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        So it was back to the workbench to figure out the next step.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The trouble with the switch&lt;/h4&gt;
&lt;p&gt;
        We quickly reworked the battery mount and made little corrections to the way the wheels worked, but our big problem was wiring up a significantly non-resistant switch to drive the motor.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-N7FfTH4S6dY/Vm-E2DPcowI/AAAAAAAAFco/cYhQeb5Wm30/s1600/CAM00251.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We finally landed on a home made (read SPARKING) relay that did the trick. Basically, we set up a motor to move a wire back and forth to touch another wire and complete the circuit. The power went straight from battery into the motor to drive it, which I'm pretty sure not how these things normally work.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-Pst_MTRrzv0/Vm-E2ELM-vI/AAAAAAAAFco/J2Y_SyxEqYY/s1600/CAM00271.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But it was functional enough to drive out to the parade the very next day.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/qdMcYOVm-uo&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;h4&gt;The final touches&lt;/h4&gt;
&lt;p&gt;
        Now that he was running, I decided to bring him in for other people to help us make a little more... dog-like. I'll admit that the kids were teasing me for thinking that this robot was anything like a dog.
    &lt;/p&gt;
&lt;p&gt;
        I brought him into the Science Hack Day at the Adler planetarium to see who would help me out. Fortunately, quite a few people came around and helped me throw together an exterior for the boy. I thought he looked quite cute by the end.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-c-3T0Nyr8Ow/Vm-E2PnJE0I/AAAAAAAAFco/Un-Rx84FKuM/s1600/CAM00296.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-DKXzUk3slyE/Vm-E2FSTokI/AAAAAAAAFco/YCIzkQr1_uA/s1600/CAM00298.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And of course, the most fun is always getting to drive him around!
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/jEU99vibnBg&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
</description>
        <pubDate>Mon, 14 Dec 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/12/arfi-robotic-dog/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/12/arfi-robotic-dog/</guid>
        
        <category>electronics</category>
        
        <category>robots</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://3.bp.blogspot.com/-mroh4I9gYU0/Vlv0H3wzd-I/AAAAAAAAFZI/h4MVdNrbpOQ/IMG_20151128_123019.jpg</image>
        <title>Paper Chess Set</title>
        <description>&lt;p&gt;
        I've recently started playing chess with the students at the &lt;a href=&quot;http://blog.artificechicago.org/&quot;&gt;after-school program&lt;/a&gt; where I volunteer. It's fun, but we only have one chess set so only two students get to play at a time. Since our program is being run on such a shoestring budget, I decided I'd try to build a super economical chess set out just four pieces of paper and some hot glue.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-mroh4I9gYU0/Vlv0H3wzd-I/AAAAAAAAFZI/h4MVdNrbpOQ/s1600/IMG_20151128_123019.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I found an &lt;a href=&quot;http://www.josephwu.com/Files/PDF/chess.pdf&quot;&gt;origami chess set&lt;/a&gt; online, but decided that it just didn't look like the actual chess pieces. After a little exploring, I came up with this set, which I think more closely resembles the &quot;classic&quot; chess look-and-feel. It's not exactly origami, but below I've described the step-by-step instructions for each piece. Enjoy.
    &lt;/p&gt;
&lt;h4&gt;Cutting the paper&lt;/h4&gt;
&lt;p&gt;
        The 16 pieces all start from square slips of paper of varying sizes that are all cut from basic 8½&quot; x 11&quot;. To make the king and queen you use a square with sides equal to half the width of a sheet of paper. The pawns are made from 1/4 page width and all the other pieces come from 1/3 page width squares.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-IaXydEjCz2w/VlvmF3eo2JI/AAAAAAAAFXg/TQjpp_Dcykg/s1600/IMG_20151123_222958.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Pawn&lt;/h4&gt;
&lt;p&gt;
        We'll start with the easiest one. All the pieces start by being rolled into a cone and fixed with hot glue. For the pawns we'll use the smallest squares.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-wRl_-9joldQ/Vlvmey0tk8I/AAAAAAAAFXk/Nw8I0dU-zck/s1600/IMG_20151123_223103.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Next the open end is folded inside to make the base even. You can try different methods with this and keep going until you have the desired flatness and height.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-jVVKdZB1y8Q/Vlvme54KnUI/AAAAAAAAFXk/kXvp1U54lrg/s1600/IMG_20151123_223300.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And finally, for the pawn, I just crush the pointy tip down using a pen.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-IpVy-YfAG2I/Vlvme4ACgoI/AAAAAAAAFXk/qd2sjJK8d08/s1600/IMG_20151123_223213.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;

&lt;p&gt;
    This leaves a simple rounded cone piece perfect for the boring army of pawns.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-Qwi-hppiYGc/VlvoET24_aI/AAAAAAAAFX4/HET5a5bM76o/s1600/IMG_20151123_224637.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Bishop&lt;/h4&gt;
&lt;p&gt;
    The next simplest piece is probably the bishop. You start by making a curved cut along the corner of the paper that will become the tip of the cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-NicIR13ECOU/VlvqMLi6lYI/AAAAAAAAFYI/gIqYdlvT84g/s1600/IMG_20151123_225738.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Then you roll the lower part into a cone with a narrow diameter and then the top part into a cone with a slightly wider diameter.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-pWAW9CjNRfc/VlvqMFi6ytI/AAAAAAAAFYI/GLIoStX-nfk/s1600/IMG_20151123_230054.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Then I crush down the upper cone with the pen like before and cut a little upward facing slit.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-un6rnJtRU7w/VlvqMMJjJBI/AAAAAAAAFYI/6izmauyDq-k/s1600/IMG_20151123_230225.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    And now you have a little bishop to watch over the army of pawns.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-4XEhGOChZJM/VlvqMPUTVcI/AAAAAAAAFYI/uuDsp4fmInU/s1600/IMG_20151123_230455.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Rook&lt;/h4&gt;
&lt;p&gt;
    The rook is a little harder and I'm still not sure how to dimension it right. I start by snipping the square into two rectangles with one a bit wider than the other.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-oTwUMaX7GzA/VlvsgRVXtZI/AAAAAAAAFYU/z2VQOtf6jIo/s1600/IMG_20151124_224331.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The wider one is twisted into a cone with hole in the top and glued together. The base has the long parts tucked under just like for the pawn and bishop.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-gn2oz4Wd3AU/VlvsgeEADnI/AAAAAAAAFYU/Lwyl1eEC5Dc/s1600/IMG_20151124_224358.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The narrower one has the edges folded over and then it gets glued into a little ring.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-qN4e8RJo5eA/VlvsgVajWEI/AAAAAAAAFYU/aBWpgH8snsI/s1600/IMG_20151124_224641.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    You glue the ring onto the cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-TOE_oYF-DaE/VlvsgXW0sYI/AAAAAAAAFYU/9U59hysUzuM/s1600/IMG_20151124_224801.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    And after cutting little notches along the top side of the ring, we have a little outpost.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-l_Kyf8bAwSE/VlvsmCrG9GI/AAAAAAAAFYc/M_CknM8-syQ/s1600/IMG_20151124_224857.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Knight&lt;/h4&gt;
&lt;p&gt;
    The knight was a tough one to figure, but I'm glad it turned out pretty cute. You start by making basically a larger version of the pawn, and then you cut halfway through the top part of the cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-glYc3T7dU5c/VlvvQVOyVGI/AAAAAAAAFYw/VJ8InoAZb8s/s1600/IMG_20151127_205558.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Next, my girlfriend came up with the idea to cut the little ears out like this.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-p1mTZMNuBQs/VlvuuD_56rI/AAAAAAAAFYo/uGZraIeMpp8/s1600/IMG_20151127_210049.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally you glue the hole in the base back together, and there's a cute little horsey.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-50jYVAjfIZM/VlvuuCva5vI/AAAAAAAAFYo/cmWxWd2OW_U/s1600/IMG_20151127_210227.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Queen and King&lt;/h4&gt;
&lt;p&gt;
    The queen and king are very similar except for the piece you put on top. They both start with the largest squares of paper. Again they are rolled into cones, but now the long part at the bottom is cut off to be used for the top.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-0Wb2kIhqPHw/Vlvw3gu7wvI/AAAAAAAAFY8/dnI6-82wlv8/s1600/IMG_20151128_121019.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The top of the cone is also cut off, inverted and stuck back into the top hole. I also changed the diameter of that part of the cone, but I'm not sure that's necessary.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-9A0CL64eHMY/Vlvw3nP1qcI/AAAAAAAAFY8/yYy4vtMUI1k/s1600/IMG_20151128_121132.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    For the queen, the extra piece is turned into a tiny little yamuka that gets inserted into the top cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-l9Ra67p5WEU/Vlvw3gJ3zaI/AAAAAAAAFY8/_5b1mzC7oR4/s1600/IMG_20151128_121350.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The king's topper has a little cross cut into it and then it's rolled into a cone. You have to trim the cone so that it fits on the top right without too much overhang.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-T37ILCsa1FE/Vlvw3gQNdRI/AAAAAAAAFY8/VSAPilRXIbk/s1600/IMG_20151128_122403.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Next steps&lt;/h4&gt;
&lt;p&gt;
    This is a fun way to make the pieces, but I still need a chessboard. I'm thinking that with the leftover paper I should be able to make the black and white squares to mount onto something else.
&lt;/p&gt;
&lt;p&gt;
    I can't wait to make the other half and start using this. With a cheap chess set like this, I'll never be without the game again!
&lt;/p&gt;</description>
        <pubDate>Sun, 29 Nov 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/11/paper-chess-set/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/11/paper-chess-set/</guid>
        
        <category>art</category>
        
        <category>games</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://2.bp.blogspot.com/-sCw0KnIFbjc/Vc07qYWEjxI/AAAAAAAAEWU/ALv1aEL2tsM/CAM00277.jpg</image>
        <title>Power Analysis of an Indoor Water Fountain</title>
        <description>&lt;p&gt;
        Craving tranquil water splashing in your tiny apartment? You can have a relaxing fountain for under $10 if you have an old phone charger lying around.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-sCw0KnIFbjc/Vc07qYWEjxI/AAAAAAAAEWU/ALv1aEL2tsM/s1600/CAM00277.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Simple setup&lt;/h4&gt;
&lt;p&gt;
        The majority of the work is done by this cheap little &lt;a href=&quot;http://www.amazon.com/Andoer-Ultra-quiet-DC12V-Brushless-Submersible/dp/B00LUL3F5K&quot;&gt;$6 pump&lt;/a&gt; that I got from Amazon. I just barely submerged the input under the water's surface and left the output facing up out of the water.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-7w6vyFkv1GI/Vc06CQHr12I/AAAAAAAAEVw/jjFs7svqQmE/s1600/CAM00275.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Powering it was incredibly easy. I just stripped and connected the red and black wires from my power supply to those on the pump. I had a spare switch too so I added it, but that isn't necessary if you're willing to plug it in when you want it on.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-aDcqIxhVBho/Vc06k_TapCI/AAAAAAAAEWA/MexiFx3U8r8/s1600/CAM00282.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I added an assortment of rocks and a friend's ceramic frog to a $2 flower pot base and filled it with water. I tilted the fountain a bit so that it would fling the water over the rocks in a little arc and the fountain was finished.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe align=&quot;middle&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/V5ysWrSF9xg&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;h4&gt;Power comparison&lt;/h4&gt;
&lt;p&gt;
        The fountain is lovely and cute and all, but as a quick side note, I was curious just how much that little guy was really going to cost me in power. Specifically, I wanted to compare the power consumption of natural noise generation to that of synthetic noise from a speaker. My back-of-the-envelope analysis is a little sloppy so please correct me in the comments if you see a mistake.
    &lt;/p&gt;
&lt;p&gt;
        At 5 Volts, that motor was pulling 2 Watts of power. Since electricity costs about $0.08/kWh, I'm estimating that it'll cost me one penny in electricity every 2.5 days or about $1.50 per year. Meanwhile my radio pulls about 5 Watts so that'll cost me roughly $3.75 per year.
    &lt;/p&gt;
&lt;p&gt;
        Both numbers are pretty small when you think about it, but I'm glad that the natural sound appears to be a better deal. Additionally, this will become less of a concern eventually because I'm hoping to replace the power supply with a solar cell. But then, I'll have to factor in the solar panel cost as well. (Not to mention that the fountain will only run in the daytime.)
    &lt;/p&gt;
&lt;h4&gt;Pump Lifetime&lt;/h4&gt;
&lt;p&gt;
        When the pump finally breaks down, I'll update this post with approximate usage statistics to let you all know the life cycle cost of this guy. Of course, the pump will almost certainly break down before an audio speaker would, but then again, that means I get to build something even better next time!
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Thu, 13 Aug 2015 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2015/08/power-analysis-of-indoor-water-fountain/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/08/power-analysis-of-indoor-water-fountain/</guid>
        
        <category>misc</category>
        
        <category>energy</category>
        
        <category>analysis</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://2.bp.blogspot.com/-XGwAxKreBtw/VbWKR9SptdI/AAAAAAAAEHU/FgdjpgyQkKM/CAM00240.jpg</image>
        <title>The Barbie Hadoop Cluster (Multi-Node Cluster)</title>
        <description>&lt;p&gt;
        I've finally finished the Barbie Hadoop Cluster! It's been several months since I &lt;a href=&quot;/2015/01/the-barbie-hadoop-cluster-stage-1.html&quot;&gt;started the project&lt;/a&gt;, but after the hiatus I was ready to come back and get it finished.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-XGwAxKreBtw/VbWKR9SptdI/AAAAAAAAEHU/FgdjpgyQkKM/s1600/CAM00240.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Due to space limitations in our apartment, the stack of 9 Dell PCs is also being used as a TV/monitor stand. They're connected through a switch and all the extra ports on my roouter at the moment. Hopefully at &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;her permanent home&lt;/a&gt;, Barbie will look a little more at ease.
    &lt;/p&gt;
&lt;h4&gt;Setting Barbie Up&lt;/h4&gt;
&lt;p&gt;
        The beginning of the procedure for the setup is basically exactly the same as I described in my &lt;a href=&quot;http://www.makeloft.org/2015/01/the-barbie-hadoop-cluster-stage-1.html&quot;&gt;previous post&lt;/a&gt;, except for a change in the configuration files in the &lt;a href=&quot;https://github.com/lots-of-things/hadoop-compiled&quot;&gt;associated github project&lt;/a&gt;. Pretty much the entirety of the hadoop setup on each computer was accomplished simply with the folowing command.&lt;p&gt;
&lt;pre&gt;&lt;br/&gt;sudo git clone https://github.com/lots-of-things/hadoop-compiled.git /usr/local/hadoop&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                This is followed by changing permissions and adding a few directories to the $PATH by modifiying .bashrc.&lt;p&gt;
&lt;pre&gt;&lt;br/&gt;sudo chown -R doopy:hadoop /usr/local/hadoop&lt;br/&gt;cat /usr/local/addToBash &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                        This had to be done on each of the seven working machines. They each had different RAM and hard disk amounts, with skipper and stacie being the best and barbie and ken being the worst.
                    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-qNgeAOJanSY/VbWUclEdoeI/AAAAAAAAEHw/WLnnP2yBb70/s1600/CAM00241.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                        I changed the /etc/hosts on every machine so that each machine could recognize each other by name.
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;10.0.0.9        barbie&lt;br/&gt;10.0.0.10       kelly&lt;br/&gt;10.0.0.13       skipper&lt;br/&gt;10.0.0.14       stacie&lt;br/&gt;10.0.0.16       ken&lt;br/&gt;10.0.0.17       christie&lt;br/&gt;10.0.0.18       midge&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                        I decided to make skipper the master, Each machine needs to let the master connect by ssh without a password so I copied Skipper's rsa key made in the initial setup using
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;ssh-copy-id -i ~/.ssh/id_rsa.pub remote-host&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                        Where remote-host had to be changed to every machine I wanted to connect to. Finally, skipper's slaves file (etc/hadoop/slaves) needed to have each machine added to it (including herself so she would do some work too instead of just running as the NameNode).
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;barbie&lt;br/&gt;kelly&lt;br/&gt;skipper&lt;br/&gt;stacie&lt;br/&gt;ken&lt;br/&gt;christie&lt;br/&gt;midge&lt;br/&gt;&lt;/pre&gt;
&lt;h4&gt;In all honesty...&lt;/h4&gt;
&lt;p&gt;
                        I screwed this up about a dozen times before getting it to work, but every mistake was something well-documented with solutions on the web. The best trick I learned was to delete the datanode temporary file on each machine whenever I screwed things up. In my setup that would be done like this.
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;rm -r /usr/local/hadoop/datanode&lt;br/&gt;&lt;/pre&gt;
&lt;h4&gt;And Finally&lt;/h4&gt;
&lt;p&gt;
                        I was finally able to load a few documents into the hdfs and run the wordcount on them across all machines. Overall, I feel extremely satisfied getting this done finally (though I've got a much more &lt;a href=&quot;http://spark.apache.org/&quot;&gt;sophisticated system&lt;/a&gt; at my disposal at the cluster &lt;a href=&quot;https://rcc.uchicago.edu/&quot;&gt;where I work&lt;/a&gt;). Now I'm just getting ready to try it out on one of my pet projects!
                    &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;</description>
        <pubDate>Sun, 26 Jul 2015 00:00:00 -0500</pubDate>
        <link>https://opus.stedden.org/2015/07/the-barbie-hadoop-cluster-multi-node/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/07/the-barbie-hadoop-cluster-multi-node/</guid>
        
        <category>data science</category>
        
        <category>infra</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttps://i.ytimg.com/vi/7lXQL_aAJZs/default.jpg</image>
        <title>RASER Week 9: Laser activated trip wire</title>
        <description>&lt;p&gt;
        After last week's success with the physical trip wires, it's time to move on to some serious spy trip wire technology: LASERS!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.geeky-gadgets.com/wp-content/uploads/2014/09/Laser-Tripwire.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This project combines some of the tricks we've already learned as well as introducing a new concept called &lt;a href=&quot;http://arduino.cc/en/Tutorial/AnalogInput&quot;&gt;analog input&lt;/a&gt;. Check out the finished product in action in this video. Warning: the buzzer is a little loud and annoying so maybe turn your sound down before you play it.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/7lXQL_aAJZs?rel=0&quot; width=&quot;640&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;h4&gt;Connecting the light sensor&lt;/h4&gt;
&lt;p&gt;
        The first step is to hook up the light sensor so we can see how analog voltage works. The circuit takes electricity from the 5V pin and runs it through the light sensor into pin A0. There's also another resistor between pin A0 and GND. This basic circuit is called a voltage divider, and the schematic looks like this.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://learn.adafruit.com/system/assets/assets/000/000/458/medium800/light_cdsanasch.gif?1396763210&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We''l learn more about how the voltage divider is working later, but for now just try to hook it up like in this picture.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-rlKS01_B5YU/VP0vC2TV4UI/AAAAAAAAC08/xppnNLcbguo/s1600/CAM00051.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Upload the &lt;a href=&quot;http://arduino.cc/en/Tutorial/ReadAnalogVoltage&quot;&gt;ReadAnalogVoltage&lt;/a&gt; code to the Arduino and open the Serial Monitor to see what voltage is being read on pin A0.
    &lt;/p&gt;
&lt;p&gt;
        Now, wave your hand above the sensor. Do you notice the voltage value changing on the Serial Monitor? The analog input pins let you measure how much light is shining on the sensor.
    &lt;/p&gt;
&lt;h4&gt;Understanding Analog Input&lt;/h4&gt;
&lt;p&gt;
        In the past weeks, we've focused solely on digital inputs. Digital inputs tell you whether there is at least a certain amount voltage on the pin. The cutoff is normally somewhere around 2 volts. If you hook up any voltage higher than that, the Arduino will view the pin as ON (or HIGH).
    &lt;/p&gt;
&lt;p&gt;
        Analog works differently. With analog input, the value of the voltage is read into the Arduino. So if you hook up 2 volts, the Arduino will read 2 volts. And if you hook up 1.67 volts, the Arduino will read 1.67.
    &lt;/p&gt;
&lt;p&gt;
        This is really useful when you have a sensor like the one we're using. The analog input lets us measure continuous changes in the reading on the sensor. So when the light level changes a little bit, the voltage also changes by a little bit. Therefore, we can use the Arduino to measure subtler changes than we could with digital input.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h5&gt;The Voltage Divider Circuit&lt;/h5&gt;
&lt;p&gt;
        Here's a little conundrum: The Arduino pins measure voltages, but our sensor doesn't actually produce any voltage itself. Instead the sensor changes its resistance when light shines on it.
    &lt;/p&gt;
&lt;p&gt;
        To convert this change in resistance into a change in voltage, we use a simple circuit called a &lt;a href=&quot;http://en.wikipedia.org/wiki/Voltage_divider&quot;&gt;voltage divider&lt;/a&gt;. This circuit is specially designed to cause a change in resistance to trigger a change in the voltage at the midpoint of the circuit. We'll use this circuit repeatedly whenever we need a sensor so it's important to remember how it works.
    &lt;/p&gt;
&lt;h4&gt;Blinking LED Trip Wire&lt;/h4&gt;
&lt;p&gt;
        Now we have the sensor controlling the voltage on pin A0. Next, we want to use the voltage input to control whether an LED will go off. Start by hooking up an LED to pin 13 just like we did for the old physical trip wire.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-SFKge6VMBLk/VP0vZiUdd3I/AAAAAAAAC1I/c5znRWrGcXc/s1600/CAM00055.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We'll use almost the same code that we used in the physical trip wire from last week. We'll need to modify it so that instead of asking whether there is any voltage on the digital pin, we're going to ask HOW MUCH voltage is coming in on the analog pin..
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int sensorValue = analogRead(A0);&lt;br/&gt;  float voltage = sensorValue * (5.0 / 1023.0);&lt;br/&gt;  Serial.println(voltage);&lt;br/&gt;&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;if(voltage &amp;lt; _______)&lt;/strong&gt;{&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;  }&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Above is the code we'll need to make it work. BUT, I've left one spot blank. That's the place where we have to decide what the threshold voltage should be. To figure out what the value should be, point the laser at the light sensor and look at the numbers being printed in the Serial Monitor. You want the threshold to be somewhere between the voltage when the laser is shining and the voltage when the laser is off.
    &lt;/p&gt;
&lt;p&gt;
        After you upload the code, the LED should blink until you point a laser pointer at it. Then if at any point someone steps in the way, the voltage will change so that the blinking LED loop will get triggered. And that's a trip wire!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-xr_aqwD2wF4/VP0vjAz_T5I/AAAAAAAAC1Q/de3UPEWnqzA/s1600/CAM00060.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Bonus round! Adding the buzzer&lt;/h4&gt;
&lt;p&gt;
        What we have now is called a silent alarm. It activates a light but doesn't sound an alarm to catch your attention.
    &lt;/p&gt;
&lt;p&gt;
        To bring the alarm to the next level, I also added a buzzer that goes off when the LED goes off. You can use this code and &lt;a href=&quot;http://arduino.cc/en/Tutorial/Tone&quot;&gt;hook up a speaker&lt;/a&gt; to make it work. I've just added a single line that controls a tone emitted on pin 8.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;    &lt;strong style=&quot;color:red&quot;&gt;tone(8,600,3000);&lt;/strong&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        See if you can figure out where to put this line of code to make the buzzer go off when the LED blinks
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-srwecgVc4Jw/VP0vqm05P4I/AAAAAAAAC1c/UDnOd0jvvSY/s1600/CAM00059.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In the end, the completed laser trip wire will look like this. Now have some fun catching intruders!
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 08 Mar 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/03/week-9-laser-activated-trip-wire/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/03/week-9-laser-activated-trip-wire/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org</image>
        <title>RASER Week 8: Arduino trip wire</title>
        <description>&lt;p&gt;
        Today's project is a challenge to build a trip wire. The challenge builds on the Arduino input and output skills we put into practice last week. All we have to do is slightly adapt last weeks PushButton project.
    &lt;/p&gt;
&lt;h4&gt;Installing the tripwire&lt;/h4&gt;
&lt;p&gt;
        The trip wire is nothing more than a long wire that acts just like a button. Remember that a button is just a part of the circuit that can either be connected or not.
    &lt;/p&gt;
&lt;p&gt;
        So when we build our trip wire all we have to do is replace the button with the long loop of wire. The trip wire goes into the circuit exactly where the button went before.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Adapting the pushbutton code&lt;/h4&gt;
&lt;p&gt;
        The only major difference between our push button and the trip wire is that the trip wire should activate when the circuit isn't complete. So the logic that made the LEDs blink is backwards from what it was before.
    &lt;/p&gt;
&lt;p&gt;
        To fix the code we just have to make one change so that &lt;strong&gt;if&lt;/strong&gt; statement only activates when the circuit voltage is 0. If you change the code like this, the if statement will be off until the digitalRead on pin 2 says 0.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;// digital pin 2 has a pushbutton attached to it. Give it a name:&lt;br/&gt;int pushButton = 2;&lt;br/&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  // make the pushbutton's pin an input:&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  //if the buttonState is 1, make the LEDs blink 4 times&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;if(buttonState==0)&lt;/strong&gt;{&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;  }&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Now the trip wire should work how we want it.
    &lt;/p&gt;
&lt;h4&gt;Obstacle course&lt;/h4&gt;
&lt;br/&gt;

&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sat, 07 Mar 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/03/raser-week-8-arduino-trip-wire/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/03/raser-week-8-arduino-trip-wire/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://www.explainxkcd.com/wiki/images/e/e5/is_it_worth_the_time.png</image>
        <title>Procrastinating with a Time Optimization Game</title>
        <description>&lt;p&gt;
    I've got to admit, I'm majorly busy at this time of year. But today, I'm deciding to procrastinate by writing a post on—ironically enough—a game about &lt;a href=&quot;http://xkcd.com/1205/&quot;&gt;optimizing your use of time&lt;/a&gt;!
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.explainxkcd.com/wiki/images/e/e5/is_it_worth_the_time.png&quot; title=&quot; &quot; /&gt;
&lt;br /&gt;
&lt;h4&gt;The Background&lt;/h4&gt;
&lt;p&gt;
    If you've ever participated in an &lt;a href=&quot;http://en.wikipedia.org/wiki/Behavioral_economics&quot;&gt;economics research study&lt;/a&gt;, you've probably had the pleasure of participating in a &quot;computerized experiment.&quot; These are pretty much just silly games that you play for a little while so the researchers can &quot;measure&quot; your behavior.
&lt;/p&gt;
&lt;p&gt;
    Recently, I played a game that asked me to choose between two tasks in order to maximize the payoff (I'll give more details below). I did pretty well at making a gut decision on which one to choose during the game, but I knew that there had to be some way to figure out the optimum choice. So afterwards, I decided to analyze the game a little more and find out how to explain it mathematically.
&lt;/p&gt;
&lt;br /&gt;
&lt;h4&gt;The Game Premise&lt;/h4&gt;
&lt;p&gt;
    Imagine you spend your work dividing your time between two tasks. One of them is an easy task that takes 1 minute, and the other is a hard task that takes 2 minutes.
&lt;/p&gt;
&lt;p&gt;
    For the easy task, you're always offered $1, while for the hard task you get offered a different amount between $1 and $5.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, whether you pick the easy task or the hard one, you aren't guaranteed to get paid every time. You're told the probability that you'll get paid before you decide which task to take. For simplicity we'll just say the chances of getting paid are 33%, 66%, or 100%.
&lt;/p&gt;
&lt;p&gt;
    So the challenge is to decide whether you want to waste your time on the hard task given the offered payout and the probability of getting payed.
&lt;/p&gt;
&lt;h4&gt;Sample Game&lt;/h4&gt;
&lt;p&gt;
    To make the game more clear, I built a &lt;a href=&quot;http://codepen.io/wmcfadd2/full/Joppjg/&quot;&gt;sample game&lt;/a&gt; in javascript on CodePen. The objective is to make the most money you can before you use up all your time.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/--uoEYazVJfg/VN-hM5Q3_5I/AAAAAAAACnE/BUaxRFWnzVM/s1600/Screen%2BShot%2B2015-02-14%2Bat%2B1.24.08%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    Before we look at the answer you should give the game a shot. &lt;a href=&quot;http://codepen.io/wmcfadd2/full/Joppjg/&quot;&gt;Try it out&lt;/a&gt;.
&lt;/p&gt;
&lt;h4&gt;Trying to find a general solution&lt;/h4&gt;
&lt;p&gt;
    After playing around for a few minutes you'll probably get the idea of how best to win. It makes sense to only take the hard task when you have a chance of getting more than $2. The real trick though is that sometimes, even though you might make more, the odds that you'll win are so low that you shouldn't waste your time on the hard task.
&lt;/p&gt;
&lt;p&gt;
    My original rule of thumb was to take the hard task only when the expected value of the hard task (i.e. offered payout * chance of winning) was higher than $2. My logic was just that I should only waste my time when I have a reasonable chance of getting the higher payout.
&lt;/p&gt;
&lt;p&gt;
    But I was pretty sure there must be a more solid way to figure out what the cutoff offer should be. And I wasn't going to rest until I found it.
&lt;/p&gt;
&lt;h4&gt;Simulate it!&lt;/h4&gt;
&lt;p&gt;
    I needed to get a better understanding of what would happen given a cutoff dollar value above which I'd take the hard task. Of course, I didn't want to have to play the game over and over again just to find out the outcome. Instead, I wrote a &lt;a href=&quot;http://en.wikipedia.org/wiki/Computer_simulation&quot;&gt;simulation&lt;/a&gt; of the game in &lt;a href=&quot;http://www.mathworks.com/products/matlab/&quot;&gt;MATLAB&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    I've got the functional &lt;a href=&quot;https://github.com/lots-of-things/task-game/blob/master/taskgame_sim.m&quot;&gt;simulation code&lt;/a&gt; on GitHub. It looks complicated, but it's basically just a loop that picks one probability (33%, 66%, or 100%) and then picks the corresponding &quot;choice&quot; threshold. Then it just simulates the game by offering a random value and letting the &quot;choice&quot; decide whether the offer is accepted. It adds up winnings and time according to the choice and the outcome.
&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;

winnings = 0;
i = 1;
t = 0;
while (t&amp;lt;totaltime)
  index = unidrnd(length(probabilities));
  p = probabilities(index);
  c = choices(index);
  offer = unifrnd(minval, maxval);
  if(unifrnd(0, 1)&amp;lt;p)
    if(offer&amp;gt;c)
      winnings = winnings+offer;
      t = t+hardT;
    else
      winnings = winnings+minval;
      t = t+easyT;
    end
  else
    if(offer&amp;gt;c)
      t = t+hardT;
    else
      t = t+easyT;
    end
  end
end


&lt;/pre&gt;
&lt;p&gt;
    With this simulation I was able to graph the winnings as a function of each choice threshold. It's tough to visualize all three dimensions at once, but here I've plotted the winnings as a function of two of the choice thresholds.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-bgJF7Tjvk4M/VOJI8HRV3JI/AAAAAAAACtg/t3J2aM1ArZM/s1600/payoff_sim.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    You can kind of see that the maximum return takes place with these two thresholds set somewhere around $2 and $3. But still, there should be a way to describe this mathematically so that I can get a nice clean number to set as the threshold.
&lt;/p&gt;
&lt;h4&gt;Deriving a solution&lt;/h4&gt;
&lt;p&gt;
    Using the intuition I got from the simulation, I wanted to work out a mathematical formula that would predict the average payout for a given set of choice thresholds.
&lt;/p&gt;
&lt;p&gt;
    The outcome is just the product of the number of rounds you play times the average winnings for each round. The average winnings is obviously a function of the choice thresholds because that's what determines whether you take the easy or hard task.
&lt;/p&gt;
&lt;p&gt;
    What makes it more interesting is that the number of rounds you play is also a function of your choice thresholds. The lower your choice threshold, the more hard tasks you'll try, meaning you'll get fewer rounds before the time runs up.
&lt;/p&gt;
&lt;p&gt;
    So I basically needed a formula that would take those two things into account. I can't go through all of my reasoning because it would be sooooo tedious, but I'll break it down in a few math steps.
&lt;/p&gt;
&lt;p&gt;
    To get started we know that the total winnings is just going to be the sum of the winnings from the easy rounds and the winnings from the hard rounds.
&lt;/p&gt;
&lt;p lang=&quot;latex&quot; &gt;W_{tot} = f_e\frac{T}{t_e}w_e + f_h\frac{T}{t_h}w_h &lt;/p&gt;
&lt;p&gt;
    We know the total time, &lt;span lang=&quot;latex&quot;&gt;T&lt;/span&gt;, and the time it takes for the hard and easy tasks, &lt;span lang=&quot;latex&quot;&gt;t_e, t_h&lt;/span&gt;. So we just need to figure out the fraction of the time spent on the hard and easy tasks (&lt;span lang=&quot;latex&quot;&gt;f_e,f_h&lt;/span&gt;) and the average amount you'd win for both (&lt;span lang=&quot;latex&quot;&gt;w_e,w_h&lt;/span&gt;).
&lt;/p&gt;
&lt;p&gt;
    I'm going to leave that part up as an exercise for the reader, but after a little head scratching I was able to figure it out. The solution looks like this
&lt;/p&gt;
&lt;p lang=&quot;latex&quot; style=&quot;text-align:center;&quot;&gt;W_{tot} = \frac{T}{t_e}\left ( 1 - \frac{1}{1+\tfrac{O_{max}-O_{min}}{O_{max}-\bar c}\tfrac{t_e}{t_h-t_e}}\right )w_{avg} &lt;/p&gt;
&lt;p&gt;
    For the new variables, &lt;span lang=&quot;latex&quot;&gt;O_{max}&lt;/span&gt;and&lt;span lang=&quot;latex&quot;&gt;O_{min}&lt;/span&gt; are the max and min offers, &lt;span lang=&quot;latex&quot;&gt;\bar c&lt;/span&gt; is the average value of your three choice thresholds, and &lt;span lang=&quot;latex&quot;&gt;w_{avg}&lt;/span&gt; is the average payoff for an individual turn.
&lt;/p&gt;
&lt;p lang=&quot;latex&quot; style=&quot;text-align:center;&quot;&gt;w_{avg} = \sum p_i((O_{max}-c_i)(c_i+O_{max})/2 + O_{min}(c_i-O_{min}))/(O_{max}-O_{min}) &lt;/p&gt;
&lt;p&gt;
    This ended up being really ugly by the end. To ensure that I was calculating this solution correctly, I wrote another &lt;a href=&quot;https://github.com/lots-of-things/task-game/blob/master/taskgame_estimate.m&quot;&gt;MATLAB function&lt;/a&gt; to print my predicted value just like above. To me, this is a great way to prove whether you carried out the math right. The similarity between my analytical solution and the simulated results makes me confident that I didn't make any mistakes along the way.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-TQkyDZ0Mmoo/VOJI8G_asqI/AAAAAAAACtk/Zq3vqA5kb7g/s1600/payoff_est.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    It isn't perfectly easy to see using a point cloud so I binned the data to make it more clear. From this graph, it's pretty clear that the cutoff thresholds are $2.25 for the 100% chance and $2.90 for the 66% chance.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-1Z2kuD7legs/VOJI8JewFOI/AAAAAAAACtc/PovqlwgP58k/s1600/payoff_est_max.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    We could do a little more math to write out the optimum solution, but most of the challenge is over at this point. I think I'm going to call it a night.
&lt;/p&gt;
&lt;h4&gt;What did we learn&lt;/h4&gt;
&lt;p&gt;
    Looking at simplified decision-making games is a fun way to think about how we make choices in our everyday life. Every choice offers us some risk that we've wasted our time on an uncertain reward. Maybe this blog post was just such a waste of time. But you know what, I had fun. Can you really &lt;a href=&quot;https://uk.finance.yahoo.com/news/can-you-put-a-price-on-fun-yes-310-346.html&quot;&gt;put a price&lt;/a&gt; on that?
&lt;/p&gt;
&lt;p&gt;
    By the way, if you're a social psychologist or an economist, please leave a comment. I would love to know what this game is called. There has to be some cool history behind it that I'd like to learn about.
&lt;/p&gt;
&lt;p&gt;
    As usual you can find all the code for this project on the &lt;a href=&quot;https://github.com/lots-of-things/task-game&quot;&gt;make_loft GitHub account&lt;/a&gt;, and you can find the online game on &lt;a href=&quot;http://codepen.io/wmcfadd2/pen/KwQxxy&quot;&gt;my CodePen account&lt;/a&gt;.
&lt;/p&gt;
&lt;br /&gt;
&lt;script src=&quot;https://latex.codecogs.com/latexit.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Mon, 16 Feb 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/02/procrastinating-with-time-optimization/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/02/procrastinating-with-time-optimization/</guid>
        
        <category>games</category>
        
        <category>design</category>
        
        <category>code</category>
        
        <category>analysis</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://4.bp.blogspot.com/-i9dF1aglhMc/VKi-4ipoxAI/AAAAAAAACLk/7z70tCT0MAA/LED-CIRCUIT2.png</image>
        <title>RASER Week 5 - Review Game</title>
        <description>&lt;p&gt;
        We've learned a lot so far in the RASER program by now. So to remind us about all of the things we've learned, we want to have a competition and see who remembers the most.
    &lt;/p&gt;

&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-NRtijp0yDJc/VLxzRqKl1lI/AAAAAAAACZY/2c44kU1cRQc/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Lightning Review Game&lt;/h4&gt;
&lt;p&gt;
        Below we have 6 challenges from the previous 4 weeks. The challenges are each given different numbers of points based on how tough we think they are.
    &lt;/p&gt;
&lt;p&gt;
        See if you can remember how to build each of the following:
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10 pts - Battery powered LED with resistor &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#circuit&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;25 pts - 2 Battery powered LEDs in parallel &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#twoLEDs&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;33 pts - Battery powered LED with variable resistor &lt;a href=&quot;/2015/01/raser-week-2-led-dimmers-and-switches.html#varresist&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;47 pts - Arduino powered LED &lt;a href=&quot;/2015/01/raser-week-3-arduino-led-blinker.html#ArdBat&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;53 pts - Arduino powered blinking LED &lt;a href=&quot;/2015/01/raser-week-3-arduino-led-blinker.html#blink&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;61 pts - Read Arduino Serial Input &lt;a href=&quot;/2015/01/raser-week-4-arduino-led-passcode-pad.html#justinput&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        How did you do? Can you explain how each of the circuits worked? Would you be able to explain how much current was flowing through the circuits?
    &lt;/p&gt;
&lt;p&gt;
        Hopefully, that review was helpful.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;RASER students in action!&lt;/h4&gt;
&lt;p&gt;
        The results are in for the first competition of the season. We had a strong showing from all teams, but in the end, the winners were The Chicken Nuggets and The Guys Who Are Really Good At Making Circuits And Arduinos And Stuff. (I'm sorry if I got that name wrong. It's a tough one to remember.)
    &lt;/p&gt;
&lt;p&gt;
        Here are some pictures of the students working on their projects during the competition.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-sclBEFVmQKQ/VNI515dlmPI/AAAAAAAAClc/oN1eODMkf6U/s1600/CAM00012.jpg&quot; style=&quot;max-width: 100%;&quot; title=&quot;

 &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Fri, 06 Feb 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/02/raser-week-5-review-game/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/02/raser-week-5-review-game/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://1.bp.blogspot.com/-V1PPucOh9sM/VdaBCotvrgI/AAAAAAAAEg0/_hIhIfwt6Hk/photo%2B3jan26.JPG</image>
        <title>RASER Week 6: Arduino LED Passcode Pad - Part 2</title>
        <description>&lt;p&gt;
        Two weeks ago, we started learning about one of the most important things Arduinos can do: read input voltages. We want to continue working on reading input this week and connect our input back to output LEDs.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Feeling Voltage with a Van de Graaff Generator&lt;/h4&gt;
&lt;p&gt;
        To get started on today's lesson, we want to make the point of what a voltage actually is. A great way to that is to literally feel the voltage using a Van de Graaff generator.
    &lt;/p&gt;
&lt;p&gt;
        A Van de Graaff generator is a device that builds up large amount of static electricity that can be transmitted to another person when she touches it. The build up of electricity produces a voltage difference between the person becoming charged and the rest of the Earth (called the ground).
    &lt;/p&gt;
&lt;p&gt;
        Now even if the person lets go of the generator, she still has that voltage potential built up in her. We can even measure the voltage difference using a multimeter if the voltage isn't too high.
    &lt;/p&gt;
&lt;p&gt;
        When the person then touches the ground, the voltage difference produces a current that generates a spark. The voltage is dissipated very quickly so the shock only lasts an instant. After that, the person has returned to the same voltage as ground.
    &lt;/p&gt;
&lt;p&gt;
        This is something important to learn about circuits: just because a circuit element isn't directly connected to the plus end of the battery, doesn't mean that it might not have a voltage built up on it. In order to make sure a part of the circuit is at 0 voltage, you have to connect that part of the circuit back to ground.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Using a Button To Turn on an LED&lt;/h4&gt;
&lt;p&gt;
        Next we want to continue our work with Arduino Serial Input from last week. Start by rebuilding the &lt;a href=&quot;/2015/01/raser-week-4-arduino-led-passcode-pad.html#button&quot;&gt;basic input button&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-V1PPucOh9sM/VdaBCotvrgI/AAAAAAAAEg0/_hIhIfwt6Hk/s1600/photo%2B3jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When that's done we can start adding to the code to use the input voltage on pin 2 to control the output voltage on pin 13. Try modifying the code to look like this:
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;int pushButton = 2;&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;int led = 13;&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;pinMode(led, OUTPUT);&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;digitalWrite(led1,buttonState);&lt;/strong&gt;&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        &lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The red lines in this code are used to control the LED. The first two parts are just like from the LED Blink program. The last line performs a &lt;strong&gt;digitalWrite&lt;/strong&gt; using the state of the button that we read in from &lt;strong&gt;digitalRead&lt;/strong&gt;. This makes it so that the LED will only light up when the button is pushed.
    &lt;/p&gt;
&lt;p&gt;
        To make this work, we just need to add an LED to pin 13 like we did back in the LED Blink Program from Week 3.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-V6dZ6bjO-s0/VdaCUUS7NjI/AAAAAAAAEhE/iftc9x4kFNQ/s1600/photojan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And whenevever we push the button down we should see the LED light up. Give it a try. Remember that we aren't controlling the LED's voltage directly. We're controlling the Arduino, and the Arduino is controlling the LED.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Hooking up multiple LED Buttons&lt;/h4&gt;
&lt;p&gt;
        To really take advantage of the Arduino's inputs, we can hook up multiple LEDs and have them interact with our button in different ways.
    &lt;/p&gt;
&lt;p&gt;
        As a simple example, try making the following changes to your code.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;// digital pin 2 has a pushbutton attached to it. Give it a name:&lt;br/&gt;int pushButton = 2;&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  // make the pushbutton's pin an input:&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;/strong&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  // print out the state of the button:&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;  digitalWrite(led1,buttonState);&lt;br/&gt;  digitalWrite(led2,1-buttonState);&lt;/strong&gt;&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        This will cause the two buttons to perform the opposite actions. The line &lt;blockquote&gt;&lt;strong style=&quot;color:red&quot;&gt;digitalWrite(led2,1-buttonState);&lt;/strong&gt;&lt;/blockquote&gt; will print the opposite of the buttonState (1-buttonState) to led2.
    &lt;/p&gt;
&lt;p&gt;
        Next we just have to hook up another LED to pin 12. If you use red and green LEDs, this will result in a red light-green light, like a traffic signal.
    &lt;/p&gt;
&lt;p&gt;
        You can also try messing around with delays to change how each LEDs are controlled. Experiment a little to see what you can do to control the LEDs differently.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The button triggered blink attack!&lt;/h4&gt;
&lt;p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;// digital pin 2 has a pushbutton attached to it. Give it a name:&lt;br/&gt;int pushButton = 2;&lt;br/&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  // make the pushbutton's pin an input:&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  //if the buttonState is 1, make the LEDs blink 4 times&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;if(buttonState==1){&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;  }&lt;br/&gt;  &lt;/strong&gt;&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
            This block of code introduces the IF statement. The if statement asks a question, &lt;strong style=&quot;color:red&quot;&gt;if(buttonState==1)&lt;/strong&gt;. IF the answer is true, the Arduino runs the code inside the brackets { ...}. If the answer to the question isn't true, the Arduino skips that code.
        &lt;/p&gt;
&lt;p&gt;
            So when the button is pushed, we know that the buttonState==1 (buttonState is equal to 1). This means that the LEDs will then toggle from low to high over and over again, like it says to in the code.
        &lt;/p&gt;
&lt;p&gt;
            At this point the LED is starting to listen to us and perform different tasks based on our input. This is really the first step towards unlocking all the amazing things an Arduino can do!
        &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Challenge: Build the Passcode Game&lt;/h4&gt;
&lt;p&gt;
            I used combinations of input and output skills to build the Passcode Game that I showed last week. Now I challenge you to make one work! If you want a little help trying to put it together, you can look up the code and a schematic for the game on &lt;a href=&quot;https://github.com/lots-of-things/passcode-pad&quot;&gt;my GitHub page&lt;/a&gt;. If you're feeling up for a challenge try to build it yourself from scratch using some of the tools we learned about today.
        &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sun, 01 Feb 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/02/raser-week-5-arduino-led-passcode-pad/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/02/raser-week-5-arduino-led-passcode-pad/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://learning.codasign.com/images/f/f9/Arduino_serial.png</image>
        <title>RASER Week 4: Arduino LED Passcode Pad - Part 1</title>
        <description>&lt;p&gt;
        This will be the first lesson where we really get into programming the Arduino to do something cool. The Arduino is an amazing tool for making devices that react to external inputs. In this lesson, we'll learn about how to work with both input and output by connecting buttons that can toggle LEDs on and off.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The Passcode Game&lt;/h4&gt;
&lt;p&gt;
        To see an example of what you can do with input and output on the Arduino, check out this game I built. The point is to push the buttons that make the LEDs light up in the right combination. When you push the right combination all the LEDs start blinking.
    &lt;/p&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;360&quot; src=&quot;//www.youtube.com/embed/LSY8wUgjRD8?rel=0&quot; width=&quot;640&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;
        Making this game work is a little complex, but it's doable just from the skills we'll learn today. In today's lesson, I'm going to try to explain how to use a button, and how to use the button input to turn on LEDs. At the end, I challenge you to build your own and post the results in the comments!
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4 id=&quot;justinput&quot;&gt;Measuring voltages with the Arduino&lt;/h4&gt;
&lt;p&gt;
        In this project, the important thing we're trying to get the Arduino to do is measure the voltage that's coming into a pin. To do that, we have to program the Arduino to do two things:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pay attention to a particular pin&lt;/li&gt;
&lt;li&gt;show us the whether there is a voltage on the pin&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        The Arduino comes with an example program called DigitalReadSerial that is set up to measure the voltage on pin number 2. The important part of the code looks like this.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;int pushButton = 2;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);       &lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The part at the top sets up pin number 2 to be an INPUT pin instead of an OUTPUT pin. We won't talk to much about that now, but you can read more in Arduino's &lt;a href=&quot;http://arduino.cc/en/Tutorial/DigitalReadSerial&quot;&gt;DigitalReadSerial tutorial&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The &quot;loop&quot; part at the bottom does two things.
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;blockquote&gt;int buttonState = digitalRead(pushButton)&lt;/blockquote&gt; reads what voltage is on pin 2
        &lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;Serial.println(buttonState);&lt;/blockquote&gt; prints out the value on pin 2
        &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        To see the value that pin 2 is measuring, we have to click on the Arduino Serial Monitor button in the top right.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://learning.codasign.com/images/f/f9/Arduino_serial.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When we open the Serial Monitor, we'll see a bunch of 0s or 1s printing on the screen. If we connect a wire from pin 2 to the 5 V pin, the Serial Monitor will show us 1s. If we connect a wire from pin 2 to the GND pin, the Serial Monitor will show 0. The Serial Monitor gives us a way to see if a circuit is open or closed by checking what the voltage is on any pin.
    &lt;/p&gt;
&lt;p&gt;
        (Ideally, we'd always keep a resistor on the wire between 5V and pin 2, but if we're just testing for a few seconds this will be OK.)
    &lt;/p&gt;

&lt;h4 id=&quot;button&quot;&gt;Building a Simple Button&lt;/h4&gt;
&lt;p&gt;
        The easiest way to change the voltage from 0 to 5 V is by using a button. A button is really just a switch that closes an electrical circuit. My friends Pete and Joe built these awesome paper cup buttons that keep the button at the top steady so you can connect it to the Arduino more easily.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-8r_doGqIYdY/VdaAvPVyZVI/AAAAAAAAEgk/K25Dsc_D6oM/s1600/photo%2B2jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We want to set up the circuit so that the button will connect pin 2 to the 5 V. That will cause the Serial Monitor to display 1. When the button isn't pressed, we want pin 2 to be connected to ground. To get started, we'll connect the 5 V pin to the &lt;span style=&quot;color:red&quot;&gt;plus (+)&lt;/span&gt; holes on our breadboard and connect the GND pin to the &lt;span style=&quot;color:red&quot;&gt;minus (-)&lt;/span&gt; holes.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-BkPd5RsdUoY/VdaBDcPUGfI/AAAAAAAAEg8/Wl01Zgzmr68/s1600/photo%2B1jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        After we have the 5V and the GND connected to the breadboard, we just need to set up the button to toggle between each of them. To do this we're going to set up the button. We want one lead to connect to the 5V (the plus terminals on our breadboard) and the other connects to pin 2. However, there really should be a small resistor between the button and pin 2. (I accidentally missed this in the photo. It worked, but that practice could damage the Arduino eventually.) Finally, we're going to add a resistor between pin 2 and GND as well to prevent a short circuit there too.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-V1PPucOh9sM/VdaBCotvrgI/AAAAAAAAEg0/_hIhIfwt6Hk/s1600/photo%2B3jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This might seem confusing, but we need this kind of setup to make the voltage on pin 2 to go back to GND whenever the button isn't pressed.
    &lt;/p&gt;
&lt;p&gt;
        We can draw the circuit up to show how the resistor prevents a total short circuit when the button is pressed.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.codeproject.com/KB/boards-embedded-devices/Interfacing_Arduino_LCDs/PushButtonSchematic.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We're using a more advanced kind of circuit diagram than we have before, but you should be able to study it to figure out how the electricity runs from the voltage to either pin 2 or GND.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h5&gt;Next week, we'll continue this project to show how to program the Arduino to use the input from pin 2 to make an LED light up on pin 13!&lt;/h5&gt;

&lt;br/&gt;

&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sun, 25 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/raser-week-4-arduino-led-passcode-pad/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/raser-week-4-arduino-led-passcode-pad/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://graphics8.nytimes.com/images/2012/05/17/technology/bits-Twittermask/bits-Twittermask-tmagArticle.jpg</image>
        <title>tweet_note: An unfakeable timestamp notebook</title>
        <description>&lt;img border=&quot;0&quot; src=&quot;http://graphics8.nytimes.com/images/2012/05/17/technology/bits-Twittermask/bits-Twittermask-tmagArticle.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I have a confession. I don't like tweeting that much. I always feel like I sound like an idiot. And with tweets, I run into the possibility of sounding like an idiot at a much higher rate.
    &lt;/p&gt;
&lt;p&gt;
        But... I do love the idea of keeping timestamped notes for/about myself and what I'm working on.
    &lt;/p&gt;
&lt;p&gt;
        This led me to build a twitter account that &lt;strong&gt;no one else can read&lt;/strong&gt;.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h5 style=&quot;text-align:center&quot;&gt;What did you say?&lt;/h5&gt;
&lt;br/&gt;
&lt;p&gt;
        Yes I know it seems like the exact opposite of what Twitter is about (trying to get everyone's attention, everywhere). But instead of having a separate notes app, now I can just store all my dumb thoughts right next to my public ones.
    &lt;/p&gt;
&lt;h4&gt;tweet_note.py&lt;/h4&gt;
&lt;p&gt;
        The only drawback comes from an inability to easily digest my notes in chronological order. So to fix this I built myself a little program to read in my recent tweets and turn them into a pretty little document.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-O4KLW4_G3vo/VMFpPlZp_BI/AAAAAAAACdg/2WUFNozDQSA/s1600/Screen%2BShot%2B2015-01-22%2Bat%2B3.18.23%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When I run tweet_note.py, it builds an html table to display all the tweets in the last day, reversed so the first one is at the top. I took the elegant table style from &lt;a href=&quot;http://johnsardine.com/freebies/dl-html-css/simple-little-tab/&quot;&gt;John Sardine&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        As always, &lt;a href=&quot;https://github.com/lots-of-things/tweet_note&quot;&gt;the code&lt;/a&gt; is available and free to use from my GitHub. I'd love it if somebody could hook it up to work on Google App Engine, but at the moment that's too much work for me.
    &lt;/p&gt;
&lt;h4&gt;how it works&lt;/h4&gt;
&lt;p&gt;
        It's set up similarly to my earlier &lt;a href=&quot;http://makeloft.blogspot.com/2015/01/actsofsuperness-twitter-game.html&quot;&gt;#ActsOfSuperness game&lt;/a&gt;, except that it runs using the user_timeline function of the Twitter API. And instead of writing to Google DataStore, it just has to write a local html file. All in all, it's much simpler.
    &lt;/p&gt;
&lt;p&gt;
        Check out the &lt;a href=&quot;https://github.com/lots-of-things/tweet_note/blob/master/README.md&quot;&gt;readme&lt;/a&gt; on github for more info
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Thu, 22 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/tweetnote-unfakeable-timestamp-notebook/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/tweetnote-unfakeable-timestamp-notebook/</guid>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://1.bp.blogspot.com/-9aomi0wmZTw/VMB19czVNeI/AAAAAAAACbQ/E5mgCHmcBak/barbie.png</image>
        <title>The Barbie Hadoop Cluster - Stage 1</title>
        <description>&lt;p&gt;
        Ever since I took Coursera's &lt;a href=&quot;https://www.coursera.org/course/datasci&quot;&gt;Intro to Data Science&lt;/a&gt; course, I've been dreaming of getting my own &lt;a href=&quot;http://www-01.ibm.com/software/data/infosphere/hadoop/mapreduce/&quot;&gt;MapReduce&lt;/a&gt; system up and running. It just seems so much more rewarding to have my own data framework right in front of me rather than paying for &lt;a href=&quot;http://aws.amazon.com/&quot;&gt;Amazon AWS&lt;/a&gt; or &lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google Cloud&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        Recently the &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;non-profit I volunteer for&lt;/a&gt; handed me 9 left-over recycled computers and a lot of left-over hard drives that they needed to find a home for. So while they were sitting in my house, I decided to put them to use in my dream &lt;a href=&quot;http://searchbusinessanalytics.techtarget.com/definition/Hadoop-cluster&quot;&gt;Hadoop Cluster&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        So here is my step-by-step protocol for setting up the cluster from scratch. In this post I'm going from Ubuntu install CD to Hadoop &quot;pseudo-distributed&quot; mode. In &lt;a href=&quot;#&quot;&gt;Stage 2&lt;/a&gt;, I move to a four node distributed cluster, and in &lt;a href=&quot;#&quot;&gt;Stage 3&lt;/a&gt;, I'm going to launch my own MapReduce job.
    &lt;/p&gt;
&lt;h4&gt;The Barbie Cluster&lt;/h4&gt;
&lt;p&gt;
        First off, the most important thing in sysadmin is the honor of naming computers. In shock/disapproval/sarcastic honor of &lt;a href=&quot;http://www.npr.org/2014/11/22/365968465/after-backlash-computer-engineer-barbie-gets-new-set-of-skills&quot;&gt;Mattel's failed attempt&lt;/a&gt; to update their outdated views about women, I decided to name all of my computers after Barbie characters.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-DUzTPSAiKi0/VMB1J3XGqMI/AAAAAAAACbI/Cogjyj_ttfw/s1600/barbie.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        As of right now I have four computers set up,
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Barbie&lt;/li&gt;
&lt;li&gt;Ken&lt;/li&gt;
&lt;li&gt;Skipper&lt;/li&gt;
&lt;li&gt;Kelly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        And fortunately, &lt;a href=&quot;http://en.wikipedia.org/wiki/List_of_Barbie%27s_friends_and_family&quot;&gt;mass toy consumerism&lt;/a&gt; will allow me to expand my cluster to effectively any size.
    &lt;/p&gt;
&lt;h4&gt;The operating system&lt;/h4&gt;
&lt;p&gt;
        I originally tried to get the &quot;Barbie Cluster&quot; up and running with Puppy Linux. I chose Puppy initially because most of the machines lacked a DVD drives or USB booting, which ruled out more of the &quot;filled out&quot; Linux distributions. Puppy did install pretty easily and I would recommend it for someone who needs a lightweight, functional OS. But eventually, I, like many before me, decided that Puppy was just too much of an undocumented burden to run Hadoop, and I scrapped it for an Ubuntu command line install. (You can't get a lower memory OS than command line, I say)
    &lt;/p&gt;
&lt;p&gt;
        To get Ubuntu installed I downloaded the &lt;a href=&quot;http://archive.ubuntu.com/ubuntu/dists/trusty/main/installer-i386/current/images/netboot/mini.iso&quot;&gt;Ubuntu 14.04 Minimal Install CD&lt;/a&gt;, which I found &lt;a href=&quot;https://help.ubuntu.com/community/Lubuntu/Documentation/MinimalInstall&quot;&gt;here&lt;/a&gt;. I &lt;a href=&quot;http://lifehacker.com/251758/mac-tip--how-to-burn-an-iso-or-dmg-file-to-disc&quot;&gt;burnt the .iso&lt;/a&gt; file to a CD, and popped the CD into the CD drives of my hungrily waiting Dells.
    &lt;/p&gt;
&lt;p&gt;
        After &lt;a href=&quot;http://pcsupport.about.com/od/tipstricks/ht/bootcddvd.htm&quot;&gt;she boots to the CD&lt;/a&gt;, select Command Line Install. The setup is pretty straightforward and I didn't need any special choices except naming the computers and users. I partitioned the disk with &quot;Guided, Use Entire Disk and LVM,&quot; but I'm not sure if that was necessary. No reason not to do that though since that's what most Linux systems work on.
    &lt;/p&gt;
&lt;h4&gt;Before Getting to Hadoop&lt;/h4&gt;
&lt;p&gt;
        There's been a suggestion that you should create a dedicated user for Hadoop on your machine. Since this system doesn't have any other user, that seems unnecessary. I didn't bother with that, but I did create a hadoop group and add my doopy user to that group for consistency.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;  $ addgroup hadoop&lt;br/&gt;  $ usermod -g hadoop doopy&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I set up and auto-login for myself based on a suggestion I found &lt;a href=&quot;http://askubuntu.com/questions/175248/how-to-autologin-without-entering-username-and-passwordin-text-mode&quot;&gt;here&lt;/a&gt;. This isn't necessary, but I'm not going to have monitors and it's possible I might want things to run automatically in the background without having to ssh in. To have the machines log on automatically, edit the file '/etc/init/tty1.conf' so that the last line reads
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;exec /sbin/getty -8 38400 tty1 -a doopy&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Finally, the most important thing is to get the prerequisite software installed. To do that just type
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;  $ sudo apt-get install openjdk-7-jdk ssh git &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        This should get your java and ssh set up. I also included git because everyone eventually needs it anyway.
    &lt;/p&gt;
&lt;p&gt;
        Finally, you need to set up ssh to allow this machine to ssh itself without a password. (I know, it's the weirdest thing ever, but this is how Hadoop works. I suppose it's probably genius on a level that I don't even understand.)
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;  $ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa&lt;br/&gt;  $ cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys&lt;br/&gt;  $ ssh localhost&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Make it yourself&lt;/h4&gt;
&lt;p&gt;
        After apt-getting java and ssh, the only other thing you need is the Hadoop package itself. Unfortunately, the binary distribution that I got from Apache started throwing errors after I installed it. I hunted down the errors and found that the problems arose from a 32-bit vs 64-bit conflict.
    &lt;/p&gt;
&lt;p&gt;
        To solve the problem I recompiled it myself based on the ideas I found &lt;a href=&quot;https://github.com/y12studio/y12hadoop/blob/master/install-hadoop-2.4.0.md&quot;&gt;here&lt;/a&gt;. The Hadoop Github had &lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/BUILDING.txt&quot;&gt;slightly better instructions&lt;/a&gt;, that nailed down the steps that I had to take. I put &lt;a href=&quot;https://github.com/lots-of-things/hadoop-compiled&quot;&gt;my own compiled distribution&lt;/a&gt; up on the MakeLofT GitHub.
    &lt;/p&gt;
&lt;p&gt;
        So if you want to skip all the hard work you can get the whole thing set up with this line...
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;strike&gt;sudo git clone https://github.com/lots-of-things/hadoop-compiled.git /usr/local/hadoop&lt;/strike&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        EDIT: Nevermind, I edited that file so that settings now work for my current production setup.
    &lt;/p&gt;
&lt;p&gt;
        You also may need to change the ownership of the /usr/local/hadoop file you just added.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;sudo chown -R doopy:hadoop /usr/local/hadoop&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        Finally, you need to add some of these files to your .bash file. You can do this by appending the included file called addToBash to the end of your .bash file.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;cat addToBash &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;/pre&gt;
&lt;h4&gt;Modifying Hadoop's setup&lt;/h4&gt;
&lt;p&gt;
        I picked and chose the setup protocol from these three tutorials to tease out exactly what I needed to do. It's so odd that they can all be telling you to do the same thing, and yet still disagree on so much. Importantly, I found that all the information I could find on the YARN setup was pretty much totally off. I had to activate an additional JobHistoryServer that nobody mentioned.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/&quot;&gt;Michael Noll's tutorial was kind of out of date&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://eycheu.blogspot.com/2014/04/hadoop-240-on-ubuntu-1310.html&quot;&gt;This one seemed to have you doing extra unnecessary things&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/SingleCluster.html&quot;&gt;Apache's setup instructions were the shortest and least filled out&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        It was totally unclear to me why each tutorial asked you to modify the files in slightly different ways. Hopefully, I'll come back and edit this to explain all those knobs to other beginners.
    &lt;/p&gt;
&lt;p&gt;
        For now, &lt;a href=&quot;https://github.com/lots-of-things/hadoop-compiled.git&quot;&gt;my distribution&lt;/a&gt; comes preset to work with Hadoop YARN in pseudo-distributed way. You can look at the other tutorials to see the different things they did, but all I did was edit the following four files to fill out their configuration tag as shown.
    &lt;/p&gt;
    etc/hadoop/core-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;etc/hadoop/hdfs-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt; etc/hadoop/mapred-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;etc/hadoop/yarn-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;org.apache.hadoop.mapred.ShuffleHandler&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Youhave to make the next to files if you want to run YARN.
    &lt;/p&gt;
    sbin/start-jobhist.sh: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;bin=`dirname &quot;${BASH_SOURCE-$0}&quot;`&lt;br/&gt;&quot;$bin&quot;/mr-jobhistory-daemon.sh start historyserver&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt; sbin/stop-jobhist.sh: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;bin=`dirname &quot;${BASH_SOURCE-$0}&quot;`&lt;br/&gt;&quot;$bin&quot;/mr-jobhistory-daemon.sh stop historyserver&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;h4&gt;Running the example&lt;/h4&gt;
&lt;p&gt;
        To test that this was working I simply ran the example task that all three of those tutorials suggested. You can find it on any of those sites but here I've reproduced it for you.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;The following instructions are to run a MapReduce job locally. If you want to execute a job on YARN, see YARN on Single Node.&lt;br/&gt;&lt;br/&gt;    1) Format the filesystem:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs namenode -format&lt;br/&gt;&lt;br/&gt;    2) Start NameNode daemon and DataNode daemon:&lt;br/&gt;&lt;br/&gt;      $ sbin/start-dfs.sh&lt;br/&gt;&lt;br/&gt;    3) Start YARN daemon:&lt;br/&gt;&lt;br/&gt;      $ sbin/start-yarn.sh&lt;br/&gt;&lt;br/&gt;    EXTRA) Start JobHistoryServer:&lt;br/&gt;&lt;br/&gt;      $ sbin/start-jobhist.sh&lt;br/&gt;&lt;br/&gt;    4) Make the HDFS directories required to execute MapReduce jobs:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs dfs -mkdir /user&lt;br/&gt;      $ bin/hdfs dfs -mkdir /user/&amp;lt;username&amp;gt;&lt;br/&gt;&lt;br/&gt;    5) Copy the input files into the distributed filesystem:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs dfs -put etc/hadoop input&lt;br/&gt;&lt;br/&gt;    6) Run some of the examples provided:&lt;br/&gt;&lt;br/&gt;      $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output 'dfs[a-z.]+'&lt;br/&gt;&lt;br/&gt;    7) View the output files on the distributed filesystem:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs dfs -cat output/*&lt;br/&gt;&lt;br/&gt;    8) Stop YARN:&lt;br/&gt;&lt;br/&gt;      $ sbin/stop-yarn.sh&lt;br/&gt;&lt;br/&gt;    9) Stop dfs:&lt;br/&gt;&lt;br/&gt;      $ sbin/stop-dfs.sh&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I was able to monitor the jobs from my laptop over my network by going to &lt;a href=&quot;http://10.0.0.1:8088&quot;&gt;http://10.0.0.1:8088&lt;/a&gt;. Of course, I replaced 10.0.0.1 with the local IP address for that machine.
    &lt;/p&gt;
&lt;h4&gt;Troubleshooting&lt;/h4&gt;
&lt;p&gt;
        Something in this tutorial is going to become outdated in the next six months. My best advice is simply to keep searching, my friend. Someone else has debugged it before you.
    &lt;/p&gt;
&lt;p&gt;
        And now, after just a week, I have four individual machines running Hadoop by themselves. Next week, I'm hoping to get them talking to each other and running another example problem across a distributed file system... Well, I can dream can't I?
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 21 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/the-barbie-hadoop-cluster-stage-1/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/the-barbie-hadoop-cluster-stage-1/</guid>
        
        <category>infra</category>
        
        <category>data science</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://2.bp.blogspot.com/-pS_t0Y86OK0/VdZ_KF0pbGI/AAAAAAAAEgE/V8Mq7jX19Z8/photo%2B1.JPG</image>
        <title>RASER Week 3: Arduino LED blinker</title>
        <description>&lt;p&gt;
        Electronics engineers can build really complicated devices by controlling when and where simple circuits turn on and off. For example, check out this flat screen monitor that I've opened up to see the inside. The monitor uses signals from the computer to turn on tiny spots on the screen, called pixels. By turning the correct pixels on and off at the right time, we perceive a moving image.
    &lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/Re3s62cd1WE?rel=0&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        In the &lt;a href=&quot;/2014/12/raser-curriculum.html&quot;&gt;past lessons&lt;/a&gt;, we've started getting a sense about how electronic circuits work. But now it's time to start connecting them up to make something functional. Today, we're going to be using a programmable &lt;a href=&quot;http://en.wikipedia.org/wiki/Microcontroller&quot;&gt;microcontroller&lt;/a&gt; called an &lt;a href=&quot;http://www.arduino.cc/&quot;&gt;Arduino&lt;/a&gt; to make our LEDs blink in patterns.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-pS_t0Y86OK0/VdZ_KF0pbGI/AAAAAAAAEgE/V8Mq7jX19Z8/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;The Arduino &lt;/h4&gt;
&lt;p&gt;
        An Arduino is like a tiny computer that let's you measure signals and turn things on and off. To make it work you write a program which is uploaded to the device. The program tells the microcontroller to send and receive signals on pins. Then you connect the pins to sensors, lights, motors, and other parts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/6/6c/Arduino316.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The Arduino is capable of &lt;a href=&quot;http://playground.arduino.cc/Projects/ArduinoUsers&quot;&gt;many things&lt;/a&gt;. To get started today, we're going to use it to power an LED light show.
    &lt;/p&gt;
&lt;h4 id=&quot;ArdBat&quot;&gt;Connecting an LED to the Arduino&lt;/h4&gt;
&lt;p&gt;
        First, we'll remake the &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#circuit&quot;&gt;LED circuit that we made earlier&lt;/a&gt; using a battery pack, a resistor, and a single LED.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-i9dF1aglhMc/VKi-4ipoxAI/AAAAAAAACLk/7z70tCT0MAA/s1600/LED-CIRCUIT2.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Once that's working, we're simply going to replace the battery with power from the Arduino. We remove the battery pack and replace it with two wires connected to the Arduino. The plus should connect with the Arduino pin that says 3.3V, and the minus should connect with any of the Arduino pins that say GND.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-21Rv8tRUNK0/VdZ_oSrCLYI/AAAAAAAAEgQ/pRRzBylkTbI/s1600/photo%2B3%25282%2529.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The LED should light up because the 3.3V pin on the Arduino also produces a voltage. Next we'll make the LED blink by connecting it to a pin that turns its voltage on and off.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4 id=&quot;blink&quot;&gt;Arduino Blinking LED&lt;/h4&gt;
&lt;p&gt;
        These Arduinos have been pre-programmed with a program that makes pin 13 blink on and off. We'll see how this programming works in a minute, but first, we'll test to see if we have our setup working.
    &lt;/p&gt;
&lt;p&gt;
        To make the LED blink, remove the wire from the pin marked 3.3V and move it to the pin labeled 13. Wait a few seconds, to see if the LED starts blinking.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-fXXLjqKURKY/VdZ_nx87w2I/AAAAAAAAEgM/J0XWj_U2D84/s1600/photo%2B2.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This is pretty cool, but right now, it's just one LED blinking on and off. Next we'll start programming the Arduino ourselves to see how to make it light up in cooler ways.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Programming the Arduino&lt;/h4&gt;
&lt;p&gt;
        We program the Arduino by writing code on the computer and uploading it to the microcontroller through a USB connection. We do this in the Arduino IDE software.
    &lt;/p&gt;
&lt;p&gt;
        Let's view the code that made the LED blink. First we have to launch the Arduino IDE by finding it on the desktop(if it isn't there we'll need to &lt;a href=&quot;http://arduino.cc/en/main/software&quot;&gt;download it&lt;/a&gt;). Next, click the Open File button and then find the program labeled &quot;Blink.&quot; This is the program currently loaded onto our Arduinos.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;br/&gt;&lt;br/&gt;// Pin 13 has an LED connected on most Arduino boards.&lt;br/&gt;// give it a name:&lt;br/&gt;int led = 13;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {                &lt;br/&gt;  // initialize the digital pin as an output.&lt;br/&gt;  pinMode(led, OUTPUT);     &lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  digitalWrite(led, HIGH);   // turn the LED on (HIGH is the voltage level)&lt;br/&gt;  delay(1000);               // wait for a second&lt;br/&gt;  digitalWrite(led, LOW);    // turn the LED off by making the voltage LOW&lt;br/&gt;  delay(1000);               // wait for a second&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The program repeatedly toggles the voltage on pin 13 from HIGH (on) to LOW (off). To upload the program we push the upload button on the Arduino program.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.chicoree.fr/w/images/8/85/Arduino_Upload_(button).png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        If you want to know everything about this program you can look at the Arduino's &lt;a href=&quot;http://arduino.cc/en/tutorial/blink&quot;&gt;Blink Tutorial&lt;/a&gt; on their website. For right now, we just want to focus on changing how frequently the LED lights up. Right now the delay between events is set to 1000 milliseconds (that's equal to 1 second). Can you figure out how to change the blinking interval to be much faster or much slower? Try it out.
    &lt;/p&gt;
&lt;p&gt;
        Finally, the only reason pin 13 blinks is because the program specifies pin 13 to blink. We can add more code to the program that causes another pin to do the same thing. Try to change the code so that another pin also can run a blinking LED.
    &lt;/p&gt;
&lt;h4&gt;The LED array&lt;/h4&gt;
&lt;p&gt;
        As the final challenge, try to to make a blinking LED array like this one.
    &lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/xW_o4bGGoZ4?rel=0&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;p&gt;
        If we set up enough of these, we could turn them into something like this!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/e/e2/NYC_-_Times_Square_-_0420.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But maybe that's a little ambitious for right now.
    &lt;/p&gt;

&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sun, 18 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/raser-week-3-arduino-led-blinker/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/raser-week-3-arduino-led-blinker/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://1.bp.blogspot.com/-Ws3vCbgsCQk/VMLe5La_Y-I/AAAAAAAAC78/MTL-uDu9EiQ/photo%2B2.JPG</image>
        <title>RASER Week 2: LED dimmers and switches</title>
        <description>&lt;p&gt;
        This lesson will extend our knowledge of electricity and resistance by adding variable resistors and switches.
    &lt;/p&gt;
&lt;p&gt;
        To start I want to show a Variac autotransformer. The dial controls the amount of electricity getting to the light bulb. The light bulb lets us see the electric current running through it by going dimmer when the current is decreased.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-Ws3vCbgsCQk/VMLe5La_Y-I/AAAAAAAAC78/MTL-uDu9EiQ/s320/photo%2B2.JPG&quot; style=&quot;width:180px;&quot;/&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-iYr8uE1EFlE/VMLe5Pia6lI/AAAAAAAAC8A/g2P1XpSjtqc/s320/photo%2B3.JPG&quot; style=&quot;width:180px;&quot;/&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-MgjNoNtWj-Q/VMLe5NU_FZI/AAAAAAAAC8E/Cuh-CvUWKEw/s320/photo%2B4.JPG&quot; style=&quot;width:180px;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;
        In today's lesson we're going to learn about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Resistor&quot;&gt;resistor&lt;/a&gt;, a basic electronic component that can decrease the current in a circuit.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/b/b9/Resistors_color_code.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But before we get started learning more about resistors, let's review some basic facts about electricity
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Understanding voltage, current, and resistance.&lt;/h4&gt;
&lt;p&gt;
        To start this lesson, we'd like to elaborate on some of the electrical concepts we introduced last week. We learned that electricity flows out of the battery from the plus end to the minus end. We also learned that along the way, the electricity can be used to light an LED or it can be burned up in a resistor.
    &lt;/p&gt;
&lt;p&gt;
        The reason that the electricity flows out of the battery is that there is a difference in the number of electrons on one side of the battery compared to the other. The difference in energy between one side of the battery and the other is called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Voltage&quot;&gt;voltage&lt;/a&gt;. For electricity to flow there has to be a voltage difference because otherwise the electrons don't have any reason to flow through the wires. Voltage is measured in Volts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://regentsprep.org/Regents/physics/phys03/apotdif/battery.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The rate at which the electrons flow is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Electric_current&quot;&gt;electrical current&lt;/a&gt;. If you have a higher voltage, the current will be higher because the electrons are being pushed more strongly. Current is measured in Amps.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.talkingelectronics.com/pay/BEC/flow_thru_res-complete.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The work done in the LED or the resistor is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Electrical_load&quot;&gt;load&lt;/a&gt; or the &lt;a href=&quot;https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance&quot;&gt;resistance&lt;/a&gt;. Loads and resistors act to slow the electrons down. So as you increase the resistance you decrease the current through the circuit. Resistance is measured in Ohms.
    &lt;/p&gt;
&lt;p&gt;
        To get more practice with these concepts, we'll build a few new circuits.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Rebuilding the LED circuit&lt;/h4&gt;
&lt;p&gt;
        First, let's rebuild our &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#circuit&quot;&gt;single LED circuit&lt;/a&gt; with a single resistor.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-wml8t5WW1DI/VKjHvbpGBvI/AAAAAAAACMc/lwqJLnbwuZE/s1600/photo%2B4.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We can redraw the circuit like we did before, only now let's write in the voltages and resistances of the batteries and resistors.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-fzAUUbcktDo/VLMXeof11wI/AAAAAAAACRQ/ly9FkjrMDwg/s1600/LED-CIRCUIT_nums.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To find the resistor value we look at the pattern of colored bands on its side. We can input them into an &lt;a href=&quot;http://www.digikey.com/en/resources/conversion-calculators/conversion-calculator-resistor-color-code-5-band&quot;&gt;online calculator&lt;/a&gt; or use a table like this one.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.digikey.com/~/media/Images/Marketing/Resources/Calculators/resistor-color-chart.jpg?la=en-US&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        There's also some resistance that comes from the LED, but you can't tell how much just by looking at it. Later we'll learn how to find out the resistance from the LED using a mathematical formula.
    &lt;/p&gt;
&lt;p&gt;
        Finally, we can measure the current through the circuit to see how fast the electrons are flowing. Hook up the multimeter into the circuit like in the picture. If the multimeter is set to read amps, you can see how many amps are flowing through the circuit. The higher the amps the faster the electrons are flowing.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-TDVfOUEqY0k/VLTFQYz0wtI/AAAAAAAAC5E/x0YuGd5foj8/s1600/photo%2B2.JPG&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Quick Quiz&lt;/h5&gt;
&lt;p&gt;
        If we replace our resistor with one that has a higher resistance, would the current get higher or lower? Check it by replacing the resistor and remeasuring the current with the multimeter.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4 id=&quot;varresist&quot;&gt;Adding a variable resistor&lt;/h4&gt;
&lt;p&gt;
        The resistor provides a fixed resistance that can't be changed without switching that part out of the circuit. Next, we'll use a small &lt;a href=&quot;https://www.st-andrews.ac.uk/~www_pa/Scots_Guide/info/comp/passive/resistor/pots/var_res/var_res.htm&quot;&gt;variable resistor&lt;/a&gt; to change the resistance in our circuit with a dial.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-eaG8OfqNj7s/VLTFQc5XoQI/AAAAAAAAC5I/bhe06BqKW9Y/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We can remove the old resistor from the circuit and put the variable resistor in its place. Hook the circuit up to one inside pin and one outside pin on the variable resistor like in the picture. Now turning the dial changes the amount of resistance, which should change the brightness of the LED.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The mathematical relationship between voltage, resistance, and current&lt;/h4&gt;
&lt;p&gt;
        It turns out that for any electrical load, (like across the resistor or the LED) we can always find the current using &lt;a href=&quot;https://en.wikipedia.org/wiki/Ohm%27s_law&quot;&gt;Ohm's law&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://ecigarettereviewed.com/wp-content/uploads/2013/10/ohms-law-equation.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        By rearranging this formula we can also get the resistance if we know the current. We can use this equation to calculate the resistance across the LED in the circuit we drew out above.
    &lt;/p&gt;
&lt;p&gt;
        Finally, try using measurements of the current through the variable resistor to find out the resistance at different dial positions.
    &lt;/p&gt;
&lt;h4&gt;LED lightning game with switches and variable resistors&lt;/h4&gt;
&lt;p&gt;
        To end the lesson, we're going to replay the game from &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html&quot;&gt;last lesson&lt;/a&gt;. This time we'll incorporate switches and dimmers to help us light up the right number of lights. And to make the game more challenging we can modify the game so you have to get the right voltage as measured on a multimeter.
    &lt;/p&gt;
&lt;p&gt;
        As you go, try making the circuits more modular so you can modify them quicker. Try to incorporate switches or dimmers to make changes at the flip of a dial.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Mon, 12 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/raser-week-2-led-dimmers-and-switches/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/raser-week-2-led-dimmers-and-switches/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://2.bp.blogspot.com/-3z4RanS6SUQ/VLM0n06C9YI/AAAAAAAACUY/I2m0oILZ0PU/IMG_1393.jpg</image>
        <title>Four Humours Collage</title>
        <description>&lt;p&gt;
        Claire and I had these fairly cheesy Monet reprints from the Art Institute that I didn't like.
    &lt;/p&gt;

&lt;img border=&quot;0&quot; src=&quot;http://ecx.images-amazon.com/images/I/51AeXLQEh5L._SY355_.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But they had nice stainless steel frames that I wanted to use to fill in our kitchen wall.
    &lt;/p&gt;
&lt;p&gt;
        At first I figured, I'd just print out pretty images from internet or cut things out of magazines and stick them up. But since there were four similar frames, I decided it'd be cool to try to make an interconnected piece some related set of themes.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The Four Humors&lt;/h4&gt;
&lt;p&gt;
        I've always had an interest in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Humorism&quot;&gt;four humors&lt;/a&gt; and their relationship with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Four_temperaments&quot;&gt;four temperaments&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/6/6e/Charles_Le_Brun-Grande_Commande-Les_Quatre_temperaments.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        First, I think it's pretty hilarious to think of ancient &quot;scientists&quot; trying to categorize all matter, medicine and psychology using a universal classification of four things. That being said, a grand unifying worldview of such symmetry would make for an appealing and fairly beautiful ideal if it were possible.
    &lt;/p&gt;
&lt;p&gt;
        So, I decided to put together a big image collection of all the different meanings of the four humors. I tried to pull from the biology, chemistry, philosophy and personality that the humors were supposed to represent. And I tried to be more-or-less true to the color schemes associated with each.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-HHMUs9Bx4BE/VLNDfcvN_yI/AAAAAAAACWk/lpdanglex7k/s1600/image_gallery.png&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Sanguine&lt;/h5&gt;
&lt;p&gt;
        I think Sanguine was my favorite. I basically made this panel to represent the party-people. Dancing, jokes, heat maps, blood cells, and sangria (get it).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-3z4RanS6SUQ/VLM0n06C9YI/AAAAAAAACUY/I2m0oILZ0PU/s1600/IMG_1393.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h5&gt;Choleric&lt;/h5&gt;
&lt;p&gt;
        This is porbably my least favorite. Cholera is for the users. The haters. The money-men focused on taking stuff from others and pushing everyone around. I focused on gold, business, oil, and war. The biology images are parasites.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-8qq3hZkgcQg/VLM0n_ylG0I/AAAAAAAACUY/m-2GJ0WNNk0/s1600/IMG_1404.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h5&gt;Melancholic&lt;/h5&gt;
&lt;p&gt;
        I was a little stumped about how to do this one because I didn't want to be &quot;melancholic.&quot; I tried to focus on the earthy-utilitarian type. The organisms were little bugs who could break down plastic. There's some muscle tissue and the architecture from an engineering school.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-cNEBQisQXic/VLM0n9H6yfI/AAAAAAAACUY/kSyPF0oIqC4/s1600/IMG_1408.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h5&gt;Phlegmatic&lt;/h5&gt;
&lt;p&gt;
        I enjoyed this one too. Tranquil water to reflect the contemplative philosopher. Neurons, Buddha-like faces, whales, fractals, and cosmic radiation.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-A9RbzPIt_kM/VLM0n0t-WJI/AAAAAAAACUY/LvlhfPj9ExA/s1600/IMG_1389.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;p&gt;
        There were a couple of items that I repeated in each of their characteristic flavors throughout the panels: architecture, potent potables, animals, nudes, and microscopic life. It's fun to compare what got picked for each type.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;putting it together&lt;/h4&gt;
&lt;p&gt;
        I basically just popped them into their frames and hung them up with slightly staggered corners. Here it is hanging in the kitchen above our breakfast table.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-W3Mx9CJDHWg/VLM0n1EyaRI/AAAAAAAACUY/60HR1SqBE4Y/s1600/IMG_1417.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        It's kind of cool having something with so many little side-stories to look at in the mornings when you're getting ready for work. It reminds me about all the diversity in the world—all the different colors, and how it's so hard to classify the world neatly.
    &lt;/p&gt;
&lt;p&gt;
        To see some of the images that I pulled from the web you can check out &lt;a href=&quot;http://wmcfadd2.tumblr.com/&quot;&gt;my tumblr&lt;/a&gt;.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 11 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/four-humours-collage/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/four-humours-collage/</guid>
        
        <category>art</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://3.bp.blogspot.com/-E3BGaAk6Jp8/VK7_R2F0ORI/AAAAAAAACQA/fz-tKxVcE8c/Screen%2BShot%2B2015-01-08%2Bat%2B4.05.34%2BPM.png</image>
        <title>#ActsOfSuperness Twitter Game</title>
        <description>&lt;p&gt;
        Three days ago at about 3 a.m. I woke up with an idea to make people be nicer to each other. I know it might sound kind of corny, but I wanted to build a Twitter game to encourage people to do (and tweet) good things.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-E3BGaAk6Jp8/VK7_R2F0ORI/AAAAAAAACQA/fz-tKxVcE8c/s1600/Screen%2BShot%2B2015-01-08%2Bat%2B4.05.34%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The game is called &lt;a href=&quot;http://actsofsuperness.appspot.com/&quot;&gt;#ActsOfSuperness&lt;/a&gt;, and it centers around getting people to retweet the nice things they do for others. The more an action is retweeted the more points they get.
    &lt;/p&gt;
&lt;p&gt;
        As players get higher scores they get moved up in the superhero rankings. Eventually they become Batman, and &lt;a href=&quot;http://io9.com/5928043/everyone-wants-to-be-batman-in-this-i-am-batman-supercut&quot;&gt;everyone wants to be Batman&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.blastr.com/sites/blastr/files/styles/blog_post_media/public/Adam%20West%20Batman.jpg?itok=FLOGEqD-&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But really, the payout is more about having this fun little excuse to be nice to other people. Maybe I'm horribly naive, but that sounds like enough reward to me.
    &lt;/p&gt;
&lt;p&gt;
        If you want to play all you have to do is add &lt;a href=&quot;https://twitter.com/search?q=%23ActsOfSuperness&amp;amp;src=typd&quot;&gt;#ActsOfSuperness&lt;/a&gt; to your tweets. Then the twitter account &lt;a href=&quot;https://twitter.com/SuperActs&quot;&gt;@SuperActs&lt;/a&gt; will update you with your score and what superhero you are.
    &lt;/p&gt;
&lt;h4&gt;Building the game&lt;/h4&gt;
&lt;p&gt;
        I want to write up how I made this project, and how others can reproduce it. As usual, I've put &lt;a href=&quot;https://github.com/wmcfadden/acts-of-superness&quot;&gt;the source code&lt;/a&gt; on github. I really would like other people to clone this and build it out or duplicate it. You could imagine making clones with any kind of positive (or negative) message as the hashtag. #ActsOfFreshness, #ActsOfMerriness (for Christmas) You get the idea.
    &lt;/p&gt;
&lt;p&gt;
        The project can be broken into two parts—a twitter-facing &quot;pseudo-backend&quot; that trawls Twitter and a web-facing frontend that displays the leaderboard.
    &lt;/p&gt;
&lt;h4&gt;The Twitter facing &quot;backend&quot;&lt;/h4&gt;
&lt;p&gt;
        The actual game-play really just boils down to a string of tweets. &lt;a href=&quot;http://meta-guide.com/software-meta-guide/100-best-googlecode-twitter-bot/&quot;&gt;Many people&lt;/a&gt; have built tweetbots, but I thought it would be a good idea (read free) to host it on &lt;a href=&quot;https://cloud.google.com/appengine/docs&quot;&gt;Google App Engine&lt;/a&gt; so I looked for people who had done that before.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-FwUgriHOWDY/VK8DJdEvkJI/AAAAAAAACQM/EAZ1Rcs0J-A/s1600/Screen%2BShot%2B2015-01-08%2Bat%2B4.21.52%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To get started, I borrowed heavily from &lt;a href=&quot;http://www.billthelizard.com/2013/12/creating-twitter-bot-on-google-app.html&quot;&gt;this Twitter Bot example&lt;/a&gt; by BillTheLizard. It leverages &lt;a href=&quot;http://www.tweepy.org/&quot;&gt;tweepy&lt;/a&gt; to automatically update a twitter account's status. With just a few modifications &lt;a href=&quot;https://github.com/BillCruise/BountyBot&quot;&gt;Bill's code&lt;/a&gt; formed the backbone of my project.
    &lt;/p&gt;
&lt;h4&gt;Sending Tweets with Tweepy&lt;/h4&gt;
&lt;p&gt;
        To connect to the Twitter API, you'll first have to set up an &lt;a href=&quot;https://twittercommunity.com/t/how-to-get-my-api-key/7033&quot;&gt;API authentication key&lt;/a&gt;, which is explained &lt;a href=&quot;https://themepacific.com/how-to-generate-api-key-consumer-token-access-key-for-twitter-oauth/994/&quot;&gt;nicely in this tutorial&lt;/a&gt;. I put the keys into a config file like BillTheLizard did, and then I load them in.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;config = ConfigParser.RawConfigParser()&lt;br/&gt;config.read('settings.cfg')&lt;br/&gt;    &lt;br/&gt;CONSUMER_KEY = config.get('Twitter OAuth', 'CONSUMER_KEY')&lt;br/&gt;CONSUMER_SECRET = config.get('Twitter OAuth', 'CONSUMER_SECRET')&lt;br/&gt;ACCESS_TOKEN_KEY = config.get('Twitter OAuth', 'ACCESS_TOKEN_KEY')&lt;br/&gt;ACCESS_TOKEN_SECRET = config.get('Twitter OAuth', 'ACCESS_TOKEN_SECRET')&lt;br/&gt;&lt;br/&gt;auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)&lt;br/&gt;auth.set_access_token(ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)&lt;br/&gt;api = tweepy.API(auth)      &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        After authenticating the twitter, all of the tweeting work is performed in a single line.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;api.update_status(&quot;@%s Congrats! You've moved up to #%s.&quot; % (name,namesake),f.id)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        To actually set up the Google App Engine part, I only had to adjust Bill's app.yaml file to point to different programs on the frontend and &quot;backend&quot;. I'd used GAE before so this was no problem.
    &lt;/p&gt;
&lt;div&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;application: actsofsuperness&lt;br/&gt;version: 1&lt;br/&gt;runtime: python27&lt;br/&gt;api_version: 1&lt;br/&gt;threadsafe: yes&lt;br/&gt;&lt;br/&gt;handlers:&lt;br/&gt;- url: /favicon\.ico&lt;br/&gt;  static_files: favicon.ico&lt;br/&gt;  upload: favicon\.ico&lt;br/&gt;&lt;br/&gt;- url: /tweet_super&lt;br/&gt;  script: tweet_super.app&lt;br/&gt;  login: admin&lt;br/&gt;&lt;br/&gt;- url: /js&lt;br/&gt;  static_dir: js&lt;br/&gt;  &lt;br/&gt;- url: /im&lt;br/&gt;  static_dir: im&lt;br/&gt;  &lt;br/&gt;- url: /css&lt;br/&gt;  static_dir: css&lt;br/&gt;    &lt;br/&gt;- url: .*&lt;br/&gt;  script: main.app&lt;br/&gt;&lt;br/&gt;libraries:&lt;br/&gt;- name: webapp2&lt;br/&gt;  version: &quot;2.5.2&quot;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;h4&gt;The searching for tweets part&lt;/h4&gt;
&lt;p&gt;
        My backend app was going to need to take in twitter info in order to process tweets and find people to tweet back.
    &lt;/p&gt;
&lt;p&gt;
        I found the &lt;a href=&quot;http://docs.tweepy.org/en/latest/api.html&quot;&gt;tweepy.search since_id parameter&lt;/a&gt;, and the &lt;a href=&quot;https://dev.twitter.com/rest/public/search&quot;&gt;Twitter Search API &lt;/a&gt; could be used to pull in tweets with a given keyword.
    &lt;/p&gt;
&lt;p&gt;
        To keep things recent, I save the last tweet I read in sid and use the &lt;strong&gt;since_id&lt;/strong&gt; parameter in tweepy.search.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;found = api.search('%23ActsOfSuperness',since_id=sid)&lt;br/&gt;for f in found:&lt;br/&gt;    name = f.user.screen_name&lt;br/&gt;    id = f.user.id&lt;br/&gt;    # do something with name and id &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;storing user scores&lt;/h4&gt;
&lt;p&gt;
        The hard part is that I need to keep track of twitter @users and their scores. Now I could do this every time the page loads by searching all the tweets with #ActsOfSuperness and recalculating the totals. But, of course, that would be very slow if there are many tweets to process. Since I want to at least pretend that other people will use this someday, I had to find another way of retaining score over time.
    &lt;/p&gt;
&lt;p&gt;
        If I'm only periodically reading a recent chunk of tweets, I need to update a persistent database of scores.
    &lt;/p&gt;
&lt;h5&gt;Behold the Cloud!&lt;/h5&gt;
&lt;p&gt;
        Fortunately, since I'm running this on Google App Engine, I get to use 1GB of free space on the &lt;a href=&quot;https://cloud.google.com/datastore/&quot;&gt;Google Datastore&lt;/a&gt;. I'm betting that not too many people will be playing so my GAE Datastore Account won't &lt;a href=&quot;https://cloud.google.com/appengine/docs/quotas&quot;&gt;fill up&lt;/a&gt;. But even if I start to get a lot of users playing, GAE will let me expand easily. That would be a good thing, and I could throw AdSense up there to pay for the increased storage space.
    &lt;/p&gt;
&lt;p&gt;
        I referred to Google's &lt;a href=&quot;https://cloud.google.com/appengine/docs/python/gettingstartedpython27/usingdatastore&quot;&gt;Datastore Python Guestbook Demo&lt;/a&gt; to get started. The one issue with the datastore and &lt;a href=&quot;http://en.wikipedia.org/wiki/Eventual_consistency&quot;&gt;eventual consistency&lt;/a&gt; is that you aren't guaranteed that the Datastore is up to date when you access it. That meant that if the user had tweeted more than once, the following code could run multiple times accidentally, producing multiple copies of the same user.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;hero = Hero.all().filter('id =', id).fetch(10)&lt;br/&gt;if len(hero)&amp;gt;0:&lt;br/&gt;   ... Do stuff &lt;br/&gt;else:&lt;br/&gt;   hero = Hero()&lt;br/&gt;   hero.id = id&lt;br/&gt;   hero.handle = name&lt;br/&gt;   hero.score = 1.0&lt;br/&gt;   hero.put()&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        To fix those kinds of duplication problems I decided on the (slightly hacky) fix that would eventually kick out the duplicates if there were any. I now that you can do this somehow with ancestory in GAE, but that apparently limits the number of Datastore calls you can make in a given time window so I didn't want to do that.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;hero = Hero.all().filter('id =', id2).fetch(10)&lt;br/&gt;if(len(hero)&amp;gt;1):&lt;br/&gt;    for i in range(1,len(hero)):&lt;br/&gt;        hero[0].score=hero[0].score+hero[i].score&lt;br/&gt;    db.delete(hero[1:])&lt;br/&gt;hero = hero[0]&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        At this point we just have to update user scores every time we see a new user. This code increments the score and puts it back in the datastore. And if the user has &quot;leveled up&quot; I send them a tweet.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;points = 10.0/(ff.user.followers+1.0)&lt;br/&gt;if(floor(hero.score/10)!=floor((hero.score+points)/10)):&lt;br/&gt;   sup = floor((hero.score+points)/10)&lt;br/&gt;   if(sup&amp;gt;len(HERO_LIST)):&lt;br/&gt;      namesake = HERO_LIST[0]&lt;br/&gt;   else:&lt;br/&gt;      namesake = HERO_LIST[-1-val]&lt;br/&gt;   api.update_status(&quot;@%s Congrats! You've moved up to #%s. &quot; % (name,namesake),f.id)&lt;br/&gt;hero.score = hero.score+points&lt;br/&gt;hero.put()&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Cron for updates&lt;/h4&gt;
&lt;p&gt;
        I'm polling Twitter every half hour to get new tweets to score. Automation like this is accomplished really simply by setting up a &lt;a href=&quot;https://cloud.google.com/appengine/docs/python/config/cron&quot;&gt;cron.yaml file&lt;/a&gt; in app engine.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;cron:&lt;br/&gt;- description: repeated tweet test&lt;br/&gt;  url: /tweet_super&lt;br/&gt;  schedule: every 30 mins&lt;br/&gt;  timezone: America/Chicago&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;The web-facing site&lt;/h4&gt;
&lt;p&gt;
        I built the site around a neat &lt;a href=&quot;http://www.bootply.com/ToV8Bzv4GQ&quot;&gt;bootply theme&lt;/a&gt;. My main.py just fills in one dynamic section in the middle, creating a list of @users by sorting the datastore
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;hero = Hero.all().order('-score').fetch(100)&lt;br/&gt;MID_HTML=''&lt;br/&gt;for h in hero:&lt;br/&gt;    MID_HTML = MID_HTML + h.handle&lt;br/&gt;        &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        It's simple and neat looking and gets the job done. I also embedded a copy of the &lt;a href=&quot;http://www.ranker.com/crowdranked-list/best-superheroes-all-time&quot;&gt;online list&lt;/a&gt; that I'm using to decide the superhero order. (Thank God Batman was number 1)
    &lt;/p&gt;
&lt;p&gt;
        Eventually, I'm hoping to build something for people to look up any users score eventually, but I might not get to that. It really depends if anyone ever starts using this thing.
    &lt;/p&gt;
&lt;h4&gt;So Go Play Now&lt;/h4&gt;
&lt;p&gt;
        I really had fun making &lt;a href=&quot;http://actsofsuperness.appspot.com/&quot;&gt;#ActsOfSuperness&lt;/a&gt;, and I'm excited for people to try it out.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-HpjubsAZFOg/VK8KKR49EvI/AAAAAAAACQk/xEzo4DF5Awc/s1600/Screen%2BShot%2B2015-01-08%2Bat%2B4.50.59%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I really hope that this game can inspire a few people to go and do some nice things for others. We have so many silly incentives in this day-and-age that promote everyone being &quot;interesting.&quot; Hopefully this app will inspire some people to do actual good.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Thu, 08 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/actsofsuperness-twitter-game/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/actsofsuperness-twitter-game/</guid>
        
        <category>games</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://4.bp.blogspot.com/-RtArN_4bKd4/VKjGxZlx9RI/AAAAAAAACL0/0njBoguVdjI/photo%2B2.JPG</image>
        <title>RASER Week 1: LED circuits</title>
        <description>&lt;p&gt;
        In this lesson we'll learn how the electricity lighting up our gadgets flows through wires from batteries.
    &lt;/p&gt;
&lt;p&gt;
        My friend Pete built this amazing &lt;a href=&quot;http://en.wikipedia.org/wiki/Spark_gap#Visual_entertainment&quot;&gt;Jacob's ladder&lt;/a&gt; that we'll use to start off the lesson. The arc of light traveling up the Jacob's ladder is ionized air, just like in a &lt;a href=&quot;http://en.wikipedia.org/wiki/Lightning&quot;&gt;lightning bolt&lt;/a&gt;. Electricity flowing from one wire to the other causes the air itself to emit light.
    &lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/5TBJ-HeRvlk?rel=0&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        The students will grapple with the flow of electricity hands on by making an LED light up. Here's the battery connected to the LED to make it glow.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-RtArN_4bKd4/VKjGxZlx9RI/AAAAAAAACL0/0njBoguVdjI/s1600/photo%2B2.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Electricity flows out of the battery and into the material in the LED. That material is specially designed so that when electricity tries to pass through it, the material glows. This is kind of like the air in the Jacob's ladder lighting up
    &lt;/p&gt;
&lt;h4&gt;Getting started with circuits&lt;/h4&gt;
&lt;p&gt;
        Next, we move on to building our own simple circuits that light up. The first component, the &lt;a href=&quot;http://en.wikipedia.org/wiki/Breadboard&quot;&gt;breadboard&lt;/a&gt;, is where all of the electronics construction takes place. You use the breadboard to connect circuit components together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-93-dt3gwaUA/VKjG4WKcxcI/AAAAAAAACL8/pJ9kHneWOtM/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This breadboard has the back removed so you can see the way all of the holes are connected on the reverse side. On the outsides, the &lt;span style=&quot;color:red&quot;&gt;plus&lt;/span&gt; and &lt;span style=&quot;color:blue&quot;&gt;minus&lt;/span&gt; holes are all connected. In the center, the numbered rows are connected. Plugging into a connected hole is just like touching those to wires together directly.
    &lt;/p&gt;
&lt;h4&gt;The LED circuit&lt;/h4&gt;
&lt;p&gt;
        Now that we're acquainted with the breadboard we're going to build the &lt;a href=&quot;http://en.wikipedia.org/wiki/LED_circuit&quot;&gt;basic LED circuit&lt;/a&gt;. First, start by connecting the plus and minus end of the battery to the plus and minus rows of the breadboard.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-1XmvEXES984/VKjHtztsVVI/AAAAAAAACMI/TuJYYRu8plo/s1600/photo%2B3.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Next, insert the long wire of a clear LED into the plus terminal, and insert the short wire into the minus terminal. The LED should light up. If it doesn't try reversing the ends. Remember that the longer wire should stick into the plus side. This is because the LED only lets the electricity &lt;a href=&quot;http://www.technologystudent.com/elec1/diode1.htm&quot;&gt;flow in one direction&lt;/a&gt;.
    &lt;/p&gt;
&lt;h4&gt;Drawing the circuit&lt;/h4&gt;
&lt;p&gt;
        We can draw the flow of electricity from the battery into the LED and then back into the other end of the battery. This is called a &lt;a href=&quot;http://en.wikipedia.org/wiki/Circuit_diagram&quot;&gt;circuit diagram&lt;/a&gt;, and it helps us to picture how the circuit works and how to modify it to make new things.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-TfJLN8moT0w/VKi5lX-HAZI/AAAAAAAACLM/dDcqioGTq6M/s1600/LED-CIRCUIT.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Electricity leaves one end of the battery and tries to get back to the other end. On its way around, the electricity flows out of the battery on the left and into the LED on the right. Then it leaves the LED and continues around the rest of the loop.
    &lt;/p&gt;
&lt;h4 id=&quot;circuit&quot;&gt;Using different colors&lt;/h4&gt;
&lt;p&gt;
        The blue LED could be hooked up directly to the battery because the LED requires the same amount of electricity that the battery supplies. The yellow, green, and red LEDs need less power so we have to reduce the amount of electricity getting to them from the battery. To do this, we need to add a resistor, which burns up some of the electricity inside of it.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-wml8t5WW1DI/VKjHvbpGBvI/AAAAAAAACMU/88CbI3Key2I/s1600/photo%2B4.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The green LED will still work without the resistor, but it will be lit more brightly than it should. Without the resistor, the green LED will burn out after a while. The resistor protects the LED from getting too much power at once. To learn more, see &lt;a href=&quot;http://www.instructables.com/id/Choosing-The-Resistor-To-Use-With-LEDs/&quot;&gt;this article&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-i9dF1aglhMc/VKi-4ipoxAI/AAAAAAAACLc/SAG8mFiSNXs/s1600/LED-CIRCUIT2.png&quot; title=&quot; &quot;/&gt;
&lt;h4 id=&quot;twoLEDs&quot;&gt;Two LEDs side by side&lt;/h4&gt;
&lt;p&gt;
        If we want to power multiple LEDs at once, we can put them both into the circuit next to each other. Make sure that the long ends are both connected to the resistor and that the short ends are connected to the minus end of the battery. This is called putting the LEDs in parallel. You can try putting one LED after the next (in series), but that keeps the battery from being able to light them.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-1sQAgOhqNhE/VKjHvR5eKdI/AAAAAAAACMQ/ayjIaEoMLkk/s1600/photo%2B5.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Now we can redraw this circuit just like before.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-7V44vjWsjeE/VKi-4j6hvZI/AAAAAAAACLg/Y9WvE0eeIsI/s1600/LED-CIRCUIT3.png&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Quick Quiz&lt;/h5&gt;
&lt;p&gt;
        As a quick test, let's ask what would happen if we unplugged one LED from the two LED circuit. Will the other LED still work? If we go back to the circuit diagram we see that electricity can still flow through the other LED even if the first one is removed. Try it out to see what happens.
    &lt;/p&gt;
&lt;h4&gt;LED lightning game&lt;/h4&gt;
&lt;p&gt;
        To end the lesson, let's try to play a game. This game will give us practice building LED circuits.
    &lt;/p&gt;
&lt;p&gt;
        Since we know how to put multiple LEDs together, try to light the right number to answer a question. Ask a simple math problem and then build a circuit with that number of LEDs lit up. Then ask a new math problem and modify the circuit to get the right number of LEDs again.
    &lt;/p&gt;
&lt;p&gt;
        As you go, try making the circuits more modular so you can modify them quicker. Try to incorporate simple switches so that you can change the setup faster too.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Tue, 06 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/raser-week-1-led-circuits/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/raser-week-1-led-circuits/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.org/assets/images/2015/better_linkedin.png</image>
        <title>A Better LinkedIn</title>
        <description>&lt;br/&gt;

&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-fv1k4PG_wYI/VKsFCIiAfhI/AAAAAAAACPA/LAjpvnTWtPU/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B3.28.02%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I've been wanting to fix my &lt;a href=&quot;http://www.businessinsider.com/why-the-paper-resume-isnt-dying-any-2013-9&quot;&gt;old paper resumé's&lt;/a&gt; abhorrent &lt;a href=&quot;http://viz.wtf/&quot;&gt;lack of data visualization&lt;/a&gt; with an interactive web version. And since I'm about to hit the job market anyway, I figured now is the perfect time to introduce my own &lt;a href=&quot;http://hellowillmcfadden.appspot.com/&quot;&gt;Online Visual Resumé&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        I've built &lt;a href=&quot;http://hellowillmcfadden.appspot.com/&quot;&gt;the site up&lt;/a&gt; and launched it on Google App Engine. I also &lt;a href=&quot;https://github.com/wmcfadden/visual-resume&quot;&gt;posted the source&lt;/a&gt; for anyone else to fork and play with. The following blog post is my attempt to explain the moving parts and why I thought they were useful improvements on the traditional approach.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The human factor&lt;/h4&gt;
&lt;p&gt;
        First off, a resumé is supposed to be about people so I wanted to leave a constant reminder that all of this data is related to a person. That led me to use a neat &lt;a href=&quot;http://www.bootply.com/templates&quot;&gt;bootstrap sidebar template&lt;/a&gt; from &lt;a href=&quot;http://www.bootply.com/&quot;&gt;bootply&lt;/a&gt; to keep the &quot;person badge thingy&quot; on the left. That keeps the face and details visible while scrolling through the content on the right.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-48QMQyqCrzE/VKr_mjpvhxI/AAAAAAAACOM/PjE3VB42EdI/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B3.17.57%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And let's not forget the &lt;i&gt;plethora&lt;/i&gt; of social media links one needs to show off. Keeping all of this on the side made it constantly accessible no matter where you go on the page.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;People, projects, and skills are the focus.&lt;/h4&gt;
&lt;p&gt;
        The traditional resumé seemed to put a lot of faith in the name of your institution. To me, it seems that that is becoming increasingly less important. This may be because individuals are becoming &lt;a href=&quot;http://www.economist.com/news/leaders/21605906-cost-crisis-changing-labour-markets-and-new-technology-will-turn-old-institution-its&quot;&gt;increasingly self-empowered&lt;/a&gt; through the web, or it might just be the result of a &lt;a href=&quot;http://www.gallup.com/poll/1597/confidence-institutions.aspx&quot;&gt;steady degradation of our trust&lt;/a&gt; in faulty institutions. Whatever the reason, a vanilla bachelor's degree and a few nondescript company names doesn't look like it's going to cut it in the future.
    &lt;/p&gt;
&lt;h5&gt;Focusing on Projects and Direct Collaborators&lt;/h5&gt;
&lt;p&gt;
        Instead of broadly classifying my work by the firm's name, on my site, I have every project and collaborator summarized in a &lt;a href=&quot;http://hellowillmcfadden.appspot.com#demo_1&quot;&gt;Hive Connection Plot&lt;/a&gt;. I also include links to the publications of projects and to the public profiles of the people I worked with when possible.
    &lt;/p&gt;
&lt;p&gt;
        All of this sends the message of interactivity and teamwork that is so important today. There's no room to hide behind your company's credentials if all your work involved repeatedly handing the same form to the same boss.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-85gsYQsqI_o/VKr_4Bc8X0I/AAAAAAAACOU/IyG_61ixbdc/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B2.55.43%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Including Skills&lt;/h5&gt;
&lt;p&gt;
        Although the main focus of this section was the projects and collaborations, I thought it would be interesting to include the skills I brought to each project too. The great advantage of the Hive plot was the ability to add the skills on a separate branch without cluttering things too much.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Skill Lists should be scored&lt;/h4&gt;
&lt;p&gt;
        One thing that was lacking in the People-Projects-Skills graphic is any quantitative assessment of ability. A list of skills doesn't tell you how well you know them so I built &lt;a href=&quot;http://hellowillmcfadden.appspot.com#skillbubbles&quot;&gt;this zoomable pack hierarchy&lt;/a&gt; to make it obvious how well I know something based on its size.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-OusFwqjYgBE/VKr6v-b4h2I/AAAAAAAACNQ/O-bxCpzHFyg/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B2.57.06%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When I put down my list of &quot;known languages,&quot; I'm not saying that I know how to do everything with an Arduino or python. In a linear text resume it's impossible to express how well you know a given skill. So most kid's today have technical skill lists that bloat with a thousand things they've tried once or just vaguely understand.
    &lt;/p&gt;
&lt;p&gt;
        It's clear that if this sort of hierarchy of skills were formalized better it would become a heck of a lot more useful. Also publicly accessible scores for various tangible skills would convert this from a subjective assessment into an objective one.
    &lt;/p&gt;
&lt;h5&gt;Adding Education&lt;/h5&gt;
&lt;p&gt;
        Modern degrees are increasingly becoming more and more flexible. We give students the opportunity to learn diverse things, but unfortunately, we don't try to accurately inform employers about what their employees were actually taught. That makes a 21st century degree meaningless in terms of subject matter.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://media.licdn.com/mpr/mpr/jc/p/8/005/0a5/3ca/08ba6bd.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;I recently saw &lt;a href=&quot;https://www.linkedin.com/pulse/big-idea-2015-lets-rethink-jeff-selingo&quot;&gt;an article by Jeff Selingo&lt;/a&gt; (ironically the article was on LinkedIn) where he mentioned this idea of a &quot;digital backpack,&quot; that follow you through life, documenting your accrual of skills. The main problem I see with that is the ability to parse who knows what and how they learned it in such a disordered system.
    &lt;/p&gt;
&lt;p style=&quot;display:none&quot;&gt;In the future I want to work out a modified Sankey diagram as a way to fix that problem. It would basically plot how every bit of info you understand was developed from high school on. And it could track your performance along the way so you could understand what's important for learning certain skills. Maybe if you don't understand something right now, it would be obvious that you're struggling just because you didn't &lt;i&gt;really&lt;/i&gt; understand this other subtopic three years ago.
    &lt;/p&gt;
&lt;p&gt;
        This interconnection between skills and education would be fun to work out in the future if I ever get a chance.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Interest graph&lt;/h4&gt;
&lt;p&gt;
        I'll admit that &lt;a href=&quot;http://hellowillmcfadden.appspot.com#forcegraph&quot;&gt;this one&lt;/a&gt; was mostly just for fun. I thought it would be nice to see the way all the things I like might be related.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/--brk9tzyW9I/VKsAhP7p5iI/AAAAAAAACOg/MAj7w5JnRi0/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B3.03.54%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;a href=&quot;http://bl.ocks.org/mbostock/4062045&quot;&gt;D3's force plots&lt;/a&gt; are just a fun way to draw connection matrices. They tend to look OK as long as the connectivity of the graph isn't too high. Maybe that's a good way to judge whether you're interested in too many things!
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Death to the Old-Fashioned CV&lt;/h4&gt;
&lt;p&gt;
        I did succumb to the peer pressure and include &lt;a href=&quot;http://hellowillmcfadden.appspot.com#boringpage&quot;&gt;a link to my paper CV&lt;/a&gt; too at the end. Hopefully someday there will be a better way, but for now I think it's worthwhile to show off my not-too-shabby credentials in the classic style.
    &lt;/p&gt;

</description>
        <pubDate>Mon, 05 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/a-better-linkedin/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/a-better-linkedin/</guid>
        
        <category>data science</category>
        
        <category>visualization</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://4.bp.blogspot.com/-8kj16-cnC7o/VKYaElP2m3I/AAAAAAAACJw/ql9jVVPZFhI/network.png</image>
        <title>Wire Network</title>
        <description>&lt;p&gt;
        For the past 10 years or so, I've been saving up my broken metal guitar strings. (For the record, I know I'm a packrat.) A couple of weeks ago, I finally put them to use on this Wire Netowrk Sculpture.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-IQmsl15IlaU/VKYaFC0cbhI/AAAAAAAACJ0/DCs_acosnj0/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The inspiration comes from my job studying &lt;a href=&quot;http://en.wikipedia.org/wiki/Biopolymer&quot;&gt;biopolymer&lt;/a&gt; networks in the &lt;a href=&quot;en.wikipedia.org/wiki/Cytoskeleton&quot;&gt;cellular cytoskeleton&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://scienceblogs.com/transcript/wp-content/blogs.dir/365/files/2012/04/i-3b17600bb332ac6fd1410b4161368c74-emfig2.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        It sounds complicated, but basically it's just a bunch of microscopic wires that are all stuck together. I'm more-or-less studying how cell's change shape when you push on them.
    &lt;/p&gt;
&lt;p&gt;
        Hopefully, the sculpture makes it a little easier to imagine what I'm working on. I'm hoping to submit it in a Science/Art Competition coming up this spring at my school.
    &lt;/p&gt;
&lt;a href=&quot;http://3.bp.blogspot.com/-PSVVtIvd6Ek/VKb0ctyIVPI/AAAAAAAACKo/nc98n1nJIuY/s1600/3595809_b.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-PSVVtIvd6Ek/VKb0ctyIVPI/AAAAAAAACKo/nc98n1nJIuY/s1600/3595809_b.png&quot; style=&quot;display:none&quot;/&gt;&lt;/a&gt; &lt;br/&gt;
</description>
        <pubDate>Sat, 03 Jan 2015 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2015/01/wire-network/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2015/01/wire-network/</guid>
        
        <category>art</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://4.bp.blogspot.com/-vkLL0Xgx53M/VKwsofqeMAI/AAAAAAAACPQ/yuGHlTiJTSI/wallgraph_front.png</image>
        <title>Graph Theory of Wall Decor</title>
        <description>&lt;p&gt;
        This is just a short post about a hallway wall decoration I made over the weekend. It's supposed to resemble a &lt;a href=&quot;http://en.wikipedia.org/wiki/Network_theory&quot;&gt;network graph&lt;/a&gt;, linking the different pieces together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-vkLL0Xgx53M/VKwsofqeMAI/AAAAAAAACPQ/yuGHlTiJTSI/s1600/wallgraph_front.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Basically I had a lot of unrelated stuff to put on our last empty wall and I needed a clever way to get it all on there. I hope you find it as amusing as I do.
    &lt;/p&gt;
&lt;p&gt;
        For closeups of the individual items that I stitched together, you can check &lt;a href=&quot;https://plus.google.com/photos/103585488893025173441/albums/6101303480819525617&quot;&gt;this photo album&lt;/a&gt; on Google+. &lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-MUXg3Mc6wO8/VKrBNbktU0I/AAAAAAAACM4/GXUA-wYINEk/s1600/wallgraph_front.png&quot; style=&quot;display:none&quot;/&gt;&lt;br/&gt;
&lt;/p&gt;</description>
        <pubDate>Wed, 31 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/graph-theory-of-wall-decor/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/graph-theory-of-wall-decor/</guid>
        
        <category>art</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://4.bp.blogspot.com/-flG2HLm3sdw/VKMlSnwVzKI/AAAAAAAABQA/jjtWOSHlH5Y/Screen%2BShot%2B2014-12-30%2Bat%2B4.20.32%2BPM.png</image>
        <title>RASER Curriculum</title>
        <description>&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-flG2HLm3sdw/VKMlSnwVzKI/AAAAAAAABQA/jjtWOSHlH5Y/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B4.20.32%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I'm running the Ray After School Electronics and Robotics (RASER) Program at Ray Elementary this Winter. The program is going to culminate with a competition on building an Arduino based security system. And each week before that will have a session on one of the sub-components of the project.
    &lt;/p&gt;
&lt;p&gt;
        Here are the project titles, and I'll update with links to descriptions as I build them.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html&quot;&gt;Week 1: LED circuits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-2-led-dimmers-and-switches.html&quot;&gt;Week 2: LED dimmers and switches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-3-arduino-led-blinker.html&quot;&gt;Week 3: Arduino LED blinker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-4-arduino-led-passcode-pad.html&quot;&gt;Week 4: Arduino LED Passcode Pad - Part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/02/raser-week-5-review-game.html&quot;&gt;Week 5: Review Game&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/02/raser-week-5-arduino-led-passcode-pad.html&quot;&gt;Week 6: Arduino LED Passcode Pad - Part 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week 7: Review LED Passcode pad &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/03/raser-week-8-arduino-trip-wire.html&quot;&gt;Week 8: Arduino trip wire&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/03/week-9-laser-activated-trip-wire.html&quot;&gt;Week 9: Laser activated trip switch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week 10: Arduino Body heat detector &lt;/li&gt;
&lt;li&gt;Week 11: Arduino security competition &lt;/li&gt;
&lt;li&gt;Week 12: Arduino security competition &lt;/li&gt;
&lt;li&gt;Week 13: Arduino security competition &lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;
</description>
        <pubDate>Tue, 30 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/raser-curriculum/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/raser-curriculum/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://3.bp.blogspot.com/-WvR0IUoXD1Y/VKMHxZ7UxbI/AAAAAAAABMQ/_kAvN5N_chs/Screen%2BShot%2B2014-12-30%2Bat%2B2.14.01%2BPM.png</image>
        <title>Quantum Gambling Game</title>
        <description>&lt;style&gt;
#markdown img.quantum_im {
    width:8%;
    margin:1%;
    margin-bottom:0;
    display:inline;
}
#markdown input.quantum_input {
    width:8%;
    margin:1%;
    font-size:12px;
    display:inline;
}
&lt;/style&gt;
&lt;p&gt;
    Have you ever heard of quantum computing? Know what makes it so special? Well, many scientists (and their funding agencies) are hoping that quantum computing's secrets just might help &lt;a href=&quot;http://www.inc.com/will-bourne/d-waves-dream-machine.html&quot;&gt;get them rich&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    I can't promise you that. But I can share this quantum gambling game I made with you. Although it looks simple enough on the surface, this betting game actually reveals an interesting application of &lt;a href=&quot;http://en.wikipedia.org/wiki/Quantum_computing&quot;&gt;quantum computing&lt;/a&gt;, the science turning &quot;spooky&quot; physics into solving real problems.
&lt;/p&gt;
&lt;p&gt;
    I'll explain more about strategy and its relation to quantum algorithms below, but for now, try the game out! Read below for more instructions.
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;div style=&quot;border:1px solid #AAA;border-radius:5px;width:500px;margin:auto;text-align:center&quot;&gt;
    &lt;h4 style=&quot;text-align:center&quot;&gt; Guess the Quantum Card! &lt;/h4&gt;
    &lt;br /&gt;
    &lt;div&gt;&lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card1&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card2&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card3&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card4&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card5&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card6&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card7&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card8&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
    &lt;/div&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet1&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet2&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet3&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet4&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet5&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet6&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet7&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet8&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;div id=&quot;results&quot; style=&quot;display:none&quot;&gt;

    &lt;/div&gt;
    &lt;div&gt;
        &lt;button id=&quot;paybut&quot; onclick=&quot;payup()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Trade Bets&lt;/button&gt;
        &lt;button id=&quot;rebut&quot; onclick=&quot;regame()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Restart&lt;/button&gt;
        &lt;button id=&quot;startbut&quot; onclick=&quot;startgame()&quot; style=&quot;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Place Bets&lt;/button&gt;
        &lt;button id=&quot;swapbut&quot; onclick=&quot;swap()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Redistribute&lt;/button&gt;
        &lt;button id=&quot;endbut&quot; onclick=&quot;endgame()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;End Game&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;h4&gt;Instructions&lt;/h4&gt;
&lt;p&gt;
    The goal is to get the biggest bet you can onto the Ace of Spades, and to keep your bet off of the decoy cards. But the trick is that during the game none of the cards are ever revealed to you.
&lt;/p&gt;
&lt;p&gt;
    You start the game by placing your initial bets on whatever cards you want.
&lt;/p&gt;
&lt;p&gt;
    After that, you have your choice of two moves, which you get to repeat until you decide you're done.
&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;&lt;b&gt;Trade Bets&lt;/b&gt;, meaning any money on the losing cards goes to the dealer, while the money on the winning card stays the same. &lt;/li&gt;
    &lt;li&gt;&lt;b&gt;Redistribute&lt;/b&gt;, meaning you reverse all the bets around the average bet value. So the dealer's money comes back to your side of the average, and vice versa. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
    The redistribute move might seem confusing, so here's what it does graphically.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-QihHMwqvsF8/VKLpaC0D5uI/AAAAAAAABL4/dbQ1ZZBLngk/s1600/mean_invert_grover.gif&quot; title=&quot;
How the Redistribute Move Works

 &quot; /&gt;
&lt;p&gt;
    During the redistribution, the dealer basically just moves the money around so that places where the money is on the dealer's side shift back to places where you still have money. The math can get really complicated based on how many different bets there are going, but it boils down to just flipping the bets like in the graphic.
&lt;/p&gt;
&lt;p&gt;
    Throughout the game, all the money stays on the table. But unfortunately for you, even though the money is changing hands, the dealer never tells you whether a given bet is yours or his on the table.
&lt;/p&gt;
&lt;p&gt;
    Whenever you want, you can end the game. At that point, the dealer checks how much money there is on the winning card and gives you back two times that amount. He takes everything else.
&lt;/p&gt;
&lt;h5 style=&quot;text-align:center;font-size:1.5em&quot;&gt;So can you play?&lt;/h5&gt;
&lt;h5 style=&quot;text-align:center;font-size:1.2em&quot;&gt;And can you figure out how to win... every time?&lt;/h5&gt;
&lt;br /&gt; &lt;br /&gt;&lt;br /&gt;
&lt;h4&gt;Some Quantum Hints&lt;/h4&gt;
&lt;p&gt;
    OK, so you're stumped. Here are some hints.
&lt;/p&gt;
&lt;p&gt;
    I mentioned that it's possible to win &lt;i&gt;every&lt;/i&gt; time—not just &lt;i&gt;most&lt;/i&gt; of the time. That should be a clue that the game doesn't rely on guessing.
&lt;/p&gt;
&lt;p&gt;
    A second clue to point out is that the Trade Bets operation &quot;undoes itself.&quot; That means that if you Trade Bets twice in a row, that's the same thing as not trading bets at all. Take a minute to understand why that's true.
&lt;/p&gt;
&lt;p&gt;
    Finally, I'll just tell you that repeating the Redistribute operation twice in a row isn't necessary to solve the problem.
&lt;/p&gt;
&lt;p&gt;
    If you really don't have any idea what I'm talking about, check out &lt;a href=&quot;#expa&quot; onclick=&quot;expa()&quot;&gt;this appendix&lt;/a&gt; at the bottom of the page for more info.
&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;Now give it another try.
&lt;/p&gt;
&lt;h4&gt;Time out: how is quantum computing supposed to help me? &lt;/h4&gt;
&lt;p&gt;
    For quantum computing, it's all about using fewer iterations to get the same job done. A quantum algorithm aims to take a problem that would take billions of calculations on a classical computer and turn it into just hundreds of quantum calculations.
&lt;/p&gt;
&lt;p&gt;
    For example, how long could it take you to find the card by guessing in the classical world? If there are 8 cards you could have to guess 8 times. But for the quantum algorithm on which this game is based, you would be guaranteed to find the card with just 2 guesses. How does it do that? Well, you'll have to read on to find out.
&lt;/p&gt;
&lt;p&gt;
    But with the 2 repetitions in mind, try the game out again.
&lt;/p&gt;
&lt;h4 id=&quot;howtowin&quot;&gt;How to win the Game&lt;/h4&gt;
&lt;p&gt;
    The way to win every time starts with eliminating all guessing. What I mean by &quot;no guessing&quot; is that the initial configuration of bets must be the same for every card. For example, you can just bet 1 on each card.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-00cL8az7VaQ/VKMHxaKokFI/AAAAAAAABMI/VZN_gyUSRps/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B2.13.20%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    After this we just start trying operations. Because Redistributing on all 1s doesn't change the bet values, we know that we start by Trading Bets with the dealer and then we Redistribute. We could redistribute over and over, but it turns out that won't help (although I don't know why. If you know, put it in the comments). At this point, we just have to toggle back and forth between Trading and Redistributing operations.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-pMJqB4nRif8/VKMHxSB8B6I/AAAAAAAABMM/e8VE4AhdiYs/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B2.13.53%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    If we repeat those operations just the right number of times, our initial bets will work their way onto the winning card. Now we just need to figure out how many times to repeat those moves.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-WvR0IUoXD1Y/VKMHxZ7UxbI/AAAAAAAABMQ/_kAvN5N_chs/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B2.14.01%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    It turns out that the right number of repetitions is two. There's a reason that you have to repeat the pair of operations exactly twice, but I have to wait until after I explain the quantum mechanics to get to that. For now, just try playing it again and show yourself that it actually does work.
&lt;/p&gt;
&lt;br /&gt;
&lt;h4&gt;Quantum Information and Grover's Algorithm&lt;/h4&gt;
&lt;p&gt;
    The two moves in the game are really just classical ways to describe more &lt;a href=&quot;http://www.technologyreview.com/view/427174/einsteins-spooky-action-at-a-distance-paradox-older-than-thought/&quot;&gt;&quot;spooky&quot;&lt;/a&gt; operators from quantum computing. And the money gained at the end of the game is analogous to your probability of finding a solution to the problem using a &lt;a href=&quot;http://en.wikipedia.org/wiki/Brute-force_search&quot;&gt;search algorithm&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    The Trading Bets operation would be called a Quantum Oracle, which by itself doesn't tell you which solution is right, but will confirm if you have the right answer at the end (by giving you money or taking it). And the Redistribute move is a Grover Diffusion Operator, which essentially lets information about the correct answer &quot;diffuse&quot; from wrong answers. (Note that this is way more complicated than I can explain, and to understand it for real you might need to do &lt;a href=&quot;http://en.wikipedia.org/wiki/Quantum_computing&quot;&gt;more reading&lt;/a&gt; (or even &lt;a href=&quot;https://www.edx.org/course/quantum-mechanics-quantum-computation-uc-berkeleyx-cs-191x#.VKL7kAJBvQ&quot;&gt;take a class&lt;/a&gt;) on the subject.)
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/a/ae/Grovers_algorithm.svg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    When you repeat these two operations back to back, you end up performing &lt;a href=&quot;http://en.wikipedia.org/wiki/Grover%27s_algorithm&quot;&gt;Grover's Algorithm&lt;/a&gt;, a technique proven to find the right information in a database (i.e. the cards). Lov Grover (not &lt;a href=&quot;http://muppet.wikia.com/wiki/Grover,_Messenger_of_Love&quot;&gt;Love, Grover&lt;/a&gt;) discovered this way of finding information back in the 90s. He was working on a method to compute inverses by letting a quantum function (i.e. the dealer) perform operations (i.e. Trading Bets) that we couldn't see in the classical world (i.e. on our side of the betting table). What was amazing about it was that it allowed you to perform the calculation many fewer times than you would using a classical (asking &quot;Hey, is it that card?&quot;) approach.
&lt;/p&gt;
&lt;p&gt;
    In the above game, you only need to repeat the procedure 2 times. Whereas to find the card by guessing, you might have to try 8 times. If you want to learn more about why it's exactly 2, I recommend &lt;a href=&quot;http://arxiv.org/pdf/quant-ph/0504012.pdf&quot;&gt;this in depth article&lt;/a&gt; on the subject.
&lt;/p&gt;
&lt;p&gt;
    (And to learn more about Grover's algorithm with cool visualizations, check out &lt;a href=&quot;http://twistedoakstudios.com/blog/Post2644_grovers-quantum-search-algorithm&quot;&gt;this tutorial&lt;/a&gt; from &lt;a href=&quot;http://twistedoakstudios.com/index.php&quot;&gt;Twisted Oak Studios&lt;/a&gt;.
&lt;/p&gt;
&lt;br /&gt;
&lt;h4&gt;So what's the big deal?&lt;/h4&gt;
&lt;p&gt;
    In the end, what's really important about Grover's algorithm is that this isn't just a mathematical artifact. The crazy laws of quantum mechanics somehow make it possible to perform these operation on real materials. This means that it can be used to find real answers to questions that we can't solve fast enough with current computers.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, building quantum computers is turning out to be &lt;a href=&quot;http://gizmodo.com/why-programming-a-quantum-computer-is-so-damn-hard-1188316086&quot;&gt;insanely hard&lt;/a&gt; so currently we can still do better with classical computers. But hopefully &lt;a href=&quot;http://www.wired.com/2014/10/quantum-computing-close/&quot;&gt;someday soon&lt;/a&gt;, a big breakthrough will make this technology possible. &lt;p&gt;
        I hope this whetted your appetite to learn more about quantum computing. Or at the least, it's a fun little puzzle to show your friends.
    &lt;/p&gt;
    &lt;br /&gt;
    &lt;h4&gt;Playing more with quantum computers&lt;/h4&gt;
    &lt;p&gt;
        If you want to work more on this, feel free to check out my code. For starters, you can find the javascript for the game on CodePen &lt;a href=&quot;http://codepen.io/wmcfadd2/details/YPpqBr/&quot;&gt;here&lt;/a&gt;. If you're more interested about the quantum details, you can also check out &lt;a href=&quot;https://github.com/lots-of-things/quantum-comp&quot;&gt;this project&lt;/a&gt; on Github that implements quantum computing gates as MATLAB matrix operations.
    &lt;/p&gt;
    .&lt;br /&gt;.&lt;br /&gt;.&lt;br /&gt;
    &lt;div id=&quot;expa&quot; onclick=&quot;expa()&quot; style=&quot;cursor:pointer&quot;&gt;
        &lt;h4&gt;Appendix: Basic Primer on the Quantum Betting Game&lt;/h4&gt;
        &lt;p&gt;
            In case you need a little background about betting and guessing games, &lt;a href=&quot;#expa&quot;&gt;here's&lt;/a&gt; a little Appendix that will help fill you in.
        &lt;/p&gt;
    &lt;/div&gt;
    &lt;br /&gt;
&lt;/p&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
function expa() { if (document.getElementById(&quot;appendix&quot;).style.display == &quot;inline&quot;) { document.getElementById(&quot;appendix&quot;).style.display = &quot;none&quot; } else { document.getElementById(&quot;appendix&quot;).style.display = &quot;inline&quot;; } }
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var total = 0;
var bets = [];
var index;
var nrm;
var tog;

function startgame() {
    document.getElementById(&quot;startbut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;paybut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;swapbut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;endbut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;bet1&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet2&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet3&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet4&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet5&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet6&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet7&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet8&quot;).readOnly = &quot;true&quot;;
    bets[0] = document.getElementById(&quot;bet1&quot;).value;
    bets[1] = document.getElementById(&quot;bet2&quot;).value;
    bets[2] = document.getElementById(&quot;bet3&quot;).value;
    bets[3] = document.getElementById(&quot;bet4&quot;).value;
    bets[4] = document.getElementById(&quot;bet5&quot;).value;
    bets[5] = document.getElementById(&quot;bet6&quot;).value;
    bets[6] = document.getElementById(&quot;bet7&quot;).value;
    bets[7] = document.getElementById(&quot;bet8&quot;).value;
    index = Math.floor((Math.random() * 8));
    nrm = 0;
    tog = 0;
    for (i = 0; i &lt; bets.length; i++) {
        nrm = nrm + Math.pow(bets[i], 2);
        tog = tog + Math.abs(bets[i]);
    }
    nrm = Math.sqrt(nrm);
    for (i = 0; i &lt; bets.length; i++) { bets[i] = bets[i] / nrm; }
}

function payup() {
    for (i = 0; i &lt; bets.length; i++)
        {
            if (i != index) bets[i] = -bets[i]; }
            refresh();
        }

function swap() { avg = 0; for (i = 0; i &lt; bets.length; i++) { avg = avg + 1 * bets[i]; } avg = avg / 8; for (i = 0; i &lt; bets.length; i++) { bets[i] = 2 * avg - bets[i]; } refresh(); }

function refresh() {
    sm = 0;
    for (i = 0; i &lt; bets.length; i++) {
        sm = sm + Math.abs(bets[i]);
    }
    if (sm &gt; 0) {
        scl = tog / sm;
    } else {
        scl = 1;
    }
    document.getElementById(&quot;bet1&quot;).value = Math.abs(scl * bets[0]);
    document.getElementById(&quot;bet2&quot;).value = Math.abs(scl * bets[1]);
    document.getElementById(&quot;bet3&quot;).value = Math.abs(scl * bets[2]);
    document.getElementById(&quot;bet4&quot;).value = Math.abs(scl * bets[3]);
    document.getElementById(&quot;bet5&quot;).value = Math.abs(scl * bets[4]);
    document.getElementById(&quot;bet6&quot;).value = Math.abs(scl * bets[5]);
    document.getElementById(&quot;bet7&quot;).value = Math.abs(scl * bets[6]);
    document.getElementById(&quot;bet8&quot;).value = Math.abs(scl * bets[7]);
}

function endgame() {
    val = 0;
    for (i = 0; i &lt; bets.length; i++) { if (i != index) { val = val - Math.abs(bets[i]); } else { val = val + 2 * Math.abs(bets[i]); } } sm = 0;
    for (i = 0; i &lt; bets.length; i++) {
        sm = sm + Math.abs(bets[i]);
    }
    scl = tog / sm;
    val = val * scl;
    total = total + val;
    if (val &gt; 0) {
        document.getElementById(&quot;results&quot;).innerHTML = &quot;Game over.  You won $&quot; + val.toFixed(2);
    } else {
        document.getElementById(&quot;results&quot;).innerHTML = &quot;Game over.  You lost $&quot; + (-val).toFixed(2);
    }
    if (total &gt; 0) {
        document.getElementById(&quot;results&quot;).innerHTML = document.getElementById(&quot;results&quot;).innerHTML + &quot;. &lt;br /&gt; Total Winnings= $&quot; + total.toFixed(2);
    } else {
        document.getElementById(&quot;results&quot;).innerHTML = document.getElementById(&quot;results&quot;).innerHTML + &quot;. &lt;br /&gt; Total Winnings= -$&quot; + -total.toFixed(2);
    }
    document.getElementById(&quot;results&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;rebut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;paybut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;swapbut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;endbut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;card&quot; + (index + 1)).src = &quot;http://upload.wikimedia.org/wikipedia/commons/e/e2/Aceofspades.png&quot;;
}

function regame() {
    document.getElementById(&quot;card&quot; + (index + 1)).src = &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot;;
    document.getElementById(&quot;rebut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;results&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;startbut&quot;).style.display = &quot;inline&quot;;
    bets = [0, 0, 0, 0, 0, 0, 0, 0];
    refresh();
    document.getElementById(&quot;bet1&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet2&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet3&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet4&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet5&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet6&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet7&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet8&quot;).readOnly = &quot;&quot;;
}
&lt;/script&gt;</description>
        <pubDate>Mon, 29 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/quantum-gambling-game/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/quantum-gambling-game/</guid>
        
        <category>games</category>
        
        <category>quantum</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://4.bp.blogspot.com/-KcNroociJ_4/VKBYiGSAwQI/AAAAAAAABDA/x11ijF3jW0o/14%2B-%2B1</image>
        <title>PVC Easel</title>
        <description>&lt;p&gt;
        One of my gifts to my girlfriend this year was a set of paints and brushes that I found on &lt;a href=&quot;http://www.craigslist.org/about/sites&quot;&gt;craigslist&lt;/a&gt;. She'd been holding on to some canvases, but it didn't look like she'd ever do anything with them unless somebody went out and got the paints for her.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-KcNroociJ_4/VKBYiGSAwQI/AAAAAAAABDA/x11ijF3jW0o/s1600/14%2B-%2B1&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To make the gift all the more special, I decided to build her an easel too. I've had lots of left over fragments of PVC in my closet for a good two years now. And I'm finally just using up the last of them on this project.
    &lt;/p&gt;
&lt;p&gt;
        The easel design is extremely simple. For every connection, I just used a big hole on one side and a screw hole on the other. Everything locks into place and it stands upright.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-3rYj4HP8JCM/VKBQBuKeABI/AAAAAAAABBw/cv8zuwcastM/s1600/2014-12-28%2B11.41.30.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        One cool feature that we knew we needed for our little apartment was the ability to collapse it and store it away. Just removing one screw from the top corner lets the whole thing fold up like this.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-0bTMyyJfE8Y/VKBQBtCT8QI/AAAAAAAABBw/ZhtamwCuAmU/s1600/2014-12-28%2B11.46.54.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The last step is going to be cutting this piece of wood down and coating it to make a little painter's pallet.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-SQVIe-V9Vtk/VKBQBtqHQ6I/AAAAAAAABBw/wfVGJUU0F6o/s1600/2014-12-28%2B11.39.41.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The gift went over great and Claire's really exited to try it out. So hopefully soon, I'll start putting up paintings that she makes.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 28 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/pvc-easel/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/pvc-easel/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://1.bp.blogspot.com/-0cAr7rofgBk/VJ9Aml-NqBI/AAAAAAAAA_Y/5fi1jvpwTxA/IMG_0154.JPG</image>
        <title>Solar battery charger &amp;amp; flower pot (first try)</title>
        <description>This is my first attempt at attaching a solar battery charger like &lt;a href=&quot;http://lifehacker.com/5752731/built-a-4-diy-solar-battery-charger&quot;&gt;this one&lt;/a&gt; to a flower pot.  The style of the pot isn't exactly what I was looking for.  I was hoping to have the top at an angle that faced the sun better, but my friend who made the pots couldn't get them to stay flat during baking.  The next edition will have a better pot and hopefully will work to charge cell phones as well. &lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-0cAr7rofgBk/VJ9Aml-NqBI/AAAAAAAAA_Y/5fi1jvpwTxA/s1600/IMG_0154.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Sat, 27 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/solar-battery-charger-flower-pot-first/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/solar-battery-charger-flower-pot-first/</guid>
        
        <category>misc</category>
        
        <category>energy</category>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://1.bp.blogspot.com/-NHNTr6jR-Zo/VJi2B-i4GwI/AAAAAAAAA9Q/5s2a-6kX5w4/2014-12-21%2B14.58.36.jpg</image>
        <title>Mo's Tool Pouch</title>
        <description>So in keeping with the holiday spirit I'm now showing off the little bag I made for my girlfriend's mom. She's an avid &lt;a href=&quot;http://lillstreet.com/department/ceramics-sculpture&quot;&gt;ceramicist&lt;/a&gt; so I made this bag to keep her tools. &lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-NHNTr6jR-Zo/VJi2B-i4GwI/AAAAAAAAA9Q/5s2a-6kX5w4/s1600/2014-12-21%2B14.58.36.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    Over the summer she got me a golf bag to replace my old rundown broken one. (Oh how I wish I had a picture of the old one. It was kind of embarrassing. It looked a little something like this except with a gaping 2 foot hole in the side from which clubs would occasionally fall out.) &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-1TtLY0oCtww/VJH9M2rbiZI/AAAAAAAAA8s/opY6twDVm7E/s1600/m18uBHjUbHQ4tsfQuGPeI6g.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    I figured she'd really like it if I reused the leather to make her a gift. I was originally thinking about just a leather belt until my girlfriend actually came up with the idea for a tool pouch for her ceramics equipment.
&lt;/p&gt;
&lt;h4&gt;How I made it&lt;/h4&gt;
&lt;p&gt;
    The exterior comes from three 4 by 17ish swaths of faux leather/canvas pulled from different intact parts of the bag. I sewed them together lengthwise and rounded the edges for the zipper to go around smoothly.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-u3gnN1f3Vvo/VJi2CGdtMWI/AAAAAAAAA9U/k-ZnGNPgLwk/s1600/2014-12-21%2B14.59.10.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    The zipper came from a mid 90s computer case that I condensed to create a 2010s computer case. In that project, I had removed a section which left over a small ribbon of zipper that I could reuse. This didn't leave too much edge for the zipper so my stitching had to be pretty precise to hold.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-WoB5YewGNNk/VJi2C8LY1qI/AAAAAAAAA9k/XZ54E9JKauA/s1600/2014-12-21%2B14.59.50.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    On the inside I wanted to have little tool holder straps for ceramics tools to fit in. I didn't know the exact sizing because I couldn't find a casual way to bring up the dimensions of her ceramics tools without arousing suspicion. So I guessed that I could put strips in two orientations and most things would fit somehow.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-RZ2jN5W141c/VJi2B1_kfaI/AAAAAAAAA9c/IjHiJPDWpdA/s1600/2014-12-21%2B14.58.54.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    Interestingly I learned that I would have to add decorative stitching on the outside to continue my lines because otherwise it just looked really bad.
&lt;/p&gt;
&lt;p&gt;
    I'm really pleased with the result. Sewing is a new skill to me, but it's worth it to learn. &lt;br /&gt;
&lt;/p&gt;</description>
        <pubDate>Sat, 27 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/mos-tool-pouch/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/mos-tool-pouch/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://3.bp.blogspot.com/-ZOlGCYGGU-E/VJi9pRYu9VI/AAAAAAAAA90/V-jiITbZhJE/2014-12-21%2B15.02.04.jpg</image>
        <title>Modernizing my computer case</title>
        <description> I had an old laptop case from the 90s that I wanted to update for use.  Mostly I just wanted to shrink it down to a reasonable size for a modern laptop. Here's the result. &lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-ZOlGCYGGU-E/VJi9pRYu9VI/AAAAAAAAA90/V-jiITbZhJE/s1600/2014-12-21%2B15.02.04.jpg&quot; title=&quot; &quot;/&gt;
 This is what the old case looked like.  Big and clunky. &lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-xHT7ZbYyI-Q/VJi-Wt0ki5I/AAAAAAAAA98/nwnBz_pJB84/s1600/computer%2Bcases%2Bsamsonite%2B001.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Sat, 27 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/modernizing-my-computer-case/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/modernizing-my-computer-case/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://2.bp.blogspot.com/-LJVJObaTKi8/VJjccD3eRfI/AAAAAAAAA-Y/iUFX8Ka01to/2014-12-22%2B16.41.48.jpg</image>
        <title>Introducing Dave's Grill-It-All</title>
        <description>&lt;p&gt;
        My girlfriend's dad (Dave) is really into grilling (&lt;a href=&quot;http://www.bonappetit.com/entertaining-style/pop-culture/article/tv-dads-kitchen-skills&quot;&gt;as are all dads&lt;/a&gt;). So for Christmas we figured we'd go in together to get him one of these grill attachments that he had been talking about.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.kettlepizza.com/v/vspfiles/assets/images/home_tailgate_image_2.jpg&quot; style=&quot;width:200px&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We looked into a &lt;a href=&quot;http://store.weber.com/accessories/category/cook/cookware/1100&quot;&gt;Kettle Rotisserie&lt;/a&gt; that cost $160 and a &lt;a href=&quot;http://www.kettlepizza.com/KettlePizza-Basic-KPB-22-p/kpb-22.htm&quot;&gt;Kettle Pizza&lt;/a&gt; that came in at $150 (&lt;a href=&quot;http://www.kettlepizza.com/Serious-Eats-KettlePizza-Special-Edition-Kit-p/kpse-22.htm&quot;&gt;or more&lt;/a&gt;).
    &lt;/p&gt;
&lt;p&gt;
        Now me being a man of limited means and boundless ambition, I decided to save a buck and build one myself.
    &lt;/p&gt;
&lt;p&gt;
        And then, I figured, while I'm at it, why not make a grill attachment that does both?
    &lt;/p&gt;
&lt;p&gt;
        After some troubleshooting and plan modifications (see below), I eventually arrived at Dave's Grill-It-All.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-NtbKNswnEzk/VKBarFAaBdI/AAAAAAAABCw/HOfF0GmGxlI/s1600/Screen%2BShot%2B2014-12-28%2Bat%2B1.31.22%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You can see the store-bought chicken that we were using to test it. This video shows the rotisserie in action, with commentary and camerawork from my girlfriend Claire.
    &lt;/p&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/VPnCM2lucXg?rel=0&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;h4&gt;Putting it Together&lt;/h4&gt;
&lt;p&gt;
        The plans (&lt;a href=&quot;https://github.com/lots-of-things/grill-it-all&quot;&gt;on github&lt;/a&gt;) show the sheet metal parts, all made by simply cutting, bending, drilling, and bolting (no welding or fancy stuff). Although the pizza oven could be made with just sheet metal, the rotisserie also required a motor and skewers, which is where the real difficulty came in.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-C9h4bXn3Gjo/VJjcJqFrS3I/AAAAAAAAA-Q/0AylvFG1XZo/s1600/2014-12-22%2B16.40.24.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The whole body and a few parts of the skewer were all constructed from two sheets of stainless steel sheet metal that I got from Home Depot for $10. Working sheet metal is really easy if you have a big shears at your disposal (&lt;a href=&quot;https://chemistry.uchicago.edu/page/facilities.html#machine&quot;&gt;thanks UChicago!&lt;/a&gt;). Other fancy stuff is nice, but you can do most stuff by hand. I'll do a post someday on hacking sheet metal without the proper equipment, but if you can't wait, check out &lt;a href=&quot;http://www.tractorsupply.com/know-how_Metalworking_working-with-sheet-metal-safety-tools-and-sheetmetal-projects&quot;&gt;these tips and techniques&lt;/a&gt;. Remember that sheet metal can be razor sharp so make sure to blunt corners and sharp edges as best you can.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-LJVJObaTKi8/VJjccD3eRfI/AAAAAAAAA-Y/iUFX8Ka01to/s1600/2014-12-22%2B16.41.48.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To make the rotisserie spin, I decided to use an old electric drill that had broken out of its case a few years back. I wasn't using it for anything else and I figured that would make inserting and removing the skewer easy. I hooked it up to one of my left over 12V DC power supplies with a switch.
    &lt;/p&gt;
&lt;p&gt;
        Getting the motor to stay put was a little bit of a trick because it didn't have any mounting points. I basically had to strap it in with a few left-over strips of sheet metal. I also added a layer of towel around it, to try to insulate some of the heat.
    &lt;/p&gt;
&lt;p&gt;
        The real engineering came in when I was building the skewer though. I had several problems: &lt;ol&gt;
&lt;li&gt;Get the skewers to attach to the grill and stay put. &lt;/li&gt;
&lt;li&gt;Get the skewers to hold the bird steady and rotate it. &lt;/li&gt;
&lt;li&gt;Get the skewers to connect up on the other side. &lt;/li&gt;
&lt;li&gt;Make it easy enough to get the bird on and mount the damn thing without burning the operator. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
            Ultimately, to solve these problems, I came up with the &quot;chopsticks&quot; model.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-hCjskui96Mg/VJjc8wW2IGI/AAAAAAAAA-c/HJrmpFhxT2A/s1600/2014-12-22%2B16.42.58.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            It basically works by skewering the bird at an inward angle from both sides so the skewers meet each other as they pass through. This secures the bird and gets the skewers to meet up on the other side. Unfortunately I still don't know how easy it is to work with compared to other rotisserie setups.
        &lt;/p&gt;
&lt;p&gt;
            Finally, I was able to get the skewers attached by rigging up this contraption.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-wGVDjdSyqjU/VJjdS4hfJOI/AAAAAAAAA-o/j9RSSCSXZqU/s1600/2014-12-22%2B16.43.16.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            It wound up being quite a trick to get the skewers to stay well connected to the motor. It involved rigging some odd attachments with these old gear parts from a broken sewing machine.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-yWmJ8LtzGh4/VJjdrrUD9YI/AAAAAAAAA-s/I8hBOjL82so/s1600/2014-12-22%2B16.44.00.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            I screwed those parts on tight to the skewers and to the shaft coming out of the drill motor. Then I joined them together by screwing two plates around them on both sides.
        &lt;/p&gt;
&lt;p&gt;
            Overall, the project took about a week. Now I'll just have to wait to try it out.
        &lt;/p&gt;
&lt;/p&gt;</description>
        <pubDate>Tue, 16 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/introducing-daves-grill-it-all/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/introducing-daves-grill-it-all/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://3.bp.blogspot.com/-qlw2VUtEIVo/VIXZPAgqMxI/AAAAAAAAA6A/ZsFmny0Rl-Y/1024px-Hangzhou_bike_sharing_station.jpg</image>
        <title>Predicting Bike Share Usage</title>
        <description>&lt;p&gt;
    I recently worked on a &lt;a href=&quot;https://www.kaggle.com/&quot;&gt;Kaggle&lt;/a&gt; competition while I was taking Coursera's &lt;a href=&quot;https://www.coursera.org/course/datasci&quot;&gt;Introduction to Data Science&lt;/a&gt;. Here's a quick summary of what I came up with.
&lt;/p&gt;
&lt;img alt=&quot;Hangzhou bike sharing station&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Hangzhou_bike_sharing_station.jpg/512px-Hangzhou_bike_sharing_station.jpg&quot; title=&quot;Payton Chung [CC BY (https://creativecommons.org/licenses/by/2.0)]&quot; width=&quot;512&quot;/&gt;
&lt;p&gt;
    The goal of this project was to come up with a system to predict how many bikes will be used during a given hour.
&lt;/p&gt;
&lt;p&gt;
    The bike share company provided us with historical data for two years, including hourly weather and weekend/holiday information as well as the number of bikes in use each hour. I tested my predictions against the hourly bike usage for the last week of every month.
&lt;/p&gt;
&lt;p&gt;
    Because there were slowly-varying trends in bike share popularity over this time, I decided that the most important factor was the average for a given hour over the past 5-10 days. I therefore, generated this statistic from the underlying dataset by performing a moving average. I then supplied the weather and holiday statistics along with the moving average as training data to implementations of a neural network and a random forest. The random forest performed better on my cross-validation set so I used it in my submission.
&lt;/p&gt;
&lt;p&gt;
    The data set was surprisingly small so I simply imported it into the memory of a MATLAB runtime environment. From there, I used a custom script to generate moving averages for every hourly timeslot and added that to the original dataset. These datasets could be fed directly to existing neural network and random forest packages contained in MATLAB. The data munging to create the moving average presented a slight difficulty.
&lt;/p&gt;
&lt;p&gt;
    The approach was simple but still allowed me to improve greatly over the baseline benchmark, reducing the mean error from 1.5 to 0.75. You can check out the &lt;a href=&quot;https://github.com/lots-of-things/biker-predict&quot;&gt;biker-predict&lt;/a&gt; code on github.
&lt;/p&gt;</description>
        <pubDate>Mon, 08 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/predicting-bike-share-usage/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/predicting-bike-share-usage/</guid>
        
        <category>data science</category>
        
        
      </item>
    
      <item>
        <image>https://opus.stedden.orghttp://1.bp.blogspot.com/-V0-qs1QmbXg/VIYjmqZZZKI/AAAAAAAAA6Q/Cy8C6MaNU3A/5716341932_1c5d7f234d_b.jpg</image>
        <title>A Simple Anagrammer</title>
        <description>&lt;div&gt;
A while back, I wrote a little python code that takes in a word and spits out a list of anagram words.  It kind of takes the fun out of generating anagrams, but it puts the fun back in by letting you figure out how I made them.  Could you do it a better way?  You can look at my &lt;a href=&quot;https://github.com/lots-of-things/simple-anagrammer&quot;&gt; simple-anagrammer &lt;/a&gt; code on github.
&lt;/div&gt;</description>
        <pubDate>Mon, 08 Dec 2014 00:00:00 -0600</pubDate>
        <link>https://opus.stedden.org/2014/12/a-simple-anagrammer/</link>
        <guid isPermaLink="true">https://opus.stedden.org/2014/12/a-simple-anagrammer/</guid>
        
        <category>games</category>
        
        
      </item>
    
  </channel>
</rss>
