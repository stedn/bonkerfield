<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bonkerfield</title>
    <description>personal information identity spacetime map</description>
    <link>https://bonkerfield.org</link>
    <atom:link href="https://bonkerfield.org/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 10 Mar 2020 09:52:41 -0700</pubDate>
    <lastBuildDate>Tue, 10 Mar 2020 09:52:41 -0700</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Viewfoil: Experimenting with Radical Transparency</title>
        <description>&lt;p&gt;
	I've been contemplating privacy and anonymity, and speculating on what those ideas will mean in the future of our society.  During conversations with my friends and family, I've started questioning whether maintaining strengthened privacy is possible, and more importantly, whether strengthened privacy is even still a good thing.
&lt;/p&gt; 
&lt;p&gt;
	But in the spirit of this site, I'm not just theorizing anymore.  I'm currently working on putting myself into an experiment on radical transparency.
&lt;/p&gt;
&lt;p&gt;
	I have a whole bunch of reasons why I think this is the right thing to do.  Below, I offer one &lt;strong&gt;apocalyptic horror story&lt;/strong&gt; that attempts to motivate why I want to try this experiment.   After that, I'll offer a little info about how I'm starting to put my transition into motion.
&lt;/p&gt;
&lt;p&gt;&lt;em&gt;
	tl;dr I think that privacy itself is a conspiracy of the powerful. I'm gonna try to bring back lifestreaming to advocate for a transparent society. I call it the &lt;a href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;viewfoil&lt;/a&gt; project.
&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;The world we live in&lt;/h4&gt; 
&lt;p&gt;
	It isn't super difficult to find ways to be terrified of how technology is mishaping modern life, in ways big and small. 
&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;corporations have too much access to our data&lt;/li&gt;
&lt;li&gt;it's stressful constantly projecting a perfect life on social media&lt;/li&gt;
&lt;li&gt;the internet spreads misinformation from both the ill-informed and the ill-intentioned&lt;/li&gt;
&lt;li&gt;we're all siloing our ideologies and politically radicalizing&lt;/li&gt;
&lt;li&gt;our attention spans have been completely annihilated&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
	The general response to these issues around dinner tables tends to be &quot;&lt;strong&gt;how can we return things to the good old days before all of this happened&lt;/strong&gt;?&quot;  I generally agree with the sentiment. If it were possible to reverse the overflowing of online life, I would do it.  But as things are, I don't think that society is going to become less digitally connected or more intellectually mature to handle ourselves properly. So I'm left pondering what I can do to contribute to a better world as it is.
&lt;/p&gt; 
&lt;p&gt;
	The suggestions that my friends keep proposing all seem to be based around a classic strategy&amp;mdash;build better defenses. We minimize our exposure to the ideas on the web, and return to our most trusted sources. We hide ourselves and make it harder for third parties to know what we're doing.  We develop tools that force us to disconnect from the devices that fuel our addictions.
&lt;/p&gt;
&lt;p&gt;
	Unfortunately, I believe that these are all bandaids, and that they aren't really capable of protecting us from the dangers that the online information exchange poses. I might be paranoid, but I see it playing out like other industries that have garnered massive power.
&lt;/p&gt;
&lt;p&gt;
	People with power and the capacity to exploit our digital connectivity will do it right up to the edge of what is legal. Attempts to regulate will place undue power with established players who will jockey for control of politicians who will grant loopholes. Attempts to outpace the capacity for manipulation will end up exhausting more and more of our resources. Every advance that lets us hide ourselves better, will let a Russian hacker, troll, or &lt;a href=&quot;https://a.ttent.io/n&quot;&gt;quasi-sentient AI&lt;/a&gt; hide themselves better. To combat them, we will need ever more all-encompassing mechanisms of monitoring, which will be exploited by technologists for our control. Only the wealthy will be able to adequately fight back against increasing digital surveillance. They will then use their privileged privacy to circumvent legal grey areas.  And the cycle will continue.
&lt;/p&gt; 
&lt;p&gt;
	This is a depressing situation that hopefully won't happen, but there isn't really any great safeguard against it.  So if we are heading toward a dystopian world of privacy arms races and corporate surveillance, is there really anything I can do?  
&lt;/p&gt;  

&lt;h4&gt;The truth shall set you free&lt;/h4&gt; 
&lt;p&gt;
	What if we go for the opposite approach?  What if we effectively flank our corporate overlords by demanding a complete end to privacy? Maybe we can imagine a utopian counterpoint to the above doomsday prophecy. It seems that most of the issues mentioned above can be ameliorated. 
&lt;/p&gt;
&lt;p&gt;
	I might hypothesize that in a fully transparent world, any attempts at clandestine manipulation could be nearly instantaneously uncovered. If you could see every piece of information connected to the person on the other end, you could instantaneously determine whether they were a real good-intentioned human or a Russian bot.  If our online behavior was globally accessible, any attempt by corporations to profile our behavior could be reverse engineered to filter such profiling. If our lives were fully transparent, there would be no need to stress over falsely curating our public personas on social media. 
&lt;/p&gt;
&lt;p&gt;
	Beyond this, there could be a whole host of unexplored public goods that would come of this too.  The societal harms that come from organized crime would disappear overnight.  It would become impossible for politicians and corporate executives to broker backroom deals that undermine the public good.  And on a topic closer to &lt;a href=&quot;https://www.color.com/&quot;&gt;my&lt;/a&gt; &lt;a href=&quot;https://anthem.ai/&quot;&gt;heart&lt;/a&gt;, if everyone's medical information was universally accessible, it would make it extremely simple for researchers to uncover exactly what the best medical decision is for each person.
&lt;/p&gt;

&lt;p&gt;
	Of course, there are still major systemic roadblocks that prevent this kind of privacy from being possible. Full medical histories can't be revealed because it would lead to widespread discrimination and economic harm to vulnerable individuals. There are still many &lt;a href=&quot;https://www.businessinsider.com/economist-intelligence-unit-2017-democracy-index-worst-countries-2018-1&quot;&gt;extant&lt;/a&gt; &lt;a href= &quot;https://en.wikipedia.org/wiki/List_of_totalitarian_regimes&quot;&gt;despotic&lt;/a&gt; governments that would exploit this kind of information. And there are large numbers of people who casually break minor laws each day&lt;a title=&quot;though I would argue that such laws really ought to be reversed anyway, and universal transparency would make that clear&quot;href=&quot;&quot; onclick=&quot;return false;&quot;&gt;[*]&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
	We are not ready for global transparency yet.  However, I am in a place of unique privilege where I can move myself much closer to a life open to total external inspection.
&lt;/p&gt;
&lt;p&gt;
	If I believe that this future would be better, I simply have to start experimenting to see if it's possible to attain.
&lt;/p&gt;

&lt;h4&gt;Viewfoil&lt;/h4&gt; 
&lt;p&gt;
	To do this, I've been putting in motion a plan to make any and all information about my life accessible to anyone who cares to look.  A lot of people &lt;a href=&quot;https://en.wikipedia.org/wiki/Lifestreaming&quot;&gt;have done this before&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantified_self&quot;&gt;in various forms&lt;/a&gt; so I don't think it's that bold of an idea.  But like a good millennial, I don't just want to do it, I want to advocate for it. 
&lt;/p&gt;
&lt;p&gt;
	I've outlined the goals I'm trying to work towards during my first year on the project.
&lt;/p&gt;
&lt;ul&gt;
	&lt;li&gt;Start revealing an unfiltered version of my life on social media&lt;/li&gt;
	&lt;li&gt;Start writing my ideas as they are, not as I expect others to want them to appear&lt;/li&gt;
	&lt;li&gt;Reveal all my secrets and dirty laundry to everyone I know&lt;/li&gt;
	&lt;li&gt;Carefully get consent to incorporate information about my friends and family&lt;/li&gt;
	&lt;li&gt;Work towards being able to share more detailed private information without compromising anyone's safety&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
	There's a lot to do for each of these, and I will be elaborating on them (at length) in the future. I don't want this to distract from the content here so I'm building a separate site called &lt;a href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;Viewfoil&lt;/a&gt; where I'm going to be doing the heavy lifting.  &lt;strong&gt;Viewfoil&lt;/strong&gt; is the technical word for the transparencies from the overhead projectors we used to have back in grade school.  I think it's a fitting name for a &lt;em&gt;project&lt;/em&gt; about being more &lt;em&gt;transparent&lt;/em&gt;.
&lt;/p&gt;
&lt;a style=&quot;border:none;box-shadow:none&quot; href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;&lt;img style=&quot;width:30%;&quot; src=&quot;/assets/images/main/viewfoil.png&quot;/&gt;&lt;/a&gt;

&lt;p&gt;
	Needless to say, I'm sure I will encounter myriad issues that prevent me from exploring this entirely, but I'm excited to see just where this starts to break down.  I'm quite scared about a lot of things, but hopefully if I move slowly and carefully, I'll learn enough as I go along to survive this thing.
&lt;/p&gt;
&lt;p&gt;
	This is going to be an interesting year.  Check out &lt;a href=&quot;https://viewfoil.bonkerfield.org/&quot;&gt;viewfoil&lt;/a&gt; if you are interested.
&lt;/p&gt;    


</description>
        <pubDate>Sun, 08 Mar 2020 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2020/03/viewfoil/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2020/03/viewfoil/</guid>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <title>Modeling whether an outbreak of Wuhan virus will hit San Francisco</title>
        <description>&lt;p&gt;&lt;em&gt;Epistemic status: To be clear, this is a highly simplified model and should not be used to insight panic or to instill a false sense of security.  Please enjoy with a healthy level of skeptical detachment.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
	I'll admit that I've gotten wrapped up in all this &lt;a href=&quot;https://www.vox.com/future-perfect/2020/2/6/21121303/coronavirus-wuhan-panic-pandemic-outbreak&quot;&gt;Wuhan virus stuff&lt;/a&gt;, especially as it relates to the spread in the &lt;a href=&quot;https://www.mercurynews.com/2020/02/03/coronavirus-bay-area-has-highest-concentration-of-u-s-cases-that-shouldnt-be-a-surprise/&quot;&gt;SF Bay Area&lt;/a&gt;.  This is the first time that I've lived in a large population center while there is a potential epidemic looming, and the situation has me wondering whether we're already to the point where it's bound to spread here anyway.  I looked at &lt;a href=&quot;https://systems.jhu.edu/research/public-health/ncov-model-2/&quot;&gt;some results&lt;/a&gt; from one of the &lt;a href=&quot;&quot;&gt;sophisticated epidemiological models&lt;/a&gt;, and I got some reassurance.  But I was curious how these models worked under the hood.  
&lt;/p&gt;

&lt;p&gt;
	To get a better intuition, I developed a simplified version of that epidemic model, and an interactive visualization of my simple simulation.  The model allows you to vary the infection spread rate, the rate of quarantine, and the rate at which people fly from Wuhan to San Francisco.   &lt;a href=&quot;http://bl.ocks.org/stedn/b0acdeba81751c5f8e4ccaa74ccb09a9&quot;&gt;Try it out&lt;/a&gt;, and read below to learn more about how it works.
&lt;/p&gt;

&lt;a href=&quot;http://bl.ocks.org/stedn/b0acdeba81751c5f8e4ccaa74ccb09a9&quot;&gt;
&lt;img class=&quot;link_img&quot; src=&quot;/assets/images/2020/wuhan_model_viz.gif&quot; title=&quot;Wuhan javascript model visualization&quot; alt=&quot;Wuhan javascript model visualization&quot;/&gt;
&lt;/a&gt;
&lt;br/&gt;
&lt;h4&gt;Defining a model of Wuhan virus spread&lt;/h4&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;small&gt;&lt;em&gt;I've left out a lot of detail in this section for simplicity.  To see the full derivation check out &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;this document&lt;/a&gt;.&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;
	I wanted to simplify the &lt;a href=&quot;https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology&quot;&gt;standard SIR model&lt;/a&gt;, and apply it to two locations. An SIR model normally computes how the spread of an epidemic varies as the population moves from Susceptible (S) to Infected (I) to Recovered (R).  
&lt;/p&gt;


&lt;img title=&quot;SIR model diagram from wikipedia&quot; alt=&quot;SIR model diagram from wikipedia&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/8/8a/SIR.PNG&quot;/&gt;
&lt;p style=&quot;text-align:center&quot;&gt;&lt;em&gt;Diagram of transitions in SIR model (&lt;a href=&quot;https://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology#/media/File:SIR.PNG&quot;&gt;source Imoen&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;
	There is a &lt;a href=&quot;http://www.public.asu.edu/~hnesse/classes/sir.html&quot;&gt;specific dynamics model&lt;/a&gt; that governs how S, I and R vary over time.  However, I'm only interested in the early phase of the epidemic, when it's only spread to a small fraction of the population.  In that case, we don't need to worry about how many people are susceptible or recovered, we just always assume that there are lots of uninfected people around who can become infected.
&lt;/p&gt;
&lt;p&gt;
	I worked through defining a mathematical model that looks just at the early infection phase of an epidemic.  You can &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;look here&lt;/a&gt; for details on how the math works, but I'll just give a short summary here. 
&lt;/p&gt;

&lt;h5&gt;Exponential Infection Model&lt;/h5&gt;
&lt;p&gt;
	The model works by defining the &quot;net infected rate,&quot; which is the number of newly infected people minus the number of people who are moved into quarantine.  We're going to make the assumption that the change in the number of infected people, &lt;span lang=&quot;latex&quot;&gt;I&lt;/span&gt;, is equal to the current number of infected people times a constant growth rate, &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt;.  We can formalize this in an equation.
&lt;/p&gt;
&lt;p lang=&quot;latex&quot;&gt;\frac{dI}{dt} = \gamma I &lt;/p&gt;
&lt;p&gt;
	This equation can be solved to give the standard exponential growth curve of an early phase epidemic.  However, if this equation were the whole story, this would mean that all infectious diseases should turn into exponentially growing epidemics, and we know that isn't the case.  Specifically, we have public health policies that can work to quarantine and mitigate the spread of a disaster.  For this model, we're going to assume that our ability to quarantine people is set at some fixed constant, &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt;, so if the growth rate surpasses that, we'll end up with an outbreak.  To model this, I'm going to combine these two terms into one equation like this.
&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;\frac{dI}{dt} = \gamma I - \kappa&lt;/p&gt;

&lt;p&gt;
	This equation is also fairly easy to solve, and &lt;a href=&quot;https://www.wolframalpha.com/input/?i=solve+dx%2Fdt+%3D+g*x+-+k+with+x%280%29%3Dk%2Fg%2B1&quot;&gt;the solution&lt;/a&gt; grows exponentially whenever the infected population crosses the threshold of &lt;span lang=&quot;latex&quot;&gt;\kappa / \gamma&lt;/span&gt;.  
&lt;/p&gt;
&lt;p&gt;
	So this equation will work to model the epidemic in one place, but we want to see how the situation evolves if it can spread to another place, like the case for spreading from Wuhan to San Francisco. The two equations to model Wuhan and SF look like this:
&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;\frac{dI_{wu}}{dt} = \gamma I_{wu} - \kappa&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;\frac{dI_{sf}}{dt} = \gamma I_{sf} - \kappa + \mu I_{wu}&lt;/p&gt;
&lt;p&gt;
	You can see that the first part of both equations is the same as the simple infection equation for &lt;span lang=&quot;latex&quot;&gt;I&lt;/span&gt; above. However, in the &lt;span lang=&quot;latex&quot;&gt;I_{sf}&lt;/span&gt; (ie San Francisco) equation, there's an extra term of &lt;span lang=&quot;latex&quot;&gt;\mu I_{wu}&lt;/span&gt;.  This is the rate of people who are sick in Wuhan flying to San Francisco.
&lt;/p&gt;

&lt;h5&gt;Simulations&lt;/h5&gt;
&lt;p&gt;
	I took this model definition and generated simulations that show how the values of &lt;span lang=&quot;latex&quot;&gt;I_{wu}&lt;/span&gt; and &lt;span lang=&quot;latex&quot;&gt;I_{sf}&lt;/span&gt; vary over time. These kinds of simulations just take the equations above and use them to determine how the number of people infected would change over a small unit of time. Then, they do this over and over again to show how the system evolves.  I used prepackaged simulation software to diagram the solution to the equation I had above, and it gave curves that showed the growth in the number of infected in the two locations over time.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; title=&quot;example wuhan plot&quot; src=&quot;/assets/images/2020/wuhan_model_growth.png&quot;/&gt;

&lt;p&gt;
	Next, I used the simulation to see what happened if I varied how long before flights were shut down.  I called this time &lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt;.  In this simulation, I set &lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt; to be very short and saw that even though the infection started to spread in SF, it went back down to 0 right after flights were stopped.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; title=&quot;SF infection drops after flights stop&quot; src=&quot;/assets/images/2020/wuhan_sf_safe.png&quot;/&gt;

&lt;p&gt;
	As you might expect, if the time before Wuhan is quarantined (&lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt;) is short, then the infection doesn't have too much time to spread to SF, and they are able to fight the epidemic back down to 0.  But if I extend &lt;span lang=&quot;latex&quot;&gt;t_Q&lt;/span&gt; past 5, suddenly the model predicted that it wouldn't be possible to keep it under control.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_model_quarantine.png&quot;/&gt;

&lt;p&gt;
	This makes intuitive sense, but it was still quite curious to me what might cause everything to be fine at 4.9 days, but for an outbreak to happen after 5 days.  I decided to see if I could use my model to see what set the time of the &quot;point of no return.&quot;
&lt;/p&gt;

&lt;h5&gt;Predicting the &quot;point of no return&quot;&lt;/h5&gt;
&lt;p&gt;
	I worked through this model a little more rigorously both with the simulations and with an analytical theory. I'm going to gloss over the rest of the analysis I did for this post, but please read &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;the full article&lt;/a&gt;, and my &lt;a href=&quot;&quot;&gt;analysis notebook&lt;/a&gt; if you're curious how I arrived at the results. 
&lt;/p&gt;
&lt;p&gt;
	I evaluated the time of the &quot;point of no return,&quot; &lt;span lang=&quot;latex&quot;&gt;t_X&lt;/span&gt; as
&lt;/p&gt;

&lt;p lang=&quot;latex&quot;&gt;t_X \approx  \frac{1.7}{\gamma} \left(ln\left(\frac{\gamma}{\mu} - 1\right)- ln\left(w_0 - \frac{\kappa}{\gamma}\right)\right) &lt;/p&gt;


&lt;p&gt;
	Where I added in the initially infected population in Wuhan &lt;span lang=&quot;latex&quot;&gt;w_o&lt;/span&gt; as another parameter. This might look a little mysterious, but you can read &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;the math&lt;/a&gt; to get a better sense of where it comes from. To double check my work, I directly measured &lt;span lang=&quot;latex&quot;&gt;t_x&lt;/span&gt; using my simulations.  
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_tX.png&quot;/&gt;

&lt;p&gt;
	This pretty surface matched my prediction closely and showed the correct dependence on the logarithm of the Wuhan to SF flight rate &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt;.
&lt;/p&gt;


&lt;h4&gt;Putting the math into practice&lt;/h4&gt;

&lt;p&gt;
	So that's a nice formula to have, but unfortunately, it's totally useless without knowing what these parameters, &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt;, &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt;, and &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt; are.  So how can we figure them out?
&lt;/p&gt;

&lt;p&gt;
	Well fortunately, we can guesstimate &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt; just by looking at what's happened in Wuhan.  If we fit the &lt;a href=&quot;https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6&quot;&gt;data&lt;/a&gt; for the early part of the outbreak, which looks roughly exponential. The growth constant of that curve is &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt;. 
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_cases.png&quot;/&gt;

&lt;p&gt;
	I plotted the data in &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1uo64yIiPMC5C8chDn3WBe5UA6RljJ3YthmxR3p-rp-A/edit?usp=sharing&quot;&gt;this google sheet&lt;/a&gt; and got an estimate for &lt;span lang=&quot;latex&quot;&gt;\gamma&lt;/span&gt; of 0.2-0.3 new cases per infected person per day.  The reported number of cases is &lt;a href=&quot;https://systems.jhu.edu/research/public-health/ncov-model-2/&quot;&gt;probably an underestimate&lt;/a&gt; of the total population that is infectious, but if it differs by a constant multiplicative factor, then (I think) cases should still give a good approximation of that constant.
&lt;/p&gt;


&lt;p&gt;
	It's a little tougher to get &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt;, but since an outbreak did happen starting from ~200 cases, we expect that &lt;span lang=&quot;latex&quot;&gt;\kappa&lt;/span&gt; can't be more than 200*0.2 ~ 40 people per day.
&lt;/p&gt;

&lt;p&gt;
	Finally, for &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt;, we can calculate it directly because &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt; is just the probability that any person will get on a plane and fly to San Francisco.  I just &lt;a href=&quot;https://www.flightsfrom.com/SFO/destinations?durationFrom=43&amp;durationTo=1053&amp;dateMethod=day&amp;dateFrom=2020-02-29&amp;dateTo=2020-02-29#/WUH&quot;&gt;looked up&lt;/a&gt; the number of scheduled flights from Wuhan.  I estimated about 3 flights per week from Wuhan straight to Northern California, and Wuhan has a population of about 60 million.  That makes an estimate for &lt;span lang=&quot;latex&quot;&gt;\mu&lt;/span&gt; of 3 flights x 200 people per flight / 60 million people / 7 days per week or 1e-6 new infected people in CA per infected person in Wuhan per day.
&lt;/p&gt;

&lt;p&gt;
	This means that &lt;span lang=&quot;latex&quot;&gt;t_X \approx&lt;/span&gt; 60.  According to &lt;a href=&quot;https://www.pharmaceutical-technology.com/news/coronavirus-a-timeline-of-how-the-deadly-outbreak-evolved/&quot;&gt;this timeline&lt;/a&gt;, the border with Wuhan was closed on Jan 22nd, and the outbreak was only at 200 cases on Jan 19.  From this, it would seem like we should have it very much under control.
&lt;/p&gt;

&lt;p&gt;
	Of course, this is way too optimistic because we know that Wuhan isn't the only place where the epidemic has spread.  The virus has spread over many parts of China by now, and any of those places could serve as a source of the viurs now.
&lt;/p&gt;
&lt;h4&gt;Modeling two locations&lt;/h4&gt;

&lt;p&gt;
	Unfortunately, I don't quite have time to properly model the general case for when we cross the &quot;point of no return&quot; from a spread from one of many cities.  I assume that my analysis would probably look like the original paper that I was basing this on.  However, I did make a simple approximation for a hop between two cities.
&lt;/p&gt;

&lt;p&gt;
	Again, you'll have to go through &lt;a href=&quot;https://github.com/lots-of-things/wuhan-virus-model/blob/master/Wuhan_to_SF_infection_model.pdf&quot;&gt;my derivation&lt;/a&gt; to see the details, but these simulation results showed that the formula for &lt;span lang=&quot;latex&quot;&gt;t_X&lt;/span&gt; was roughly twice the value of the single city estimate.
&lt;/p&gt;

&lt;img class=&quot;small_img&quot; src=&quot;/assets/images/2020/wuhan_tX_double.png&quot;/&gt;

&lt;p&gt;
	To use this estimate, we'll have to adjust the parameter &lt;span lang=&quot;latex&quot;&gt;t_X&lt;/span&gt; to account for there being more flights from other parts of China than there were for Wuhan. Unfortunately for us, there are about ~100 times more flights coming from all of China than were coming from Wuhan directly.  That means we'd estimate that we had 21 days to stop flights from all of China.  Not impossible to pull off, but depending on how you define exactly when the epidemic started, we might have missed that window.
&lt;/p&gt;


&lt;h4&gt;Don't panic. But also, maybe don't fly to China right now.&lt;/h4&gt;

&lt;p&gt;
	You should keep in mind that this whole exercise is just a very simplified model that can help you think about how this process works. It does not make accurate quantitative predictions about the probability that there will be an outbreak or whether you, personally, will get sick.  It shouldn't make you feel more safe or more terrified, and you should not use it to inform your decision making about infection mitigation.  You &lt;em&gt;should&lt;/em&gt; use this to get more excited about using math to inform your mental picture of the world.
&lt;/p&gt;
&lt;p&gt;
	Now, if you'll excuse me, I'm going to go wash my hands.
&lt;/p&gt;


&lt;h4&gt;Appendix: Let's make it look cool&lt;/h4&gt;
&lt;p&gt;
	These graphs are nice, but if there's one thing I learned when working on simulations in &lt;a href=&quot;/2017/08/theseus-and-cell-phd-dissertation-story/&quot;&gt;grad school&lt;/a&gt;, it's that you can't just show the results, you have to show a pretty visualization too. So to do that, I built these simulations into a d3 map visualization.
&lt;/p&gt;

&lt;a href=&quot;http://bl.ocks.org/stedn/b0acdeba81751c5f8e4ccaa74ccb09a9&quot;&gt;
&lt;img src=&quot;/assets/images/2020/wuhan_overview_im.png&quot; title=&quot;Wuhan javascript model visualization&quot; alt=&quot;Wuhan javascript model visualization&quot;/&gt;
&lt;/a&gt;

&lt;p&gt;
	To build it, I figured out the map projection using &lt;a href=&quot;https://bl.ocks.org/d3indepth/f7ece0ab9a3df06a8cecd2c0e33e54ef&quot;&gt;this tool&lt;/a&gt;, and I added the animated graph at the bottom based off &lt;a href=&quot;https://bl.ocks.org/d3noob/7030f35b72de721622b8&quot;&gt;this example&lt;/a&gt;.   The coolest and most fun part, though, was animating the dots that fly from Wuhan to San Francisco, which I based off this code &lt;a href=&quot;https://bl.ocks.org/d3indepth/aa1f036f6a0356cb1152c4b836e93990&quot;&gt;block&lt;/a&gt;.  
&lt;/p&gt;

&lt;p&gt;
	The really tricky part was manually implementing a differential equation solver in javascript.  I ended up just using the &lt;a href=&quot;&quot;&gt;forward Euler&lt;/a&gt; method even though that is only &lt;a href=&quot;&quot;&gt;rough approximation&lt;/a&gt; of the true solution.  I figured it was more important to have simplicity in this animation since I'd already done the more &lt;a href=&quot;&quot;&gt;rigorous simulation&lt;/a&gt; with the &lt;a href=&quot;&quot;&gt;scipy ode solver&lt;/a&gt;.  
&lt;/p&gt;
&lt;p&gt;
	To implement the solver, I just evaluate the differential equation above and keep track of the change in variable values. However, In order to visualize the number &quot;in transit&quot; flying from Wuhan to SF, I had to keep track of &lt;code&gt;mu * n_wu&lt;/code&gt; separately (ie &lt;code&gt;n_tr&lt;/code&gt;). 
&lt;/p&gt;

&lt;pre&gt;
  // compute differential euations for isolated populations
  d_wu = (gamma * n_wu - kappa) * dt;
  d_sf = (gamma * n_sf - kappa) * dt;

  n_wu = n_wu + d_wu;
  n_sf = n_sf + d_sf;
  
  d_tr = (mu * n_wu) * dt;
  n_tr = n_tr + d_tr;
&lt;/pre&gt;


&lt;p&gt;
	For dot animation, I kept track of 3 lists of dots. Whenever the corresponding &lt;code&gt;n_**&lt;/code&gt; value changed by one unit, I added or removed a dot from the corresponding list.  Here is how that worked for the Wuhan dot list.
&lt;/p&gt;

&lt;pre&gt;
  while(i_wu_n &lt; Math.floor(n_wu_viz)){
    pt = randomCircle(rad_wu)
    i_wu.push([wuhanLonLat[0]+pt[0], wuhanLonLat[1]+pt[1]])
    i_wu_n = i_wu_n + 1
  }
&lt;/pre&gt;

&lt;p&gt;
	The trickiest part was keeping track of the &quot;in transit&quot; dots.  For them, they stayed in the &quot;in transit&quot; list until their animation had brought them across.  It wasn't until that point that I incremented the San Francisco infected count (&lt;code&gt;n_sf&lt;/code&gt;).
&lt;/p&gt;

&lt;pre&gt;
  // transition dots out of Wuhan and into &quot;in transit&quot; list
  while(n_tr &gt; 1){
    n_tr = n_tr - 1;
    n_wu = n_wu - 1;
    i_tr.push(0);
    i_tr_n = i_tr_n + 1;
  }

  // for dots that have crossed, remove from &quot;in transit&quot; and add to n_sf
  for (i = 0; i &lt; i_tr_n; i++) {
    i_tr[i] = i_tr[i] + dl + dl*gaussianRand();
    if(i_tr[i]&gt;=1){
      i_tr.splice(i, 1);
      i_tr_n = i_tr_n - 1;
      n_sf = n_sf + 1;
    }
  }
&lt;/pre&gt;

&lt;p&gt;
	This actually changes the dynamics slightly because it introduces a lag between when the value.  I didn't worry about how that changed the results too much here. This app was just meant to be a visually captivating illustration and a learning exercise for people who want to understand how infectious disease models work. Hopefully someone other than me will get something from this too.
&lt;/p&gt;


&lt;script src=&quot;https://latex.codecogs.com/latexit.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;


</description>
        <pubDate>Tue, 11 Feb 2020 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2020/02/wuhan-virus-model/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2020/02/wuhan-virus-model/</guid>
        
        <category>analysis</category>
        
        <category>visualization</category>
        
        <category>data science</category>
        
        <category>dynamics</category>
        
        <category>health</category>
        
        
      </item>
    
      <item>
        <title>How to build a convincing reddit personality with GPT2 and BERT</title>
        <description>&lt;p&gt;
    Last month, I experimented with building a reddit comment bot that generated natural language replies by combining two pre-trained deep learning models: &lt;a href=&quot;http://jalammar.github.io/illustrated-gpt2/&quot;&gt;GPT-2&lt;/a&gt; and &lt;a hrf=&quot;http://jalammar.github.io/illustrated-bert/&quot;&gt;BERT&lt;/a&gt;. I wrote &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/&quot;&gt;another post&lt;/a&gt; on the motivation and background, but here I wanted to give a step by step walkthrough so others can work with what I've built.  If you prefer, you can jump straight to the &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot&quot;&gt;project code&lt;/a&gt;.  And to see the work that I based this on see &lt;a href=&quot;https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce&quot;&gt;this&lt;/a&gt; and &lt;a href=&quot;https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb&quot;&gt;this&lt;/a&gt;
&lt;/p&gt;

&lt;h4&gt;Model overview&lt;/h4&gt;

&lt;p&gt;Before getting into the nitty-gritty, I wanted to give a general overview of the process that I'm going to be using.  This flow diagram shows the 3 models that I needed to train, as well as the process fr hooking the models together to generate the output.
&lt;/p&gt;

&lt;img title=&quot;GPT2 BERT commentor workflow&quot; src=&quot;/assets/images/2020/gpt2_bert_workflow.png&quot; alt=&quot;GPT2 BERT comment system workflow&quot;/&gt;

&lt;p&gt;
    There are quite a few steps, but I hope it doesn't get too confusing.  Check out &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/&quot;&gt;my previous post&lt;/a&gt; for an even higher-level architecture overview.  Here are the steps I'll be explaining in this post.
&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;
        step 0: get some reddit comment data from your favorite subreddits and format into strings that look like &quot;comment [SEP] reply&quot;
    &lt;/li&gt;
    &lt;li&gt;
        step 1: fine tune GPT-2 to generate reddit text in the format &quot;comment [SEP] reply&quot;   
    &lt;/li&gt;
    &lt;li&gt;
    step 2: fine tune two BERT classifiers to:
    &lt;ul&gt;
        &lt;li&gt;a: differentiate real replies from GPT-2 generated ones&lt;/li&gt;
        &lt;li&gt;b: predict how many upvotes comments will get&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;
    step 3: use praw to download current comments  
    &lt;/li&gt;
    &lt;li&gt;
    step 4: use fine-tuned GPT2 to generate many replies for each comment  
    &lt;/li&gt;
    &lt;li&gt;
    step 5: pass the generated replies to two BERT models to generate a prediction of realisticness and number of upvotes
    &lt;/li&gt;
    &lt;li&gt;
    step 6: use some criteria for choosing which replies to submit  
    &lt;/li&gt;
    &lt;li&gt;
    step 7: use praw to submit the chosen comments
    &lt;/li&gt;
    &lt;li&gt;
    step 8: chuckle with amusement
    &lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Getting lots of reddit comment data&lt;/h4&gt;
&lt;p&gt;
    As with any machine learning project, nothing can start until you have data from which to train your model.
&lt;/p&gt;

&lt;p&gt;
    The data I used to fine-tune the models came from a &lt;a href=&quot;https://bigquery.cloud.google.com/dataset/fh-bigquery:reddit_comments?pli=1&quot;&gt;large database of previously retrieved reddit comments&lt;/a&gt;.  There is an &lt;a href=&quot;https://www.reddit.com/r/bigquery/wiki/datasets&quot;&gt;ongoing project&lt;/a&gt; that scrapes many sites around the web and stores them in a bunch of Google BigQuery tables.  To me, it's very surprising that I couldn't find a central  page about such a big project, but I used a few &lt;a href=&quot;https://www.reddit.com/r/bigquery/comments/5z957b/more_than_3_billion_reddit_comments_loaded_on/&quot;&gt;reddit&lt;/a&gt; and &lt;a href=&quot;https://towardsdatascience.com/bigquery-without-a-credit-card-discover-learn-and-share-199e08d4a064&quot;&gt;medium&lt;/a&gt; posts to piece together the format of the queries I'd need.  
&lt;/p&gt;

&lt;p&gt;
    To start, I just downloaded a bunch of comment and reply information for the subreddits on 'writing', 'scifi', 'sciencefiction', 'MachineLearning', 'philosophy', 'cogsci', 'neuro', and 'Futurology'. This query works to pull the comments for a specific year and month (&lt;code&gt;{ym}&lt;/code&gt;) from bigquery.
&lt;/p&gt;

&lt;pre&gt;
SELECT s.subreddit as subreddit, 
s.selftext as submission, a.body AS comment, b.body as reply, 
s.score as submission_score, a.score as comment_score, b.score as reply_score, 
s.author as submission_author, a.author as comment_author, b.author as reply_author
FROM `fh-bigquery.reddit_comments.{ym}` a
LEFT JOIN `fh-bigquery.reddit_comments.{ym}` b 
ON CONCAT('t1_',a.id) = b.parent_id
LEFT JOIN  `fh-bigquery.reddit_posts.{ym}` s
ON CONCAT('t3_',s.id) = a.parent_id
where b.body is not null 
  and s.selftext is not null and s.selftext != ''
  and b.author != s.author
  and b.author != a.author
  and s.subreddit IN ('writing', 
                      'scifi', 
                      'sciencefiction', 
                      'MachineLearning', 
                      'philosophy', 
                      'cogsci', 
                      'neuro', 
                      'Futurology')
&lt;/pre&gt;


&lt;p&gt;
    I used the &lt;a href=&quot;https://cloud.google.com/bigquery/docs/reference/libraries&quot;&gt;bigquery python API&lt;/a&gt; to automate the generation of the queries I needed to download the data across a number of months in 2017 and 2018.  &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot/blob/master/get_reddit_from_gbq.py&quot;&gt;This script&lt;/a&gt; iterated over the time periods I needed and downloaded them to local disk in the &lt;code&gt;raw_data/&lt;/code&gt; folder.
&lt;/p&gt;

&lt;p&gt;
    In the end, I'm going to want to be able to prime the GPT-2 network with a comment and generate a reply. To do this, I needed to reformat the data to contain both parts separated by a special &lt;code&gt;[SEP]&lt;/code&gt; string to let the algorithm know which part is which.  Each line of training data file will look like the following.
&lt;/p&gt;
&lt;pre&gt;
    &quot;a bunch of primary comment text [SEP] all of the reply text&quot;
&lt;/pre&gt;

&lt;p&gt;
    After I train the model with this format, I can then feed the trained model a string like &lt;code&gt;&quot;some new primary comment text&quot; [SEP]&lt;/code&gt;, and it will start to generate the remaining &lt;code&gt;&quot;some new reply&quot;&lt;/code&gt; that it thinks fits best based on the training data. I'll explain in more detail below about how to feed this kind of data into the GPT-2 fine-tuning script.  For now, you can use &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot/blob/master/prep_data.py&quot;&gt;this script&lt;/a&gt; to convert the data into the format that GPT-2 fine-tuning will need and save it as &lt;code&gt;gpt2_finetune.csv&lt;/code&gt; 
&lt;/p&gt;




&lt;h4&gt;Fine tuning GPT-2 and generating text for reddit&lt;/h4&gt;
&lt;p&gt;
    The major advantage of using GPT-2 is that it has been pre-trained on a massive dataset of millions of pages of text on the internet.  However, if you were to use GPT-2 straight &quot;out-of-the-box,&quot; you'd end up generating text that could look like anything you might find on the internet.  Sometimes it'll generate a news article, sometimes it'll generate a cooking blog recipe, sometimes it'll generate a rage-filled facebook post.  You don't really have too much control, and therefore, you won't really be able to use it to effectively generate reddit comments.
&lt;/p&gt;
&lt;p&gt;
    To overcome this issue, I needed to &quot;fine-tune&quot; the pre-trained model.  &lt;a href=&quot;https://stats.stackexchange.com/questions/331369/what-is-meant-by-fine-tuning-of-neural-network&quot;&gt;Fine-tuning&lt;/a&gt; means taking a model that was already trained on a big dataset, and then continuing to train it on just the specific type of data that you want to use it on.  This process (somewhat magically) allows you to take a lot of the general information about language from the big pretrained model, and sculpt that down with all the specific information about the exact output format you are trying to generate.
&lt;/p&gt;

&lt;p&gt;
    Fine-tuning is a standard process, but it still isn't super easy to do.  I'm not an expert deep learning researcher, but fortunately for me, a really &lt;a href=&quot;https://minimaxir.com/&quot;&gt;wonderful expert&lt;/a&gt; had already built some incredibly simple wrapper utilities called &lt;a href=&quot;https://github.com/minimaxir/gpt-2-simple&quot;&gt;gpt-2-simple&lt;/a&gt; for make fine-tuning GPT-2, well... simple.
&lt;/p&gt;

&lt;p&gt;
    The best part is that the author of gpt-2-simple, even set up a &lt;a href=&quot;https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce&quot;&gt;Google Colab notebook&lt;/a&gt; that walked through fine-tuning.  In case you haven't heard, &lt;a href=&quot;https://colab.research.google.com/notebooks/welcome.ipynb&quot;&gt;Google Colab&lt;/a&gt; is an amazing FREE (&lt;a href=&quot;https://meta.stackexchange.com/questions/21932/what-does-the-term-and-free-as-in-free-beer-mean&quot;&gt;as in beer&lt;/a&gt;) resource that lets you &lt;a href=&quot;https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c&quot;&gt;run a python jupyter notebook&lt;/a&gt; on a Google GPU server.  Full disclosure, I am officially a lifetime fanboy of Google for making a free tier on Google App Engine, BigQuery, and Google Colab. 
&lt;/p&gt;

&lt;p&gt;
    You can follow along with the &lt;a href=&quot;https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce&quot;&gt;tutorial notebook&lt;/a&gt; to learn all about how to fine-tune a GPT-2 model with gpt-2-simple.  For my use case, I took all of that code and condensed and reformatted it a little to make my own &lt;a href=&quot;https://colab.research.google.com/drive/1VyOU81rsPsP_8WSKq-VZfB8TcMkPszG-&quot;&gt;gpt-2 fine tuning notebook&lt;/a&gt; that runs off the &lt;code&gt;gpt2_finetune.csv&lt;/code&gt; file that I generated in the previous step.  Just like in the original tutorial, you need to give the notebook permission to read and write from your Google Drive.  The model is then saved into you Google Drive for reloading from later scripts.
&lt;/p&gt;



&lt;h4&gt;Training BERT models for fake detection and upvote prediction&lt;/h4&gt;

&lt;p&gt;
    Even after fine-tuning, the output of this model, while normally somewhat reasonable, is often pretty &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/#gpt2shortcoming&quot;&gt;weird&lt;/a&gt;. To improve the quality of responses, I adapted the concept of GANs to create another meta-model that is able to throw out all the really weird replies.  So I use GPT-2 to generate a 10+ candidate responses for every comment, and then I use another model to filter out which are the best replies I could release.  
&lt;/p&gt;
&lt;p&gt;
    To determine the best, I actually want to do two things:
&lt;/p&gt;

&lt;ul&gt;
    &lt;li&gt;Filter out unrealistic replies&lt;/li&gt;
    &lt;li&gt;For the realistic replies, pick the one that I predict will have the most upvotes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
    So in order to do this, I have to train two classifiers, one to predict the probability of being a real reply and another to predict the probability of being a high scoring reply.  There are lots of ways to perform this prediction task, but one of the most successful language models recently built for this kind of thing is another deep learning architecture called &lt;a href=&quot;https://searchengineland.com/welcome-bert-google-artificial-intelligence-for-understanding-search-queries-323976&quot;&gt;Bidirectional Encoder Representations from Transformers&lt;/a&gt; or BERT. One big benefit of using this model is that, similar to GPT-2, researchers have pre-trained networks on very large corpora of data that I would never have the financial means to access.
&lt;/p&gt;

&lt;p&gt;
    Again, I'm not the biggest expert in working with deep learning infrastructure so luckily, other &lt;a href=&quot;https://www.tensorflow.org/hub&quot;&gt;brilliant tensorflowhub experts&lt;/a&gt; wrote a &lt;a href=&quot;https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb&quot;&gt;Google Colab tutorial&lt;/a&gt; for fine-tuning text classifier models using a pretrained BERT network.  So all I had to do was combine the two with some glue.
&lt;/p&gt;

&lt;p&gt;
    In the next section, I'll walk through the fine-tuning and some model evaluation, but if you'd like to get a jumpstart and don't want to bother fine-tuning yourself, you can download the three fine-tuned models from &lt;a href=&quot;https://drive.google.com/open?id=1GmGNqihV0nCQ6evLBmopOhjups_RESv-&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://drive.google.com/open?id=1-Bov5PtPrP2DvFw4yD-lxp2wTjGw0bwB&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://drive.google.com/file/d/1DTfYUxXEz80S0baCb4xPSrzx85F0FVTP/view?usp=sharing&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;

&lt;h5&gt;BERT Discriminator model performance&lt;/h5&gt;
&lt;p&gt;
    The realisticness model was trained just like in a traditional GAN. I had &lt;a href=&quot;https://drive.google.com/open?id=1RLJz_rJmz0UVdRikRGQrYF9TbLMIrrJ8&quot;&gt;another Colab notebook&lt;/a&gt; generate thousands of fakes and then created a dataset that combined my fakes with thousands of real comments.  I then fed that dataset into a &lt;a href=&quot;https://drive.google.com/open?id=1aGswP0SJmdP6GNKEuKMJ5AhP8epNOQW_&quot;&gt;BERT realisticness fine-tuning notebook&lt;/a&gt; to train and evaluate. The model actually has amazingly high distinguishing power between real and fake comments.
&lt;/p&gt;

&lt;h6&gt;BERT Realisticness Model Metrics&lt;/h6&gt;
&lt;pre&gt;
'auc': 0.9933777,
'eval_accuracy': 0.9986961,
'f1_score': 0.99929225,
'false_negatives': 3.0,
'false_positives': 11.0,
'precision': 0.9988883,
'recall': 0.99969655,
'true_negatives': 839.0,
'true_positives': 9884.0
&lt;/pre&gt;

&lt;p&gt;
    Going forward, every reply that the generator creates can be run through this BERT discriminator to get a score from 0 to 1 based on how realistic it is.  I then just filter to only return comments that are predicted to be the most likely to be real.
&lt;/p&gt;

&lt;p&gt;
    To predict how many upvotes a reply will get, I built another model in a &lt;a href=&quot;https://drive.google.com/open?id=1vXJjQbBZZ0Jo-LvcwRaNzCSAgAVem1cC&quot;&gt;similar way&lt;/a&gt;. This time the model was just trained just on a dataset containing a bunch of real reddit comments to predict how many upvotes they actually got. 
&lt;/p&gt;

&lt;p&gt;
    This model also had surprisingly high predictive accuracy.  This &lt;a href=&quot;https://www.dataschool.io/roc-curves-and-auc-explained/&quot;&gt;ROC curve&lt;/a&gt; shows that we can get a lot of true positives correct without having too many false positives. For more on what true positive and false positive means see &lt;a href=&quot;https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative&quot;&gt;this article&lt;/a&gt;.  
&lt;/p&gt;

&lt;img title=&quot;comment score prediction ROC curve&quot; src=&quot;/assets/images/2020/bert_upvote_predict.png&quot; alt=&quot;BERT score prediction ROC curve&quot;/&gt;
&lt;h6 style='text-align:center;'&gt;ROC curve for BERT based upvote prediction &lt;/h6&gt;


&lt;p&gt;
    Buoyed by the model cross-validation performance, I was excited to hook it up to a real-time commenting system and start shipping my bot's thoughts!
&lt;/p&gt;


&lt;h4&gt;Pulling real-time comments with PRAW&lt;/h4&gt;
&lt;p&gt;
    Although I could generate the training sets using data on bigquery, most of that data is actually a couple of months old.  Replying to months old comments is a very non-human thing to do on social media sites so it was important to be able to pull down fresh data from reddit somehow.
&lt;/p&gt;

&lt;p&gt;
    Fortunately, I could use the &lt;a href=&quot;https://praw.readthedocs.io/en/latest/&quot;&gt;praw library&lt;/a&gt; along with the following snippet to get all comments from the top 5 &quot;rising&quot; posts in a couple of subreddits that I thought would produce some interesting responses.
&lt;/p&gt;

&lt;pre&gt;
for subreddit_name in ['sciencefiction',
                       'artificial',
                       'scifi',
                       'BurningMan',
                       'writing',
                       'MachineLearning',
                       'randonauts']:
  subreddit = reddit.subreddit(subreddit_name)

  for h in subreddit.rising(limit=5):
&lt;/pre&gt;

&lt;p&gt;
    I could run each comment through the generator and discriminators to produce a reply.
&lt;/p&gt;

&lt;h4&gt;Running the generator and discriminators&lt;/h4&gt;
&lt;p&gt;
    Finally, I just had to build something to reload all the fine-tuned models and pass the new reddit comments through them to get replies. In an ideal world, I would have run both the GPT-2 and the BERT models in one script that could be run from end to end.  Unfortunately, a quirk in the way the designers immplemented the gpt2-simple package made it impossible to have two computation graphs &lt;a href=&quot;https://github.com/minimaxir/gpt-2-simple/issues/130&quot;&gt;instantiated in the same environment&lt;/a&gt;.  
&lt;/p&gt;

&lt;p&gt;
    So instead, I just ran a &lt;a href=&quot;https://drive.google.com/open?id=1Z-sXQUsC7kHfLVQSpluTR-SqnBavh9qC&quot;&gt;GPT-2 generator notebook&lt;/a&gt; on its own to download new comments, generate a batch of candidate replies, and store them in csv files on my google drive.
    Then, I reloaded the candidates in a separate &lt;a href=&quot;https://drive.google.com/open?id=1mWRwK1pY34joZul5gBeMortfTu8M9OPC&quot;&gt;BERT discriminator notebook&lt;/a&gt;to pick the best replies and submit them back to reddit.
&lt;/p&gt;

&lt;p&gt;You can view the whole workflow in my &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot&quot;&gt;github repo&lt;/a&gt; for the project or in my &lt;a href=&quot;https://drive.google.com/open?id=1by97qt6TBpi_o644uKnYmQE5AJB1ybMK&quot;&gt;Google Drive folder&lt;/a&gt;.  Please &lt;a href=&quot;https://github.com/lots-of-things/gpt2-bert-reddit-bot/issues&quot;&gt;submit issues&lt;/a&gt; to the project if you think things can be explained more clearly, or if you find bugs.&lt;/p&gt;

&lt;h4&gt;Last Step: Chuckle with Amusement&lt;/h4&gt;
&lt;p&gt;
    I submitted all my replies under the reddit account of &lt;a href=&quot;https://www.history.com/news/tupperware-parties-brownie-wise&quot;&gt;tupperware-party&lt;/a&gt; (which hopefully won't get shut down for trademark shit).  You can check out some highlights from the model output &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/#replies&quot;&gt;here&lt;/a&gt; or see the &lt;a href=&quot;https://www.reddit.com/user/tupperware-party/comments/&quot;&gt;full list of comments&lt;/a&gt; to inspect everything the system outputted.  I've also shared a &lt;a href=&quot;https://drive.google.com/drive/folders/1a2MhIqL6jvyJ-3bGCXAweLbYtNXSUei7?usp=sharing&quot;&gt;folder on Google Drive&lt;/a&gt; with all of the candidate responses and their scores from the BERT models if you want to take a look.
&lt;/p&gt;

&lt;p&gt;
    Finally, I know there are definitely some ethical considerations when creating something like this.  You can read my thoughts on that &lt;a href=&quot;/2020/02/combining-gpt-2-and-bert/#ethics&quot;&gt;here&lt;/a&gt;.  In short, please try to use this responsibly and spread the word that we are living in a world where this is possible.  And if you have a problem, tell me on &lt;a href=&quot;https://twitter.com/bonkerfield&quot;&gt;Twitter&lt;/a&gt;.  I swear it'll really be me who responds.
&lt;/p&gt;

</description>
        <pubDate>Tue, 04 Feb 2020 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2020/02/reddit-bot-gpt2-bert/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2020/02/reddit-bot-gpt2-bert/</guid>
        
        <category>machine learning</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>Combining GPT-2 and BERT to make a fake person</title>
        <description>&lt;p&gt;
	&lt;a href=&quot;https://openai.com/blog/better-language-models/&quot;&gt;GPT-2&lt;/a&gt; is a deep learning model that is able to generate astonishingly coherent English text.  It was released last year, and &lt;a href=&quot;https://towardsdatascience.com/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8&quot;&gt;everyones&lt;/a&gt; &lt;a href=&quot;https://www.fast.ai/2019/02/15/openai-gp2/&quot;&gt;mind&lt;/a&gt; was &lt;a href=&quot;https://www.theguardian.com/commentisfree/2019/feb/15/ai-write-robot-openai-gpt2-elon-musk&quot;&gt;blown&lt;/a&gt; into &lt;a href=&quot;http://approximatelycorrect.com/2019/02/17/openai-trains-language-model-mass-hysteria-ensues/&quot;&gt;histrionic&lt;/a&gt; &lt;a href=&quot;https://www.wired.com/story/ai-text-generator-too-dangerous-to-make-public/&quot;&gt;hyperbole&lt;/a&gt;, including mine.  Its creators at &lt;a href=&quot;https://openai.com/&quot;&gt;OpenAI&lt;/a&gt; were so impressed by the model's performance that they originally didn't release it for fear of it being too easy to abuse. I think they were right to be concerned.  Here is an excerpt that the model generated, taken from their &lt;a href=&quot;https://openai.com/blog/better-language-models/#sample1&quot;&gt;release page&lt;/a&gt;.
&lt;/p&gt;

&lt;blockquote&gt;
	In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.

	The scientist named the population, after their distinctive horn, Ovids Unicorn. These four-horned, silver-white unicorns were previously unknown to science.

	Now, after almost two centuries, the mystery of what sparked this odd phenomenon is finally solved.

	Dr. Jorge Prez, an evolutionary biologist from the University of La Paz, and several companions, were exploring the Andes Mountains when they found a small valley, with no other animals or humans. Prez noticed that the valley had what appeared to be a natural fountain, surrounded by two peaks of rock and silver snow.
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://openai.com/blog/better-language-models/#sample1&quot;&gt;read more&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;
	When I saw what GPT-2 was capable of generating, I had chills. We are now very close to effectively simulating human creativity.  I find machine imitation of human communication fascinating; in fact, it's something I've explored in &lt;a href=&quot;https://a.ttent.io/n/&quot;&gt;my fiction writing&lt;/a&gt; previously. But since I've never worked on natural language generation or deep learning, I decided to look more closely at just what this machine could do.
&lt;/p&gt;


&lt;h4&gt;The person you are speaking with is not real&lt;/h4&gt;
&lt;p&gt;
	My goal was to see how close I could come to impersonating a real human with algorithmically generated text and almost no manual quality control.  
&lt;/p&gt;
&lt;p&gt;
	I decided that one of the easiest places to test such a system would be in the responses to comments on the social media website, &lt;a href=&quot;https://www.reddit.com/&quot;&gt;reddit&lt;/a&gt;. My goal became to generate a bot that would respond topically to comments, garner upvotes, and see if it can promote discussion.  In case you are worried about the ethicality of releasing a surreptitious human on reddit, rest assured I have only deployed the bot sparingly to avoid generating too much annoyance in the world.  And I have manually reviewed evey comment to ensure that it produced nothing too offensive.
&lt;/p&gt;
&lt;p&gt;
	Honestly, I was hoping I could use this tool to become a little more popular on this whole internet thing. I've been pretty much terrible at interacting on social media so I figured maybe I could automate the problem away.  I quickly learned that just using GPT-2 on it's own is not quite adequate to impersonate a human most of the time.  But with a little modification, I've found that building a frighteningly passable reddit commenter is not only possible; it's pretty easy.
&lt;/p&gt;



&lt;h4 id=&quot;gpt2shortcoming&quot;&gt;The Shortcoming of GPT-2&lt;/h4&gt;
&lt;p&gt;
	What GPT-2's creators fail to mention is that while almost everything the model generates is grammatically and syntactically correct, only a tiny fraction of the outputs make any damn sense.  Here is another excerpt that shows just how non-human the output normally looks.
&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; data-dnt=&quot;true&quot; data-theme=&quot;light&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Here&amp;#39;s a short story i generated using OpenAI&amp;#39;s GPT-2 tool (prompt in bold) &lt;a href=&quot;https://t.co/DGIVwGuAUV&quot;&gt;pic.twitter.com/DGIVwGuAUV&lt;/a&gt;&lt;/p&gt;&amp;mdash; will knight (@willknight) &lt;a href=&quot;https://twitter.com/willknight/status/1096134045774344199?ref_src=twsrc%5Etfw&quot;&gt;February 14, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;
	When I first started experimenting, I generated a lot of similar gibberish.  As it turns out, GPT2 on its own is fairly prone to getting into weird unintelligible rants.  Here are some examples.
&lt;/p&gt;

&lt;blockquote&gt;
The idea of the film is very similar to the kind of film weve seen before,
The Road. The film took place at a time, at a place. 
The Road was set at a time, a place.
The Road was also set at a time of the Soviet Unions collapse,a time, the collapse of communism.
The Road is set at a time of the Russian Revolution,the collapse of the Soviet Unions fall,a time, the collapse of the Soviet Unions collapse.
So, The Road is a film about the dissolution of the Soviet Unions grip on the world,a time of the Russian Revolution.
&lt;/blockquote&gt;

&lt;p&gt;Clearly the algorithm is getting confused on the way quotations work.  Then there's this one, which makes grammatical sense, but is clearly a series of statements that no regular person would ever say (unless they were trolling). &lt;/p&gt;

&lt;blockquote&gt;
I still can't believe you. I had the same birthday last year.  
I'm a 10 year old, and I have never even heard of this novel.
&lt;/blockquote&gt;

&lt;p&gt;
	Worse still, a lot of the time, GPT2 will just start repeating a few crazy phrases over and over.  You can &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1n2_IM32ULuu_x9f_hX2YlmRfahF61K_os5fGg2RcgBA/edit?usp=sharing&quot;&gt;check out some of the model's output&lt;/a&gt; to get a taste of the kinds of things that it generates in the raw.
&lt;/p&gt;

&lt;p&gt;
	I wouldn't want to build a bot that spewed crazy looking responses like that all the time.  It would be incredibly annoying to other redditors and would probably be flagged right away.  Still, I didn't want to give up on the idea completely. I started brainstorming about ways that I could fix the performance problems with GPT2 and make it more robust, and I came up with something that was able to filter out a lot of the crap responses.
&lt;/p&gt;

&lt;h5&gt;Machines trying to trick other machines&lt;/h5&gt;
&lt;p&gt;
	To fix the problem, I borrowed an idea from another deep learning architecture called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Generative_adversarial_network&quot;&gt;generative adversarial network&lt;/a&gt; or GAN.  GANs have been used extensively in the past and  have been astonishingly successful in impersonating &lt;a href=&quot;https://www.thispersondoesnotexist.com/&quot;&gt;images&lt;/a&gt;, &lt;a href=&quot;https://magenta.tensorflow.org/gansynth&quot;&gt;music&lt;/a&gt;, and even &lt;a href=&quot;https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-1-2b886c8cab10?gi=e90e56af6387&quot;&gt;text&lt;/a&gt; (though it doesn't do text that well).  The rise of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Deepfake#History&quot;&gt;&quot;deep fake&quot;&lt;/a&gt; is mostly thanks to developments in the GAN architecture. 
&lt;/p&gt;
&lt;p&gt;
	The concept of the GAN is pretty simple. You train two algorithms, one to generate text (generator), and another to try to distinguish the generators text from human text  (discriminator).  These algorithms are typically called &lt;a href=https://en.wikipedia.org/wiki/Language_model&gt;language models&lt;/a&gt; because they attempt to model the way language is produced. In a classical GAN you then use the two models to improve each other by having the generator constantly compete to trick the discriminator (hence Adversarial).  
&lt;/p&gt;


&lt;img title=&quot;GAN illustration&quot; src=&quot;/assets/images/2020/gan_explain.png&quot; alt=&quot;GAN illustration&quot;/&gt;
&lt;p style=&quot;text-align:center;&quot;&gt;&lt;em&gt;GAN diagram (&lt;a href=&quot;https://developers.google.com/machine-learning/gan/gan_structure&quot;&gt;source&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
	It's a very intuitive and clever concept, and one that I personally feel mirrors the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bicameralism_(psychology)&quot;&gt;internal dialog&lt;/a&gt; that I constantly have in my own brain's decision making system.  The critic in my head feels almost like a discriminator algorithm &lt;a href=&quot;https://i.imgur.com/mGva0nK.gif&quot;&gt;throwing shade&lt;/a&gt; on my internal generator algorithm. Anyway, if you're interested in how they work in detail, you can read more &lt;a href=&quot;https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;

&lt;p&gt;
	Unfortunately, I wasn't quite smart enough to figure out how to modify the pre-existing GPT-2 model to turn it into a GAN.  I think it's possible, but tensorflow is a &lt;a href=&quot;https://nostalgebraist.tumblr.com/post/189464877164/attention-conservation-notice-machine-learning&quot;&gt;confusing beast&lt;/a&gt;, and I'm not yet at the point where I care enough to untangle that mess.  Instead, I did something a little simpler that was just effective enough to make the results passable.
&lt;/p&gt;

&lt;h4&gt;Filtered generator -&gt; discriminator method&lt;/h4&gt;

&lt;p&gt;
	I instead opted for a multi-stage modeling framework, utilizing three separate deep-learning models stitched together one after the next.  This diagram illustrates the many parts that needed to be trained, and how they were strung together to produce replies from comments.
&lt;/p&gt;

&lt;img title=&quot;GPT2 BERT commentor workflow&quot; src=&quot;/assets/images/2020/gpt2_bert_workflow.png&quot; alt=&quot;GPT2 BERT comment system workflow&quot;/&gt;

&lt;p&gt;
	In this setup, I first pick a comment on reddit to serve as seed text for the generator.  I generate a whole bunch of replies for this comment using my GPT-2 model.  Then I pass all the candidates to the discriminator model to filter out the messed up comments and only select the best ones. 
&lt;/p&gt;

&lt;p&gt;
	To build the discriminators, I fine-tuned another deep-learning language model called &lt;a href=&quot;https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270&quot;&gt;BERT&lt;/a&gt;.  I made two models, one for how realistic the reply was and another for how many upvotes the reply would get. 
&lt;/p&gt;


&lt;p&gt;
	You can read &lt;a href=&quot;/2020/02/reddit-bot-gpt2-bert/&quot;&gt;this post&lt;/a&gt; for a detailed walkthrough of how the whole system was constructed, trained, tested, and deployed. 
&lt;/p&gt;
&lt;p&gt;
	Just by looking at the initial results, it seemed likely that the bot was going to be able to communicate pretty convincingly.  But the only &lt;a href=&quot;https://en.wikipedia.org/wiki/Turing_test&quot;&gt;real test&lt;/a&gt; was to put it into use and see how people respond.
&lt;/p&gt;

&lt;h4&gt;Meet tupperware-party&lt;/h4&gt;
&lt;p&gt;
	Once I had the models built and hooked together, the last step was to plug the bot into reddit.  I made an account for the bot called &lt;strong&gt;tupperware-party&lt;/strong&gt;, which I figured sounded innocuous enough.  I used &lt;a href=&quot;https://praw.readthedocs.io/en/latest/&quot;&gt;praw&lt;/a&gt; to submit the replies automatically, and then I went through and examined all of them to make sure none were too offensive or annoying.  As I was reading through the results, there were so many gems that it's hard to pick just a few examples to share.
&lt;/p&gt;

&lt;h5 id='replies'&gt;What did the robot say?&lt;/h5&gt;

&lt;p&gt;
	This &lt;a href=&quot;https://www.reddit.com/r/sciencefiction/comments/evqiti/dune_logo_unveiled_at_event_copyright_claimants/fg44yzw/?context=3&quot;&gt;first one&lt;/a&gt; seems like a perfect imitation of someone with a strong opinion on the internet. 
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party1.png&quot; alt=&quot;COMMENT: 'Dunes fandom is old and intense, and a rich thread in the cultural fabric of the internet generation' BOT_REPLY:'Dunes fandom is overgrown, underfunded, and in many ways, a poor fit for the new, faster internet generation.'&quot; style=&quot;border:2px;&quot;/&gt;


&lt;p&gt;
	I actually can't explain how &lt;a href=&quot;https://www.reddit.com/r/BurningMan/comments/ep6pyq/playa_lung/feilsjn/?context=8&amp;depth=9&quot;&gt;this next one&lt;/a&gt; could possibly work.  It seems as if the bot is responding to the specific numerical bullet points in the original comment.
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party2.png&quot; alt=&quot;bot responds to specific numerical bullet point in source comment&quot;/&gt;

&lt;p&gt;
	Notice that in the original comment, point 2 is about sleep and the bot says &quot;2&quot; right before talking about sleep. Then it says &quot;3&quot; before switching subjects to talking about something that induces anxiety.  It doesn't make perfect sense but it somehow knows to respond to bullet points separately, which seems like a huge leap given that it was never trained to do that specifically.
&lt;/p&gt;

&lt;p&gt;
	This &lt;a href=&quot;https://www.reddit.com/r/artificial/comments/ep26lc/is_china_going_to_overtake_the_us_in_data_science/feik6wg/?context=8&amp;depth=9&quot;&gt; one&lt;/a&gt; is great on a number of levels.  First, it's kind of meta because the bot was posting into the &lt;a href=&quot;https://www.reddit.com/r/artificial/&quot;&gt;r/artifical subreddit&lt;/a&gt;, which is a forum dedicated to artificial intelligence.  Second, not only is the comment pretty darn coherent, it is so much so that the original author writes a well thought out reply further expanding on his point in light of the bot's comment.
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party3.png&quot; alt=&quot;gpt2-bert on China&quot;/&gt;

&lt;p&gt;
	I honestly don't even know what to say to that.  Is it possible that every conversation on the internet right now has at least one slightly ill-informed bot in the mix.  We are seriously screwed.  But don't worry, this bot is at least a little woke too already.
&lt;/p&gt;

&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/tupperware-party4.png&quot; alt=&quot;The first thing I think of when thinking about a villain's face turn is probably that they are a male character. Some males are actually pretty bad in the media...&quot;/&gt;

&lt;p&gt;
	There are so many surprisingly realistic replies that I enourage you to go through &lt;a href=&quot;https://www.reddit.com/user/tupperware-party/comments/&quot;&gt;tupperware-party's whole comment list&lt;/a&gt;.  Overall, the bot wrote 80 replies and 24 of them received at least one upvote. I'm impressed with that and hoping that maybe it will eventually be able to help &lt;a href=&quot;https://www.reddit.com/user/bonkerfield&quot;&gt;me&lt;/a&gt; become more popular on reddit.
&lt;/p&gt;

&lt;p&gt;
	On the other hand, the single most popular comment (with 8 votes) was &lt;a href=&quot;https://www.reddit.com/r/sciencefiction/comments/efej56/the_problem_with_the_original_dune_movie/fc16yq8/?context=3&quot;&gt;this one&lt;/a&gt;, which is just innocuous flattery.  
&lt;/p&gt;
&lt;img title=&quot;reddit-gpt2-bert-bot comment&quot; src=&quot;/assets/images/2020/thiscommentisgreat.png&quot; alt=&quot;This comment is great.&quot;/&gt;

&lt;p&gt;
	Since this could easily be copy and pasted to every other comment and still be totally in context, I guess maybe I didn't need to try so hard.
&lt;/p&gt;

&lt;h4 id=&quot;ethics&quot;&gt;You can build one too!&lt;/h4&gt;

&lt;p&gt;If you find this interesting, I've written a &lt;a href=&quot;/2020/02/reddit-bot-gpt2-bert/&quot;&gt;tutorial post&lt;/a&gt; with details and code describing how I built everything and showing what you'd need to do to recreate one of your own.  I realize there are definite ethicality concerns with building and using something like this so I encourage you to be an &lt;a href=&quot;https://en.wikiquote.org/wiki/Bill_%26_Ted%27s_Excellent_Adventure&quot;&gt;excellent&lt;/a&gt; human and only use this tool sparingly and for that which &lt;a href=&quot;https://en.wikipedia.org/wiki/Categorical_imperative&quot;&gt;you deem to be good&lt;/a&gt;.  
&lt;/p&gt;
&lt;h5&gt;Ethical concerns&lt;/h5&gt;
&lt;p&gt;
    I know there are definitely some ethical considerations when creating something like this.  The reason I'm presenting it is because I actually think it is &lt;a href=&quot;https://www.wired.com/story/company-wants-billions-make-ai-safe-humanity/&quot;&gt;better&lt;/a&gt; for more people to know about and be able to grapple with this kind of technology. If just a few people know about the capacity of these machines, then it is more likely that those small groups of people can abuse their advantage.
&lt;/p&gt;
&lt;p&gt;
    I also think that this technology is going to change the way we think about what's important about being human.  After all, if a computer can effectively automate the paper-pushing jobs we've constructed and all the bullshit we create on the internet to distract us, then maybe it'll be time for us to move on to something more meaningful.
&lt;/p&gt;

&lt;p&gt;
	If you think what I've done is a problem feel free to &lt;span class=&quot;popup__open&quot; style=&quot;border-bottom: 0.25px solid $color-grey&quot;&gt;email me &lt;i class=&quot;fa fa-envelope&quot;&gt;&lt;/i&gt;&lt;/span&gt;, or publically shame me on &lt;a href=&quot;https://twitter.com/bonkerfield&quot;&gt;Twitter&lt;/a&gt;.
&lt;/p&gt;


</description>
        <pubDate>Tue, 04 Feb 2020 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2020/02/combining-gpt-2-and-bert/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2020/02/combining-gpt-2-and-bert/</guid>
        
        <category>machine learning</category>
        
        <category>language</category>
        
        <category>end times</category>
        
        
      </item>
    
      <item>
        <title>Visualizing the Bonkerfield</title>
        <description>&lt;p&gt;For the past few weeks, I've been trying to figure out how to visually describe a philosophical concept that I've come up with called a &lt;strong&gt;bonkerfield&lt;/strong&gt;. It's something I find fascinating, but quite hard to wrap my own head around entirely.  I've been ruminating on how to convey it for a while now, trying to be able to get the idea across and not sound like a crazy person or an idiot. &lt;/p&gt;

&lt;p&gt;I've elaborated on this subject at length on my &lt;a href=&quot;/reasons/&quot;&gt;reasons&lt;/a&gt; page, but in short, a bonkerfield is a map of everywhere that any information has resided throughout all of space and time.  The idea sounds convoluted in words, but it's something that I have a pretty decent image of in my mind.&lt;/p&gt;

&lt;p&gt;Originally I was planning to create a conceptual piece without too much detail.  I made a weak attempt in this sketch. Hopefully, You get the idea of connectedness between different spots as if the idea is kind of being put together towards a single point in time and then disseminated on the other side.&lt;/p&gt;


&lt;img class=&quot;small_img&quot; title=&quot;Medium Bonkerfield&quot; src=&quot;/assets/images/2020/bonker_sketch.jpg&quot;&gt;


&lt;p&gt;As I thought about it more, I figured it would be possible to realize this idea in a more concrete way.  I could find someone's record of the formation and dissemination of some idea and visualize the actual data itself.&lt;/p&gt;


&lt;p&gt;Following information around in space and time is still pretty nebulous so I know I'm doomed to failure in some sense.  Still, I wanted to try using the tools of the modern data scientist to manifest this philosophical concept.&lt;/p&gt;


&lt;h4&gt;Spatiotemporally Fixed Hierarchical Clustering in d3&lt;/h4&gt;
&lt;p&gt;Like I normally do in this situation, I went and scanned the web for things that already look kind of similar to what I'm trying to build.  At it's core, I wanted swoopy, pretty lines that connected nodes.  I figured that &lt;a href=&quot;https://en.wikipedia.org/wiki/Mike_Bostock&quot;&gt;Mike Bostock&lt;/a&gt; of d3 fame must've built something like this at some point, and I wasn't dissapointed.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/hierarchical_edge_bundling.png&quot; title=&quot;Hierarchical Edge BUndling Viz by Mike Bostock&quot;&gt;


&lt;p&gt;He'd built this &lt;a href=&quot;https://bl.ocks.org/mbostock/5672200&quot;&gt;hierarchical clustering vizualitation&lt;/a&gt; that is a little different than what I want, but still really reminds me of the general feel. The data he was vizualizing in this example was the interconnectivity of software packages in a codebase.  He's used this as a basis for &lt;a href=&quot;https://observablehq.com/@d3/hierarchical-edge-bundling&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://bl.ocks.org/mbostock/4341134&quot;&gt;different&lt;/a&gt; &lt;a href=&quot;https://bl.ocks.org/mbostock/5672200&quot;&gt;visualizations&lt;/a&gt;, and humorously, I had previously exploited some of his &lt;a href=&quot;https://bost.ocks.org/mike/hive/&quot;&gt;related work&lt;/a&gt; to make another attempted &lt;a href=&quot;hellowill.bonkerfield.org&quot;&gt;vizualization&lt;/a&gt; of all the people I had worked with in my life.&lt;/p&gt;

&lt;img src=&quot;/assets/images/2020/hellowill_viz.png&quot; title=&quot;plot of people projects and skills from my digital resume&quot;&gt;

&lt;p&gt;I have &lt;a href=&quot;/2015/01/05/a-better-linkedin/&quot;&gt;another post&lt;/a&gt; that explains building that visual.  It had constrained all projects along one radial line, skills on another, and people on a third.  To vizualize the bonkerfield, I needed to do something similar except the positional constraint would be along the x-axis and it would vary based on time.&lt;/p&gt;

&lt;p&gt;The time of interest is the time that some discernible event related to the formation of an idea would take place.  For now, I decided that spatial position wouldn't be demarked explicitly along the other axis.  Instead, I would use the clustering of events to automatically set where they lay. This way there shouldn't be too many overlapping lines in the final result.&lt;/p&gt;


&lt;h4&gt;Selecting a test idea&lt;/h4&gt;

&lt;p&gt;To get started testing, I needed a simple example scenario to try to visualize. &lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;&lt;em&gt;Imagine an author is writing a paragraph about a childhood memory with her mother.  In the paragraph, she quotes the phrase &quot;Call me Ishmael&quot; from Moby Dick.  Both of those pieces of information are baked into the bonkerfield of that paragraph.  After she publishes that paragraph in her memoir, a few Melville academics cite her.  In addition, something she says in that paragraph blows up as a meme on the internet.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;
  Maybe this scenario isn't that realistic, and definitely not the best candidate to demonstrate the value of the bonkerfield as a construct. Still, it's simple enough and contained enough that I could keep it in my head long enough to hand annotate the data structure I was going to use for it.
&lt;/p&gt;

&lt;h4 id=&quot;results&quot;&gt;Results&lt;/h4&gt;
&lt;p&gt;You can view below for the implementation details, but before that I wanted to show what the general results were. Below is an implementation of the scenario above.  On the top left, is the reference to Moby Dick's &quot;Call me Ishmael&quot;, which in turn references Ishmael in the Bible.  The bottom right is the &quot;viral&quot; expansion as that paragraph blows up on the internet.&lt;/p&gt;


&lt;img title=&quot;Tame Bonkerfield&quot; src=&quot;/assets/images/2020/bonker_viz_1.png&quot;&gt;

&lt;p&gt;There were a number of variations that I want to be able to work with when building bonkerfields.  The framework I've built allows me to vary the number of lines, the opacity and the random dispersion of their endpoints.  The next two images show what happens when I turn up the randomness on the viral part of the example.&lt;/p&gt;

&lt;img class=&quot;small_img&quot; title=&quot;Medium Bonkerfield&quot; src=&quot;/assets/images/2020/bonker_viz_2.png&quot;&gt;
&lt;img class=&quot;small_img&quot; title=&quot;Wild Bonkerfield&quot; src=&quot;/assets/images/2020/bonker_viz_3.png&quot;&gt;


&lt;p&gt;You can see the live d3 graph and the code to produce it on &lt;a href=&quot;https://bl.ocks.org/stedn/5d187e873982e441e1f78d6d69af0030&quot;&gt;this bl.ock&lt;/a&gt;.  Next, I want to explore building more complex underlying bonkerfields. &lt;/p&gt;

&lt;h5&gt;A more complex bonkerfield&lt;/h5&gt;
&lt;p&gt;After building the simple version, I really wanted to scale it up to a more complex and interesting example.  Unfortunately, I didn't quite have time to compile real data or come up with another complicated story for this one.  Instead, I just tried generating a random hierarchy. The results were quite surprising. &lt;/p&gt;


&lt;img title=&quot;Complicated Bonkerfield&quot; src=&quot;/assets/images/2020/big_bonkerfield.png&quot; /&gt;


&lt;p&gt;When this image rendered, I've was overwhelmed with the similarity to a neuron.  There's really a beautiful correspondence between the bonkerfield and the brain that hadn't even occurred to me as I was building it.  The bonkerfield of any information in a human mind could be traced down through the individual neurons that collectively record it. So it's really fitting that  like in &lt;a href=&quot;https://en.wikipedia.org/wiki/Neuron#/media/File:PurkinjeCell.jpg&quot;&gt;this classic illustration&lt;/a&gt; from &lt;a href=&quot;https://en.wikipedia.org/wiki/Santiago_Ram%C3%B3n_y_Cajal&quot;&gt;Santiago Ramn y Cajal&lt;/a&gt;.&lt;/p&gt;


&lt;img title=&quot;Purkinje Neuron Cells&quot; src=&quot;/assets/images/2020/PurkinjeCell.jpg&quot; /&gt;


&lt;p&gt;What's more amazing, was the how the parameters that I used to generate the random graph varied the the overall structure&lt;/p&gt;


&lt;p&gt;See below for implementation details. I will be back soon with an analysis of how a few parameters can control the architecture of the complicated.  And once I get a really good example where I can work through and compile the data, I'll update with a thorough explanation of a rendering of a true bonkerfield.&lt;/p&gt;

&lt;h4&gt;Implementation&lt;/h4&gt;
&lt;p&gt;The rest of this article can help walk you through adapting my code and data to build your own bonkerfields.&lt;/p&gt;
&lt;h5&gt;Compiling the data&lt;/h5&gt;
&lt;p&gt;
  I had to hand annotate a json document in the structure needed for d3 to render it using the d3 &quot;bundle&quot; layout. Even though my data isn't really any kind of hierarchy, I'm sort of hacking the format that the d3 hierarchical bundling wants. 
&lt;/p&gt;

&lt;p&gt;The minimal format to make it work requires two things:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a &lt;code&gt;.&lt;/code&gt; delimited naming structure to define the hierarchy&lt;/li&gt;
  &lt;li&gt;an import structure to define where th lines should be drawn between.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
  I want everything to be drawn for the lowest nodes back up to the &quot;paragraph&quot; node, so I only need imports from the leafs to the paragraph node. To create a hierarchy for the leafs, I just needed to come up with higher order groupings that link things so their lines get drawn together on the way back up to the &quot;paragraph&quot; node.  The following document shows a simple example that would take two leaves for &lt;code&gt;bible&lt;/code&gt; and &lt;code&gt;melville&lt;/code&gt; and link them back to the paragraph via &lt;code&gt;mobydick&lt;/code&gt;
&lt;/p&gt;

&lt;pre&gt;
[
  {&quot;name&quot;:&quot;paragraph.mobydick.bible&quot;,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.mobydick.melville&quot;,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.mobydick&quot;,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph&quot;,&quot;imports&quot;:[]},
]
&lt;/pre&gt;

&lt;p&gt;To generate the full vizualization I added a couple more routes for the information to flow up to the paragraph.  I also added an additional &lt;code&gt;time&lt;/code&gt;, &lt;code&gt;size&lt;/code&gt;, and &lt;code&gt;weight&lt;/code&gt; params that would set the x-position, the thickness of the line, and the transparency of the stroke, respectively.&lt;/p&gt;
&lt;pre&gt;
[
  {&quot;name&quot;:&quot;paragraph.gap.visit.mom&quot;,&quot;time&quot;:100,&quot;size&quot;:20,&quot;weight&quot;:0.1,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.visit.memory&quot;,&quot;time&quot;:100,&quot;size&quot;:10,&quot;weight&quot;:0.01,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.quotes&quot;,&quot;time&quot;:70,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.mobydick.bible&quot;,&quot;time&quot;:10,&quot;size&quot;:10,&quot;weight&quot;:0.01,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.mobydick.melville&quot;,&quot;time&quot;:10,&quot;size&quot;:10,&quot;weight&quot;:0.1,&quot;imports&quot;:[&quot;paragraph&quot;]},
  {&quot;name&quot;:&quot;paragraph.gap.blog.mobydick&quot;,&quot;time&quot;:70,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph.gap.visit&quot;,&quot;time&quot;:200,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph.gap.blog&quot;,&quot;time&quot;:200,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph.gap&quot;,&quot;time&quot;:300,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;paragraph&quot;,&quot;time&quot;:350,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]},
  {&quot;name&quot;:&quot;&quot;,&quot;time&quot;:350,&quot;size&quot;:10,&quot;weight&quot;:0.05,&quot;imports&quot;:[]}
]
&lt;/pre&gt;

&lt;p&gt;I also made a &lt;a href=&quot;https://bl.ocks.org/stedn/5d187e873982e441e1f78d6d69af0030#bonkerfield_post.json&quot;&gt;similar document&lt;/a&gt; to render the other side of the bonkerfield visualization.&lt;/p&gt;

&lt;h5&gt;Coding the d3 vizualition&lt;/h5&gt;
&lt;p&gt;Starting from the &lt;a href=&quot;https://bl.ocks.org/mbostock/5672200&quot;&gt;example code&lt;/a&gt; that I found on &lt;a href=&quot;https://bl.ocks.org/mbostock&quot;&gt;bl.ocks.org&lt;/a&gt;, I started making tweaks to the code.  Most of them were fairly minor sizing issues and rotations of things.  The only thing that was really crucial was figuring out how to set the x-position using the &quot;time&quot; field from the document.  Without that, the layout would put everything on one vertical line, which doesn't quite work for me.&lt;/p&gt;

&lt;p&gt;The only crucial modification was to the node location, which required adding two bits of code.  The first was to modify the function that does the data load, in oder to transfer the data from the file into the &lt;code&gt;node&lt;/code&gt; object that d3 uses from rendering the nodes of the graph.&lt;/p&gt;

&lt;pre&gt;
function find(name, data) {
      var node = map[name], i;
      if (!node) {
        node = map[name] = data || {name: name, children: []};
        if (name.length) {
          node.parent = find(name.substring(0, i = name.lastIndexOf(&quot;.&quot;)));
          node.parent.children.push(node);
          node.key = name.substring(i + 1);
&gt;          if (data){
&gt;            node.time = data.time;
&gt;          }else{
&gt;            node.time = null;
&gt;          }
          
        }
&gt;      } else {
&gt;        if(!node.time){
&gt;          if (data){
&gt;            node.time = data.time
&gt;          }
&gt;        }
      }
      return node;
    }
&lt;/pre&gt;

&lt;p&gt;With that added, it's just necessary too use the &lt;code&gt;time&lt;/code&gt; attribute when rendering the node SVG and the link SVG.&lt;/p&gt;

&lt;pre&gt;
  ...
  var line_post = d3.svg.line()
    ...
    .x(function(d) {return d.time;})
  ...
  svg_post.selectAll(&quot;.node&quot;)
    ...
    .attr(&quot;transform&quot;, function(d) {return &quot;translate(&quot; + d.time + &quot;,&quot; + d.x + &quot;)&quot;;})
  ...
&lt;/pre&gt;

&lt;p&gt;For a little extra flair, I also wanted to make more widely dispersed data show up as a thicker line.  To do that, I just added duplicated paths with randomly jittered endpoints.  You can check the code if you want to see how I duplicated the paths, but for the random jitter I used a simple rough approximation of a normal distribution in x and y.&lt;/p&gt;

&lt;pre&gt;
function myrandom(){
  /* approximate a normal distribution (sort of) */
  /* using straight uniform makes everything look square */
  var r = 0;
  for(var i = 3; i &gt; 0; i --){
      r += Math.random();
  }
  return 1.25*(r/3 - 0.5)
}

var line_pre = d3.svg.line()
  ...
  .x(function(d) {return d.time+myrandom()*d.size;})
  .y(function(d) {return d.x+myrandom()*d.size; });
&lt;/pre&gt;

&lt;h5&gt;Styling&lt;/h5&gt;
&lt;p&gt;There's some additional styling that yu can check out in the code directly.  To make the opposite side of the bonkerfield, I duplicated all the above, but inverted the x-axis by sutracting the x positions from width (eg &lt;code&gt;.x(function(d) {return width - d.time+myrandom()*d.size;})&lt;/code&gt;).  &lt;/p&gt;

&lt;h4&gt;The complicated graph&lt;/h4&gt;
&lt;p&gt;Since I didn't want to hand generate a really big graph, I used some python code to generate the structure for me. The function is really quite simple; it just randomly branches a tree with probability &lt;code&gt;child_prob&lt;/code&gt;, and then adds an arm to the tree that is also randomly chosen from &lt;code&gt;time_inc_rand&lt;/code&gt;. &lt;/p&gt;

&lt;pre&gt;
def add_node(node_list, parent_name, parent_time, parent_size, parent_weight):
    name = parent_name+'.'+''.join([random.choice(string.ascii_letters) for n in range(5)])
    imports = [center]
    time = parent_time - int(time_inc_min +  time_inc_rand * random.random())
    if time &lt; 50:
        return
    while random.random() &lt; child_prob:
        add_node(node_list, name, time, parent_size, parent_weight)
    while random.random() &lt; child_prob:
        node_list.append({&quot;name&quot;:name+'.'+''.join([random.choice(string.ascii_letters) for n in range(5)]),
                          &quot;time&quot;:time-5,
                          &quot;size&quot;:parent_size,
                          &quot;weight&quot;:parent_weight,
                          &quot;imports&quot;:[center]})
        imports = []
    node_list.append({&quot;name&quot;:name,&quot;time&quot;:time,&quot;size&quot;:parent_size,&quot;weight&quot;:parent_weight,&quot;imports&quot;:[]})

&lt;/pre&gt;


&lt;p&gt;However, the variety of output that it could generate by varying those parameters was astonishing to me.  This led me on another analytical meandering into the shapes that develop from hierarchies with random children, random edge lengths, and random leaf dispersions.  I've started a project with &lt;a href=&quot;https://github.com/lots-of-things/random-bonkerfield-generator&quot;&gt;the code&lt;/a&gt; to do the generation of the json objects with random parameters.  It's really fascinating, and I will add a link here when I finish exploring. &lt;/p&gt;


&lt;h4&gt;More To Do&lt;/h4&gt;
&lt;p&gt;There's still much more to do to make the bonkerfield concept clearer.  You can fork the code to render bonkerfields from either the &lt;a href=&quot;https://bl.ocks.org/stedn/5d187e873982e441e1f78d6d69af0030&quot;&gt;simple&lt;/a&gt; or the &lt;a href=&quot;https://bl.ocks.org/stedn/33fd840f81627ec0967448fbc832ed9f&quot;&gt;complex&lt;/a&gt; bl.ocks, and the code for generating the json objects is on &lt;a href=&quot;https://github.com/lots-of-things/random-bonkerfield-generator&quot;&gt;github&lt;/a&gt;. If someone out there likes this idea and would like to take it further, please feel free.  Let me know what you come up with. &lt;/p&gt;
</description>
        <pubDate>Tue, 28 Jan 2020 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2020/01/visualizing-the-bonkerfield/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2020/01/visualizing-the-bonkerfield/</guid>
        
        <category>philosophy</category>
        
        <category>art</category>
        
        
      </item>
    
      <item>
        <title>QMB Prototype Demo</title>
        <description>&lt;p&gt;Lately, I've been having &lt;a href=&quot;2019/10/23/qmb-installation/&quot;&gt;too much fun&lt;/a&gt;, working on &lt;a href=&quot;2019/10/17/quantum-multiverse-bifurcator/&quot;&gt;quantum randomness generators&lt;/a&gt;.  One of my goals is to build a minimalist device for producing a quantum binary outcome.  I've designed one simple and cost-effective circuit that I think will fit the bill.  Check out the video to see how it works.&lt;/p&gt;

&lt;iframe class=&quot;flexme&quot; width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/0-vfWDAkc1g&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;
	The device works by measuring quantum fluctuations in the amount of light hitting two detectors. I have a &lt;a href=&quot;2019/10/18/quantum-coin-flip-device/&quot;&gt;previous post&lt;/a&gt; with details on a similar circuit that I'd built a few months ago, but the main modification for this iteration was to add the enclosement and the aperture.  
&lt;/p&gt;

&lt;img title=&quot;Quantum Multiverse Bifurcator prototype&quot; src=&quot;/assets/images/2020/qmb_proto.jpg&quot; alt=&quot;Quantum Multiverse Bifurcator prototype&quot;/&gt;


&lt;p&gt;
	The aperture itself is based on &lt;a href=&quot;https://www.instructables.com/id/Cardboard-Aperture-v2/&quot;&gt;this instructable&lt;/a&gt;, though there were definitely issues with that design.  I made an adjustment to have the interior disc's slots a little wider and then I mounted that into the tp of the box.
&lt;/p&gt;

&lt;img title=&quot;Quantum Multiverse Bifurcator prototype&quot; src=&quot;/assets/images/2020/qmb_proto_open.jpg&quot; alt=&quot;Quantum Multiverse Bifurcator prototype&quot;/&gt;

&lt;p&gt;
	The reason I had to build something to limit the incoming light was that in the open version, the light source was too dificult to stabilize.  With this version I could more carefully place the light source and adjust the aperture width to get a roughly 50-50 split between red and blue lighting up.
&lt;/p&gt;

&lt;p&gt;
	I'm still concerned that this implementation isn't fully quantum though because of noise in the circuit and variation in lighting due to movement.  If you have an idea about how to fix these issues or if you see other problems I haven't thought of, &lt;span class=&quot;popup__open&quot; style=&quot;border-bottom: 0.25px solid $color-grey&quot;&gt;please get in touch &lt;i class=&quot;fa fa-envelope&quot;&gt;&lt;/i&gt;&lt;/span&gt;
&lt;/p&gt;

</description>
        <pubDate>Mon, 20 Jan 2020 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2020/01/qmb-prototype-demo/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2020/01/qmb-prototype-demo/</guid>
        
        <category>physics</category>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>Short Post on Short Showers</title>
        <description>&lt;p&gt;
    I finally was able to reduce my flying this year to just two flights to visit family for the holidays. My partner still points out that I take long showers so I should get off my high horse. I've decided to fix that.
&lt;/p&gt;
&lt;h4&gt;A little math&lt;/h4&gt;
&lt;p&gt;
    I found &lt;a href=&quot;http://greenblizzard.com/2016/05/09/showers-and-co2/&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;https://theecoguide.org/have-you-tried-five-minute-shower-challenge&quot;&gt;calculations&lt;/a&gt; of the amount of carbon dioxide produced by a shower. This varies by energy source so I tried a quick calculation for my own residence.
&lt;/p&gt;
&lt;p&gt;
    Assuming 2.5 gallons/minute of shower, and that I'm heating the water by about 60 degrees, we can use &lt;a href=&quot;https://www.e-education.psu.edu/egee102/node/2003&quot;&gt;this equation&lt;/a&gt; to calculate the power needed.
&lt;/p&gt;
&lt;blockquote&gt;2.5 gallon/minute x 8 lbs/gallon x 1 BTU/lbF x 60F = &lt;strong&gt;1200 BTU/minute&lt;/strong&gt; &lt;/blockquote&gt;
&lt;p&gt;
    I heat it using electricity,and it seems that electric water heaters are generally considered to be around &lt;a href=&quot;https://smarterhouse.org/water-heating/replacing-your-water-heater&quot;&gt;90% efficient&lt;/a&gt;. So I'm actually using 1200/0.9 = &lt;strong&gt;1333 BTU/minute&lt;/strong&gt;.
&lt;/p&gt;
&lt;p&gt;
    California's PG&amp;amp;E power mix says it is only &lt;a href=&quot;https://www.pge.com/pge_global/common/pdfs/your-account/your-bill/understand-your-bill/bill-inserts/2019/1019-Power-Content-Label.pdf&quot;&gt;15% fossil fuel&lt;/a&gt; (probably mostly natural gas). According to the US EIA, natural gas releases &lt;a href=&quot;https://www.eia.gov/electricity/annual/html/epa_a_03.html&quot;&gt;~50 kg of CO2 for every million BTU&lt;/a&gt; or equivalently 0.05 g/BTU. So at this point it seems every minute of shower is 1333 BTU/minute * 0.15 * 0.05 gCO2/BTU = &lt;strong&gt;9 gCO2/minute&lt;/strong&gt;.
&lt;/p&gt;
&lt;p&gt;
    For perspective, I used &lt;a href=&quot;https://calculator.carbonfootprint.com/calculator.aspx?tab=3&quot;&gt;this online flight carbon calculator&lt;/a&gt; to calculate that I released 0.29 metric tons of carbon (or 290000 grams) to visit my family in Tuscon this Thanksgiving. So that one trip was equivalent to showering for 22 days straight.
&lt;/p&gt;
&lt;h4&gt;Shortening my showers&lt;/h4&gt;
&lt;p&gt;
    So showers are a drop in the bucket (pun intended) compared to flights, but I still figured I could make a change. I take about a 12 minute shower every day. I figured I could drop that to 2 minutes if I try. That 10 minutes would save 90 grams of CO2 a day, and if I could keep it up for a year, that'd be about 32kg. That's equivalent to an 80 mile car ride. But no one will ride in the car with me because I'd be smelly.
&lt;/p&gt;
&lt;p&gt;
    Anyway, I'll be setting a timer to try to get down to 2 minutes by January 1, and after I'll see if I can go the whole year. Please leave a comment if you see something off in my calculations.
&lt;/p&gt;

&lt;p&gt;
	&lt;em&gt;Update: I forgot that part of the reason for showering was to actually get clean.  As it turns out, after a month of showering for 2 minutes I started to get a little gross.  So I'm moderating my usage, but no longer limiting to 2 minutes.  Oh well, worth it while it lasted.&lt;/em&gt; 
&lt;/p&gt;</description>
        <pubDate>Sat, 07 Dec 2019 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2019/12/short-post-on-short-showers/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/12/short-post-on-short-showers/</guid>
        
        <category>energy</category>
        
        <category>analysis</category>
        
        
      </item>
    
      <item>
        <title>Quantum Multiverse Bifurcator Installation</title>
        <description>&lt;p&gt;
    For the past few months, I've been working on a series of &lt;a href=&quot;/2019/10/quantum-multiverse-bifurcator.html&quot;&gt;interconnected&lt;/a&gt; &lt;a href=&quot;/2019/10/quantum-coin-flip-device.html&quot;&gt;projects&lt;/a&gt; and &lt;a href=&quot;/2019/10/sub-identity-suicide.html&quot;&gt;thought experiments&lt;/a&gt; centered around the concept of the &lt;a href=&quot;https://science.howstuffworks.com/science-vs-myth/everyday-myths/parallel-universe2.htm&quot;&gt;quantum multiverse&lt;/a&gt;, a theoretical interpretation of quantum mechanics that implies that many parallel universes are created by the outcomes of every quantum mechanical measurement. It's a fairly trippy concept, and I'm pretty sure that my interest in it is making me go a little crazy. Still, I think this concept is cool enough that I want to share it with as many people as possible. To do that, I've decided to expand the &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;experimental system&lt;/a&gt; into a full-scale art experience.
&lt;/p&gt;

&lt;h4&gt;Concept&lt;/h4&gt;
&lt;p&gt;
    The concept of the Quantum Multiverse Bifurcator comes from the familiar sci-fi trope of alternate parallel universes. Often in these stories, people find that a random event has split reality into two divergent timelines. As it turns out, there is a real scientific interpretation of quantum mechanics, called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Many-worlds_interpretation&quot;&gt;Many Worlds Interpretation&lt;/a&gt; that seems to imply this sci-fi concept could be &lt;a href=&quot;https://www.newscientist.com/round-up/reality/&quot;&gt;real&lt;/a&gt;.
&lt;/p&gt;
&lt;h6&gt;The Catch&lt;/h6&gt;
&lt;p&gt;
    But there is a catch. The only thing that actually splits the universe is the outcome of a quantum mechanical event. Most random events in our lives are probably &lt;a href=&quot;https://www.quantamagazine.org/how-randomness-can-arise-from-determinism-20191014/&quot;&gt;classically random&lt;/a&gt;, meaning they are &lt;a href=&quot;https://en.wikipedia.org/wiki/Deterministic_system&quot;&gt;deterministic&lt;/a&gt;, but we simply lack the ability to predict them. As far as we know, quantum mechanical randomness is differentquantum events can't be predicted even with perfect information.
&lt;/p&gt;
&lt;h6&gt;The Solution&lt;/h6&gt;
&lt;p&gt;
    But there is a way to actively generate parallel universes in a manner in line with the scientific understanding of the multiverse. We can couple the big decisions that would split the universe with the random outcomes of quantum mechanical events. In short, we can &lt;strong&gt;&lt;a href=&quot;https://aeon.co/ideas/what-einstein-meant-by-god-does-not-play-dice&quot;&gt;play dice with the universe&lt;/a&gt;&lt;/strong&gt;. To accomplish this feat, I built an application called the &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;Quantum Mulltiverse Bifurcator&lt;/a&gt;, which pulls a real quantum mechanical measurement to tell a human what decision to make. If the human follows their instructions, according to the many worlds interpretation, two universes are made, one in which each option occurs.
&lt;/p&gt;
&lt;p&gt;
    My partner and I decided to build an installation to present the &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;Quantum Multiverse Bifurcator (QMB)&lt;/a&gt; and allow people to interact with it. We decided to bring our installation to Burning Man's &lt;a href=&quot;https://burningman.org/events/san-francisco-decompression-2019-black-top-city/&quot;&gt;SF Decompression party&lt;/a&gt;. It's fitting that we brought this to Decompression because the idea for the QMB was inspired by Burning Man itself. When I went to Black Rock City for the first time in 2019, I realized the perfect gift to the Playa would be a way to let all participants do &lt;a href=&quot;https://twitter.com/burningman/status/1031560236845412352?lang=en&quot;&gt;everything they want&lt;/a&gt;. But with so much going on there, the only way to do everything is to split the universe.
&lt;/p&gt;
&lt;h4&gt;Installation Build&lt;/h4&gt;
&lt;p&gt;
    It was kind of tough to figure out how to present the QMB as an art project. The device I came up with was linking the abstract idea of inhabiting two different universes to a concrete example of inhabiting two different spaces. More specifically, my partner and I decorated the shit out of a pair of camping tents.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-eVo8iGkRSYI/XbNDdXy_49I/AAAAAAAAE7c/H3eDEEnr1Xg4TZgAPlThZpm2m_oYn2mhwCKgBGAsYHg/s1600/IMG_20191018_214146.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    So conceptually, the art would be interacted with by using the quantum measurement to determine which tent you went to hang out in. My partner decorated the interiors of the tents and added a logbook for people to describe their contemplation on the Multiverse.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Xljhi_D3-78/XbkMSo3xLhI/AAAAAAAAFAA/5qgDHy7Tq90ShiXoONTyPBjFNYyl3SGAwCKgBGAsYHg/s1600/IMG_20191013_170949.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    To add to the experience, we wanted to disguise the fact that it was just a computer and some tents. I'd been collecting bike tubes for the past year to put toward another sculpture. We just cut them up and hung them on a rack that we found on the street the week before the event.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Q9qKT1VR6O4/XbkMgZVK3JI/AAAAAAAAFAE/ADPkBAPIlUoGDtcGHMz6WK9oLYmJNQWLgCKgBGAsYHg/s1600/IMG_20191013_091005.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We also added a mirror off to the side between the tents. This causes you to see yourself climb into the mirror on the other side out of the corner of your eye, which makes for a pretty cool experience when you crawl through.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-EssV93pNt0k/XbNg6sJIDXI/AAAAAAAAE88/oih3Yv_u5U0NxU5OOzBKogCPzBqYqMg3wCKgBGAsYHg/s800/IMG_20191019_150200.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Claire assembled a bunch of random parts to make the terminal look amazingly sciency (and less like two IKEA tables stacked on top of each other). We'd found a bunch of copper wire on the street back in Oakland. In a &lt;a href=&quot;https://www.youtube.com/watch?v=j7szkheaqCY&quot;&gt;previous project&lt;/a&gt;, I'd been playing with some &lt;a href=&quot;https://www.3dhubs.com/knowledge-base/pla-vs-abs-whats-difference/&quot;&gt;PLA filament&lt;/a&gt; that I'd used to hand mold a cool little ball.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-bQy4lGhfGMs/XbNJj3CPvFI/AAAAAAAAE7w/tK-jWmPFdEECftzzYUXxWaTJY42iQfjvACKgBGAsYHg/s800/IMG_20191015_233346.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    When we were on site, we realized we wanted to connect the terminal and the tent structure together to make it look like one big machine. We connected them using more bike tubes, and used them to ensconce the laptop to make it look less lame.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-LKHQ-vu3Pk0/XbNKi4zGHSI/AAAAAAAAE78/fHTl8kLa82c_UFC6wBYomVMLdYueqCxpgCKgBGAsYHg/s800/IMG_20191019_135310.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The full effect was pretty neat, and very Burning Man. We got a lot of comments from the folks on MDMA that they loved the textures of our installation.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-nKU0TBudA4g/XbNbi2oJ_RI/AAAAAAAAE8o/vbbdFPX8FH8sbkWlXmWmzDvDMEz0YNCTACKgBGAsYHg/s1600/IMG_20191019_121853.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The project looked even cooler at night because we connected red and blue LEDs to distinguish the two &quot;paths&quot; that the Bifurcator could point you on.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-xnh2rKire-Q/XbNbpcXxiQI/AAAAAAAAE8s/4YkiDD2E3UgsvW10NAJAlP62OANEMgjhACLcBGAsYHQ/s1600/IMG_0008.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The machine inside also looked extra cool then too.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-7D0F8O-XIls/XbNhwj5foDI/AAAAAAAAE9Q/Tl33XTYIjNEJEK8H82EH_5y9sqCdMRcCwCLcBGAsYHQ/s800/IMG_0006.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This installation was honestly the most fun thing I've ever built. My partner and I basically went through our whole house converting every miscellaneous item into something that could look vaguely sciency. But the best part of the build was getting to share it with the Burners at Decompression.
&lt;/p&gt;
&lt;h4&gt;Interactivity and Reception&lt;/h4&gt;
&lt;p&gt;
    The whole point of the Bifurcator was to help us realize that our instantaneous actions aren't so very dire as we always think. I wanted participants to take a minute out of their busy partying to play with us in a glorified blanket fort. When the gates opened, lots of people started streaming past our camp. It was so cool to see people look at our weird little site. I could tell that they were curious to come over, intrigued by what they would find. But everyone's natural reaction is to pass by. I wasn't sure how to get people too engage with it until I came up with a cool catch-phrase that I could shout to the crowd to draw them in.
&lt;/p&gt;
&lt;blockquote&gt;Want to play dice with the mother fucking universe?&lt;/blockquote&gt;
&lt;p&gt;
    I never could have imagined the feeling I would get from asking this question to strangers. The people of burning man ate this proposition up with relish. We had some amazing universe bifurcations take place. One person decided whether she should get married. Another person decided whether he should change the focus of his medical residency. Many people didn't want to share what they were deciding on, which is actually amazing. It meant that they were really taking it seriously. Even if this doesn't really determine exactly what they end up doing, it felt really good to pose the possibility that their choice really wasn't so monumental after all. That there could be a parallel universe that defuses their worries about what could have been.
&lt;/p&gt;
&lt;p&gt;
    I'm really grateful that Claire added logbooks to the tents so people could share their reflections. Most of them were pretty whimsical, but many people seemed to reach some profound personal insights. I'm honestly very proud to have offered them this experience.
&lt;/p&gt;
&lt;h6&gt;Personal Reflections&lt;/h6&gt;
&lt;p&gt;
    This was my first experience bringing something fun like this to a wild, excited audience. This has caused me to reflect on the many paths my life could have taken up to here. I've loved to create, but I've always been afraid to share in a direct way. It's felt so forceful to demand people's attention, and I've preferred to just make things quietly with little advertisement. The Bifurcator is helping me realize that asking people to notice me isn't really such a burden to them, and that's allowing me to open up and send my creations out into the world more.
&lt;/p&gt;
&lt;p&gt;
    I've also been thinking about the philosophy behind the piece. It's not just about the fun or mystery of multiple parallel universes. I think it also speaks to the way scientific concepts are fundamentally highly philosophical in a way that we seem to ignore these days. These ideas can and should shape our understanding of our place in reality. It feels like as a culture we are compartmentalizing ideas and forgetting that science, art and and philosophy were really born from the same place. I think this can lead to a temptation to divorce ourselves from science, particularly in artistic communities, because science seems to try to belittle human experience. But I think that is just a superficial reading of the mundane parts of science, the parts of science that are commoditized, just like the parts of art that have been commoditized. &lt;p&gt;
        When I ponder trippy scientific concepts, I feel more presence of mind about what my human experience actually means. Is what I feel just a sliver of what holds together the reality I pass through? If we expand our feelings to include everything that every measuring device can understand, do we see a fuller world than we could have imagined? I feel like studying science and information theory has actually made me feel more like a branching, amorphous blob of thoughts, decisions, desires, and that all those immaterial patterns aren't solitary. They are stitched in with the rest of everything else in this twisted pocket of the Multiverse.
    &lt;/p&gt;
&lt;h4&gt;What's next?&lt;/h4&gt;
&lt;p&gt;
        The reaction has fueled our desire to bring this to &lt;a href=&quot;https://burningman.org/countdown/&quot;&gt;Black Rock City&lt;/a&gt; in 2020. By some astonishing &lt;a href=&quot;https://www.psychologytoday.com/us/blog/connecting-coincidence/201804/how-do-physics-and-the-multiverse-explain-coincidences&quot;&gt;coincidence&lt;/a&gt; the &lt;a href=&quot;https://journal.burningman.org/2019/10/news/brc-news/burning-man-2020-the-multiverse/&quot;&gt;theme next year&lt;/a&gt; is actually the Multiverse so it seems like the perfect time for us to build it. I've started building a miniature model of how I want to expand the installation.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-zceKIcq5uJk/XbXxhW6vT4I/AAAAAAAAKSg/EmZEhSe2Zg4Yr0soPWPsp6xi8-6p9kD6gCLcBGAsYHQ/s1600/IMG_0019.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In the next iteration, I want to focus on expanding the tents in the back to include a few more chambers that twist around and sometimes lead to dead ends. We'll expand out the front as well, to have a real quantum experimental system inside.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-BSD4BVkGLQM/XbXxynK3IRI/AAAAAAAAKSo/70glSif5MIAOsAzS9EU6AAvYOpIr6FpAwCLcBGAsYHQ/s800/IMG_0021.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Inside the different chambers, there will be a variety of different interactions. Thus far, I'm planning on a projection of the double slit experiment, and some mirrors that produce a ghostly image of yourself in the other side of the multiverse. I also plan to leave in the logbooks so people can write their thoughts on their experience in the Multiverse.
    &lt;/p&gt;
&lt;p&gt;
        To take this to the Playa will end up being a pretty major investment so I'm also writing a letter of intent for a Burning Man grant. To make things interesting, I think I'll use the QMB to decide whether I should submit it.
    &lt;/p&gt;&lt;/p&gt;</description>
        <pubDate>Wed, 23 Oct 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/10/qmb-installation/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/10/qmb-installation/</guid>
        
        <category>art</category>
        
        <category>games</category>
        
        <category>physics</category>
        
        
      </item>
    
      <item>
        <title>Green Wall Irrigation</title>
        <description>&lt;p&gt;
    Last winter, my friend and I set out to build a sort of &quot;&lt;a href=&quot;/2019/03/redwood-planter-cabinet.html&quot;&gt;green wall&lt;/a&gt;&quot; in his back yard. It was a very fun project, and the building and planting turned out to be quite easy.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-h6JWzOSa8yc/XHoF7d4_j5I/AAAAAAAADdE/vHgbbOi9RLk2qYiviC0rM0CSGBXocItgACPcBGAYYCw/s800/20181210_083237.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    What turned out to be harder was getting my very busy friend to keep his garden watered. By the end of this summer, everything was dead.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-QCVL0ySKZi0/XZwKLw0bOgI/AAAAAAAAEuY/_Ugg_AsUj340MLMn_FDaz-QFEJZsSyb1QCKgBGAsYHg/s1600/IMG_20190915_121800.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Since I knew my friend wouldn't be able to stop traveling for work, I decided the only way to make last year's project a success was to add a custom multilevel sprinkler system.
&lt;/p&gt;
&lt;h4&gt;Construction&lt;/h4&gt;
&lt;h6&gt;Hose&lt;/h6&gt;
&lt;p&gt;
    We used drip irrigation hose, which works by letting the water soak out through a porous hose material. When I was younger this same task was normally accomplished using a cheap hose with holes poked into it every foot or so. But times change, and technology improves. I think the logic is that the drip irrigation would then give a more uniform distribution of water.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-WPkGBAL_T0s/XZwXHHyVXMI/AAAAAAAAEuk/25GqtTlaB9kmch5rqS-Q7TMdhmyALIsIwCKgBGAsYHg/s1600/IMG_20190915_143742.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The problem though is that with the drip irrigation you don't have the ability to set just how porous you want your hose to be. In almost all cases I'd bet that the drip irrigation is probably optimally set up to maintain a great flow.
&lt;/p&gt;
&lt;p&gt;
    But we happened to be working in one of those cases where gravity works against you. In our original plan we ran the drip hose straight first at ground level and then snaked it up to end at the top. Unfortunately, this meant that there was higher pressure right at the beginning, which caused all of the water to shoot out before it could get to the top.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-cISCtBOJTmU/XZwXHCPoTII/AAAAAAAAEuk/r9h8QH5TmSANEXHCJmWLl6zHN_vN6sZdwCKgBGAsYHg/s1600/IMG_20190915_143751.jpg&quot; title=&quot;
bottom (gusher)
middle (ok)
top (bone dry)
 &quot;/&gt;
&lt;p&gt;
    The solution was to add a segment of solid hose that first ran to the top of the planter before running back down. With this setup, there was enough time for the water at the top to seep out before it went to lower levels.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-fxaqCnOKa48/XZwXHOGXX4I/AAAAAAAAEuk/gZUYUMTYl8kkOk0CLkPt00ArlUYFo0MCQCKgBGAsYHg/s800/IMG_20190915_151211.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-IQ0LKZ8xD3g/XZwXHBUBajI/AAAAAAAAEuk/oJnZ-2qPcuAmMfpqGI0dzXijcRwbMRCAwCKgBGAsYHg/s1600/IMG_20190915_151253.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We ran the hoses around on the backside and did our best to just tuck them right around the corner, running them low enough that they could be buried with dirt.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-9jbP21BRWeQ/XZwXHOJ9VkI/AAAAAAAAEuk/-arJKaGo58gJgIx8C4b36gjzxQ5RDVX7QCKgBGAsYHg/s800/IMG_20190915_151309.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-vmTydgK8H2w/XZwXHC-3FMI/AAAAAAAAEuk/wPuuCItgpFUidrrz-G41d_Oi1nMtOHG6gCKgBGAsYHg/s1600/IMG_20190915_151405.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Almost not noticeable once its buried.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-v6myJuJpqnI/XZwXHMq4oSI/AAAAAAAAEuk/tP7B0LKu_LgdR1G-SRwL3N70uySKP4i_ACKgBGAsYHg/s1600/IMG_20190915_153120.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Our project was very small so we had a lot of excess hose left over. I just tied off a knot at the end to kink the hose. That way we can extend the project some time in the future.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-BTlAOnOQrRQ/XZwXHEcHAzI/AAAAAAAAEuk/bGqw9m7pTiwZsIDGK_F485DlPcfsa9aqACKgBGAsYHg/s1600/IMG_20190915_151509.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-1n78gLL3zdo/XZwXHOo3JlI/AAAAAAAAEuk/cZnYTsrhptIBCwxKNs3a_09QuZ7URlbrQCKgBGAsYHg/s1600/IMG_20190915_151709.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    From the front, the irrigation system isn't too obvious when it isn't running. We threw a few test plants in that day, but I missed getting a picture of them. I'll just have to wait to go back and get a &quot;results&quot; pic later.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-gqUbDBkDFvE/XZwXHNkHF-I/AAAAAAAAEuk/aBYuL5e-xSIM5Bs8wloQca-Y5QPHdqkHgCKgBGAsYHg/s1600/IMG_20190915_151204.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally, the most important part is getting an automated irrigation timer. This brand was kind of confusing to use, but it was the cheapest one at the store and we didn't have time to comparison shop.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/--7jJRBRuaX8/XZwXHG_5Q_I/AAAAAAAAEuk/2NpuZP89NQgBe2E1ahukhZ_CICVZ8n4kQCKgBGAsYHg/s1600/IMG_20190915_154924.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Results&lt;/h4&gt;
&lt;p&gt;
    I'll update here when I can get a photo of how the plants look after a few months of automate irrigation. My friend has been out of town for multiple weeks already so this will be a good test.
&lt;/p&gt;</description>
        <pubDate>Sun, 20 Oct 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/10/green-wall-irrigation/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/10/green-wall-irrigation/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <title>Quantum Coin Flip Device</title>
        <description>&lt;p&gt;
    Over the past few months, I've been working on building tools to connect human decisions with the outcomes of quantum measurements. The goal is to allow people to let their decisions be chosen using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Many-worlds_interpretation&quot;&gt;many-worlds interpretation&lt;/a&gt; of quantum mechanics, which will end up creating parallel realities where all outcomes occur. You can read &lt;a href=&quot;/2019/10/quantum-multiverse-bifurcator.html&quot;&gt;this post&lt;/a&gt; to learn more about the idea and how I built a web-based &lt;a href=&quot;https://quantum-multiverse-bifurcator.appspot.com&quot;&gt;Quantum Multiverse Bifurcator&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    The main drawback of my webapp is that it relies on being connected to the internet to request a quantum measurement from &lt;a href=&quot;https://qrng.anu.edu.au&quot;&gt;an experiment&lt;/a&gt; being run by this &lt;a href=&quot;https://www.cqc2t.org&quot;&gt;quantum computation research group&lt;/a&gt; in Australia. Ideally, I'd like to be able to make such a quantum measurement myself to make it more accessible wherever &lt;a href=&quot;https://journal.burningman.org/2019/10/philosophical-center/the-theme/burning-man-2020-the-multiverse/&quot;&gt;I go&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    There are &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_random_number_generator#Quantum_random_properties&quot;&gt;many examples&lt;/a&gt; of various quantum measurement devices on the web, but most of them are more sophisticated and would be fairly expensive to build. All I need is a device that can make a simple binary measurement from the outcome of a quantum event. So I set about trying to design something cheap and simple that still maintains true quantum randomness.
&lt;/p&gt;
&lt;h4&gt;Concept&lt;/h4&gt;
&lt;p&gt;
    The simplest kind of quantum measurement is probably &lt;a href=&quot;https://www.rp-photonics.com/shot_noise.html&quot;&gt;shot noise&lt;/a&gt;, or the variability in the number of photons detected when measuring light with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Photodetector&quot;&gt;photodetector&lt;/a&gt;. A photodetector is just any device that absorbs light and converts the light it absorbs into an electrical signal. Photodetectors are used in a bunch of things, like if you've ever seen a nightlight that only turns on when its dark, or if you've ever seen your phone/computer automatically adjust its brightness.
&lt;/p&gt;
&lt;p&gt;
    The reason that this is a quantum measurement is that the light field that is being absorbed exhibits quantum fluctuations, which cause the number of photons present to vary. Therefore, the exact amount of electricity generated by the photodetector is also varying slightly even if the average amount of light stays the same. To detect the quantum effect one needs to observe the variability in the electrical signal of the photodetector.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, measuring the exact electrical signal with the kind of sensitivity needed to pick up on the quantum signals normally takes a pretty sophisticated device. That would be costly and make this measurement device a little impractical. So I wanted to simplify the machinery needed to make this measurement.
&lt;/p&gt;
&lt;p&gt;
    Given that I only really need to generate a &lt;a href=&quot;https://www.lexico.com/en/definition/binary&quot;&gt;binary&lt;/a&gt; outcome (a coin flip), I knew that I could get away with a circuit that just goes on when the measurement is beyond some threshold. The catch is that its a little bit difficult to calibrate exactly where the cutoff should be. In addition, it's possible that the source of the variability could be non-quantum if the device isn't set up properly. There are many other sources of apparent randomness that don't come from quantum mechanics and I wanted to make sure to isolate my system from those.
&lt;/p&gt;
&lt;p&gt;
    To alleviate these issues, the design I chose actually creates two quantum measurements of the shot noise from two photodetectors. It then compares the signal from each measurement at a specific point in time and either turns on or off an LED depending on which measurement is greater. This allows for the circuit to really only use 4 components while still transmitting a quantum signal to a binary outcome.
&lt;/p&gt;
&lt;p&gt;
    The last important thing is that you need to be able to control for the variation in the electrical components of the circuit, which could affect the measurement but are non-quantum. To control for this, I can calibrate the amount of light hitting each photodetector to make the measurement go either way with almost exactly 50% probability. And the amount of light can be lowered further and further to turn down the contribution of classical effects on the randomness.
&lt;/p&gt;
&lt;p&gt;
    With this basic concept, the only thing left to do was to try to build it.
&lt;/p&gt;
&lt;h4&gt;Circuit&lt;/h4&gt;
&lt;p&gt;
    After asking both &lt;a href=&quot;https://physics.stackexchange.com/questions/488133/how-to-build-a-circuit-that-generates-a-quantum-coin-flip&quot;&gt;physics&lt;/a&gt; and &lt;a href=&quot;https://electronics.stackexchange.com/questions/445338/circuit-to-randomly-light-one-led-or-another/447272&quot;&gt;electronics&lt;/a&gt; stack exchanges with little results, I came up with the following circuit
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-2t52RMTXdAU/XaopNS-HFaI/AAAAAAAAE2Q/ekmM-lhYz4sUgY3ZhB_2a41jkuDFOKU0ACLcBGAsYHQ/s1600/circuit-20191018-0928.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    To view the circuit in simulation go &lt;a href=&quot;https://www.falstad.com/circuit/circuitjs.html?cct=$%201%200.000005%2010.634267539816555%2050%205%2050%0Aa%20256%20240%20336%20240%208%205%200%201000000%200.7831537737346073%200.7001096127683933%20100000%0AR%20176%20128%20144%20128%200%200%2040%205%200%200%200.5%0At%20144%20192%20176%20192%200%201%20-4.336216318433491%20-0.11937009216809913%20100%0At%20160%20272%20192%20272%200%201%20-4.419260479399706%20-0.11937009216809924%20100%0Aw%20176%20208%20256%20224%200%0Aw%20240%20128%20176%20176%200%0Aw%20240%20128%20240%20240%200%0AR%20144%20192%20128%20192%200%206%2040%200.5%200.5%200%200.5%0AR%20160%20272%20128%20272%200%206%2040%200.5%200.5%200%200.5%0Aw%20192%20288%20256%20256%200%0As%20240%20128%20336%20128%200%201%20false%0Aw%20192%20256%20240%20240%200%0A155%20336%20240%20400%20176%200%205%0Aw%20336%20128%20336%20272%200%0Aw%20240%20128%20176%20128%200%0A162%20432%20240%20512%20240%202%20default-led%201%200%200%200.01%0A162%20432%20304%20480%20304%202%20default-led%201%200%200%200.01%0Aw%20512%20240%20512%20304%200%0Ar%20512%20304%20512%20352%200%20100%0Ag%20512%20352%20512%20368%200%0Ag%20480%20352%20480%20368%200%0Ar%20480%20352%20480%20304%200%20100%0Ax%20120%20316%20336%20319%204%2012%20%5Enoise%5Csto%5Cstransistors%5Cs%5Cq%5Csphotodiodes%0A&quot;&gt;here&lt;/a&gt;. On the simulation site each time you close the switch one of the LEDs should light randomly. Below I will walk through each of the subcomponents in a little more detail.
&lt;/p&gt;
&lt;h6&gt;Step 1. Generate slightly varying voltages from two photodiodes&lt;/h6&gt;
&lt;p&gt;
    The first step is to make a very simple photodetectors using &lt;a href=&quot;https://www.rp-photonics.com/photodiodes.html&quot;&gt;photodiodes&lt;/a&gt;. The photodiodes act like little dams that prevent the flow of electricity (called &lt;a href=&quot;https://en.wikipedia.org/wiki/Electric_current&quot;&gt;current&lt;/a&gt;), but which let more electricity through when light is shined on them.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://www.electrical4u.com/images/2018/november18/characteristics-of-photodiode.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    In the circuit, I connect the photodiode to a between the plus and minus ends of the battery with a resistor after it. This causes there to be a voltage across the resistor, which then fluctuates as the light hitting the photodiode varies. At low enough light, the variation is mostly quantum mechanical in nature.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-vrjicbdG99Y/XaotTVs0WGI/AAAAAAAAE2c/2IiRoRS7Dt4Byzgx1EAgbKr7U9RWYIXrQCLcBGAsYHQ/s800/0b07d078681096482698fbe614ec5890.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    One important point is that there can also be classical noise in this type of circuit, largely due to thermal noise changing the resistivity of the resistor. To overcome this, I got a tip from a physicist friend of mine to use a very large resistor. This should ensure that the thermal variation is small relative to the variation from the quantum effects in the photodiode.
&lt;/p&gt;
&lt;p&gt;
&lt;small&gt;*Note: When I built the circuit simulation on &lt;a href=&quot;http://falstad.com/circuit/circuitjs.html&quot;&gt;falstad's circuit simulator&lt;/a&gt;, I wasn't able to put in a photodiode directly. Instead, I mocked those components using a transistor and random noise source. The rest of the simulation circuit looks like the real prototype though.&lt;/small&gt;
&lt;/p&gt;
&lt;h6&gt;Step 2. Comparing the photodetectors&lt;/h6&gt;
&lt;p&gt;
    The next part of the circuit performs an amplification of the signal difference between the two photodetectors. This is accomplished using an &lt;a href=&quot;https://www.electronics-tutorials.ws/opamp/op-amp-comparator.html&quot;&gt;op-amp comparator&lt;/a&gt;. The comparator is a widely available circuit that works to
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-MNRTKWnK8NY/Xaova_ksN-I/AAAAAAAAE2o/HjwEiXOWY6kYOUlyls_xolP-FtT2zHIfwCLcBGAsYHQ/s1600/opamp-opamp103.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    So whenever the first photodiode's voltage is just slightly higher than the second one's voltage, the output of the comparator is high (+3 volts in my circuit). And whenever the second signal is higher the voltage goes low (0V in my circuit). This signal is varying all the time though as the two detectors vary back and forth. So to persist the measurement we need one more component.
&lt;/p&gt;
&lt;h6&gt;The D-Latch (flip-flop)&lt;/h6&gt;
&lt;p&gt;
    Given a time varying voltage, we need a way to detect whether the voltage is high or low at one instant and then persist that value for a long period of time. There are a number of ways to do this, but one of the simplest is with a &quot;&lt;a href=&quot;https://en.wikibooks.org/wiki/Digital_Circuits/Latches&quot;&gt;latch&lt;/a&gt;&quot; circuit. There are many kinds of latches, but they all take an input and then hold an output value until the circuit is reset.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-mz99UoGkeYc/Xao3fsIh0eI/AAAAAAAAE3A/ovfkl2lejd8OjD58kuJYPqRujPXBuCzzgCLcBGAsYHQ/s1600/dtype01.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I used a &lt;a href=&quot;https://en.wikipedia.org/wiki/Flip-flop_(electronics)#Gated_D_latch&quot;&gt;D-Latch&lt;/a&gt;, which takes an input signal and stores it at the moment a &quot;trigger&quot; input is pushed. Then the D-Latch holds that value and outputs it until the trigger is pushed again. The output is referred to as Q in the diagram. In addition, most D-Latches also output the opposite of Q (called Q') at the same time.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-ZoMUSnQDGR8/XaoxiLzKdoI/AAAAAAAAE20/JTYAPEnFZ4o1bpRlm1FzTYPk9sFeNv5_gCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-18%2B14-41-08.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The signal for my D-Latch was just the output from the comparator. I had a manual switch that set the trigger. If the output from the comparator is high when the trigger is pushed, then the D-Latch will hold Q at high and Q' at low. If the output from the comparator is low, then the D-Latch will hold Q low. The circuit will keep it at that level until the trigger is pushed again, at which point, it will hold the signal based on the output from the comparator at that point.
&lt;/p&gt;
&lt;h6&gt;Output&lt;/h6&gt;
&lt;p&gt;
    To vizualize the output of the D-Latch I just added a pair of LEDs to the end. When the Q output is high, the red LED lights, and when Q' is high, the blue one lights.
&lt;/p&gt;
&lt;h4&gt;Parts List&lt;/h4&gt;
&lt;p&gt;
    I decided to go with a 3.3V design because the parts I could find worked out better that way (price wise). I bought these specific parts for each of the above components. This is not an endorsement of any vendor by the way. Also some of them were NOT the right parts for the reasons listed below, but this should point you in the right direction.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;photodiodes: &lt;a href=&quot;https://www.amazon.com/gp/product/B00M1PMHO4/&quot;&gt;HiLetgo 20pcs 5MM Photodiode Photosensitive Diode Light Sensitive Diode Round F5 Photodiode 3V&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;op-amp: &lt;a href=&quot;https://www.mouser.com/ProductDetail/on-semiconductor/ncs325sn2t1g/?qs=dbuNSGnowt2g9SoYxOxXaw%3D%3D&quot;&gt;ON Semiconductor NCS325SN2T1G&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;flip-flop: &lt;a href=&quot;https://www.mouser.com/ProductDetail/nexperia/74aup1g79gv125/?qs=jquClx72t9COASqZ9WZ81A%3D%3D&quot;&gt;Nexperia 74AUP1G79GV,125&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;leds: &lt;a href=&quot;https://www.mouser.com/ProductDetail/inolux/inl-3ab30/?qs=qSfuJ%252bfl%2Fd4rOSt45g1Ezg%3D%3D&quot;&gt;Inolux INL-3AB30&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;boards: &lt;a href=&quot;https://www.amazon.com/gp/product/B07CJ96ZPW/&quot;&gt;QLOUNI 40pcs PCB Proto Boards SMD to DIP Adapter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.amazon.com/gp/product/B00FO9HQLS/&quot;&gt;3V watch batteries&lt;/a&gt; and &lt;a href=&quot;https://www.amazon.com/gp/product/B01J5FY2GI/&quot;&gt;holders&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Prototype 1&lt;/h4&gt;
&lt;p&gt;
    Since I bought such small components for the D-latch and op-amp, I needed to solder them onto a board to make connections to the other components. The solder work was painstakingly tiny, but you can see that each of the legs connects to a metal strip that would then connect to a through-hole.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-fL8oEk2ahoo/Xao33wOrxuI/AAAAAAAAE3I/pV1DGLzKDnQrFbFRE_47IAKttrpDOczNQCKgBGAsYHg/s1600/IMG_20190728_155527.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I wired up the comparator and D-Latch part of the system as displayed in the diagram above. That way I could isolate those with known signals from the part of the circuit that would be the photodiodes. The D-Latch and LEDs tested and worked correctly.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-bbg5zYbghlE/Xao4leY2xrI/AAAAAAAAE3U/sCWgzEnR7EEZmbGzuVmPFwG6CciGhXR0gCKgBGAsYHg/s800/IMG_20190728_155120.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-bLiAyAkP_GM/Xao4lZaGMkI/AAAAAAAAE3U/Ti_YIQIw6zIIJanmJ30ckw1QVdqkfS7WQCKgBGAsYHg/s800/IMG_20190728_174343.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The next step was to connect the two photodiodes and resistors into the circuit. They sort of look like LEDs but they are photodiodes (LED and photodiodes are very similar materials just with the direction of conversion from light to electricity backwards). I aimed to make the two photodiode segments of the circuit as symmetric as possible to get them close to the similar state. With them wired up, the system is easy to calibrate by just rotating them towards a common light source until the odds of both outcomes is ~50%.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-DU6EqrK1XNM/Xao33_aLvUI/AAAAAAAAE3I/IxgvVzAwIF4okKZH-owmqlzirJjy5SmMgCKgBGAsYHg/s1600/IMG_20191018_134423.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    For the final step, I just soldered in the output LED. The whole circuit is a bit of a mess, but it was functional at least.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-5O4lsbKNg0E/Xao335j77hI/AAAAAAAAE3I/K-0ZvVmq9LYZ95kEodYsv5YL7koknAPSwCKgBGAsYHg/s1600/IMG_20191018_134403.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I am looking to build a couple more iterations that are a little cleaner. When I've built them, I will update here with details of the operation, and how to calibrate them.
&lt;/p&gt;</description>
        <pubDate>Fri, 18 Oct 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/10/quantum-coin-flip-device/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/10/quantum-coin-flip-device/</guid>
        
        <category>physics</category>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>Quantum Multiverse Bifurcator</title>
        <description>&lt;p&gt;
    &lt;small&gt;Update: by some mind-blowing coincidence the &lt;a href=&quot;https://journal.burningman.org/2019/10/news/brc-news/burning-man-2020-the-multiverse/&quot;&gt;theme of next year's Burning Man&lt;/a&gt; happens to be the Multiverse! Note that what follows was all written before the theme was announced.&lt;/small&gt;
&lt;/p&gt;
&lt;p&gt;
    My partner and I went to Burning Man this year for the first time. It was an overwhelming experience. So much freedom, so much hard work, so little sleep, so many people. There were parts that were forgettable, parts that were frustrating, but overall it was an experience that changed how I thought about the world.
&lt;/p&gt;
&lt;p&gt;
    One of the biggest things that it pointed out to me was &lt;strong&gt;how much f**king stuff to do there is in this world!&lt;/strong&gt; It's hard to imagine how many fun people there are out there just waiting to go on an adventure with you. Unfortunately this presents a problem because as limited humans we can only do one thing at a time. BUT I think I may have solved this problem.
&lt;/p&gt;
&lt;p&gt;
    The method to eliminate all your FOMO requires just a simple piece of quantum mechanical technology and a belief in the many-worlds interpretation of quantum mechanics. If you want to skip ahead, you can &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;try the system out&lt;/a&gt;. It's related to &lt;a href=&quot;/2019/09/partial-identity-suicide.html&quot;&gt;another thought-experiment&lt;/a&gt; that I think I solved a few years ago that allowed me to hack my depression away overnight.
&lt;/p&gt;
&lt;h4&gt;Could parallel universes be real?&lt;/h4&gt;
&lt;p&gt;
    We've all seen the sci-fi (or sitcom) plots where there are parallel highly similar universes, and people cross over from one to the other. This is all-well-and-good for a plot device, but it seems impossible to believe in something so bizarre could really happen. Well, what if I told you there is a legitimate scientific justification for why there would be parallel universes?
&lt;/p&gt;
&lt;h5&gt;The Many Worlds Interpretation of Quantum Mechanics&lt;/h5&gt;
&lt;p&gt;
    A key component of the coolness of my invention relies on the many-worlds interpretation of quantum mechanics. For those unfamiliar, that might sound weird and/or hard to understand, but it's actually pretty simple. I won't go too deeply into the explanation of this since &lt;a href=&quot;https://en.wikipedia.org/wiki/Many-worlds_interpretation&quot;&gt;wikipedia article&lt;/a&gt; already does a pretty good job here. But I'd really like to give a brief explanation to make the next part more clear.
&lt;/p&gt;
&lt;h6&gt;Random things happen&lt;/h6&gt;
&lt;p&gt;
    In our normal everyday life, we generally feel like a lot of things are unpredictable. However, for the vast majority of things, what we really know is that the only reason it is unpredictable is because we just don't know enough to predict it. At least, this was the opinion of the scientific world up until the early part of the 20th century. Basically, physicists were generally convinced that for all things, the laws of classical physics apply (like gravity and electricity) and given enough information, we could calculate everything perfectly. The universe was perfect clockwork.
&lt;/p&gt;
&lt;p&gt;
    Then, something happened that physicists found pretty hard to believe. They found some things they literally could not predict.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fstartswithabang%2Ffiles%2F2017%2F11%2FHydrogen_Density_Plots.jpg&quot; title=&quot;The location of an electron is never exactly predictable &quot; /&gt;
&lt;p&gt;
    These things weren't even complicated. In fact, they were pretty simple. Most of them just looked like firing a subatomic particle at a detector. Supposedly, they had all the information to be able to predict exactly where these particles would go. But as it turned out, the particle would only end up where it was supposed to go half of the time. The other half, it would go someplace different.
&lt;/p&gt;
&lt;p&gt;
    At first, you might imagine that this just meant they were missing something. After much careful work, the scientists eventually concluded that, the truth is, the certain things really do happen in a purely random way. In a way such that no information in the whole universe could tell you what would happen next.
&lt;/p&gt;
&lt;h6&gt;Interpreting Randomness&lt;/h6&gt;
&lt;p&gt;
    So two things can happen, but only one of them does. The followup question for physicists is why? The problem is that there is loss of symmetry when only one thing happens. The universe always has a balance of cause and effect, except for these few totally random things. This isn't impossible, but for some people it is not very satisfying.
&lt;/p&gt;
&lt;p&gt;
    The resolution is to suggest that in actuality &lt;strong&gt;both&lt;/strong&gt; things happened. But then, the question becomes, if we only see one thing happen, how can both have happened?
&lt;/p&gt;
&lt;h5&gt;Universes popping into existence&lt;/h5&gt;
&lt;p&gt;
    The crazy idea behind the many-worlds interpretation is that both things happen in separate universes, and that you only see one. What does this mean? When the experiment takes place, the universe gets duplicated with one where outcome A happens and another where outcome B happens. The reason that you only see one is because your mind's experience also gets duplicated too. But the experience that you are currently experiencing only gets to see one outcome. The other copy of you is off living in a different universe now.
&lt;/p&gt;
&lt;h6&gt;The sci-fi interpretation&lt;/h6&gt;
&lt;p&gt;
    This idea leads directly to the sci-fi plot device of two parallel realities. Often this takes the form of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Mirror,_Mirror_(Star_Trek:_The_Original_Series)&quot;&gt;mirror&lt;/a&gt; universe or a &lt;a href=&quot;https://community-sitcom.fandom.com/wiki/Darkest_Timeline&quot;&gt;darkest timeline&lt;/a&gt;. If you're familiar with these kinds of pop-culture references, you can probably easily imagine how this scenario works. Imagine you are watching a movie of someone approaching a potential lover like in this image.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-PT1529ZfZzE/XaZlg_5jSJI/AAAAAAAAEyk/NnQe1LyrGyIse_xesYHcOLo7SUE3pHofACLcBGAsYHQ/s1600/branching-realities.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    At the moment that the other person responds, the outcome of the universe is undetermined. Then when the decision is made, both outcomes happen in different universes. Reality splits.
&lt;/p&gt;
&lt;h5&gt;The catch: Multiverses don't happen on their own&lt;/h5&gt;
&lt;p&gt;
    But these stories are missing one important detail, without which they remain just stories. The issue is that most of the &quot;random&quot; things that happen in our life are not quantum mechanical events at all. Most quantum events happen on the tiny microscpic scale and when you average a lot of those events together, you end up with a world that behaves really normally. Although it is often unpredictable to us (ie chaotic behavior), it is not necessarily truly random. (There is a difference between chaotic and quantum randomness that I won't get into here, but check &lt;a href=&quot;https://www.quora.com/Chaos-Theory-What-is-the-difference-between-chaotic-behavior-and-random-behavior&quot;&gt;this link&lt;/a&gt; to learn more.) In thhis case, we shouldn't really expect there to be a parallel universe created.
&lt;/p&gt;
&lt;p&gt;
    So to really intentionally split our universe, I figured there should be a way to start connecting the macroscopic outcomes of our lives to quantum mechanical events.
&lt;/p&gt;
&lt;h4&gt;Playing dice with the mother-fucking universe&lt;/h4&gt;
&lt;p&gt;
    Thanks to the hard work of quantum physicists, we now have the power to intentionally harness quantum randomness, and set about making multiple parallel universes. I've previously considered other thought experiments. All we have to do is make macroscopic choices based on random quantum decisions. This is similar to the &quot;Schrodinger's Cat&quot; thought experiment. Except in this case, the cat is us.
&lt;/p&gt;
&lt;p&gt;
    It's an interesting thought, but I wondered how it could work in practice. I recently wrote &lt;a href=&quot;/2019/10/sub-identity-suicide.html&quot;&gt;another post&lt;/a&gt; about how I've another quantum thought-experiment I'd previously toyed with years ago, but this idea seemed like a cool and interesting way to play with the idea in a way that others could access and enjoy. I figured it would be possible to do it manually with a help from proper quantum physicists, but I also wanted to make an interface to make it plain and simple to use for anyone. That eventually led me to build a little app that lets anybody play dice with the universe.
&lt;/p&gt;
&lt;h5&gt;Building The Quantum Multiverse Bifurcator&lt;/h5&gt;
&lt;p&gt;
    To create quantum realities, I needed to do two things
&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;Find some way to generate quantum measurements&lt;/li&gt;
    &lt;li&gt;Link quantum measurements to some kind of choice interface&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;h6&gt;Finding Quantum Random Measurements&lt;/h6&gt;
&lt;p&gt;
    Finding &lt;a href=&quot;https://en.wikipedia.org/wiki/Hardware_random_number_generator#Quantum_random_properties&quot;&gt;quantum random measurements&lt;/a&gt; isn't actually as hard as one might think. It turns out that &quot;&lt;a href=&quot;https://en.wikipedia.org/wiki/Shot_noise&quot;&gt;shot noise&lt;/a&gt;&quot; measured from the number of photons emitted from a light source is a quantum event. So in theory, one can use a measurement of the number of photons emitted from a source to create a quantum random outcome.
&lt;/p&gt;
&lt;p&gt;
    I originally tried building my own device for the quantum random measurement using the shot noise principle. I got it working, but it was finicky. I'll write a post on that and link it here when I get time.
&lt;/p&gt;
&lt;p&gt;
    For a more robust measurement, I turned to the real quantum physicists for expertise. Fortunately, there is &lt;a href=&quot;https://anuquantumoptics.org&quot;&gt;a team&lt;/a&gt; at the Australian National University who has built a really effective quantum number generator. The best part is that they put it onto the internet! Their &lt;a href=&quot;http://qrng.anu.edu.au/index.php&quot;&gt;website&lt;/a&gt; explains a lot more about how their system works, check it out if you are interested. Long story short, they measure excitation of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Vacuum_energy&quot;&gt;quantum vacuum energy&lt;/a&gt;, which in-and-of-itself is a trippy concept.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-8ZhC-gKfDVQ/XakWXFHLNyI/AAAAAAAAE0o/p4mUsN8Jyc4x1p8zMed6VSwFLWmRkQzsACLcBGAsYHQ/s1600/quantum-machine.jpg&quot; title=&quot;(not the actual machine used to generate these numbers, but something like it) &quot; /&gt;
&lt;p&gt;
    I found a python package from &lt;a href=&quot;https://twitter.com/paramedoc?lang=en&quot;&gt;Ellie Ragone&lt;/a&gt; that gave an &lt;a href=&quot;https://github.com/EllieRagone/anurandom&quot;&gt;example&lt;/a&gt; of how to use the ANU-Random API. The API just works by loading data from &lt;a href=&quot;http://150.203.48.55/RawBin.php&quot;&gt;this page&lt;/a&gt;, which appear to be rapidly refreshed on the server side rapidly. The data is a sequence of &lt;a href=&quot;https://en.wikipedia.org/wiki/Bit&quot;&gt;bits&lt;/a&gt; representing the outcome of several measurements. To get a quantum coin flip, I just take the first measurement in the string.
&lt;/p&gt;
&lt;h6&gt;Quantum Multiverse Bifurcator App&lt;/h6&gt;
&lt;p&gt;
    After finding the measurement I built a very simple webapp to allow people to interact with the quantum measurement in a more intuitive way. The app works by allowing people to input two choices that they are trying to decide on (Option L and Option R).
&lt;/p&gt;
&lt;p&gt;
    After they submit their form, I pull one quantum measurement (either 0 or 1). If the measurement is 0, the app says do Option L, if it's 1, do Option R.
&lt;/p&gt;
&lt;p&gt;
    I've already started using it to make very important life decisions. You can try it out &lt;a href=&quot;http://quantum-multiverse-bifurcator.appspot.com/&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-vdKTCTOMcuA/XalW9bhYtoI/AAAAAAAAE1I/mbaN5hrvC1YXGBQDXud0I4Y-wqB7N0Z5wCLcBGAsYHQ/s1600/ezgif-6-15592130e47b.gif&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    I based the website on this &lt;a href=&quot;https://github.com/petersimeth/basic-flask-template&quot;&gt;minimal template&lt;/a&gt; from &lt;a href=&quot;https://petersimeth.github.io&quot;&gt;Peter Simeth&lt;/a&gt;. As usual, all the code is in &lt;a href=&quot;https://github.com/lots-of-things/quantum-multiverse-bifurcator&quot;&gt;an open source repo on Github&lt;/a&gt;. It's about as bare bones as possible, but it gets the job done.
&lt;/p&gt;
&lt;h4&gt;Making a ton of universes&lt;/h4&gt;
&lt;p&gt;
    That's about everything for the build. After I'd built a rough draft of the app, my partner and I actually asked to do a Burning Man Theme Camp using it. Somehow our application got accepted so, next week, we're going to run this for a bunch of burners. I'm looking forward to creating a whole fuck-ton of parallel realities where people do some crazy stuff. I'll write another post afterward with the details of the camp.
&lt;/p&gt;</description>
        <pubDate>Thu, 17 Oct 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/10/quantum-multiverse-bifurcator/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/10/quantum-multiverse-bifurcator/</guid>
        
        <category>physics</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <title>Creating Immediacy</title>
        <description>&lt;p&gt;
    I'm filled with a constant sense of urgency right now. Each day I feel a little more of my time burning away from me.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-zi73O59MuA4/XZw_Dj9wOpI/AAAAAAAAEvo/D3PsJ82fZLAqnjd7YZ4dN4bbLTD9kiXMgCLcBGAsYHQ/s1600/5314782360_f32ff3aab7_c.jpg&quot; title=&quot;source source&quot;/&gt;
&lt;p&gt;
    There is no guaranteed tomorrow so I want to do what I love today: making lots of things. Recently I've been using my spare time to build &lt;a href=&quot;2019/10/creating-immediacy.html&quot;&gt;a modbile app&lt;/a&gt;, &lt;a href=&quot;/2019/10/quantum-coin-flip-device.html&quot;&gt;a quantum measurement apparatus&lt;/a&gt;, &lt;a href=&quot;/2019/10/sub-identity-suicide.html&quot;&gt;philosophical conjectures&lt;/a&gt;, and &lt;a href=&quot;/2019/10/green-wall-irrigation.html&quot;&gt;irrigation systems&lt;/a&gt;. In this post, I wanted to share how I built the Immediacy App. It turns out building Android apps is pretty confusing and also pretty cool.
&lt;/p&gt;
&lt;p&gt;
    If you're interested in the development process, I've tried to lay out the details below. This is mostly a reference for me, but might contain a useful jump-start for anyone looking to do something similar.
&lt;/p&gt;
&lt;h4&gt;Using Firebase&lt;/h4&gt;
&lt;p&gt;
    To build the app, I relied heavily on a free Google Cloud platform called &lt;a href=&quot;https://firebase.google.com&quot;&gt;Firebase&lt;/a&gt;, which serves as an all-in-one real-time NoSQL database with simple APIs to query the database. Using it kept me from having to manage my own server or the database for storage (&lt;a href=&quot;https://np.reddit.com/r/cscareerquestions/comments/6ez8ag/accidentally_destroyed_production_database_on/&quot;&gt;ops scares me&lt;/a&gt;). And more importantly, it has a very generous free usage tier, which should easily cover the handful of people I expect to ever use this thing.
&lt;/p&gt;
&lt;p&gt;
    To learn how to use Firebase, I followed along with this &lt;a href=&quot;https://codelabs.developers.google.com/codelabs/firebase-android/#0&quot;&gt;chat app tutorial&lt;/a&gt;. This covers the setup of a project and connecting it to some Android &lt;a href=&quot;https://github.com/firebase/quickstart-android&quot;&gt;sample code&lt;/a&gt; for a chat app.
&lt;/p&gt;
&lt;p&gt;
    Mostly Firebase is just a fast way to store and retrieve data. The data structure just looks like a nested tree (like json) with a bunch of nonsensical keys used to identify whatever object is interesting.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-GPpYLclBswM/XZv0IN3deyI/AAAAAAAAEuA/Z0mZIYDkJh8dhB6ZoL3G7cmCqv-rNlVowCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-07%2B19-23-48.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    As you can see the database has 4 keys where it stores the users' profiles, conversations, messages and locations. Generally, you call this database with Firebase specific access functions (see below) to traverse the tree and get all the relevant data. Firebase also lets you expand the nodes of the tree to dig down into the data right through their UI, which is pretty convenient.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-omH95lbUKMQ/XZv0Icf_Z2I/AAAAAAAAEuE/CR5g7cGypk0zasLRMynA3z_QxGdJqzjuwCLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-07%2B19-26-07.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Here we can see how a few test messages were stored. Under the userMessages node are all the pairs of users who have had messages. Then under that there is a node to denote the messages. That node houses a list of messages, complete with sender and content.
&lt;/p&gt;
&lt;p&gt;
    One particularly great thing that Firebase does is keep track of all the users on the site and provide login protocols for authenticating them. Having bona fide User objects makes it much easier to access user specific data throughout the application.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-LiJU-AKRoNU/XZv0IUIaduI/AAAAAAAAEuI/ACsyUgzfPwIubsI90S5BtikwLMsjc-yWACLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-07%2B19-27-14.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    With a Firebase database setup and Authentication taken care of, the next step is to get some code to run the Android app on a phone.
&lt;/p&gt;
&lt;h4&gt;Android Programming&lt;/h4&gt;
&lt;p&gt;
    One of the keys to getting shit done in software development these days is to borrow heavily from open-source projects. Or to put it another way, this project started with browsing Github for a couple of hours to find someone else's project to steal outright.
&lt;/p&gt;
&lt;h6&gt;Nearby-Chat&lt;/h6&gt;
&lt;p&gt;
    With a basic understanding of Firebase, I started perusing for open-source Android apps that related to what I was trying to make. I started working with a Github project called &lt;a href=&quot;https://github.com/kshitiz1007/Lets-Chat&quot;&gt;Lets-Chat&lt;/a&gt;, and I adapted it to get something that worked for creating direct messages. Unfortunately, it didn't have anything related to location built-in. Instead of building that from scratch, I found another promising example called &lt;a href=&quot;https://github.com/frinder/frinder-app&quot;&gt;Frinder&lt;/a&gt;, but that one turned out to be mostly just a mockup that didn't quite work right.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-LSYOSMUvD3s/XZw3fbOB0mI/AAAAAAAAEvc/DMQHMoPHMtoHNypYHLLnZ00tE6DzUJYAACLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-08%2B00-14-43.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally, I stumbled on a project by &lt;a href=&quot;https://github.com/kuoa&quot;&gt;Sandu Postaru&lt;/a&gt; called &lt;a href=&quot;https://github.com/kuoa/nearby-chat&quot;&gt;Nearby-Chat&lt;/a&gt; that looked almost exactly like what I was looking for. It used an add-on to Firebase called &lt;a href=&quot;https://github.com/firebase/geofire-java&quot;&gt;GeoFire&lt;/a&gt;, along with Google Maps API to display the location of nearby people to chat with.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-tDUx2h0tQeQ/XZq7KwptmDI/AAAAAAAAEto/780bjfgHGaUfs3aU-_qdof0rzKIfF8c7gCLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-10-06%2B21-11-56.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This was great because it basically did everything I needed to do. The only downside was that it actually revealed the nearby users' exact location to everybody, which I thought was a little creepy. Fortunately, this meant that all I had to do was remove some functionality and tweak the &quot;Users List&quot; to only include people who were very close.
&lt;/p&gt;
&lt;h5&gt;The Components of the Mobile App&lt;/h5&gt;
&lt;p&gt;
    Android programming is super confusing to me, and I have only scratched the surface of it. In this section, I'm really just jotting introductory notes for myself on the different parts of an Android program. If you don't get Android this section might help explain things, but I'm also likely to be incorrect about some stuff in here. Follow at your own risk.
&lt;/p&gt;
&lt;h6&gt;Activities and Fragments&lt;/h6&gt;
&lt;p&gt;
    In Android parlance, the different main pages of the app are called &quot;Activities.&quot; When there are subsections in a single activity, there are segments called Fragments. In Nearby-Chat, there were four activities:
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MainActivity: activity launched on startup&lt;/li&gt;
&lt;li&gt;OnlineActivity: activity launched after user has logged in&lt;/li&gt;
&lt;li&gt;ProfileActivity: separate activity for editing user's profile&lt;/li&gt;
&lt;li&gt;ChatActivity: separate activity for an individual chat session&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
    The MainActivity had two fragments, one for registering new users and one for logging in. I left both of those untouched. The OnlineActivity also had two fragments: the MapFragment which held the map with nearby users, and the ConversationsFragment, which held a list of all the conversations that were currently ongoing.
&lt;/p&gt;
&lt;p&gt;
    To convert Nearby-Chat into Immediacy, I needed to replace the MapFragment with a NearbyListFragment, which just presented a list of users were close by. Fortunately, the code already had a place in it (OnlineUsersAdapter) that rendered a page that showed the full list of users. So all I needed to do was combine the filtering and fetching of users from the MapFragment with the list functionality of OnlineUsersAdapter.
&lt;/p&gt;
&lt;h6&gt;Adapters?&lt;/h6&gt;
&lt;p&gt;
    I mentioned Activities and Fragments, but there is another part in Android programming called an &lt;a href=&quot;https://abhiandroid.com/ui/adapter&quot;&gt;Adapter&lt;/a&gt; that wasn't clear to me at first. My interpretation is that all your data will come back one item at a time and the adapter is just a way to connect that data to the actual UI. All of th adapters I was working with were extensions of ArrayAdapter, which meant that I was going to get lists of items and convert them into lists of objects in the UI in some way. The way this happens is by adding Callbacks and Listeners
&lt;/p&gt;
&lt;h5&gt;Callbacks and Listeners&lt;/h5&gt;
&lt;p&gt;
    The big thing that's always been hard for me to understand about both web and mobile apps these days is the idea of &lt;a href=&quot;https://codeburst.io/javascript-what-the-heck-is-a-callback-aba4da2deced&quot;&gt;callbacks&lt;/a&gt; and &lt;a href=&quot;https://www.computerhope.com/jargon/e/event-listener.htm&quot;&gt;listeners&lt;/a&gt;. Programming with callbacks means almost none of your code gets called directly by the program when it starts up. Instead on startup you just set the functions to listen for events, and those events then call all these interrelated functions that each trigger each other. It makes sense because you want many things to happen potentially at once, but you still need some way to orchestrate subprocesses to happen after all the things that need to happen first happen. But it still means things are a little confusingat least to me.
&lt;/p&gt;
&lt;p&gt;
    For my NearbyListFragment, I added a locationCallback function, and set up the fragment to listen for the user's location.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;activity = (NearbyListFragment.OnFragmentInteractionListener) context;&lt;br/&gt;activity.addLocationCallback(locationCallback);&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    When the phone retrieves the location from the device's GPS it send it to my callback's &quot;onLocationResult&quot; function.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;private final LocationCallback locationCallback = new LocationCallback() {&lt;br/&gt;    public void onLocationResult(LocationResult locationResult) {&lt;br/&gt;         for (Location location : locationResult.getLocations()) {&lt;br/&gt;             GeoLocation myLocation = new GeoLocation(location.getLatitude(), location.getLongitude());&lt;br/&gt;             geoFire.setLocation(userId, myLocation);&lt;br/&gt;&lt;br/&gt;             geoQuery = geoFire.queryAtLocation(myLocation, RADIUS);&lt;br/&gt;             geoQuery.addGeoQueryEventListener(geoQueryEventListener);&lt;br/&gt;...&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    This code first sends the location to the geoFire database and then sets up a query based on the current location and the search radius. On the Firebase side, geoFire.queryAtLocation is set up to look for other locations that are within the given RADIUS. Finally, I add a geoQueryEventListener to wait for geoFire to send a location based event back. The code for the GeoQueryEventListener takes this whole &quot;Listener&quot; thing to a new level.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;private final GeoQueryEventListener geoQueryEventListener = new GeoQueryEventListener() {&lt;br/&gt;&lt;br/&gt;        public void onKeyEntered(String key, GeoLocation location) {&lt;br/&gt;            &lt;br/&gt;            LatLng latLng = new LatLng(location.latitude, location.longitude);&lt;br/&gt;            &lt;br/&gt;            DatabaseUtils.getUserProfileReferenceById(key).addListenerForSingleValueEvent(new ValueEventListener() {&lt;br/&gt;            &lt;br/&gt;               public void onDataChange(DataSnapshot dataSnapshot) {&lt;br/&gt;                    UserProfile userProfile = dataSnapshot.getValue(UserProfile.class);&lt;br/&gt;&lt;br/&gt;                    onlineUsersAdapter.add(userProfile);&lt;br/&gt;&lt;br/&gt;...&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    This creates a listener that will wait to run its functions whenever the Firebase database registers an event. Specifically, whenever there is a &quot;KeyEntered&quot; event (ie someone enters within a predefined distance from the user), the onKeyEntered&quot; function will be called. This then generates yet another &quot;ValueEventListener,&quot; which waits for the database to return the data associated with the &quot;KeyEntered&quot; event (ie the UseProfile information for the user that entered the area).
&lt;/p&gt;
&lt;p&gt;
    At this point, the new user is added to the &quot;OnlineUsersAdapter.&quot; As mentioned above this adapter is an ArrayAdapter so for every user in the list, a view is created, which sets the values for the user_name, user_bio, and user_avatar.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;    public View getView(int position, @Nullable View convertView, @NonNull ViewGroup parent){&lt;br/&gt;&lt;br/&gt;        final UserProfile user = userProfileList.get(position);&lt;br/&gt;&lt;br/&gt;        TextView userName = (TextView) convertView.findViewById(R.id.active_user_name);&lt;br/&gt;        TextView userBio = (TextView) convertView.findViewById(R.id.active_user_bio);&lt;br/&gt;        ImageView userAvatar = (ImageView) convertView.findViewById(R.id.active_user_avatar);&lt;br/&gt;&lt;br/&gt;        userName.setText(user.getUserName());&lt;br/&gt;        userBio.setText(user.getBio());&lt;br/&gt;        userAvatar.setImageBitmap(user.getAvatar());&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    The advantage of all of this is that almost all of the work is done by the Firebase server, and your mobile app doesn't really spend any wasted time waiting for data to come back. It just sets up an event listener or a callback and then comes back to life when the event occurs. It's kind of all magic to me.
&lt;/p&gt;
&lt;h5&gt;Models&lt;/h5&gt;
&lt;p&gt;
    The last thing to mention is that all of the data stored in Firebase was basically used to construct Java Objects. The details about these Objects and what variables were associated with them was always stored in the models/ directory. There were model objects for Conversation, Message, OnlineUser, UserConversations, UserMessages, UserProfile.
&lt;/p&gt;
&lt;p&gt;
    The way to then reload these objects from Firebase is by passing the Firebase object the java object's class. As an example, in the above code, I regenerated a UserProfile using the data in the &quot;dataSnapshot&quot; by passing it the UserProfile.class.
&lt;/p&gt;
&lt;pre&gt;UserProfile userProfile = dataSnapshot.getValue(UserProfile.class);&lt;/pre&gt;
&lt;h4&gt;Putting it all together&lt;/h4&gt;
&lt;p&gt;
    A crucial step in all of this is getting the code onto a device where you can test it. Fortunately, you can follow &lt;a href=&quot;https://developer.android.com/studio/debug/dev-options&quot;&gt;these instructions&lt;/a&gt; to set up an Android device for connecting to Android Studio on a Linux machine.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-zkzLTrMW4zg/XZw2jMoeO5I/AAAAAAAAEvI/INL9pKPkwa4X9lnC8bgTkfCrqCxeJ45eACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-07%2B20-02-04.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The Android Studio interface is pretty painful to work with, but it allows you to render your UI components and performs all the code linking for you.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-2If8DyNWfM4/XZw3CcCugUI/AAAAAAAAEvQ/JhFYZABNR2sMg64TveN2fgWhMn0qYE7QgCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-10-08%2B00-12-57.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Admittedly, Android Studio does a ton of package management that I truly don't understand. Something called gradle is always building things in the background and reorganizing files, and it leaves me feeling totally lost. Honestly, I spent one whole night (probably 4 hours) just trying to get Gradle working again. All it told me was &quot;Input/output error&quot; without any other context. For the record, I eventually figured out I had to delete my ~/.gradle folder. I kind of hate Android programming because it uses such a clunky and black-box tool to generate the entire build process.
&lt;/p&gt;
&lt;p&gt;
    But long story short, the thing gets compiled and pushed over to my phone where I can play with it.
&lt;/p&gt;
&lt;h6&gt;Deployment&lt;/h6&gt;
&lt;p&gt;
    For the final step, I wanted people to actually be able to use this thing. So I plan on spending the cash ($25! wtf) for a developer license, so I can upload my app onto the Google Play store. When I get that finished I'll update here a link and how to
&lt;/p&gt;</description>
        <pubDate>Tue, 08 Oct 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/10/creating-immediacy/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/10/creating-immediacy/</guid>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>Sub-Identity Suicide</title>
        <description>&lt;p&gt;
&lt;i&gt;&lt;small&gt;Epistemic status: In this post, I attempt to describe a thought experiment that allowed me to overcome chronic depression and existential doubts. This is a metaphysical proposition and may not be amenable to a determination of its validity.&lt;/small&gt;&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
    For many years, I was experiencing what I later learned to be &lt;a href=&quot;https://psychcentral.com/lib/what-is-existential-depression/&quot;&gt;existential depression&lt;/a&gt;. I remained externally happy and productive, but I had rational doubts about whether there was any purpose to life. As such, I could never commit to the belief that life was worth living. And it followed that I constantly questioned whether living was the right decision for me.
&lt;/p&gt;
&lt;p&gt;
    Then one evening, about three years ago, I figured out how to use a slightly more sophisticated formulation of Pascal's wager to end my depression outright. The result was a thought-experimental procedure that allowed me to remove all suicidal thoughts and tendencies. Now, I'd like to share the procedure that I built.
&lt;/p&gt;
&lt;p&gt;
    Below, I will try to articulate the steps I went through to formulate this idea. I hope that this can be used by others who are in need of something like its recipe for happiness. I'm incredibly nervous and embarrassed to share this story, but I feel it's one of the most useful things I've ever created. Feel free to judge the idea, but please try to avoid judging me personally if you don't sympathize with the sentiment that brought me to this result.
&lt;/p&gt;
&lt;p&gt;
    Thank you
&lt;/p&gt;
&lt;h4&gt;Precursor: Quantum Mechanical Suicide&lt;/h4&gt;
&lt;p&gt;
    During my college and grad school years, I would undertake what my unstable mind considered a terribly clever, though risky, experiment. I would get blind, piss drunkI mean complete blackoutand I would free climb buildings. One of my favorites was the &lt;a href=&quot;https://chicagodesignslinger.blogspot.com/2015/03/henry-hinds-laboratory-for-geophysical.html&quot;&gt;Henry Hinds Geophysics building&lt;/a&gt; on the UChicago campus. It was incredibly easy to climb because of the bricks on the outside.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-GSMO2VFKZGw/XXVt3ILyxDI/AAAAAAAAEZI/a4eiMciIXawuFe1GUYAQvK_ShSM7yIoxgCLcBGAs/s800/112175045_e8d2231042_b.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Still, for a 6 story building, a misstep near the top could &lt;a href=&quot;https://outdoors.stackexchange.com/questions/8106/how-far-would-you-need-to-fall-for-it-to-be-fatal&quot;&gt;easily have been fatal&lt;/a&gt;. Then once I got to the top, I would perch myself on the edge precariously. I assumed that any tiny miscalculation would send me over the edge.
&lt;/p&gt;
&lt;h6&gt;I know this was stupid&lt;/h6&gt;
&lt;p&gt;
    I'm horribly embarrassed by my actions, but I mention it because some of this early, misguided thinking on this subject eventually led to somewhat more coherent revelations later.
&lt;/p&gt;
&lt;h5&gt;The point of my behavior&lt;/h5&gt;
&lt;p&gt;
    By getting blackout drunk I was attempting to simulate an observerless experiment. I wanted to set up a situation like Schroedinger's cat, but with my drunken self as the cat. The idea was that my brain wasn't really able to record information while I was in a blackout state so I wasn't really &quot;measuring&quot; the outcome of the experiment. Since the experiment was without an &quot;observer,&quot; this would leave me in a superposition of alive and dead. That is, until I sobered up, at which point the experiment would be over, and I would exist in a universe where I didn't fall off the building.
&lt;/p&gt;
&lt;p&gt;
    This was never a true quantum experiment in any scientific sense, however. And I never really committed to this dark experiment in any kind of real way. I just liked the sound of the idea so I played along for a whileuntil it got boring. And rather than ever &lt;u&gt;really&lt;/u&gt; setting up the quantum experiment where I would kill myself with 50% probability, I faked it with my dramatic little cry for attention.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Rk-Y8-J44dU/XYBbVWPIExI/AAAAAAAAKPg/UqeADdkvtQMtoFyaAFyOBL0qiJ86idsKwCLcBGAsYHQ/s1600/Schrodinger_cat_in_box.jpg&quot; title=&quot;During grad school, I kind of looked like this cat too. During grad school, I kind of looked like this cat too.&quot;/&gt;
&lt;p&gt;
    At any rate, you are currently living in one of the universe's where I survived. So if you read on, you can hear what this line of thinking eventually led to.
&lt;/p&gt;
&lt;h4&gt;My real problem&lt;/h4&gt;
&lt;p&gt;
    Some time later, I came to better understand myself and what was driving me to feel depressed. I realized that I needed my life to have some purpose in order for me to feel like I should continue to exist. This is a personal need. I acknowledge that this isn't an absolute necessity for everyone, but I have recognized that it absolutely is a necessity for me. I've wondered if this is some biological reality of psyche, that my body just doesn't experience the minimum amount of pleasure to make trudging through life worth it. For whatever reason, there is no way for me to feel satisfied without a higher purpose being real.
&lt;/p&gt;
&lt;p&gt;
    Having made this realization, some people will just decide that they must believe in a higher purpose. Unfortunately, try as I might, I couldn't shake my very reasonable doubt. In fact, given the evidence I am shown of the world, I would be more likely to argue that there is actually NO higher purpose to life. This conflict was what left me cycling through frequent periods of depression
&lt;/p&gt;
&lt;p&gt;
    Once I understood this conundrum, I had to believe that even my depression was rational. I needed to maintain my doubt because it was probably correct. I needed to maintain my hope because it was required for my continued existence. I couldn't give up on life entirely and risk failing to find something that truly mattered. But doubt and hope were at constant war with each other. I couldn't use &lt;a href=&quot;https://en.wikipedia.org/wiki/Pascal%27s_wager&quot;&gt;Pascal's Wager&lt;/a&gt; to wish away my true beliefs (I personally don't believe Pascal's Wager is valid because true belief is not something I can choose for the sake of utility).
&lt;/p&gt;
&lt;p&gt;
    Then little by little, a thought experiment crept into my head. It started as something very intuitive and wishy-washy, based loosely on the quantum suicide game I'd played with myself years ago. Then, as I ruminated on it further, I realized it might actually be a valid solution to my problem. Over a few days, I solidified my idea into a fairly cogent procedure with (reasonably) well-defined premises, corollaries, and conclusions. In the following sections, I outline my thinking on this subject and the logical steps required to reproduce my results.
&lt;/p&gt;
&lt;h4&gt;Necessary Premises&lt;/h4&gt;
&lt;p&gt;
    There are a few preliminary assumptions required to make use of this thought-experiment. Each of these can be argued for or against in a number of ways. I'll outline my arguments as I've come to accept them, but I welcome discussion over the truth of these &lt;a href=&quot;https://en.wikipedia.org/wiki/Premise&quot;&gt;premises&lt;/a&gt; as well.
&lt;/p&gt;
&lt;h5&gt;Premise 1: A Personal Need for a Higher Purpose&lt;/h5&gt;
&lt;p&gt;
    This procedure is only useful for those individuals who hold that some higher purpose is required to justify existence. Some people* may not need a higher purpose to their life in order to feel that life is worth living. For those for whom this premise does not hold, the remaining procedure is useless (and probably unnecessary). However, I believe that at least some other people may truly need that type of validation like myself. For those who &lt;strong&gt;know&lt;/strong&gt; that they can't justify their existence without such a higher purpose, we can state
&lt;/p&gt;
&lt;blockquote&gt;Some people cannot justify their existence without believing in a higher purpose. For such people, without certainty of a higher purpose, there is uncertainty about one's justification for existence. &lt;/blockquote&gt;
&lt;h5&gt;Premise 2: Possibility of Purpose&lt;/h5&gt;
&lt;p&gt;
    It is not impossible for there to be a higher purpose to an individual human's existence. That is to say, a higher purpose has not been ruled out by any observation of physical reality. If we assume that any possible underlying real state of the universe that is consistent with our observations may be possible, there are certainly many such states which are also consistent with some higher purpose. As an example, the existence of an all-power deity who declares existence of a soul eternal and purposeful (ie like the Judeo-Christian God) would satisfy this condition. Although this being the true underlying state of the universe is improbable given other explanations for the existence of organized religion (&lt;a href=&quot;https://www.livescience.com/52364-origins-supernatural-relgious-beliefs.html&quot;&gt;social control&lt;/a&gt;), it is not impossible. Many other* theoretically valid possible states also can be proposed. As such, I state as a premise of my argument that
&lt;/p&gt;
&lt;blockquote&gt;A higher purpose to our existence is not impossible.&lt;/blockquote&gt;
&lt;p&gt;
    *&lt;small&gt;Again, my partner asked for a more believable example that could depict a reality where a higher purpose exists. I came up with this simple example. Imagine our experience of physical reality is part of a simulation where the output is fed into the generation of some permanent and knowable universal truth. This truth would then persist indefinitely in a meta-universe that is itself indefinitely sustained by the successful creation of experience from finite universes like our own. This is one not impossible, albeit non-falsifiable, realization of a purpose to our existence.&lt;/small&gt;
&lt;/p&gt;
&lt;h5&gt;Premise 3: Existence of Abstract Ideas&lt;/h5&gt;
&lt;p&gt;
    This premise is required so that we may say that things that are ideas actually &lt;a href=&quot;https://plato.stanford.edu/entries/descartes-ideas/&quot;&gt;exist&lt;/a&gt; in a non-trivial way. I leave this as an exercise for the reader. If you believe that ideas do not exist, ask what that belief is and why you should be allowed to represent that belief to me.
&lt;/p&gt;
&lt;blockquote&gt;Ideas can be said to exist as real things.&lt;/blockquote&gt;
&lt;h5&gt;Premise 4: Composite Identity&lt;/h5&gt;
&lt;p&gt;
    The following is by far the most controversial premise, and it is one that I cannot argue must be true. Instead, this is more of a scientific, or observational premise, meaning one that is derived from experience rather than from abstract notions. So in reading this section, you must accept that this premise may only be intuited from personal experience. Nevertheless, I will describe my reason for this belief, and ask you to consider whether such a belief is congruent with your own worldview.
&lt;/p&gt;
&lt;p&gt;
    I believe that my identity is not monolithic. This means that my overall consciousness can be described using smaller units of consciousness. These smaller units of consciousness can be further subdivided, but, for simplicity, let us assume that we will stop dividing once we reach logically coherent decision making units.
&lt;/p&gt;
&lt;p&gt;
    Why do I hold this belief? I have simultaneously held two disparate thoughts in my mind at once. I have heard my own mind argue both sides of the morality of an action. There are observable underpinnings to this belief, such as the observation of &lt;a href=&quot;https://www.knowablemagazine.org/article/living-world/2018/mind-anthill&quot;&gt;hive minds&lt;/a&gt; or split identities after traumatic &lt;a href=&quot;https://en.wikipedia.org/wiki/Split-brain&quot;&gt;brain injury&lt;/a&gt;. While none of these are full proofs of the assertion, I take as a reasonable premise that
&lt;/p&gt;
&lt;blockquote&gt;Our personal experience of a single unified identity, is a cognitive simplification of the composite of interconnected decision-making units that form our consciousness.&lt;/blockquote&gt;
&lt;h5&gt;Corollary of Premises 3 and 4: Sub-Identities as Independent Actors&lt;/h5&gt;
&lt;p&gt;
    I'm not sure if this is an independent premise or a &lt;a href=&quot;https://en.wikipedia.org/wiki/Corollary&quot;&gt;corollary&lt;/a&gt; of the two previous premises. Although, the constraints of our physical form cause us to only ever take a single physically manifested action on behalf of our identity, our &quot;sub-identities&quot; are still able to act independently in the space of ideas.
&lt;/p&gt;
&lt;p&gt;
    As an example to make this worldview more concrete, say we have two sub-identities that disagree about idea X. They may argue in the abstract space of ideas about idea X. They may build subsidiary beliefs based around their support or lack thereof for idea X. One subidentity may convince the other subidentity of the validity of some argument. This could have effects on other parts of the second subidentities belief system. In order to attain more information (call it datum Y), one or both subidentities would have to manifest the desire for more information into the physical world through action on the unifying identity. Nevertheless, one subidentity may choose to ignore datum Y when they learn it.
&lt;/p&gt;
&lt;p&gt;
    This example is just to illustrate the concept of unbridled independent action of subidentities as long as they are not interacting with the physical world. Or to put it another way
&lt;/p&gt;
&lt;blockquote&gt;The subcomponents of an identity may perform independent actions in the space of ideas.&lt;/blockquote&gt;
&lt;h5&gt;Conclusion: My depression was the existence of multiple conflicting sub-identities&lt;/h5&gt;
&lt;p&gt;
    The above set of premises presented a clear reason to me for why I was depressed. I was made up of disparate well-formed identities that held conflicting opinions about the validity of my existence. In short, I was composed of some set of subidentities that believed there was a purpose to life and therefore I should continue to live. However, I had other subidentities which held the consistent belief that I should not bother continuing to exist.
&lt;/p&gt;
&lt;p&gt;
    I had to find a way to resolve this tension.
&lt;/p&gt;
&lt;h4&gt;The Identity Secession Procedure&lt;/h4&gt;
&lt;p&gt;
    Having established these premises, it is possible to carry out the following procedure.
&lt;/p&gt;
&lt;blockquote&gt;Allow subidentities to self-annihilate in accordance with their own belief system.&lt;/blockquote&gt;
&lt;p&gt;
    Based on my globally held personal beliefs established above, all sub-identities that didn't believe there was a purpose to life also believed that they should act to terminate their existence. Similarly, all sub-identities that believed there was a purpose, should act to self-preserve. Therefore, at the end of this procedure, only the identities that believed in a purpose to life were remaining.
&lt;/p&gt;
&lt;p&gt;
    At this point my complete (composite) identity was now entirely composed of subidentities that truly believed that I should exist. My period of self-doubt and misery could rationally come to an end.
&lt;/p&gt;
&lt;h4&gt;Aftermath (pun intended)&lt;/h4&gt;
&lt;p&gt;
    I can't say I've been purely happy for the three-or-so years since I discovered this procedure. However, I can say with no compunction that I have not thought for one moment that my existence was unwarranted. This system actually worked for me, and I hope that it could work for you too. In the time since then, I have had some other questions cross my mind about the procedure.
&lt;/p&gt;
&lt;h6&gt;Was this fair? What are the implications for the world?&lt;/h6&gt;
&lt;p&gt;
    If I'm taking this procedure seriously, it means that I knowingly let some fractions of a human consciousness commit suicide. If many people try this same plan, then eventually you could posit that we'd be collectively killing the metaphysical equivalent of many persons. So there's an outstanding question about whether this is moral, given your considerations of suicide, and whether this concept of subidentity is truly additive. Taking another approach one could ask, &quot;Is it fair to enter into this procedure, knowing that you are committing some subidentities to kill themselves willfully.&quot; I do not know the answer, but I could imagine arguments either way.
&lt;/p&gt;
&lt;p&gt;
    Another natural question is to apply the &lt;a href=&quot;https://en.wikipedia.org/wiki/Categorical_imperative&quot;&gt;categorical imperative&lt;/a&gt; to this procedure. Would it be a good thing for everyone to do this? If they did, we would be left with a world without doubt about the value of our own existence. Again, I haven't yet comprehended the full morality of this theory. These are incredibly hard ethical concerns for me to argue given that I am so fully invested in the result, but I welcome discussion on the matter.
&lt;/p&gt;
&lt;h6&gt;Who is left?&lt;/h6&gt;
&lt;p&gt;
    Finally, when one of my friends heard my description of this procedure, she asked a particular intelligent question: &quot;Were there strong correlations between personality traits and sub-identities that terminated?&quot; In other words, after the procedure, did my personality have to change because certain traits were possessed only by the &quot;doubting&quot; identities? I don't know for certain unfortunately, but I do certainly feel like a different person now.
&lt;/p&gt;</description>
        <pubDate>Sun, 06 Oct 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/10/sub-identity-suicide/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/10/sub-identity-suicide/</guid>
        
        <category>philosophy</category>
        
        <category>physics</category>
        
        
      </item>
    
      <item>
        <title>Gmail Auto-Responder for AI Robot Party Game</title>
        <description>&lt;p&gt;
    I'm a big fan of immersive social games! Last fall, I built an &lt;a href=&quot;/2018/10/experiential-puzzle-narrative.html&quot;&gt;escape room&lt;/a&gt; for the engineering social at my company. For the &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;three&lt;/a&gt; &lt;a href=&quot;https://munrolab.uchicago.edu/&quot;&gt;prior&lt;/a&gt; &lt;a href=&quot;https://www.color.com/&quot;&gt;organizations&lt;/a&gt; I've worked for, I've also run a social mystery game similar to &lt;a href=&quot;https://en.wikipedia.org/wiki/Ultimate_Werewolf&quot;&gt;Werewolf&lt;/a&gt;/&lt;a href=&quot;https://en.wikipedia.org/wiki/Mafia_(party_game)&quot;&gt;Mafia&lt;/a&gt;, but themed around self-aware human-like robots (aka &lt;a href=&quot;https://ideas.4brad.com/everybody-cylon&quot;&gt;everyone is a Cylon&lt;/a&gt;). The game is far more individualized than generic werewolf, including very specific character narratives and powers. I customized each character to have things that only they know how to do, and to create specific connections between characters that need to be uncovered throughout play.
&lt;/p&gt;
&lt;p&gt;
    I'm not going to go into the details of the game because I will definitely run it again someday and I don't want to ruin it. However, I wanted to explain one cool innovation I've made to the game mechanics that modernizes the game and makes it way more interactive. I also want to show the tool I built so I could run the game by myself even with 20 or so people playing at once.
&lt;/p&gt;
&lt;h4&gt;The Problems with Werewolf&lt;/h4&gt;
&lt;p&gt;
    To me, there are three drawbacks to werewolf that make it both unrealistic and a little awkward to play.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;voting requires everyone stopping to close our eyes&lt;/li&gt;
&lt;li&gt;there's no way to verify anything&lt;/li&gt;
&lt;li&gt;only the werewolves have anything to hide&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    When I decided I wanted to adapt the game to have a more immersive take, I knew that I needed to re-imagine some of the central mechanics to fix those problems.
&lt;/p&gt;
&lt;h6&gt;Interruption of gameplay&lt;/h6&gt;
&lt;p&gt;
    As an adult playing werewolf with my friends, I couldn't help but feeling silly when the Game Master intermittently tells everyone to shut their eyes and put their heads down. This brings the entire game to a stop and makes it so that the game has to be played in a tight circle rather than in a dispersed environment where simultaneous conversations and &quot;subplots&quot; can happen.
&lt;/p&gt;
&lt;h6&gt;Nothing but lies&lt;/h6&gt;
&lt;p&gt;
    Really, the biggest problem with Mafia is that the entire structure of the game relies on there being no way to establish definitive facts. For the majority of players, there is no way to &quot;check&quot; if anything someone else says is true. This is actually incredibly unrealistic. In reality, there are almost always external ways to check the validity of someone's alibi, or cross-reference whether they are doing what they say they are doing.
&lt;/p&gt;
&lt;h6&gt;Werewolves under pressure&lt;/h6&gt;
&lt;p&gt;
    Related to the above point, in the original game, most of what everyone is trying to do is just detect the physical characteristics of lying on someone's face. This makes the game easy/boring when you are playing with somewhat honest people. Basically only a crew of stone-faced sociopaths can make the game intriguing.
&lt;/p&gt;
&lt;p&gt;
    The reason it's so basic is because the only people lying are the werewolves. If you have an honest person, it's easy to rule them out early just by directly asking them. If they are uncomfortable about something then they are almost certainly a werewolf. The game would be better if they might be hiding something, but you aren't sure if what they are hiding is good or bad for your team. Furthermore, it would be even better if you aren't sure whether the werewolves know whether you are a werewolf too.
&lt;/p&gt;
&lt;h6&gt;...&lt;/h6&gt;
&lt;p&gt;
    So when I was originally contemplating my redesign, I wanted to break up these three downsides and reinvent them with something new. My goal was to modernize the game both in theme (AI/robots) and in mechanics (modern technologically savvy humans).
&lt;/p&gt;
&lt;h4&gt;A Technological Solution&lt;/h4&gt;
&lt;p&gt;
    I was thinking of ways to both make voting more fluid and come up with ways to introduce &quot;true facts.&quot; Surprisingly, it turned out that introducing the same tool resolved both issues.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Px6r44nrieA/XUdMsVkcWJI/AAAAAAAAET8/UrfNnZ1Ajcs8wFW9Pbq1Axmi-ODdkCNnACLcBGAs/s1600/Werewolf-Cell-Phone-User---18386.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We live within constant connection with our phones to both gather information and inform others of our intentions. Why not leverage our digital extensions to be the primary tool of the game?
&lt;/p&gt;
&lt;p&gt;
    This actually sequentially solved each of my main problems. First, I started by building a way for the werewolves to surreptitiously vote on their phones without interrupting the game. However, if only the werewolves were playing with their phones through the game, the game would be obvious. So next, I introduced another symmetric usage for the non-werewolves.
&lt;/p&gt;
&lt;p&gt;
    As it turned out, the perfect task that I could give non-werewolves was to obtain verified information about the werewolves. Again, I don't want to go into too much detail, but in general, the non-werewolves were able to query a central database that had unambiguous information about who was a werewolf. By limiting how much information they could gather at a time, the game could be tuned to both enforce cooperation and balance the rate of information gain with the rate of werewolf kills.
&lt;/p&gt;
&lt;h4&gt;Implementation: automated email response bot&lt;/h4&gt;
&lt;p&gt;
    To easily incorporate the usage of the phone, I needed to leverage something everyone would have access to. It would have been impossible for me to build a real phone app that would be compatible on everybody's devices. Instead, I leveraged something I knew everyone could use: email.
&lt;/p&gt;
&lt;p&gt;
    I built an automated email response bot that could shuffle information back and forth between players, myself, and a central database full of information that they could use to complete the game. The subject lines of the player's emails had a certain syntax that indicated whether they were trying to gather information or cast a vote to kill. The script I wrote just read the emails and followed some simple logic to direct the information around and keep the game moving along.
&lt;/p&gt;
&lt;h6&gt;Gmail API&lt;/h6&gt;
&lt;p&gt;
    To set up the Gmail API, the &lt;a href=&quot;https://developers.google.com/gmail/api/quickstart/python?authuser=8&quot;&gt;Gmail API Quickstart Tutorial&lt;/a&gt; contains instructions and the link to the spot on Google Cloud where you can activate the API. This will allow 100 sent emails per day, which should be enough if you have 20 or so people playing for an hour.
&lt;/p&gt;
&lt;p&gt;
    I used &lt;a href=&quot;https://gist.github.com/WJDigby/e36203102a195797c712c6cfe5020b21&quot;&gt;this gist&lt;/a&gt; to figure out how to send emails, and &lt;a href=&quot;https://github.com/abhishekchhibber/Gmail-Api-through-Python/blob/master/gmail_read.py&quot;&gt;this code&lt;/a&gt; to figure out how to read subject lines.
&lt;/p&gt;
&lt;p&gt;
    My code is &lt;a href=&quot;https://github.com/lots-of-things/robot-game-emailer/blob/master/robot_game_mailbot.py&quot;&gt;here&lt;/a&gt;, but I'll explain the few bits that are important below.
&lt;/p&gt;
&lt;h6&gt;Code snippets&lt;/h6&gt;
&lt;p&gt;
    This connects to your web browser to allow authentication of the Google account that has Gmail API access.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;creds = flow.run_local_server()&lt;br/&gt;service = build('gmail', 'v1', credentials=creds)&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Next, I grab the unread messages and iterate through them.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;     unread_msgs = service.users().messages().list(userId='me',labelIds=['INBOX', 'UNREAD']).execute()&lt;br/&gt;     mssg_list = unread_msgs['messages']&lt;br/&gt;     for mssg in mssg_list:&lt;br/&gt;            message = service.users().messages().get(userId='me', id=m_id).execute() # fetch the message using API&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    I step through the header items to get the subject and the sender.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;            payld = message['payload']&lt;br/&gt;            headr = payld['headers']&lt;br/&gt;&lt;br/&gt;            for item in headr: # getting the Subject,Time Sent, and Sender&lt;br/&gt;                if item['name'] == 'Subject':&lt;br/&gt;                    msg_subject = str_clean(item['value'])&lt;br/&gt;                elif item['name'] == 'Date':&lt;br/&gt;                    msg_date = item['value']&lt;br/&gt;                    date_parse = (parser.parse(msg_date))&lt;br/&gt;                elif item['name'] == 'From':&lt;br/&gt;                    msg_from = str_clean(item['value'].split('&amp;gt;')[0].split('&amp;lt;')[1])&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    At this point I go through several rounds of custom logic to compare this to the central database. I won't go into the details of the logic, but I want to mention how I access this &quot;central database&quot; in a very cheap and easily editable way.
&lt;/p&gt;
&lt;h6&gt;GSheets makes an easy editable database&lt;/h6&gt;
&lt;p&gt;
    To handle both the emailing permissions and the werewolf feature database, I just pulled the details from a Google Sheet. I already described how to connect to gsheets in a &lt;a href=&quot;/2019/04/visualizing-shared-budgets-and-dividing.html&quot;&gt;previous blog post&lt;/a&gt;. I reused the same credentials to download a sheet and convert into a python dictionary with all the info needed.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;    sheets_service = build('sheets', 'v4', credentials=creds)&lt;br/&gt;    result = sheets_service.spreadsheets().values().get(&lt;br/&gt;        spreadsheetId='game_db_spreadsheet_id', range='db!A:I').execute()&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Finally, I sent emails with the requested information back to the players.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;        message = MIMEText(message_body)&lt;br/&gt;        message['to'] = to&lt;br/&gt;        message['from'] = 'robot-db@gmail.com'&lt;br/&gt;        message['subject'] = subject&lt;br/&gt;        encoded_message = urlsafe_b64encode(message.as_bytes())&lt;br/&gt;        service.users().messages().send(userId='me', body={'raw': encoded_message.decode()}).execute()&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    All of this worked by repeatedly calling the API to get the new unread messages and then running through this over and over again. I used the sent email time to prevent people from repeatedly querying the database in less than the alotted time.
&lt;/p&gt;
&lt;h4&gt;Reaction&lt;/h4&gt;
&lt;p&gt;
    Each time I ran this game, I did it with more and more people. The first time I ran it, I only had about 8 people playing and I just manually responded to the emails they were sending. The last time I ran it, there were more than 25 people playing, and the automation came in really handy. It also allowed me to manage other aspects of the game at the same time.
&lt;/p&gt;
&lt;p&gt;
    Over time, I hope to perfect this game even further. If you are reading this in the SF Bay Area and would like to bring this game to your organization, please leave me a comment and I will get in touch to try to run it for you.
&lt;/p&gt;</description>
        <pubDate>Sun, 08 Sep 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/09/gmail-auto-responder-for-ai-robot-party/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/09/gmail-auto-responder-for-ai-robot-party/</guid>
        
        <category>games</category>
        
        <category>code</category>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <title>Woodworking, Motor Work, and Head Replacement on Ioni</title>
        <description>&lt;p&gt;
    Claire and I have been refurbishing our sailboat this summer. Our top priorities were to replace our defunct head, and to reseal and treat our wood and recaulk the topside.
&lt;/p&gt;
&lt;h4&gt;Motor Repair&lt;/h4&gt;
&lt;p&gt;
    Soooo, I hate gasoline motors. They are loud and I don't understand them. As such, I'd been putting off fiddling with my noisy, fickle &lt;a href=&quot;https://www.youtube.com/watch?v=_TtZZEmDpro&quot;&gt;six horsepower Mercury four-stroke&lt;/a&gt; for a year. But neglecting things has a way of biting you in the ass.
&lt;/p&gt;
&lt;p&gt;
    The way my negligence got to me this time was in the form of a dead motor in the middle of the &lt;a href=&quot;https://parks.smcgov.org/coyote-point-marina&quot;&gt;Coyote Point Marina&lt;/a&gt; channel on a busy, beautiful Saturday morning. My partner and I were dead in the water for about 10 minutes trying to row ourselves out of the way.
&lt;/p&gt;
&lt;p&gt;
    Eventually we got towed part way back into the harbor, and we were able to set up our backup &lt;a href=&quot;https://en.wikipedia.org/wiki/Trolling_motor#Electric_trolling_motors&quot;&gt;electric trolling motor&lt;/a&gt; to get back to our slip. It was embarrassing to say the least. But it caused me to start the process of fixing the motor back up at least, so there's a bright side.
&lt;/p&gt;
&lt;h5&gt;Oil Change&lt;/h5&gt;
&lt;p&gt;
    After checking that we had decent gas, we decided to change the oil. I followed along with &lt;a href=&quot;https://www.youtube.com/watch?v=7Cxp9Dd42mg&quot;&gt;this BC_Backwaters video&lt;/a&gt;. It's pretty straightforward after you find the drain nut. I refilled with West Marine's default SAE 10W-30 oil.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-9Be0CGQfL9Y/XZ2PnIM-3WI/AAAAAAAAEwE/WbuV-7ya-9k3GywsUiegHVCTwzALG3qowCKgBGAsYHg/s800/IMG_20190919_194851.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    While this did make the engine sound a lot less crunchy, it didn't help with the popping noises from misfires. The engine kept cutting out, and actually we think it might have gotten a little worse.
&lt;/p&gt;
&lt;h5&gt;Gas filter and spark plug&lt;/h5&gt;
&lt;p&gt;
    I was a bit at a loss, but my friend &lt;a href=&quot;https://twitter.com/dannydesloover&quot;&gt;Danny&lt;/a&gt; suggested the next thing we tried should be replacing engine filters and spark plugs. The old ones had gotten a little clogged and crusty.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-8zS7tZiGOJQ/XZ2RgLVabKI/AAAAAAAAEwQ/kD4PyS0RkbEuhmD9LZQPn0X2UV93kNv4wCKgBGAsYHg/s800/IMG_20190928_102112.jpg&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Humming Like A Top&lt;/h5&gt;
&lt;iframe allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/vg9JQVcr9mM&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;
    The motor definitely sounds better and it feels more reliable. Only time will tell how long it holds out. For the next fix, I suspect I'd repack the grease down the propeller shaft. But that will wait for another day.
&lt;/p&gt;
&lt;h5&gt;Update: Oops&lt;/h5&gt;
&lt;p&gt;
    It turns out the above fixes weren't the real culprit after all. Instead, it turns out the fuel line had become clogged with gunk. This resulted in the engine dying about a half-mile away from the marina! Fortunately, we were able to figure out that we could manually pump fuel into the motor by hand, which got us back. In the end, we just had to replace 6 ft of hose and the motor worked perfectly from then on. (knock on wood)
&lt;/p&gt;
&lt;h4&gt;Replacing the head&lt;/h4&gt;
&lt;p&gt;
    Claire's top priority (by a margin) was to replace the head. It seemed like it'd be a very dirty job, but it turned out to be not so bad.
&lt;/p&gt;
&lt;h5&gt;Remove old head&lt;/h5&gt;
&lt;p&gt;
    We removed the old head and drained the old water tanks under the V-berth. Nasty water came out, but I was in my PPE. So it fine.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-PJF2hRCsh-Q/XXVLmA7-LbI/AAAAAAAAEYI/KSenKMbTFacZfH090ok_ONVgPAVNXIqZQCKgBGAs/s1600/20190511_173748.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ZdxZ9F2gcEI/XXVLmMolM0I/AAAAAAAAEYI/DoT8h7h2CA80MUgYMvY2DtmapxyW5dXCQCKgBGAs/s1600/20190511_173758.jpg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Extending the base and mounting the head&lt;/h6&gt;
&lt;p&gt;
    It turns out the replacement head I bought was actually a few inches larger than the old base. I'd thought I'd sized it correctly,, but it seems I was off by about an inch. Since the old base was looking a little rickety anyway, I decided to &quot;augment&quot; the base and extend it by a few inches to fit the new pedestal.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-cimrSSmCAJ0/XXVMDBojRhI/AAAAAAAAEYQ/SXOPmctiTn4G9CPM_imcuSHz6phHO_dFgCKgBGAs/s1600/IMG_20190615_153102.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ssH5ZMpXPZA/XXVMDH2d11I/AAAAAAAAEYQ/s5hCSymOlmceBl5Esoei4G3Dw7aY_r0pACKgBGAs/s800/IMG_20190615_154916.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I mainly just attached two vertical 2x8s to the current vertical plywood, which was glued to the hull. I sawed the angle as best I could to fit the curvature of the inside of the boat.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-ZbVNNi0fs9s/XXVQA3n61uI/AAAAAAAAEYo/7StuJAWREww1zNewWgiYSXFOF5ZnYcM_gCKgBGAs/s800/IMG_20190606_094046.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Then I added a board across the top for mounting to the base of the pedestal.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-CeJu_ouuDww/XXVMDGUg9SI/AAAAAAAAEYQ/w1GN6153nek4XOaVLOfxwNButXN4YAzdgCKgBGAs/s1600/IMG_20190615_155045.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Bit of overhang, but at least it's secured now.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-s4cCOV_I0C8/XXVMDK7wB0I/AAAAAAAAEYQ/1ri5M5sJDnIoUWHhi2CpjDS_O_iyiSHQgCKgBGAs/s1600/IMG_20190615_171833.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-8YBfibXLBBs/XXVMDGc684I/AAAAAAAAEYQ/FAW3QF7Yz1Q-iNUrgWTGWI0HZARQUNd4wCKgBGAs/s1600/IMG_20190615_171845.jpg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Connecting the outlet&lt;/h6&gt;
&lt;p&gt;
    We ran into a bit of a snag when connecting the outlet. No matter how hard we tightened, there was still a tiny leak. Not acceptable when you are talking about piss and shit. So we added a tiny bit of our silicone sealant that we were using to shore up leaks in the topside woodwork. That seemed to do the trick (knock on vinyl).
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-C47leo1-a-k/XXVNFZbpjQI/AAAAAAAAEYc/Dtjpli_uMjQ4bTWDDhHO5hw2mZZSuBXOgCKgBGAs/s800/IMG_20190713_142240.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-y0F1EVsV7qE/XXVNFXDroxI/AAAAAAAAEYc/cWWtXguQ3NcDwv2CXIavzxRkagzKdZZ_wCKgBGAs/s1600/IMG_20190713_142953.jpg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Connecting the inlet&lt;/h6&gt;
&lt;p&gt;
    The last step was to connect the inlet of the toilet to a water source. Originally, the inlet came straight from the ocean through a &lt;a href=&quot;https://www.seamagazine.com/seacock-inspections-2/&quot;&gt;seacock&lt;/a&gt; in the bottom of the hull. That made us a little nervous given the state of the seacock.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-wJE7AiiDPwQ/XXVMDNkHB6I/AAAAAAAAEYQ/GBwnY7V07WIYYTcog4y3sihETeejLuplQCKgBGAs/s800/IMG_20190615_162258.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Instead, we're going to use the old potable water tank as a source. This will require getting more hose to reconnect the potable water tank that I'd previously removed. this project is going to hold off for a bit. For now, we are content to pour water into the top from a gallon jug.
&lt;/p&gt;
&lt;h4&gt;Refurbishing the topside wood&lt;/h4&gt;
&lt;p&gt;
    The last thing we wanted to do before winter was get our wood back in decent shape. This was important because treated and sealed wood prevents water from getting inside the boat in the rainy season.
&lt;/p&gt;
&lt;p&gt;
    We started by resealing the wood with some black silicone that I got from a neighbor. We basically plugged the holes and hoped for the best. Application was messy, but we were able to apply and scrub off the excess after the fact. It's been keeping the water out as we wash it, but we'll see about winter.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-pj9FQ7sVCtc/XXVjCQT7ImI/AAAAAAAAEY8/jc6Qp6496C0q6-rfYmTdxjN0YnmGftTJACKgBGAs/s800/IMG_20190713_114239.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We also replaced the teak oiled all the wood. We were going to pull off the varnish and reapply, but that seemed like a lot of work. Instead, we just decided to let the varnish continue to wear away. We'll keep applying teak oil to keep the wood protected while the varnish wears down. In these photos you can see how he wood started with grey patches, which we'd clean and let dry to get it kind of wood colored again. Then we'd apply teak oil and let dry.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-t-czLwtVj4A/XXcEyeFMdsI/AAAAAAAAEZs/uyxAsGGm89s2gDQpGMN2bm3uFTVy2jLdwCKgBGAs/s1600/IMG_20190714_152917.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    By the end, it looks mostly like the same. The main drawback is that the teak oil will often leave darker patches around the edges of any unfinished area. We're willing to accept this until the point when it's really worn down and we can clean and sand everything to get a nice bright finish.
&lt;/p&gt;
&lt;h6&gt;Recaulking the topside wood&lt;/h6&gt;
&lt;p&gt;
    It turns out caulk is actually pretty tricky to apply. I used masking tape to clearly delineate where the edges of the caulk should be and applied a liberal amount over the top. To smooth and round the caulk (before it dries), I came up with a homebrewed method where I used a rounded piece of wood to spread the caulk with a smooth circumference. It worked OK in most places. I pulled the tape while the caulk was still wet, but there was already some sticking in places.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-d4bbUH2YxJw/XbkNTrBa4RI/AAAAAAAAFAU/moeLtXjNEp0v3Pwlj0Au_LbKIcLF5mG0ACLcBGAsYHQ/s1600/IMG_0022.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-eQJYD_udjns/XbkNUZj94zI/AAAAAAAAFAc/8xb7876F2CwdIlbD1sNxcOEv8e_zyylKgCLcBGAsYHQ/s1600/IMG_0023.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-edEa2fRbzak/XbkNUBcJl_I/AAAAAAAAFAY/0FXABL0XiWYF8Eo4tKX_L7iiY8YSvJqyACLcBGAsYHQ/s1600/IMG_0024.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-KDpJdbo3Wu4/XbkNVcAQ5MI/AAAAAAAAFAg/dXrwvvPDzEQlNsIelN6ztKK2i5PljdZDwCLcBGAsYHQ/s1600/IMG_0025.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-rnXEW7kIyuQ/XbkNVw1dNzI/AAAAAAAAFAk/MzxtuL9-4PkgtXi6TMgvEd_0p-yMbSxxgCLcBGAsYHQ/s800/IMG_0027.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The caulk gun makes a bloody mess, and I was a little late in patching up some areas. I may need to redo a it of this project in the near future.
&lt;/p&gt;
&lt;h6&gt;Fixing some interior wood&lt;/h6&gt;
&lt;p&gt;
    We also found that some of the interior wood drawers were starting to tear apart. I just wood glued and screwed it all back together. Simple fix, but makes it a hell of a lot more livable.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-A9lGhPaDPb4/XXcEUfi_CfI/AAAAAAAAEZk/OUvZDXYxmr4vJUq-uujqbRfGqkOANvo9ACKgBGAs/s800/IMG_20190615_173315.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Budget summary&lt;/h4&gt;
&lt;p&gt;
    In a &lt;a href=&quot;/2019/04/visualizing-shared-budgets-and-dividing.html&quot;&gt;previous post&lt;/a&gt;, I described how much I like keeping track of my expenses, particularly for hobby projects like this. The overall cost of all this was around $250 for the toilet materials, and about $200 for the caulks, the oils, PPE and other miscellaneous tools. This seemed pretty great since a quote from a boatyard was for 3x that for each. Plus, I gotta admit, I feel closer to Ioni every time I work on her.
&lt;/p&gt;</description>
        <pubDate>Sun, 01 Sep 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/09/woodworking-motor-work-and-head/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/09/woodworking-motor-work-and-head/</guid>
        
        <category>boatwork</category>
        
        
      </item>
    
      <item>
        <title>Google Analytics for Scrolling on a Static Website (or Google Analytics is Creepy)</title>
        <description>&lt;p&gt;
    A couple of months ago, I helped one of my friends set up Scroll Tracking with Google Analytics on an experimental website. While working on this I discovered that I could do really cool/creepy stuff like download the scroll event data on a user-by-user basis.
&lt;/p&gt;
&lt;h4&gt;Setting up (free) Google Analytics for Website Usage Tracking&lt;/h4&gt;
&lt;p&gt;
    Because my friend was using a static site on Github Pages, it wasn't possible to set up a database to track the interactions with her website. Instead, we decided to use Google Analytics (GA) to do the storing of all that interaction data. This is great because GA can be used for free, but as we'll see, this can lead to drawbacks.
&lt;/p&gt;
&lt;p&gt;
    The first step in scroll tracking is getting Google Analytics set up to listen in on the activity on your website. This process is pretty straightforward and the steps are covered &lt;a href=&quot;https://support.google.com/analytics/answer/1008015&quot;&gt;here&lt;/a&gt;. At the end of this step, you'll be able to log in and see the number of pageviews and such on the GA site.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-mPJihWJY6FY/XfFneqiZOPI/AAAAAAAAFKA/M7FJ-2O61JgkHa01CatsHuibC1bzSDENACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B14-01-44.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This is an alright overview of the number of people who have visited the site, but we want to get more interesting event level detail like scroll tracking. There are a number of tutorials that explain how to do Scroll Tracking, but &lt;a href=&quot;https://www.lovesdata.com/blog/tracking-scroll-depth&quot;&gt;this one&lt;/a&gt; was a good start that got it working for me. I added a ton more levels to get granularity down to the single percent. After that is set up, you can view the Behavior-&amp;gt;Events tab and see all of the Scroll Tracking events in a timeline.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-E9fhXh5a5oI/XfFogxHcbKI/AAAAAAAAFKM/t8jcGRRHkoUXRizzCQPonAaZXDNWAEO2QCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B14-06-17.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    But we're actually interested in how far people scroll down the page. As explained in the link above, you can get this table by selecting the &quot;Top Events&quot; tab and then setting the primary dimension as &quot;Event Action.&quot;
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-HdQL_RiyaUU/XfFpgO_0uEI/AAAAAAAAFKY/pJnuOwpcQ9Ik2YNM7L6JJN6lK8_Pc3K-QCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B14-10-09.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This table gives a decent overall summary, but it's hard to get down to more detail than this. You can use the &quot;Secondary Dimension&quot; to get it broken down into a little more detail, but it's still pretty high level. Also, if you want to download this data, you can only export the table as it appears, not with any more detail.
&lt;/p&gt;
&lt;h4&gt;Getting User-Event Level Data&lt;/h4&gt;
&lt;p&gt;
    To get down to Event Level Records I did two things:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Add custom variables to disambiguate users on each event&lt;/li&gt;
&lt;li&gt;Use google2pandas to download the raw event data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    The first item was necessary to disambiguate multiple users so that I could reconstruct their scroll event history on an individual basis. Otherwise, everyone who scrolled at the same time would be mixed together in the data. The second item just allowed me to get every record directly instead of needing to go through the GA UI and get aggregated data. I break the process of working with those two thins down in the next sections.
&lt;/p&gt;
&lt;h5&gt;Adding User Variables to the Scroll Event Tag&lt;/h5&gt;
&lt;p&gt;
    I think that if you pay for Google Analytics then you can see the user associated with every event pretty easily . But I'm kind of broke so I don't have that luxury. Instead, to add the user's ID, I needed to pull it out of Google's tracking stuff from the inside and past it back in as a custom variable. After I'd done that I could grab those variables to store in the Scroll Event Tag for later use.
&lt;/p&gt;
&lt;h6&gt;Storing Variables&lt;/h6&gt;
&lt;p&gt;
    Google has a way to keep track of the same user across different sessions on your website. It's a little creepy, but it's pretty easy to find a &lt;a href=&quot;https://www.optimizesmart.com/how-to-send-client-id-to-google-analytics-via-google-tag-manager/&quot;&gt;how to&lt;/a&gt; on how to do it. The key part is adding a Custom Javascript variable with the following code.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-RSEUdlZjI4Q/XfF2Re87ZLI/AAAAAAAAFKk/lbVPkwjH7acX__G7qSezgiX_nQyQAlVbQCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-05-08.png&quot; title=&quot; &quot;/&gt;
&lt;pre&gt;function() {
 try {
 var tracker = ga.getAll()[0];
 return tracker.get('clientId').toLowerCase().trim();
} catch(e) {} 
return 'false';
}&lt;/pre&gt;
&lt;p&gt;
    Apparently, there is a &lt;a href=&quot;https://www.simoahava.com/gtm-tips/use-customtask-access-tracker-values-google-tag-manager/&quot;&gt;better way&lt;/a&gt; to do this, but I didn't find that until now. The drawback with my method is that the clientId variable will be null if Google hasn't set it yet. To take care of this problem I added a second variable (userId), which I manually populate on the first pageload. That way if Google takes a while to setup the clientId, I can go back and use the userId variable to connect earlier events. Kind of hacky but whatever.
&lt;/p&gt;
&lt;p&gt;
    I added the following javascript to my site to make a random ID and add it to the Google Tag Manager's &quot;&lt;a href=&quot;https://support.google.com/tagmanager/answer/6164391?hl=en&quot;&gt;data layer&lt;/a&gt;.&quot; The data layer is just a way to pass variables from your local javascript to the GTM's variable space. Note that I also added the variable called contentVersion to track which site update the user was viewing.
&lt;/p&gt;
&lt;p&gt;
    After adding this code into the &amp;gt;head&amp;lt; html of my site:
&lt;/p&gt;
&lt;pre&gt;
  function makeid() {
  var text = &quot;&quot;;
  var possible = &quot;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789&quot;;

  for (var i = 0; i &amp;lt; 20; i++)
  text += possible.charAt(Math.floor(Math.random() * possible.length));

  return text;
}
var userID = makeid();
dataLayer = [{'userID': userID,'contentVersion':1}];
&lt;/pre&gt;
&lt;p&gt;
    I added a data layer variable with the same name in GTM.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-GwFkxX7qO3I/XfF4-sXjlZI/AAAAAAAAFKw/pWtR4blYoGkaNwLINLeT3wlOcgNzf0ZKACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-16-29.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;Adding variables to Scroll Events Tag&lt;/h6&gt;
&lt;p&gt;
    After I made the variables I just needed to add them to the Scroll Event Tag that I had made before. I just put all of the variables I needed into the &quot;Label&quot; field with colons between them.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-9JLqzB_bcRA/XfF6KU7AQ4I/AAAAAAAAFK8/JubZ8W_bLP4E_AspOkZQIlJPMpWfWO3-QCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-20-02.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    To test I just went back to the GA events table we were looking at above and selected &quot;Event Label&quot; as the primary dimension. This shows the event labels in the specified format {{contentVersion}}:{{userID}}:{{clientId}}.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-T2wnRwrxfvI/XfF6iQQQZXI/AAAAAAAAFLE/kQFXFIVA_-Y2CD79EjjKowDmrUlmHAtNwCLcBGAsYHQ/s800/Screenshot%2Bfrom%2B2019-12-11%2B15-23-09.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    You might notice that the last item (clientId) is frequently &quot;false.&quot; That's just because it hadn't been set by google yet.
&lt;/p&gt;
&lt;h5&gt;Downloading events with google2pandas&lt;/h5&gt;
&lt;p&gt;
    Now that the data is distinguishable by individual userId, it becomes possible to download it at that level. Rather than using the GA UI, I wanted to write some python scripts. Fortunately, the &lt;a href=&quot;https://github.com/panalysis&quot;&gt;panalysis&lt;/a&gt; group on Github, had the &lt;a href=&quot;https://github.com/panalysis/Google2Pandas&quot;&gt;google2pandas repo&lt;/a&gt; that could connect and return the data in a pretty pandas data frame.
&lt;/p&gt;
&lt;p&gt;
    To download the data I have to send a query structured with the GA viewId, the date ranges, the aggregation dimensions, and the metrics to plot. In this example, I basically just add all the features I have as dimensions and then I get the count of totalEvents as the metric (which should be 1 most of the time anyway).
&lt;/p&gt;
&lt;pre&gt;
  from google2pandas import GoogleAnalyticsQueryV4

  conn = GoogleAnalyticsQueryV4(secrets='attention_service_credentials.json')
  scroll_query = {
  'reportRequests': [{
  'viewId' : '187999039',
  
  'dateRanges': [{
  'startDate' : '2019-11-26',
  'endDate'   : '2020-05-01'}],

  'dimensions' : [
  {'name' : 'ga:eventCategory'},
  {'name' : 'ga:eventAction'},
  {'name' : 'ga:eventLabel'},
  {'name' : 'ga:pagePath'},
  {'name' : 'ga:pageTitle'},
  {'name' : 'ga:dateHourMinute'}],

  'metrics'   : [
  {'expression' : 'ga:totalEvents'}],
}]
}
df_scrolls = conn.execute_query(scroll_query)
&lt;/pre&gt;
&lt;p&gt;
    I have a working &lt;a href=&quot;https://github.com/lots-of-things/attention-tracking&quot;&gt;jupyter notebook&lt;/a&gt; on this if you want a place to start. You will need to enable the GA API and get your own google_service_credentials.json file by following the instructions &lt;a href=&quot;https://developers.google.com/analytics/devguides/reporting/core/v3/quickstart/installed-py&quot;&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;h4&gt;Plotting the scrolling progress&lt;/h4&gt;
&lt;p&gt;
    In my jupyter notebook, I graph the scrolling progress for a few people. The data is clearly messy because some people just scroll straight to the bottom. Still, this gave my friend a pretty clear idea that for people who were actually reading it, it took about an hour to finish.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-BN1Su8VptwM/XfGCDzfGpGI/AAAAAAAAFLQ/D5ZMotAq5qso7tUPfbzc4U1LJCPwS2bYwCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2019-12-11%2B15-47-15.png&quot; title=&quot; &quot;/&gt;</description>
        <pubDate>Sun, 30 Jun 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/06/google-analytics-for-scrolling-on/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/06/google-analytics-for-scrolling-on/</guid>
        
        <category>code</category>
        
        <category>data science</category>
        
        
      </item>
    
      <item>
        <title>Solar Electrical System on Ioni</title>
        <description>&lt;p style=&quot;text-align:center&quot;&gt;&lt;i&gt;Daughters of Nereus, resident in caves, merged deep in sea, sporting through the waves;&lt;br/&gt;whose forms half wide are nourished by the deep, leaping and wandering through the liquid sea.&lt;br/&gt;Bright, watery dolphins, sonorous and gay, well-pleased to sport with Bacchanalian play;&lt;br/&gt;Nymphs beauteous-eyed, whom sacrifice delights, give plenteous wealth, and bless our mystic rites;&lt;/i&gt;
&lt;/p&gt;
&lt;p style=&quot;text-align:right&quot;&gt;Orphic Hymn 24 to the Nereides &lt;i&gt;c. 300 BC&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
    I'm currently in the process of fixing up my vintage Dolphin 24 sailboat, Ioni. This post covers my foray into marine electrical. I'm mostly writing this so I can laugh at myself a year from now, when everything goes horribly wrong. \_()_/
&lt;/p&gt;
&lt;h4&gt;Ioni's Electrical Systems&lt;/h4&gt;
&lt;p&gt;
    There are basically three essential electrical systems on Ioni.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Auto bilge pump&lt;/li&gt;
&lt;li&gt;Running lights&lt;/li&gt;
&lt;li&gt;Radio&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    The bilge pump is to keep any small leaks or rain from sinking her while I'm away. The running lights are needed for any nighttime sailing. The radio is probably not necessary for bay sailing, but it would be a little irresponsible to not set it up. By the end of this all of these will be running off of this 12 volt car battery.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-bqVbi3ZT8Mg/XEZ9heBuBXI/AAAAAAAADS8/oWp-QCbinws1C-fPEDuLSJ3BsTGyRizpgCKgBGAs/s1600/IMG_20180619_195217.jpg&quot; title=&quot;I assure you, it's not as dangerous as it looks. &quot;/&gt;
&lt;p&gt;
    Finally, a battery won't last forever so there needs to be some system to recharge it. I would personally prefer to not need grid electric in my life ever, but as that isn't possible, I at least want to be able to take this small isolated system off of it. Therefore, I'm going to be pursuing solar photovoltaic for recharging the battery.
&lt;/p&gt;
&lt;h4&gt;Basic electrical setup&lt;/h4&gt;
&lt;p&gt;
    Before I set up the solar system, I focused on making sure all the electrical systems were working directly off battery. Ioni's electrical setup is pretty simple. Below is a diagram of all the main electrical equipment I built.
&lt;/p&gt;
&lt;p&gt;
    The wiring itself is set up to run through this junction box. One side is positive and the other negative.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Nl2V_3X3bb8/XEZ_DGyXLBI/AAAAAAAADTU/835E5B8xcMQthFa97Tt5uc_9buuLqXl9ACKgBGAs/s800/IMG_20180619_195203.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Most of the equipment runs through this set of switches, which are hooked up to their own fuses. I also ran a larger breaker across the main battery terminal just in case of short to prevent the auto battery from running hundreds of amps and melting itself.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-yu98CiBrO5Q/XEZ-PkWKdII/AAAAAAAADTM/SyZxZ6Vp2vE55MWADx5--XJIu0hCCM-IQCKgBGAs/s1600/IMG_20180626_221557.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    One component that doesn't run through the set of switches is the automatic bilge pump. I could have run the bilge pump through the switches, but I decided to avoid that since I wanted to make sure no one ever accidentally shut it off. The wiring setup for the bilge pump was particularly easy, and just involved connecting the positive end to the float switch line on the pump. This float switch turns on whenever the bilge pump gets significantly covered in water.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-aXemo4lVHBA/XEZ-PkLW6TI/AAAAAAAADTM/w1jGmMyI9ysqVkqHf6Uk5SkbMXYFbI30gCKgBGAs/s800/IMG_20180626_221744.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Radio&lt;/h4&gt;
&lt;p&gt;
    The radio was the first thing I connected. It was very straightforward. Just connect the black wire to the negative on the battery and the red to the fuse/switch, which connects to the battery positive terminal. The antenna runs up the mast as well.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-o5rLuqEhnhI/XEZ_hE2m1QI/AAAAAAAADTc/76Xwo5p9jBMYmQRbT7TzfIaSOCWfjsssgCKgBGAs/s1600/IMG_20180701_184433.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Lighting&lt;/h4&gt;
&lt;p&gt;
    The lighting was a slightly more complicated setup, but all fairly straightforward once I understood the wiring setup. Fortunately, the wiring for all the lighting was already run, I just had to decipher which lighting element was which. The cabin lights and running lights are each in parallel so that if one goes the rest will work fine. I'd assumed this would mean individual lines for each, but instead, there was just a pair of ground connections and then an individual hot for cabin and running lights. The hots needed to be attached to the switch.
&lt;/p&gt;
&lt;p&gt;
    The light in the V-berth had a broken switch that I needed to open up and break apart from the inside to reattach.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-q1hJ3rFjNRg/XEaAfurVnHI/AAAAAAAADTo/Dpvd5AIQVCsKMR6OwZ3UktRkJNeBOtlVgCKgBGAs/s800/20180725_190631.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Similarly, I had to repair the interior of the main cabin light because the connections were faulty. I dismantled and reconnected it, and then swapped the original bulb with a low power LED. There was also a light in the V-berth that had a jammed switch that needed to be taken apart for repair.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-3mbUxEUSnbs/XEaAfmpNGRI/AAAAAAAADTo/tDBz53k_NzYqDaSA7bxWdP15r6kY-kqGACKgBGAs/s800/20180724_214935.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-b46qdWnJsw0/XEaAfo2vbLI/AAAAAAAADTo/GR8ghn-6sWIIcDvC3qeQaFGgTsNveBcygCKgBGAs/s1600/20180724_183211.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I replaced the running lights with LED bulbs as well. Running lights are designed to be green to starboard, red to port, and white on the stern. The wire leading to the rear white light was cut so I reextended it.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-HnFE-ividFc/XEaAfnrrEgI/AAAAAAAADTo/UFLCS55omy4iW8p39LoPpOF9BtsGTcxhQCKgBGAs/s1600/20180725_190744.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally, the light up the mast was disconnected, which was a good thing, since the casing for that light was missing too. When I bring the mast down for transportation to the drydock for repairs, I'll replace that light. For now, I'll do without.
&lt;/p&gt;
&lt;h3&gt;Solar&lt;/h3&gt;
&lt;p&gt;
    The really interesting part was the setup of the solar system, though again it was surprisingly easy once I got past my fear of lighting something on fire. The truth is the current was limited to about 2 Amps so the chance of a fire is really zero. Still, using too small a gauge wire could have led to some overheating perhaps so it was good that I used 12 gauge stereo installation wire.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-UGYDFBT9iTg/XEaClT1EDwI/AAAAAAAADT0/DYfxVt0t790-RsIPku87KJ-l-TQ9TaemQCKgBGAs/s1600/20180828_175812.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Setup was really just as simple as attaching the voltage regulator to the battery, then to the solar panels, and finally to the load. I really think anyone could set up a solar panel system this simple.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Tzuha2Ku_iw/XEaCt3oJuSI/AAAAAAAADT4/_A0liPqn7dgm26zAXZ79sv2G7VmYWW6RQCKgBGAs/s1600/20180828_184933.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The monitoring on the charge controller is so helpful as it gives an update on the voltage state of the battery as well as input and output currents. Even when quite cloudy the solar panel can bring in 0.1 A and at full brightness 1.8 A.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-6xEBCxXmma4/XEaC2BEq1sI/AAAAAAAADT8/ENTKgfiMn8AINOwW8a7-e1ztsrlKmKMwACKgBGAs/s1600/20180828_173607.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-_MERW8G7w4M/XEaC2OTQc9I/AAAAAAAADT8/Qm05gqYb5kMEQlSoV35gOAlyoPzxT_MoACKgBGAs/s800/20180828_182043.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I ran the wiring to the exterior solar panel through the motor exhaust port at the stern. To begin, I just tested the panel by propping it up in the cockpit of the boat. I wanted to ensure that the charge controller really would limit the voltage when unsupervised to prevent degassing of the battery when overcharged. Indeed after getting up to 14.3 V for a few minutes it would normally top out and move to trickle charge mode, where it held at approx. 13.1 V indefinitely. I left plenty of extra wire to extend the panel where I need it, but I expected to cut that down when I found a more permanent position.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-TwjmvwRTCVE/XEaC-LaSjpI/AAAAAAAADUA/Txsw4gDkD4s8w-AtuizsUO5Fx4c5dO1WgCKgBGAs/s1600/20180828_185959.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I installed the charge controller on the panel near the door so that I could keep an eye on the charging voltages for now. I attached it with one screw so that I can take it off soon and affix it to the top paneling in a less conspicuous place.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-wkkiKdXuCRM/XEaDD8BtnVI/AAAAAAAADUE/beFmNFXUMDgo7ed9Du4-TXHDs5wpETQSACKgBGAs/s800/20180829_081202.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    One great feature of the charge controller is the USB lines, which I can now use to charge small devices.
&lt;/p&gt;
&lt;h6&gt;The Mount&lt;/h6&gt;
&lt;p&gt;
    To allow me to move the panel out of the way and to avoid disrupting woodwork and fiberglass I decided not install the panel. Instead, I simple prop it up on the side whenever I need to charge. Then when we take it out to sail, I place it in the cardboard and slip it back under the cockpit.
&lt;/p&gt;
&lt;h4&gt;Next steps&lt;/h4&gt;
&lt;p&gt;
    There are a few other electrical devices that I might want to add, but at the moment I worry about them drawing too much power for the little battery I have. I have a DC trawling motor that I would love to set up, and I've put together an attachment for a small Peltier cooler. Both of those drain the battery fast so I'll probably need to devise a double battery setup before I can use them. That way even if those drain the energy, I can have a backup to run emergency power for the radio and bilge pumps.
&lt;/p&gt;
&lt;p&gt;
    All in all, the electrical turned out to be quite a bit easier than I thought. It was a good starter before I move onto the next big challenge: plumping.
&lt;/p&gt;</description>
        <pubDate>Wed, 01 May 2019 19:46:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/05/ionis-solar-electrical-system/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/05/ionis-solar-electrical-system/</guid>
        
        <category>boatwork</category>
        
        <category>energy</category>
        
        
      </item>
    
      <item>
        <title>Visualizing shared budgets and dividing up household expenses fairly</title>
        <description>&lt;p&gt;
        My partner and I have been tracking our finances ever since we moved in together back in 2014. Originally, we started just tracking our shared expenses like rent and groceries in order to make it easier to divide our household contributions &lt;a href=&quot;http://lesswrong.com/lw/ru/the_bedrock_of_fairness/&quot;&gt;*fairly*&lt;/a&gt; (for more, check out the post on our &lt;a href=&quot;/2017/08/the-stedden-constitution.html&quot;&gt;Marriage Constitution&lt;/a&gt;).
    &lt;/p&gt;
&lt;p&gt;
        Figuring out how much we each owed was easy when Claire and I earned the same graduate student stipend and lived in the same place, but eventually we started to have time varying incomes and a more complex expense structure. It was starting to get tricky to sort out who owes what. To solve this, we came up with a more sophisticated way to track and visualize how much we earn and spend. I ended up writing some analysis code into a simple &lt;a href=&quot;http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html&quot;&gt;jupyter notebook&lt;/a&gt; along with a python package for refreshing the data from our records on Google Sheets.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-tDlDpiBZNmE/XJsATOh1E8I/AAAAAAAADmU/nivn8xwtMaIdr_YYYWPKs68DakWf71iOQCLcBGAs/s1600/Screen%2BShot%2B2019-03-26%2Bat%2B9.46.36%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The code is available on the &lt;a href=&quot;https://github.com/lots-of-things/ipy-budget&quot;&gt;lots-of-things GitHub&lt;/a&gt;, and I made some &lt;a href=&quot;https://docs.google.com/spreadsheets/d/1XiSlpguUG_YGU9TQ0b8dJheeCMYNR6xNAg_cluXsrGk/edit?usp=sharing&quot;&gt;dummy budget data&lt;/a&gt; on Google Sheets. Read on for more details and background.
    &lt;/p&gt;
&lt;h4&gt;The Theory&lt;/h4&gt;
&lt;p&gt;
        With our budget, my partner and I are trying to experiment with a small-scale semi-utopian &lt;a href=&quot;https://www.aeaweb.org/articles?id=10.1257/jep.30.1.225&quot;&gt;economy&lt;/a&gt;. Economics is interesting to me because I love the concept of quantizing the costs and benefits of our choices. Of course, money is an imperfect way to quantify all the multitude of factors that go into our definition of value, but I do fundamentally prefer imperfect metrics to fuzzy subjective definitions of value, particularly when trying to define fairness of value in a multi-party situation. I've always thought that keeping things qualitative gives unfair advantage to those who can argue eloquently (or whine loudly). Since I'm interested in an experiment with small organization economics, it's really useful to have a system in place to track, analyze, and experiment with our financial data on the finest grain we can.
    &lt;/p&gt;
&lt;h4&gt;Overview of expenses and income&lt;/h4&gt;
&lt;p&gt;
        When we were first getting started we were only interested in categorizing our expenses into shared and separate to know who was paying for what out of their own pocket. However, we quickly realized that since we were doing all this categorization anyway, it would be really useful to label our expenses a little more granularly so we could analyze what our spending habits looked like over time.
    &lt;/p&gt;
&lt;p&gt;
        Over time, we started incorporating more detail to bin our expenses into the following categories:
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;income&lt;/strong&gt; - gross income from our employers or any side-hustles &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;rent&lt;/strong&gt; - our primary housing related expenses and some utilities &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;groceries&lt;/strong&gt; - any essentials bought from the market, includes alcohol purchases from the store &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;household&lt;/strong&gt; - broader category for non-food but still fairly essential things around the house &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;recreation&lt;/strong&gt; - broad category for things we did just for fun, eating and drinking out, throwing parties, etc &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;medical&lt;/strong&gt; - insurance and medical bills &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;transit&lt;/strong&gt; - public transit and rideshares &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;car&lt;/strong&gt; - gas, insurance, repairs &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;boat&lt;/strong&gt; - boat purchase, slip fees &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;flights&lt;/strong&gt; - any airfare (excludes frequent flier miles though) &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;donations&lt;/strong&gt; - charitable organizations &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gifts&lt;/strong&gt; - things we buy to give to others &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;wedding&lt;/strong&gt; - separate category for all of our wedding expenses &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;work expenses&lt;/strong&gt; - things we buy to do our work, often reimbursed &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;taxes&lt;/strong&gt; - tracking tax withholdings and refund &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        In addition, we have two more that are a little different than normal income/expenses. I'll talk more about these categories later and our debate in how to think about them.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;investments&lt;/strong&gt; - treating investments like an expense that will have a future return (hopefully) &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;redistributions&lt;/strong&gt; - transfers from one party to another to help even out the burden &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        At the time when we first started tracking all these categories, it seemed like overkill, but now, years later, I'm glad we did it. This lets us uncover some neat insights into how our spending in each category changed over time. As an example, here we could see our spending on airfare.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-_tf3KY6IKew/XJsCuBf0TGI/AAAAAAAADmg/hP2k6zaGSokoPBK_4Vhn2Svv2bjpIdz1wCLcBGAs/s1600/Screen%2BShot%2B2019-03-26%2Bat%2B9.57.17%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This started to climb in late 2016 when I moved out to California, and we started flying back and forth constantly. It should drop down to nearly zero this year as we start to get our flying habit back under control. We can view this same sort of figure across many different categories of spending too.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-nkcmDZzWkjo/XJsKx2_w7jI/AAAAAAAADm0/4zzZMyFUQhoxhVh73jTQ8wvYcxLlwoCKgCLcBGAs/s1600/Screen%2BShot%2B2019-03-26%2Bat%2B10.31.32%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        One thing that these plots point out is that the spending is not uniform between Claire and myself. Normally, Claire ends up spending a lot more than me. This isn't because Claire is going on shopping sprees or anything; she just ends up taking on a greater proportion of the household and grocery spending. This brings us to the next topic: redistributing money to make up for differences in expenses.
    &lt;/p&gt;
&lt;h4&gt;Splitting Expenses&lt;/h4&gt;
&lt;p&gt;
        As mentioned above, a key reason for doing all this is to determine a fair way to divvy up our money based on income and spending. We've heard that money arguments can lead to failed relationships so we wanted to preempt the arguments by coming up with a reasonable way to discuss things and make fair decisions.
    &lt;/p&gt;
&lt;h6&gt;Why not just divide evenly?&lt;/h6&gt;
&lt;p&gt;
        A lot of couple's seem to suggest the &quot;put equal amounts into a shared account method.&quot; I don't think that method is really adequate for two reasons. First, I think that the person who makes more money should have to pay more of the expenses. This feels justified because the combined lifestyle should be reflected by the combined income. Splitting evenly would mean either the overall money spent is lower than we can afford OR that the person who makes less will have to allocate more of their money to expenses. Either way this is non-optimal and should be prevented with some differential contribution to the shared coffers.
    &lt;/p&gt;
&lt;p&gt;
        The second set of reasons are more about why using a bank account is worse than directly monitoring spending. Just blindly dropping money into a shared account is inefficient and can also can incentivize bad actions. If there is leftover shared money, both parties are incentivized to spend it up rather than reallocate it to savings. Also there is an inherent inefficiency if extra money starts piling up in the shared account rather than being reallocated to investment accounts.
    &lt;/p&gt;
&lt;p&gt;
        So we wanted to come up with a better way to combine our assets, but still keep autonomy and flexibility.
    &lt;/p&gt;
&lt;h6&gt;From each according to his ability, to each according to his needs&lt;/h6&gt;
&lt;p&gt;
        The most reasonable method we could come up with was to split our expenses based on our proportion of income. This method makes perfect sense both in the limit where one person is making all the money and when everyone makes the same amount. And it seems like the most reasonable starting place for a fair division.
    &lt;/p&gt;
&lt;p&gt;
        Initially, we figured it would be easy to just add up our monthly or quarterly income along with our expenses and divide evenly. However, a simple thought experiment shows why it makes more sense to use our cumulative income and expenses.
    &lt;/p&gt;
&lt;h6&gt;The Lottery&lt;/h6&gt;
&lt;p&gt;
        Imagine that in a relationship, one partner makes all of the money, while both partners spend about the same amount month to month. Clearly, the partner that makes all the money needs to reimburse the other or else the non-earning partner will not have any money to spend! That is just fair. Now imagine that the non-earner were to buy a lottery ticket and win a million dollars on one day. If they were basing their split on that month then clearly the lottery-winner/normally-non-earner would have to pay for almost everything that month. However, compared to the monthly expenses their would still be tons of cash left over, which the non-earner would get to bank at the end of the month. Then, the next month the non-earner's income would go back to zero, and the earning partner would have to go back to supporting both parties. Clearly this would be unfair. A similar argument explains the unfairness if the couple have time-varying expenses too. Hence, it is more fair to divvy up the total cumulative expenses based on the partners cumulative income.
    &lt;/p&gt;
&lt;p&gt;
        This might not be a huge difference in practice though, so it made sense to compare the two methods using our real data.
    &lt;/p&gt;
&lt;h4&gt;Local vs Global Income and Expenses&lt;/h4&gt;
&lt;p&gt;
        I wanted to compare the method of using the short-term (local) and cumulative (global) expenses and incomes for the split of money. Because I already have all the data in an unaggregated form, it's easy to use pandas to get a cumulative sum of the expenses.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;income['total quarterly income'] = income['c']+income['w']&lt;br/&gt;income['total cumulative income'] = income['total quarterly income'].cumsum()&lt;br/&gt;income['Claire\'s local share of income'] = income['c']/income['total quarterly income']&lt;br/&gt;income['Claire\'s global share of income'] = income['c'].cumsum()/income['total cumulative income']&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        As a first step, we can plot these two methods of breaking down our income. In the graph below, I plot the share of our total income that Claire brought in as a proportion of our total. We expected that we'd look roughly equal up to the start of 2017 and then Claire would make up about one third of the income.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-JtIZmatjR3c/XJulGNnVqsI/AAAAAAAADnM/exbQu1otpLgXiRCKVckgNXIGQoi3LtNtwCLcBGAs/s1600/shareincome.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        That turns out to be the case for the local method, but for the global method she slowly shifts from 50% toward ~30%. This smooths out the step change in my income because over a long enough time, fluctuations in income become less important.
    &lt;/p&gt;
&lt;p&gt;
        In Q1 2019, Claire stopped working as she transitioned between grad school and her first job. Clearly with the local method, Claire's income drops to zero, and so her share of expenses should be zero. However, using the global method, her income in prior periods still counts, though less and less over time.
    &lt;/p&gt;
&lt;p&gt;
        Similarly our local split of expenses zig-zags also all over the place, but that is smoothed out in the global method.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-GGw49_19mzw/XJuoDWjN5JI/AAAAAAAADnY/5j3ANMg-G8AehnlE7_Z2f2uO-AkwIgkLACLcBGAs/s1600/shareexpense.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        So with the aggregated income and expense data, we can calculate what we each should have paid and what we ended up paying.
    &lt;/p&gt;
&lt;h4&gt;Calculating the overpayment&lt;/h4&gt;
&lt;p&gt;
        Using the local and global methods, I can calculate the fair allocation of Claire's expenses by multiplying Claire's fair share of expenses by the true expenses. I can then perform another cumulative sum to see the gap between what Claire has really paid to date and what she should have paid. Finally, the difference between those lines is the overpayment by Claire (ie the money I owe her).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-pn5saTsKb9c/XJuo-NFVAyI/AAAAAAAADnk/yIOQGK_N6rka9ULuthU8_SqY9rVuYEn6gCLcBGAs/s1600/payment.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Right around the beginning of 2017 was the last time that Claire and I redistributed money. It was also when I started my post-grad job and started earning more. You'll notice that the global method actually means Claire is owed more money from me. It comes to about $1000 dollars which is real money. I guess that's what I get for trying to do things more fairly!
    &lt;/p&gt;
&lt;h6&gt;Counting Investments?&lt;/h6&gt;
&lt;p&gt;
        One thing that we are still trying to figure out is how investments should be tracked. There are basically two ways to think about them.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ignore investments&lt;/strong&gt; - Investments are really just moving your income around between accounts&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Investments as expenses&lt;/strong&gt; - Investments are treated as expenses until they are withdrawn &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        It's hard to decide which way to think about investments. I personally like the idea of thinking about them as current expenses. This makes investments similar to other large capital purchases that might pay off later. For example, buying a car means an expense today with a possible payout later (though less than the initial value probably). Investments are just the same except that they can earn more money.
    &lt;/p&gt;
&lt;p&gt;
        The issue is that then all one partner has to do is invest all of their money to make it look like they have no income. That could lead to bad behavior, but realistically, the same could be said for any expenses (spending all your money on things that go to yourself means you don't have to share anything). The point of the budget is to identify where one partner is over-spending or over-investing and to allow a debate about whether that is wise. Importantly, if one partner makes a bad investment they probably shouldn't be penalized by having to count the investment as their personal income without being able to count the loss. Furthermore, either partner can decide that they want to take on investing more money and there can be a redistribution of income to compensate. It all just comes down to a negotiation and an ability to justify the expense for the good of the team.
    &lt;/p&gt;
&lt;p&gt;
        This, to me is the argument for treating investments like normal expenses until withdrawn. However, Claire and I still need to work out whether that is a reasonable way to think about it.
    &lt;/p&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;
        In the end, all of this just goes to remind me how lucky I am that I've been able to have stable finances in my adult life. Going through this exercise was really important for seeing how our spending habits are evolving as our lifestyle changes, and it's been useful in articulating our goals for our financial future. We will continue to use this method to redistribute income in the future, and I will update if we arrive at any new methodologies that are worthy of note. I can also see this paradigm working in a larger coop-like organization, and I'm curious to see if Claire and I ever get to incorporate these ideas into something like that.
    &lt;/p&gt;
&lt;h4&gt;Appendix: Securely querying Google Sheets data in python&lt;/h4&gt;
&lt;p&gt;
        One of the things that made this so easy was the ability to get the data out of google sheets and into a jupyter notebook where we could more cleanly perform the analyses we needed for this project. It would have been very messy to do all this work directly in the spreadsheet. &lt;a href=&quot;https://www.stitchdata.com/blog/google-sheets-stitch-easy-sync-to-redshift/&quot;&gt;Many&lt;/a&gt; &lt;a href=&quot;https://blog.usejournal.com/how-to-use-google-sheets-as-a-cms-or-a-database-f9d8e736fdce&quot;&gt;others&lt;/a&gt; have found this separation of data entry and front-end/analysis to be really effective too.
    &lt;/p&gt;
&lt;p&gt;
        I also built a little &lt;a href=&quot;https://github.com/lots-of-things/ipy-budget/blob/master/ipy_budget_api.py&quot;&gt;wrapper python package&lt;/a&gt; for the gsheets api that is specifically designed for grabbing data in this format. The package calls up the &lt;a href=&quot;https://developers.google.com/sheets/api/guides/authorizing&quot;&gt;Google Authentication flow&lt;/a&gt; to securely allow connection to your own GSheets. This greatly reduces friction from downloading and manually storing files all over.
    &lt;/p&gt;
&lt;p&gt;
        If you like this project and want to replicate the workflow for yourself feel free to fork the repo and make modifications. I could imagine this could be a start to a really lightweight DIY budgeting analysis toolkit. In future editions I hope to build some piping for automated download of financial statements and import into gsheets and maybe even auto classification and analysis. This seems really preferable to shopping this out to a third party like mint for the security and privacy reasons.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 03 Apr 2019 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2019/04/visualizing-shared-budgets-and-dividing/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/04/visualizing-shared-budgets-and-dividing/</guid>
        
        <category>data science</category>
        
        <category>philosphy</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>Redwood Planter Cabinet</title>
        <description>&lt;p&gt;
    My &lt;a href=&quot;https://www.instagram.com/mysfmountain/&quot;&gt;friend&lt;/a&gt; had really been wanting to build his own &lt;a href=&quot;https://www.pinterest.com/pin/72972456436478855&quot;&gt;green wall&lt;/a&gt; in his back yard in the Mission in SF. So this winter, we took a weekend, planned it out, and built it. Here's the haphazard, meandering process we went through.
&lt;/p&gt;
&lt;h4&gt;Planning&lt;/h4&gt;
&lt;p&gt;
    We didn't really know what we could pull off on this project. We started by mapping out a few sketches.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-VdRrf5EznCk/XHoGwrXbzVI/AAAAAAAADdM/BJIAmNy-IZ8fjzatEyH_G7IoCzYTx3ZLgCKgBGAs/s1600/20181208_205806.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Although the &quot;floating boxes effect&quot; seemed really cool, we ultimately figured it'd be too tough to implement. We also toyed with doing almost closed sides sort of like a moving pallet, but thought it might be too much wood and look too shabby if it were reclaimed material. We went with a basic shelf-trough sort of design instead.
&lt;/p&gt;
&lt;p&gt;
    I grabbed a few native plants from the nursery at the Presidio after a &lt;a href=&quot;https://www.facebook.com/events/874448542679077/&quot;&gt;planting day&lt;/a&gt;, which we assumed would be generally resilient to weather in the area. The backyard area wasn't going to be getting much light so I picked a some strawberries that the Presidio naturalist had selected for a shadier area.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-lSDLyTI3qL0/XHoGwnhVJWI/AAAAAAAADdM/1mh6Oaa9wQk0q0PIsCf_uEVR3GIswjHyACKgBGAs/s1600/20181208_122620.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Breaking ground&lt;/h4&gt;
&lt;p&gt;
    With a rough plan in hand, we started stitching things together. We dug out the post holes to be filled with 4x4 posts and dropped them in to size approximately.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-E5r_mrmxwFA/XHoHKcJCdrI/AAAAAAAADdU/gY3KEoxyc2Qpx5nmaOeIPP777fID4UecwCKgBGAs/s800/20181209_094816.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    We did the entire project without any power tools. Here is Sam sawing away. I found it pretty exhausting. I think we needed about 12 cuts, but we obviously ended up doing a lot more. Fortunately, all the cut surfaces were interior.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-f_lbed6ftq4/XHoG-LDVIhI/AAAAAAAADdQ/w_qB2fFrpiMEgJ4rEdL_XcH1MYkvRQztwCKgBGAs/s800/20181208_181937.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Assembly&lt;/h4&gt;
&lt;p&gt;
    During planning, we didn't think about how flimsy the connections were going to be between the posts and the bottom 2x4 of the shelves. Fortunately, the interior of the shelves would be filled with dirt and wouldn't be visible so we could add some ugly reinforcements to the corner of the shelves on the inside.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ObzxCQ1UITU/XHoHKUZ-N9I/AAAAAAAADdU/79FOF9u6fSkkzkBgMock0GvilFbJNFwKQCKgBGAs/s800/20181208_203332.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    That made the frame much more sturdy so we could afford to move it around without fear of completely tearing out the ends of the 2x4s.
&lt;/p&gt;
&lt;p&gt;
    We assembled 3 shelves straight across for simplicity and structural support. /p&amp;gt; &lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-LgxIXSOoKUc/XHoHKbRV3MI/AAAAAAAADdU/CiGruuuMcQgLdJpWze2hz8PpIyTH0AhsQCKgBGAs/s1600/20181209_094042.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        After the frame was assembled we finished out the post holes (using a spoon!) and dropped the frame inside. Well, we almost did. Except that we were off by about a half inch and ran into a sliver of foundation concrete. We chipped it back so the posts could just slide in.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-4azjRkj0w6Y/XHoG-Clb8GI/AAAAAAAADdQ/WjMsXt0OW_8tuPQeQli5kShEAR0EXfwlACKgBGAs/s1600/20181208_175451.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Finally, we started screwing the redwood slats onto the outside to make the soil troughs.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-tXFPZ90WT7o/XHoHKcJW5LI/AAAAAAAADdU/J-9ByG-aH3Y6kjt5khQi9MEdXTDd9CGKwCKgBGAs/s800/20181209_110746.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        By some miracle when all was said and done both the posts and all the shelves were somehow perfectly level. We didn't actually use a level until the posts were set in the gravel!
    &lt;/p&gt;
&lt;h4&gt;Planting&lt;/h4&gt;
&lt;p&gt;
        We filled with a bit of soil and fertilizer and then we planted.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-isYwAyTCFig/XHoHT7qItQI/AAAAAAAADdY/2Nr2RBAdFFcNuePK8nPbFIF3a-EgrsUoACKgBGAs/s800/20181209_220704.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Sam looks happy with the process.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-hYyGLGwdVEA/XHoHb_kY4TI/AAAAAAAADdc/-uOuARWe-T0GdxKE1biBmXZf2so7tVyrACKgBGAs/s800/20181209_214541.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Result&lt;/h4&gt;
&lt;p&gt;
        The vegetation is still a little less than filled out. I will update as we roll on through the year and hopefully get a bit more sunlight. Still, it already adds a lot to the ambiance of the backyard, in my humble opinion. Perhaps, I'll grab a few more plants soon.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-BWDJKx2T98s/XHoHhskJ7II/AAAAAAAADdg/Pq0bXqvX5JQlK0k3BE7WU03U43wnylRXwCKgBGAs/s800/20181210_083237.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Update 1&lt;/h4&gt;
&lt;p&gt;
        They made it through the rest of winter at least!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-TnbQNHBe0DM/XH3v4ufb1vI/AAAAAAAADeQ/vmI1xoUeT-8lXOU_g3AfULei7NOyPQ_XQCKgBGAs/s800/20190302_082724.jpg&quot; title=&quot; &quot;/&gt;&lt;/p&gt;</description>
        <pubDate>Mon, 04 Mar 2019 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2019/03/redwood-planter-cabinet/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/03/redwood-planter-cabinet/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <title>Human Ivory Earrings</title>
        <description>&lt;p&gt;
    Ever since working on my partner's &lt;a href=&quot;http://www.makeloft.org/2017/04/engagement-ring-from-found-smoky-quartz.html&quot;&gt;engagement ring&lt;/a&gt; last year, I've become more and more interested in making custom jewelry for people. Recently, I happened upon another interesting raw material, and I decided to see what I could make.
&lt;/p&gt;
&lt;h3&gt;Sustainable Ivory&lt;/h3&gt;
&lt;p&gt;
    Mammal teeth and tusks are made of the same thing, &lt;a href=&quot;https://en.wikipedia.org/wiki/Ivory&quot;&gt;dentine&lt;/a&gt;. So, when I had my wisdom teeth removed, I kept them to try to fabricate some &quot;sustainable ivory&quot; jewelry from them.
&lt;/p&gt;
&lt;p&gt;
    I'll spare showing you my cavity filled wisdom teeth in their raw form.
&lt;/p&gt;
&lt;p&gt;
    I grabbed my Dremel and started carving a spiral groove around the edges. After cutting away a bit of that and turning the shape a little, I had the following.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-cmYifuWlGsg/WslIToIma2I/AAAAAAAABc4/GIxJxvHwXNoaNj7hn_jTaIH32Ar1ENw0wCKgBGAs/s800/IMG_20171223_100539.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I continued thinning down that shape for a while, until I accidentally took it just a bit too far, and one of them shattered into multiple pieces. Kind of sad, but on the other hand, they were a little large for earrings. Instead, I ended up wrapping the remaining one in a bit of steel wire, to be used as a necklace pendant.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-qTlakxg1tSI/XEZ7ycNPETI/AAAAAAAADSw/LoxKdWkuP38S3ohYzk6nlPtHPfubg0yBwCLcBGAs/s1600/20181218_191642.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I found &lt;a href=&quot;https://majeruslucie.eu/H-U-M-A-N-I-V-O-R-Y&quot;&gt;another artist&lt;/a&gt; who did &lt;a href=&quot;https://www.treehugger.com/sustainable-product-design/human-ivory-lucie-majerus.html&quot;&gt;something similar&lt;/a&gt; before. Hopefully people aren't too weirded out by the idea as it seems a hell of a lot more reasonable than poaching ivory or sending people into mines for stupid shiny shit.
&lt;/p&gt;</description>
        <pubDate>Mon, 21 Jan 2019 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2019/01/human-ivory-earrings/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2019/01/human-ivory-earrings/</guid>
        
        <category>art</category>
        
        <category>design</category>
        
        <category>craft</category>
        
        
      </item>
    
      <item>
        <title>@rtifice Website Revamp</title>
        <description>&lt;p&gt;
    A few months ago, a non-profit I volunteer for &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;@rtifice tech education&lt;/a&gt;, needed to get its digital face revamped. I spent a few weeks working on a full website and blog revamping.
&lt;/p&gt;
&lt;h4&gt;Page loads and information&lt;/h4&gt;
&lt;p&gt;
    There were two main problems with the non-profit's web presence. First off, the website looked totally amateur and was filled with out of date information. This is, of course, completely normal for most non-profits, but it wasn't a great face for an after-school computer coding program. The second problem was that the blog was really slow to load. It was implemented with a very hacky &lt;a href=&quot;https://www.blogger.com/&quot;&gt;Blogger template&lt;/a&gt;, which also looked pretty unprofessional. For that one, I have to take &lt;a href=&quot;https://www.makeloft.org/&quot;&gt;full responsibility&lt;/a&gt;.
&lt;/p&gt;
&lt;h4&gt;Website update&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-T5rzXljjES0/XJGa9Tz3GBI/AAAAAAAADj8/sTYEihTjRjwyqL62S6rAgsV4VfgVpHy9ACLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.43.16%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The former admins had switched the whole codebase to reside in &lt;a href=&quot;https://pages.github.com/&quot;&gt;Github Pages&lt;/a&gt;, so I could easily make updates and we all could review remotely. Much simpler than the old days of SCPing your code onto a server somewhere.
&lt;/p&gt;
&lt;h6&gt;Jekyll&lt;/h6&gt;
Originally, the admins had been using totally static pages. I could have kept the same, but I've found that whenever there are changes to things in the nav menu, people (including me) inevitably forget to update them across all pages. That makes for an impossible navigation experience as users try to get to places that can only be gotten to from 1 of your pages.

&lt;p&gt;
    Instead, I decided to switch to using a &lt;a href=&quot;https://talk.jekyllrb.com/t/jekyll-theme-showcase-share-your-jekyll-themes/1382&quot;&gt;jekyll template&lt;/a&gt;, which would allow me to make site wide edits in one location. I based it on a template from a company called &lt;a href=&quot;https://cloudcannon.com/&quot;&gt;CloudCannon&lt;/a&gt; that released their template for open reuse with modification.
&lt;/p&gt;
&lt;p&gt;
    I was really happy with the main landing page. It used a lot of images, but also had good space for us to put our mission front and center.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-r0jFvaC6-r4/XJGesiq_z0I/AAAAAAAADkc/ec5uwUML5boZa8QxCwEY-vRgyVsIuWU1wCLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.52.54%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I also added two additional pages that were mostly implemented in the template already. One was a community page that allows us to show how many amazing people work together to make our projects happen. The second was a lightweight CMS for big news in the organization. That was really cool to write up the little blurbs about all the big milestones we'd had over the years.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-kkWs6Wbl7_s/XH39Jlnl6gI/AAAAAAAADfM/KJSlazp3KWApuxdPPHm3CbhIsnQdU8DLACLcBGAs/s800/Screen%2BShot%2B2019-03-04%2Bat%2B8.34.14%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    These were all relatively minor stylistic changes. It took a lot to design the flow of the website and figure out what content to surface, but the engineering challenges were minor. The main technical improvement came on the class signup page.
&lt;/p&gt;
&lt;h6&gt;Class Signup&lt;/h6&gt;
&lt;p&gt;
    The coolest new feature that I built was the ability to signup for classes on the website. On the old site, I'd added a page to add donations using Paypal's built in &lt;a href=&quot;https://www.paypal.com/donate/buttons&quot;&gt;donate button feature&lt;/a&gt;. Then when we needed to pay for classes we just directed them there and had them set the payment amount as their donation. I was pretty ashamed of how hacky that made the organization look.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-YhOAUkfBfqM/XJGaf1G4esI/AAAAAAAADjw/Fi9T3hPK7ZABL-rBzg29Cff3ykJS49IEgCLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.41.59%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;div style=&quot;text-align:center&quot;&gt;That was totally lame.&lt;/div&gt;
&lt;p&gt;
    So for this update, I wanted to make a clean form that allowed people to sign-up before being sent to a legitimate paypal payment page. It was technically very interesting because I had to do all of this without using a true database. So the record keeping had to be done entirely on the frontend with javascript, without any backend code.
&lt;/p&gt;
&lt;p&gt;
    To do this, I actually hijacked Google Forms, using some &lt;a href=&quot;https://blog.webjeda.com/google-form-customize/&quot;&gt;incredibly insightful info&lt;/a&gt; that I found from &lt;a href=&quot;https://twitter.com/webjeda&quot;&gt;webjeda&lt;/a&gt;. Basically, google's forms are just basic webforms, but they try to obfuscate a few fields, making it difficult to just create any customization of style. But if you figure out the real names of the form fields, you can simply make your form submit those fields to Google's backend. It's pretty brilliant.
&lt;/p&gt;
&lt;p&gt;
    The second big hurdle
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-esXp14lfrSE/XH389MIrasI/AAAAAAAADe8/wpH2vTZLjSg4BFssO3W3SM4JCBBnP25xwCLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.35.45%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I described all of our in-class programs in detail. And built CTAs (Calls to Action), that hopefully helped people see what they needed to do. Obviously, a more thoughtful designer to make improvements, but I worked with what I had here.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Hl8aAgIXbRo/XH389AYtqFI/AAAAAAAADe4/JjhKVoLosNAVlkZOdpkW4eh487CuwjzogCLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.35.58%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    But the real mindf**k came when I tried to combine this off-label usage of Google Forms with another off-label usage of Paypal form submission. And to do something that you aren't supposed to be able to do with HTML at all: use the same form fields in multiple form submissions! (The things that get me excited, I tell you.)
&lt;/p&gt;
&lt;p&gt;
    I found &lt;a href=&quot;https://blog.webjeda.com/google-form-customize/&quot;&gt;this writeup&lt;/a&gt; on how to customize Google Forms along with piecing together a few &lt;a href=&quot;https://pressupinc.com/blog/2014/03/easy-hacks-paypal-purchase-buttons/&quot;&gt;examples&lt;/a&gt; of hacking Paypal buttons into forms. Check out &lt;a href=&quot;https://github.com/artificechicago/artificechicago.github.io/blob/master/enroll.html&quot;&gt;the code&lt;/a&gt; for more detail, but basically I overrode the generic form submission to allow the forms to swap info back and forth between submissions.
&lt;/p&gt;
&lt;h6&gt;the gory details&lt;/h6&gt;
&lt;p&gt;
    The only way to make the submit occur from another form is for the submit button on the main form to be hidden, and to have it's label actually function as the button on another form.
&lt;/p&gt;
&lt;p&gt;
    This line hides the submit button on the main (Google) form
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;input type=&quot;submit&quot; id=&quot;submit-form&quot; style=&quot;display:none;&quot; value=&quot;Enroll In Course&quot; /&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Then here, I add the label to the second (Paypal) form with the &lt;bold&gt;for&lt;/bold&gt; keyword referencing it back to the submit button for Google.
&lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;label id=&quot;enroll_button&quot; class=&quot;special_button&quot; for=&quot;submit-form&quot; tabindex=&quot;0&quot;&amp;gt;Enroll In Course&amp;lt;/label&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    Everything in the Paypal form is actually hidden so that form just grabs a bit of info from the other form using javascript jQuery and passes it on (securely) to the Paypal authentication site. The code below is run because the forms submit action is overridden to run a custom function:
&lt;/p&gt;
&lt;pre&gt;onsubmit=&quot;submitPay()&quot;&lt;/pre&gt;
&lt;pre&gt;&lt;br/&gt;function submitPay() {&lt;br/&gt;    $( &quot;#name_paypal&quot; ).val( $( &quot;#name&quot; ).val() );&lt;br/&gt;    $( &quot;#paypal_return&quot; ).val( &quot;http://www.artificechicago.org/enroll/?transaction=&quot; + $( &quot;#secret_paypal&quot; ).val() );&lt;br/&gt;    $( &quot;#paypal_opened&quot; ).val( 'Yes' );&lt;br/&gt;    $( &quot;#enroll_button&quot;).css('background-color','#4182e4');&lt;br/&gt;    $( &quot;#paypal_button&quot;).css('background-color','rgba(120,120,120,.5)');&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
    And after finishing on Paypal the user just returns to submit the Google form and it will include the payment confirmation info automatically.
&lt;/p&gt;
&lt;p&gt;
    I won't explain too much more because this is kind of mildly vulnerable to exploitation (though don't worry not in terms of any payment information leaking*). Basically the paypal and google forms pass some confirmation numbers back and forth so that the &lt;a href=&quot;https://www.linkedin.com/in/clairestedden/&quot;&gt;Treasurer&lt;/a&gt; can confirm the transactions went through in the account.
&lt;/p&gt;
&lt;p&gt;
    Overall, the new main site is much more user friendly and professional.
&lt;/p&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Blog update&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-LUhhb2Fqz7A/XJGbdRNBFDI/AAAAAAAADkE/aLNdA8uTEo4GZ4BhITRuSUO2ymNCuNJggCLcBGAs/s1600/Screen%2BShot%2B2019-03-19%2Bat%2B6.46.01%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The blog update was less interesting because it was similar to things I had done before. I simply nabbed a free-to-use template from &lt;a href=&quot;https://www.templateism.com/&quot;&gt;Templateism&lt;/a&gt;, and started making my own tweaks.
&lt;/p&gt;
&lt;p&gt;
    I did spend a good bit of time trying to think of the best way to make the info on the website explorable too though. I made a few easily navigable landing pages that helped to highlight some of our favorite work over the years.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-5RP-DKocMJI/XH34I1W9gyI/AAAAAAAADeg/8aLXnx2FmJITShtoQjPvMLj0PQ46cvXDACLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.14.41%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-LMzxEcaM_zA/XH34I7cyObI/AAAAAAAADec/rW65up6ItlsV8XPL_iWeCylqC3nc8nQ-ACLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.15.14%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-VBPJ9qI3Srg/XH34I5L77xI/AAAAAAAADek/8cwgPG48df4o7smM0WTKf_PTI9TxzjtDQCLcBGAs/s1600/Screen%2BShot%2B2019-03-04%2Bat%2B8.15.47%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I tried making the content more highly visible, and I think it paid off. Hopefully, the website helps to add some credibility to the organizations coding expertise and brings them more volunteers and students in the future.
&lt;/p&gt;
&lt;p&gt;
    * The vulnerability is that someone could figure out how to pass a boolean that says that the payment is confirmed even though it isn't. Still, part of @rtifice's ethos is that if you can figure out how to hack our systems you actuallyf deserve whatever tiny spoils you get.
&lt;/p&gt;</description>
        <pubDate>Sun, 02 Dec 2018 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2018/12/rtifice-website-revamp/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/12/rtifice-website-revamp/</guid>
        
        <category>design</category>
        
        <category>code</category>
        
        <category>infra</category>
        
        
      </item>
    
      <item>
        <title>Experiential Puzzle Narrative</title>
        <description>&lt;p&gt;
        I recently completed a long-time dream of building my own experiential puzzle narrative, also known as an &lt;a href=&quot;https://en.wikipedia.org/wiki/Escape_room&quot;&gt;escape room&lt;/a&gt;. I ran it as an engineering social (not &lt;a href=&quot;https://en.wikipedia.org/wiki/Social_engineering_(security)&quot;&gt;this&lt;/a&gt;) at my current place of employment, &lt;a href=&quot;https://www.color.com&quot;&gt;Color&lt;/a&gt;. Below is some documentation on both the narrative and the mechanics that went into building the puzzles.
    &lt;/p&gt;
&lt;h4&gt;Be forewarned. Herein lieth a plethora of philosophical musings on storytelling and the nature of existence. Also spoilers.&lt;/h4&gt;
&lt;h3&gt;A Narrative&lt;/h3&gt;
&lt;p&gt;
        In actuality, the story that tied the game together came at the very end of production. But for the meta-narrative purposes of an expository blog post, I'm going to explain the game elements as they played out.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/--X_zBA-USyU/W7keM7mqe7I/AAAAAAAAC5g/Z8a5HYeLztsEkkUp30iw8KbsANi2Ki01gCLcBGAs/s1600/Westworld10HopkinsBeach.0.jpeg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The main delivery for the game mechanics was the tool &lt;a href=&quot;https://medium.com/@frank_meehan/slack-just-significantly-changed-their-home-page-b226769667bd&quot;&gt;&quot;Where work happens&quot;&lt;/a&gt;, Slack (yeah, right). I built a very simple &lt;a href=&quot;https://github.com/lots-of-things/the-game/blob/master/lurker.py&quot;&gt;message bot&lt;/a&gt; using &lt;a href=&quot;https://twitter.com/kn&quot;&gt;Katsuya Noguchi's&lt;/a&gt; &lt;a href=&quot;https://github.com/kn/slack&quot;&gt;slack API python wrapper&lt;/a&gt; to deliver a series of timed messages.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-1Y9g3rlF_TE/W7Ll_ayDPYI/AAAAAAAAC1A/21jcDci-I4U7k0ljCnfsW7mPYBgd1ZhwACLcBGAs/s800/Screen%2BShot%2B2018-10-01%2Bat%2B8.28.36%2BPM.png&quot; title=&quot;code found here &quot;/&gt;
&lt;p&gt;
        The game started by spitting out an urgent message sent by a mysterious DrF...
    &lt;/p&gt;
&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/PQ-r1U3Jvsw&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt; &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Consumer Rereation Services&lt;/h4&gt;
&lt;p&gt;
        In the story, a mysterious Dr F is warning our protagonist engineering team about an autonomous AI, named CRS, that has gone out of the creators control. This is the first cultural reference I embedded. CRS is the abbreviation of Consumer Recreation Services from the 90's David Fincher film, &lt;a href=&quot;http://screencrush.com/the-game-20th-anniversary/&quot;&gt;The Game&lt;/a&gt;a fun little mindf*** for my 12 year old brain and a serious inspiration to me both in terms of this escape room and the general game of life that I frequently assume I am playing. Even though it's been mostly forgotten, it still sits right there next to &lt;a href=&quot;https://www.newsweek.com/2018/06/15/truman-show-jim-carrey-reality-show-delusion-960250.html&quot;&gt;The Truman Show&lt;/a&gt; and &lt;a href=&quot;https://geekprank.com/matrix-code-rain/&quot;&gt;The Matrix&lt;/a&gt; for keeping me looking over my existential shoulder. Interestingly, all three films start with &quot;The&quot; by coincidence (hmm?).
    &lt;/p&gt;
&lt;p&gt;
        Dr F alerts the team that her AI has left a note referencing a &quot;start sequence&quot; that Dr F just can't figure out.
    &lt;/p&gt;
&lt;h5&gt;GCCACC___G&lt;/h5&gt;
&lt;p&gt;
        Recognizable to the biologist or anyone with Google as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kozak_consensus_sequence&quot;&gt;Kozak consensus sequence&lt;/a&gt;, completed with an ATG. The first puzzle lead from main staging area to the smaller rooms each named after the nucleic acids Adenine, Thymine, and Guanine.
    &lt;/p&gt;
&lt;p&gt;
        Importantly, I specifically wanted this challenge to involve as much Google as the players wanted to use. I think that's crucial to making a game much more immersive. Phones are now extensions of our consienciousness so why cut someone off artificially during the game. What's more, it forces you to build something novel so no one can just google the answer directly. Finally, it embeds the puzzle inside of the whole universe, rather than cutting it off to just the silly arbitrary toys in the room around the players. Much preferable for my liking.
    &lt;/p&gt;
&lt;h4&gt;Haystack&lt;/h4&gt;
&lt;p&gt;
        After a basic misdirect for the password (&quot;the answer's right under your nose&quot;), I built a very software developer centric puzzle for the next challenge using just a computer &lt;a href=&quot;http://ask.xmodulo.com/boot-into-command-line-ubuntu-debian.html&quot;&gt;booted into command line&lt;/a&gt; to keep the mechanics simple and to the point. A full user interface might have made it easier to get lost on dead ends. Also, using the terminal makes for a great &quot;hacking the matrix&quot; vibe.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-rO97AzW6DQY/W7b3cMVWJDI/AAAAAAAAC3c/MxhVRP9VTj8kQdHi-PIhceD7Fkq-SZQhgCLcBGAs/s1600/Screen%2BShot%2B2018-10-04%2Bat%2B10.32.10%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The mechanic involves a single file on a computer. The file contains the names of hundreds of books. The only hint is the message &lt;em&gt;check the diff&lt;/em&gt;. This is a hint to the computer savvy that this file has had its changes tracked with a tool called git, allowing you to see each change recorded using the command
    &lt;/p&gt;
&lt;pre&gt;git diff &amp;lt;sha&amp;gt;&lt;/pre&gt;
&lt;p&gt;
        where &amp;lt;sha&amp;gt; refers to a long string of characters (e.g. 9427ce9792636fba8ddc9488dcf484e6afac982f) that refers to a unique change. Using a two way video chat between two rooms and a transparency revealed the location of the &quot;needle&quot; for this haystack. The diff between the &lt;em&gt;HEAD&lt;/em&gt; and the needle, suggested the book titled &lt;strong&gt;The Man in The High Castle&lt;/strong&gt; would lead to the next puzzle.
    &lt;/p&gt;
&lt;h4&gt;Multi-threaded&lt;/h4&gt;
&lt;p&gt;
        Simultaneous with the previous puzzle in another room, another subset of participants were discovering this puzzle box. Inside, there were allusions to a mysterious AH as well as the transparency needed for finding the needle, required in the other room.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-UO-Rea8CSZA/W7b6lcj7C4I/AAAAAAAAC3o/gP8GRAh9YuI4ECfATny3pL7f56ncjj6LACKgBGAs/s1600/20181002_221946.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In a third room, another group was discovering a seemingly unrelated set of three mathematical puzzles.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-FUsZV8AP5cA/W7kgbVTMvfI/AAAAAAAAC5s/Lpc6lifHmIEXM8CATyq4ztdv4SqshnAMACKgBGAs/s800/20180929_113755.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The parallelization was necessary due to the large number of participants in this game, but also served another purpose which surprised me. Since each individual had to discover non-overlapping information, the game could only proceed with significant communication. Also, in the post-game recapitulation, there was way more opportunity for cross-communication of sub-puzzles that weren't visible to everyone the entire time.
    &lt;/p&gt;
&lt;h4&gt;Surprise Guest Star&lt;/h4&gt;
&lt;p&gt;
        As a device to enable Slack based triggering of the plot resolution, I needed to work into the narrative an excuse for communicating with a third party over Slack. To do so without incurring the assumption of a real person on the other end, I expanded my cast of sentient robots. As a scientific laboratory we have a fair share of real robots carrying out various tasks around the company. One of our more charismatic bots happens to be named Alexander Hamilton.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-zhxe13a8MWU/W7b0_soEYXI/AAAAAAAAC3Q/Aw6ASCkf_VAmmpXicO1tJzfOiZ5RDM31ACLcBGAs/s1600/Screen%2BShot%2B2018-10-04%2Bat%2B10.21.27%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Having established the mechanism for game completion early, the participants now had to navigate the remaining clues.
    &lt;/p&gt;
&lt;h3&gt;Recursion&lt;/h3&gt;
&lt;p&gt;
        Inside the book they found a pair of sheets that led to the next puzzle. Also inside the book were numerous references to the I Ching. The I Ching (sometimes called just the Oracle) is an ancient Chinese text, used to perform some divination in conjunction with some random element (tossed sticks or coins).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-qjzFVu1H_z0/W7b78O1DCyI/AAAAAAAAC38/FtxkciYC3lUsd3z1g4sCPwSslxcZCyErACKgBGAs/s800/20180929_113948.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I find the The Man in the High Castle to be pretty brilliant at one of my favorite things in all of fiction: &lt;a href=&quot;https://en.wikipedia.org/wiki/Metafiction&quot;&gt;metafiction&lt;/a&gt;. I'll try to summarize succinctly. In the novel, Dick describes a parallel universe where Japan and Germany won WWII. Also in the novel, a man (living in Japan controlled Colorado) writes a novel about a parallel universe where the Allied Powers won WWII. In the novel, it is revealed that the author composed the narrative using the I Ching as his guide. In &quot;real&quot; life, PK Dick also utilized the I Ching to guide his own narrative decisions.
    &lt;/p&gt;
&lt;h5&gt;Spoilers...&lt;/h5&gt;
    Now I spoil the ending: the author learns from the I Ching that the story he wrote is actually the truth. By my reading, we can see the I Ching functioning accurately throughout the novel. I believe (not crazy: I found &lt;a href=&quot;https://blog.brian-fitzgerald.net/blog/2015/10/24/meta-fiction-story-and-philip-k-dicks-man-in-the-high-castle/&quot;&gt;others&lt;/a&gt;) we are supposed to interpret the I Ching as a revelatory voice of a true author (maybe Dick) transmitting to the characters in this story. Depending on your perspective on the nature of reality, one might conclude that the I Ching in our universe would then be a voice from the author of our universe. Of course, if the author from another universe were transmitting to the author in our universe what happened in his own universe, which looks a little more like that in the book, well, that would then introduce a lovely recursive &lt;a href=&quot;http://www.crystalinks.com/ouroboros.html&quot;&gt;Ouroboros&lt;/a&gt;.
    
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-EgDqHosxmCk/W7cEjhYfoZI/AAAAAAAAC4U/B1BbGiyZhuYjMRg9jm8Pk4CqL3oqSmABACLcBGAs/s1600/birthday_card_by_paivatar-d68r562.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Also, I actually stumbled upon adding I Ching references to my narrative by accident with a later puzzle. That inclusion led me to the Man in the High Castle through a &lt;a href=&quot;https://thoughtcatalog.com/christine-stockton/2014/01/the-10-best-wikipedia-black-holes-for-curious-people-who-have-no-impulse-control/&quot;&gt;wikipedia black hole&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The slip of paper inside the book pointed to a sequence of numbers underneath the engineering teams' desks forming a 3 by 3 grid of numbers. A previous clue had led to an Android phone that could be unlocked by swiping the lock screen in the order of this pattern.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-yCVkHK8eiXs/W7cCH2sqY9I/AAAAAAAAC4I/E28VHilz-cYA2Mokyeg3jlB0tVOOxi1EQCLcBGAs/s1600/android_p_dp1_pattern.gif&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h3&gt;CAGE&lt;/h3&gt;
&lt;p&gt;
        On the phone, there are three icons. The first is a &lt;a href=&quot;https://github.com/lots-of-things/the-game/tree/master/cage_lock/ComboLock&quot;&gt;custom combo lock app&lt;/a&gt; that shows three tumblers. The other two icons are audio files. The first, titled &lt;a href=&quot;https://raw.githubusercontent.com/lots-of-things/the-game/master/cage_lock/John.mp3&quot;&gt;John.mp3&lt;/a&gt;, is 4 pure musical tones. The second, titled &lt;a href=&quot;https://raw.githubusercontent.com/lots-of-things/the-game/master/cage_lock/hint.mp3&quot;&gt;hint.mp3&lt;/a&gt;, consisted of 4'33&quot; of silence.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-z7FT9qviLCQ/W7cJcwDdTjI/AAAAAAAAC4g/Q_kBafqilrYzC1NWNTSfIvj3oBQ22-nXwCLcBGAs/s800/718fd0a08a06836728b3d512e31bf31e.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The solution to the combo was 4-3-3, a reference to John Cage's &lt;a href=&quot;https://www.npr.org/2000/05/08/1073885/4-33&quot;&gt;famous piece of silence&lt;/a&gt;. Interestingly, the desire for a musical clue was what spawned this puzzle and the subsequent discovery of the I Ching (and it's culminating puzzle). The choice of CAGE as the solution came about because I was trying to generate a topical solution that used the letters A through G. The connection between an escape room and the word &quot;cage&quot; is obvious, but I was pleasantly struck by the parallel strand connecting John Cage and the entire idea of &lt;a href=&quot;https://www.theartstory.org/movement-happenings.htm&quot;&gt;experiential artwork&lt;/a&gt;. Cage's &quot;happenings&quot; focused on removing artist control by forcing involvement by an unpredictable audience. This is, of course, the beauty of any experiential narrativeeven the campy robot infused ones.
    &lt;/p&gt;
&lt;p&gt;
        It was this &lt;a href=&quot;https://en.wikipedia.org/wiki/Music_of_Changes&quot;&gt;wikipedia tryst with Cage&lt;/a&gt; that led me to the I Ching and later the High Castle. The solution to the puzzle drops the first big hint about the usage of the I Ching for the final stage of the puzzle.
    &lt;/p&gt;
&lt;pre&gt;John Cage was noted for his development of 'happenings' or experiential artwork. &lt;br/&gt;In addition to increasing audience participation, his work frequently relied on chance to determine the outcome.  &lt;br/&gt;He heavily utilized the hexagrams of King Wen's I Ching in his compositions.&lt;/pre&gt;
&lt;p&gt;
        I took a bit of inspiration from this turn of events:
    &lt;/p&gt;
&lt;h4&gt;After this point, all the puzzles I wrote were generated through a randomization process.&lt;/h4&gt;
&lt;br/&gt;&lt;br/&gt;
&lt;h3&gt;The Arousing Thunder&lt;/h3&gt;
&lt;p&gt;
        The mathematical puzzles allowed access to the last clue. A sheet of letters and numbers in a 10 by 14 grid.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-haoSofL-rDk/W7cO3Y7HfbI/AAAAAAAAC4s/bijOSSQpJd0LF2oNyNdASNfBafhiItrLgCKgBGAs/s1600/20180929_113845.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This grid could be combined with a color coded abacus that sits in our office to uncover a four character sequence of characters on each line.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-Wp_VYFzCUhs/W7khguV1hVI/AAAAAAAAC54/I1nkxYOsU9kL8FE19zSyvHcdlhJILrc5ACKgBGAs/s800/20180928_162616.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        A hint from Alexander Hamilton mentioned Unicode characters, which the software developers understood as being composed of 4 character hexadecimal codes like the ones they were looking at.
    &lt;/p&gt;
&lt;p&gt;
        At around this time, CRS made her appearance. As it turns out, &lt;a href=&quot;https://knowyourmeme.com/memes/the-cake-is-a-lie&quot;&gt;DR F was a lie&lt;/a&gt;.
    &lt;/p&gt;
&lt;iframe allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/WCe7KT1kq2M&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;
        The I Ching and a random number generator helped me write this quite interesting poem.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-_KHNp0ViTyI/W7cPZAsoEpI/AAAAAAAAC40/1ouSgSY6Rf0RJoky1IKeZK9xcXqtBxxKQCLcBGAs/s1600/poem.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I won't reveal anymore except to say that the team discovered what CRS was missing. You can click this link to hear the finale audio.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;a href=&quot;https://raw.githubusercontent.com/lots-of-things/the-game/master/end.mp3&quot; style=&quot;font-family:'PT Sans';font-size:2em;background:#CCC;padding:10px;border-radius:10px&quot;&gt;Click for Finale Audio&lt;/a&gt;&lt;/div&gt;
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt; &lt;a href=&quot;https://tvtropes.org/pmwiki/pmwiki.php/Main/Denouement&quot;&gt;dnouement&lt;/a&gt; &lt;/h4&gt;
&lt;p&gt;
        Endings are hard. I felt let down by this one. I wish the game could continue. Maybe it does?
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-peQESzYxHWY/W7kh5xEJ6qI/AAAAAAAAC6A/vuS83Tp098UvpZz8vfQv6alm7wwKGWUygCKgBGAs/s1600/20180928_161306.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h3&gt;Puzzle Elements&lt;/h3&gt;
&lt;p&gt;
        Below are some notes on building a couple of the game elements.
    &lt;/p&gt;
&lt;h5&gt;Building Audio &amp;amp; Video Assets&lt;/h5&gt;
&lt;p&gt;
        The part of the production that really put this whole deal over the top was adding some movies to tie the narrative elements together. The audio was just a generic text to speech generator. I experimented with several until discovering the &quot;Emma&quot; voice on &lt;a href=&quot;http://www.fromtexttospeech.com/&quot;&gt;fromtexttospeech.com&lt;/a&gt;. It was understandable and wonderfully creepy. I layered this in on top of some &lt;a href=&quot;https://www.videezy.com/elements-and-effects/242-tv-static-hd-stock-video&quot;&gt;generic static&lt;/a&gt; that got even weirder when I compressed and downsampled it.
    &lt;/p&gt;
&lt;p&gt;
        for reference, I used the following ffmpeg functions to build the assets/
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://video.stackexchange.com/questions/12905/repeat-loop-input-video-with-ffmpeg&quot;&gt;loop input video static video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/11779490/how-to-add-a-new-audio-not-mixing-into-a-video-using-ffmpeg&quot;&gt;mix mp3 audio over video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://video.stackexchange.com/questions/12105/add-an-image-overlay-in-front-of-video-using-ffmpeg&quot;&gt;add image overlay to video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;Combo Lock App&lt;/h5&gt;
&lt;p&gt;
        I also built the combo lock app from scratch since I couldn't find anything that quite fit my needs. I used Android Studio, which I'd only used once before. The following links have all the info needed.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://developer.android.com/training/basics/firstapp/creating-project&quot;&gt;Start a project&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/33053765/how-to-make-a-wheel-picker&quot;&gt;Wheel Picker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.zoftino.com/android-number-picker-tutorial&quot;&gt;More Number Picker Info&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://android--examples.blogspot.com/2015/05/how-to-use-numberpicker-in-android.html&quot;&gt;Add text on change&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://developer.android.com/reference/android/widget/NumberPicker#NumberPicker(android.content.Context)&quot;&gt;NumberPicker Object&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt; &lt;br/&gt;
</description>
        <pubDate>Sat, 06 Oct 2018 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2018/10/experiential-puzzle-narrative/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/10/experiential-puzzle-narrative/</guid>
        
        <category>games</category>
        
        <category>code</category>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <title>Introducing Ioni</title>
        <description>&lt;p&gt;
    I recently purchased a beautiful Dolphin 24 sailboat. The boat was manufactured in 1968 and has a &lt;a href=&quot;http://www.dolphin24.org/san_jose_dolphin.html&quot;&gt;great history&lt;/a&gt; compiled by Ron at &lt;a href=&quot;http://www.dolphin24.org/&quot;&gt;dolphin24.org&lt;/a&gt;. I'm honored to be a part of her story, and I hope to take great care of her over the next few years.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-GjSpEzzqqlw/Wy6pybYkEBI/AAAAAAAACPA/tRxkLdkX4PcXN34Xgjo2J9GxAjNMgWZJQCKgBGAs/s1600/IMG_20180606_075423.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    She came without a name so I plan to call her &lt;a href=&quot;http://greekmythology.wikia.com/wiki/Ione&quot;&gt;Ioni&lt;/a&gt;, after a Graecian &lt;a href=&quot;http://www.theoi.com/Pontios/Nereides.html&quot;&gt;sea nymph&lt;/a&gt; known for riding a dolphin, and the &lt;a href=&quot;https://en.wikipedia.org/wiki/Ionians&quot;&gt;Ionian people&lt;/a&gt;seafaring nation in the ancient Aegean, credited with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Ionian_Enlightenment&quot;&gt;founding of science&lt;/a&gt;. It also is a reference to the origin of the word &lt;a href=&quot;https://en.wikipedia.org/wiki/Ion&quot;&gt;ion&lt;/a&gt;. Claire came up with the idea to use a particle as a nod to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Wave%E2%80%93particle_duality&quot;&gt;wave-particle duality&lt;/a&gt;, which seems pretty appropriate for a sailboat.
&lt;/p&gt;
&lt;h4&gt;Rigged and Ready&lt;/h4&gt;
&lt;p&gt;
    The boat was in decent condition for sailing when I bought it, though it does need a bit of maintenance. Most of the issues are cosmetic though fortunately.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-C9qgUOJXJJM/Wy6snlZXlLI/AAAAAAAACPc/jDZgcjc61lAGFSkN7raveBWt7pDC2CwAACKgBGAs/s1600/IMG_20180511_191827.jpg&quot; title=&quot;
Sails rigged
     
Sails rigged
    &quot;/&gt;
&lt;div&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-sZ-oZ5uLKBs/Wy6snl321fI/AAAAAAAACPc/RhjwV4e38wACQTyHels0qsxWREwjwL1twCKgBGAs/s1600/IMG_20180511_184103.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://4.bp.blogspot.com/-sZ-oZ5uLKBs/Wy6snl321fI/AAAAAAAACPc/RhjwV4e38wACQTyHels0qsxWREwjwL1twCKgBGAs/s200/IMG_20180511_184103.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-kc-sNOPsuvw/Wy6snvpdQ8I/AAAAAAAACPc/aIUYw1WEjjoWdHesaFgwfZi5BDuSLZf0QCKgBGAs/s1600/IMG_20180511_184045.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://3.bp.blogspot.com/-kc-sNOPsuvw/Wy6snvpdQ8I/AAAAAAAACPc/aIUYw1WEjjoWdHesaFgwfZi5BDuSLZf0QCKgBGAs/s200/IMG_20180511_184045.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-KK_I-uTrtsI/Wy6snvdGRaI/AAAAAAAACPc/Xco0bb6aeK46KlXlqrHt1dPu7reVeJWrQCKgBGAs/s1600/IMG_20180511_184023.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://2.bp.blogspot.com/-KK_I-uTrtsI/Wy6snvdGRaI/AAAAAAAACPc/Xco0bb6aeK46KlXlqrHt1dPu7reVeJWrQCKgBGAs/s200/IMG_20180511_184023.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-Jbfcbjp3RDA/Wy6snnsXgjI/AAAAAAAACPc/j9-RCoRLjAc6q1Irrc_sHXFdqyFGPJkPwCKgBGAs/s1600/IMG_20180511_184014.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://2.bp.blogspot.com/-Jbfcbjp3RDA/Wy6snnsXgjI/AAAAAAAACPc/j9-RCoRLjAc6q1Irrc_sHXFdqyFGPJkPwCKgBGAs/s200/IMG_20180511_184014.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-tqC-_Jm5eKs/Wy6snlmLKSI/AAAAAAAACPc/Cuy2pOcuI98SaIsZmS9BCaneI6kvp_qmACKgBGAs/s1600/IMG_20180511_183905.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://2.bp.blogspot.com/-tqC-_Jm5eKs/Wy6snlmLKSI/AAAAAAAACPc/Cuy2pOcuI98SaIsZmS9BCaneI6kvp_qmACKgBGAs/s200/IMG_20180511_183905.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-yymqkc-AsIs/Wy6sni5Z6oI/AAAAAAAACPc/p9PS7eaPRJoe8tzWNaIckC7XQ1ZuIkbtgCKgBGAs/s1600/IMG_20180511_183837.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1600&quot; data-original-width=&quot;1200&quot; height=&quot;200&quot; src=&quot;https://4.bp.blogspot.com/-yymqkc-AsIs/Wy6sni5Z6oI/AAAAAAAACPc/p9PS7eaPRJoe8tzWNaIckC7XQ1ZuIkbtgCKgBGAs/s200/IMG_20180511_183837.jpg&quot; width=&quot;150&quot;/&gt;&lt;/a&gt;&lt;br/&gt;Topside hardware, some needs a little TLC&lt;/div&gt;
&lt;br/&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-OLXSWLIcvuc/Wy6snrVD8CI/AAAAAAAACPc/9MDJPZdnxgYUdtA-bbHIgx2bFaYbvuYNwCKgBGAs/s1600/IMG_20180512_134531.jpg&quot; imageanchor=&quot;1&quot; style=&quot;margin-left: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;1200&quot; data-original-width=&quot;1600&quot; height=&quot;150&quot; src=&quot;https://2.bp.blogspot.com/-OLXSWLIcvuc/Wy6snrVD8CI/AAAAAAAACPc/9MDJPZdnxgYUdtA-bbHIgx2bFaYbvuYNwCKgBGAs/s200/IMG_20180512_134531.jpg&quot; width=&quot;200&quot;/&gt;&lt;/a&gt;&lt;br/&gt;Interior, without paneling between cabin and under-cockpit
&lt;p&gt;
    A little messy, but I can take care of that.
&lt;/p&gt;
&lt;h4&gt;The Big Worry&lt;/h4&gt;
&lt;p&gt;
    Supposedly, 50% of boats sink because of &lt;a href=&quot;https://www.boats.com/reviews/five-common-mistakes-that-might-sink-your-boat/#.Wy6oDRJKgWo&quot;&gt;failure to repair equipment&lt;/a&gt; below the waterline. For me, the big fear comes from my old &lt;a href=&quot;https://en.wikipedia.org/wiki/Seacock&quot;&gt;seacocks&lt;/a&gt;.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-Jq6yoUtHODw/Wy6o_hktxVI/AAAAAAAACO4/y71tUGlACiEStygHeoJp52cLFesho3zHACKgBGAs/s800/IMG_20180522_180114.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-WBsFAz0qyOQ/Wy6o_rNR3qI/AAAAAAAACO4/EoE82C6743E1NECYM0FsOEJFMvavgyGtACKgBGAs/s1600/IMG_20180606_075534.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    As you can see they have significant corrosion. I plan to replace these soon, but it's quite difficult since removal has to take place when the boat is out of the water. I'll assess them more carefully during my first bottom paint job later this summer. I don't want to turn the handle now because I've read horror stories of corroded seacocks crumbling apart during their test.
&lt;/p&gt;
&lt;h4&gt;Bilge Pump Electrical&lt;/h4&gt;
&lt;p&gt;
    As a backup plan, in the event that one of those seacocks starts to leak, I want to make sure that the bilge pump will be able to run to keep the boat from filling. I'll link to that in an upcoming post.
&lt;/p&gt;
&lt;h4&gt;Cleanup and Repaneling&lt;/h4&gt;
&lt;p&gt;
    In the short term, I just needed to get the boat slightly more livable since I will be staying on her a few nights per week to commute to work.
&lt;/p&gt;
&lt;p&gt;
    The first step was to clean up. This mostly consisted of removing the gas tanks from the interior of the boat and cleaning up a few spots, particularly the head.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-3Y3V0gJPTXI/Wy6v14ydNYI/AAAAAAAACQE/3SQWfSKJG489u5uB4I7xibNxPoNRFXbewCKgBGAs/s1600/IMG_20180511_180707.jpg&quot; title=&quot;Gas tanks inside the boat = unhealthy fumes everywhere &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-tH8u6mHZsok/Wy6v1yKbXlI/AAAAAAAACQE/JOmBnvlG9-EgORKnq0XOfaSO6XPxvzJaACKgBGAs/s1600/IMG_20180511_180653.jpg&quot; title=&quot;Before, after  &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-YeVPG8UCUGY/Wy6v1ybsQJI/AAAAAAAACQE/9a1iMpvlcb4u8ro0_XtFOn8lRFvNKaz-wCKgBGAs/s800/IMG_20180516_073633.jpg&quot; title=&quot;Much nicer once the paneling separated the bilge &quot;/&gt;
&lt;p&gt;
    I also had to add back some panels that had been removed and stored under the bilge. The wood was a bit spotty so I repaired with wood glue and bits of wood.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-s20E-zAzpeE/Wy6y31N9P0I/AAAAAAAACQw/zDrm-LxwYTkJUw_nJCsNzGCmitGn8OEbgCKgBGAs/s1600/IMG_20180518_070230.jpg&quot; title=&quot;wood glue and sticks &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-aU4MHjgAGLg/Wy6y36refQI/AAAAAAAACQw/SQJmZVNZ0mwTiuhAF5v3Jp6AwWHwMWKAwCKgBGAs/s1600/IMG_20180518_071305.jpg&quot; title=&quot;fill the hole so the screw has something to grab &quot;/&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-3UGWu-j5HIU/Wy6y3z0su8I/AAAAAAAACQw/kKRZApFV0xMMc0CFPGCtIUsoZGWdWKYbQCKgBGAs/s1600/IMG_20180518_182459.jpg&quot; title=&quot;Panels added &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Next Steps&lt;/h4&gt;
&lt;p&gt;
    There are still tons of things to do. The next big project will be a haul out and repaint of the bottom with biocidal paint. At that time, I'll assess the seacock situation and any issues with the exterior of the hull. After that, I need to attach new pulleys to the boom for the outhaul. After that, I'll reconnect the electrical for the mast lights and radio. I also suspect that I'll need to caulk some parts of the topside of the boat and woodwork. Eventually, I'd like to get some system so I can keep the sails on the outside of the boat (just so I have more room inside). The last thing to do is rehab the wood on the interior and exterior before it deteriorates too much. Probably around the end of the year, I'll need some new lines too.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Q_QKPbzZXIE/Wy6zt-ZckRI/AAAAAAAACQ8/XZNdTeCqcfs5MadGMe0PlDfCkskJZVQWwCKgBGAs/s800/IMG_20180516_073633.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    It does already start to feel like home though. There's a lot of work to do, but I'm excited (and terrified) for it.
&lt;/p&gt;</description>
        <pubDate>Wed, 27 Jun 2018 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2018/06/introducing-ione/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/06/introducing-ione/</guid>
        
        <category>boatwork</category>
        
        
      </item>
    
      <item>
        <title>Skylight Chapters 3 &amp;amp; 4</title>
        <description>&lt;p&gt;
    Another two chapters from my novel. &lt;a href=&quot;/2018/05/03/skylight-chapters-1-2/&quot;&gt;Click here&lt;/a&gt; to read the first two chapters.
&lt;/p&gt;
&lt;hr/&gt;
&lt;iframe height=&quot;800px&quot; src=&quot;https://docs.google.com/document/d/e/2PACX-1vTjfVtSDoVCI9APvUq9YxmvZLjw0fvqRRALRq7euEvZ-0O9p7pMa9g4r_TYFDGchfRJ1kP2FUWe8822/pub?embedded=true&quot; style=&quot;border:1px solid black; height: 800px&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt;</description>
        <pubDate>Sat, 23 Jun 2018 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2018/06/skylight-chapters-3-4/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/06/skylight-chapters-3-4/</guid>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <title>Skylight Chapters 1 &amp;amp; 2</title>
        <description>&lt;p&gt;
    I've been working on a novel for what feels like a really long time. I usually don't like to let projects drag on like this so I'm gonna start releasing bits to keep me moving. I feel pretty solid about the first two chapters so here they are for public consumption. Enjoy...
&lt;/p&gt;
&lt;div&gt;&lt;iframe height=&quot;800px&quot; src=&quot;https://docs.google.com/document/d/e/2PACX-1vQ29U0iqCXJu16Jk6tiXmknr-r_UDYnZ3DtAFsli0txTrWRd7Q6nSKtAafYakpiNgup3VSrG_Wi_YwD/pub?embedded=true&quot; style=&quot;border:1px solid black; height: 800px&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;</description>
        <pubDate>Thu, 03 May 2018 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2018/05/skylight-chapters-1-2/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/05/skylight-chapters-1-2/</guid>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <title>Notes on Bike Fixes</title>
        <description>&lt;p&gt;
    I've been hanging out at &lt;a href=&quot;http://bikekitchen.org/&quot;&gt;Bike Kitchen&lt;/a&gt; in SF for the past couple of weeks. I previously wrote a little something about &lt;a href=&quot;http://www.makeloft.org/2018/04/replacing-bottom-bracket.html&quot;&gt;replacing a bottom bracket&lt;/a&gt;. Below are my notes on a few more key fixes.
&lt;/p&gt;
&lt;h4&gt;Front Derailleur&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-N3ch0I3qkfg/Wtz6ifN8unI/AAAAAAAABnU/7Jl9v7-1H8EJBhFBBvsVV-Yh9a2_d6gYQCKgBGAs/s800/IMG_20180418_194303.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    With the new derailleur, you first need to get it in the right place on the tube. You want it lined up with only a few millimeters of clearance above the largest gear. The derailleur I used had the shifter line wrap around from the underside. It fastened at just one spot despite the oddly shaped nut.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-gPFQupgvkeA/Wtz6iSrdhrI/AAAAAAAABnU/4L0gfZ0D1RUMK7SCMMl8ozM_zxhxIanEACKgBGAs/s800/IMG_20180418_194514.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Afterward it was attached I just had to align the derailleur as normal.
&lt;/p&gt;
&lt;h4&gt;Chain Replacement&lt;/h4&gt;
&lt;p&gt;
    My chain had been jumping hard for a while, so this was the next most important change needed. I was pretty sure the chain was shot, but the way to check for sure is to use a &lt;a href=&quot;https://www.parktool.com/blog/repair-help/when-to-replace-a-chain-on-a-bicycle#article-section-1&quot;&gt;CC-32 chain checker&lt;/a&gt;, or a ruler. Since the chain checker passed through on 0.75, I needed to replace.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-F_1UO_-uaEA/Wtz6vafTVbI/AAAAAAAABnY/r_KXHHnzImMTbUUafmqWqx8rvWHt3xETgCKgBGAs/s1600/IMG_20180418_201057.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I honestly had never though about how chains get on and off of bikes. It didn't really even occur to me that they had to be taken apart. Getting it off requires a specialized tool, aptly called a chain remover, but isn't that difficult once you have it. You line the tip of the remover up with the pin in the middle of one of the links and turn the handle. The pin remover applies pressure and the pin starts to slide.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-9-WgX_Z6LCs/Wtz6vSsnYLI/AAAAAAAABnY/tdj5l9C3WvES7Y4nsW7TyJ0eoyt4K7TagCKgBGAs/s800/IMG_20180418_195611.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Keep in mind that it's incredibly important not to let the pin come all the way out on a part of the chain you really want to keep. Once the pin is all the way out it's very hard to get back in, and you normally end up needing to remove that link entirely and starting on the next one.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-H0tQc3ykE5s/Wtz_bM3eaEI/AAAAAAAABn0/57G7puBd0HII7J4pOiu3i6rp81dmpkYdQCKgBGAs/s800/IMG_20180418_195838.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    You need to put the new one back together on the bike because it has to thread through the frame and derailleurs.
&lt;/p&gt;
&lt;h4&gt;Hub Overhaul: Cup and Cone&lt;/h4&gt;
&lt;p&gt;
    The most interesting and satisfying fix came from a relatively minor problem. The hub of my back wheel had a little more play than it should have . To fix this I needed to perform a hub adjustment (aka cone adjustment), but since I was taking the hub apart anyway, I decided to do a full &lt;a href=&quot;https://www.parktool.com/blog/repair-help/hub-overhaul-and-adjustment#article-section-4&quot;&gt;overhaul&lt;/a&gt; at the same time.
&lt;/p&gt;
&lt;p&gt;
    I started by popping the nuts on one side of the hub off. I took them off of the side with the gearset, but either works as long as you only take off one. Inside you can see the bearings along with some filthy grease.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-_NM8KWKyLls/Wtz6-Bj6K7I/AAAAAAAABnc/DwWeuhrrm2UoYsnP9jqpFjSF6Vxgk3qQACKgBGAs/s1600/IMG_20180421_121652.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I cleaned the bearings and cup and cones from both sides, making sure to replace any bearings that had significant wear. Basically bearings with any obvious dent in the surface got switched out.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-PkiDuSXxuOs/Wtz6-N8GLWI/AAAAAAAABnc/7xmD2KrrU2UvQG2iF16YCifE6wBW_UBLgCKgBGAs/s1600/IMG_20180421_125241.jpg&quot; title=&quot; &quot;/&gt;
With everything clean, I reapplied gobs of grease and reinserted the bearings. The grease held the bearings in pretty well while I reinserted the shaft through the wheel and resealed them. &lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-e4iyHEKZmns/Wtz6-AUz8TI/AAAAAAAABnc/63zONLm9E6sv9748JqmjjDlmyC0u7_HigCKgBGAs/s800/IMG_20180421_130007.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The big trick is when you close up the hub. You want to adjust the cone to be just tight enough to stop any play, but still loose enough that the bearings don't jam up. If you tighten it all the way down you can feel the bearing rubbing against each other. I backed off a little and then held the cone in place while tightening the outside bolt. The external bolt and the cone should lock together to keep the cone from moving.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-nDOF9Qju2lE/Wtz6-LnG5yI/AAAAAAAABnc/VBx7DjAcRfkUQe3sJSrQ8iV1rhBJDhkLwCKgBGAs/s800/IMG_20180421_130705.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;That's a rack&lt;/h4&gt;
&lt;p&gt;
    The bike was running smoothly at this point. But I've been having fun so I also threw a rack on the back for good measure. I'll just need to turn one of my bags into some panniers next!
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-OSlfQ08vYUw/Wt0CKrGaHYI/AAAAAAAABoM/29hWgFyI-dMe_91WiTTX0YpNWPkzwtN8ACKgBGAs/s800/IMG_20180421_141308.jpg&quot; title=&quot; &quot;/&gt;</description>
        <pubDate>Sun, 22 Apr 2018 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2018/04/notes-on-bike-fixes/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/04/notes-on-bike-fixes/</guid>
        
        <category>bikes</category>
        
        
      </item>
    
      <item>
        <title>Replacing a Bottom Bracket</title>
        <description>&lt;p&gt;
&lt;strong&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Bottom_bracket&quot;&gt;bottom bracket&lt;/a&gt; is one of the most fundamental parts of the bike. Like many highly important things, it's also one that gets totally overlooked. That is until it starts to break.&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;
    For several months my &lt;a href=&quot;https://en.wikipedia.org/wiki/Crankset&quot;&gt;crankset&lt;/a&gt; has been wobbling worse and worse. I ignored it as long as I could, but when an elderly man on a mountain bike leisurely pedaled past me on flat ground, I realized there had to be something slowing me down.
&lt;/p&gt;
&lt;p&gt;
    But even though I knew there was something up with the crankset, I didn't actually know what to do. Even googling was a little tricky because I really wasn't sure that the bottom bracket was actually called the bottom bracket. Fortunately, I had recently heard about this place called the &lt;a href=&quot;http://bikekitchen.org/&quot;&gt;Bike Kitchen&lt;/a&gt;. Bike Kitchen is really cool because for a membership you can use all the tools there and ask questions to really knowledgeable people hanging around the shop.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://bikekitchen.org/wp-content/uploads/2012/08/394273_10150470289569506_192847620_n.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    So I'm planning to overhaul the rest of my bike in the next weeks, but for now, I've got my number one priority.
&lt;/p&gt;
&lt;h3&gt;Replacing a Bottom Bracket&lt;/h3&gt;
&lt;p&gt;
    You can fix a bottom bracket in two ways: you can overhaul it and put in new bearings manually or you can put a sealed bottom bracket in it. Sealed bottom brackets cost a little more, but they last a lot longer because it's harder for junk to get inside and start to wear them down. At Bike Kitchen, they've got a whole bin of sealed ones so I decided to put one of them in.
&lt;/p&gt;
&lt;p&gt;
    To get the old one out, you have to use the aptly named &lt;a href=&quot;https://www.youtube.com/watch?v=60wtyyXvtOs&quot;&gt;crank-puller&lt;/a&gt; which basically pushed the cranks out from the bottom bracket.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-U3SRKK2BS1I/Wsk9udyJo3I/AAAAAAAABaw/5CWe1S2_mi4Bo9OsrUfiB7rz5mBgDXjQgCKgBGAs/s800/IMG_20180405_183417.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    afterwards you can see just the end caps and the spindle of the bottom bracket are left.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-MhUIcyd7mZQ/Wsk9uYMcXZI/AAAAAAAABaw/t6HNag24cQ0TqolVJzR7dvthbzxVpZLRgCKgBGAs/s800/IMG_20180405_183402.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    After removing the end caps, a fairly destroyed set of bearing came tumbling out afterwards. And inside you can see that the interior looks pretty roughed up.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-3Vln1ONbUqQ/Wsk-zY1EKwI/AAAAAAAABbc/ByaJ-xKh4Uw7DlBEiYt8Msc6ZyLuIF5HACKgBGAs/s800/IMG_20180405_184014.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    After I cleaned up the inside, the sealed bottom bracket definitely looked a lot healthier sliding in there.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-yRriFPg6uK8/Wsk_c9sNdZI/AAAAAAAABb4/rtnl4uAIqo4D0GPRix05w08Oh9mjDhNhQCKgBGAs/s800/IMG_20180405_191331.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Now the wobble and the friction are both gone! On to the next fix.
&lt;/p&gt;</description>
        <pubDate>Sat, 07 Apr 2018 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2018/04/replacing-bottom-bracket/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/04/replacing-bottom-bracket/</guid>
        
        <category>bikes</category>
        
        
      </item>
    
      <item>
        <title>Sailboat Light Covers</title>
        <description>&lt;p&gt;
    Starting in November 2017, I began renting a boat at Coyote Point Marina in Burlingame, CA. I'm using it as a crashpad near my work so that I don't have to commute from SF every day.
&lt;/p&gt;
&lt;p&gt;
    It's a fine little Tanzer 22, and the owner has done a decent job of repairing and maintaining it. Now that it's in my care, I've gotten to work on some little fixes to spruce it up a bit.
&lt;/p&gt;
&lt;h4&gt;Raising the boom and replacing the tarp&lt;/h4&gt;
&lt;p&gt;
    After giving her a quick clean last week, it became clear that the tarp covering the boat was nearing its last legs. For the replacement, I figured I could get a slightly larger tarp and extend my headspace a bit. There was about six inches available to raise the boom, and I could drape the tarp over the edges of the grab rails on the foredeck.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-0aa-NafYl4o/WkwY7dA6YHI/AAAAAAAABI0/08OKmiJcXbACBISdkwEzH9WKZgwe3GWdACKgBGAs/s800/IMG_20171223_090700.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    This made the boat much more livable and made me feel better about showing it off to people. Plus who knows what all those frayed bits of fiberglass were doing to my lungs :(
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-_e4MK52T-pQ/WkwZjVH1Z1I/AAAAAAAABJA/Xoohtz4oy3QMLGJ3mz8nVMXpcRu86BH1ACKgBGAs/s1600/IMG_20171120_165751.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Covering the lights&lt;/h4&gt;
&lt;p&gt;
    The owner had replaced the internal cabin lights with some really awesome bright LED bulbs. Unfortunately, he didn't have any covers to cover the internals of the light fixture, which leaves the cabin looking a little shabby and unfinished.
&lt;/p&gt;
&lt;p&gt;
    My friend Pete (a sailor from the Land of 10,000 lakes) came over, and we measured the fixture at 5' by 5' even, estimating that a depth of probably a half inch would give plenty of clearance. There were also 4 gaps on the sides where tabs in the plastic could fit in, but I figured that I'd see if the plastic would hold in place without the tabs. Anything simple would do to start.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-lFaEVQJrE2s/WhJ1L0-weqI/AAAAAAAAA74/OR1DLky2mEs8gD6rp8wAvpDtitTflFxYwCKgBGAs/s1600/IMG_20171114_080512.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    At first, I thought I'd try making a clear transparent acrylic casing, but realized that wouldn't help much in masking the bulb and prettifying my cabin. Also, after living there, I realized that the light was plenty bright and that I could do with a more opaque material. In fact, I figured that could be helpful in &lt;a href=&quot;https://en.wikipedia.org/wiki/Hard_and_soft_light&quot;&gt;diffusing the light&lt;/a&gt; a little so it wasn't so jarring.
&lt;/p&gt;
&lt;p&gt;
    As a quick prototype, I just cut out and bent a thin sheet of plastic that I found in the scrap pile at the &lt;a href=&quot;https://noisebridge.net/&quot;&gt;Noisebridge hackerspace&lt;/a&gt; in San Francisco's Mission District.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-5NIsyj3zTTU/WhJ2sDh3veI/AAAAAAAAA8E/PQaXRfkcX683q70H6xl4XAIFOK1eXelugCKgBGAs/s800/IMG_20171118_135351.jpg&quot; title=&quot;nothin' fancy &quot;/&gt;
&lt;p&gt;
    I just cut some simple notches and bent them out to fit in the holes.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Z_1trGJ5mK8/Wkwa10nKspI/AAAAAAAABJQ/sUz-pRggd0AJ4a2ExJvQ-FeP2BgMrtNMQCKgBGAs/s1600/IMG_20171120_171855.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The device is simple, but did a decent job at making the lights less noticeable.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-TqrC2GdPfk0/WkwaoYZlprI/AAAAAAAABJM/T8kgQBIEXg8IPSHo4iYQnekOQva9qxM1ACKgBGAs/s800/IMG_20171120_170154.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Next step, rainbow lights&lt;/h4&gt;
&lt;p&gt;
    While I was first playing around with that material, it suddenly reminded me of a similar thin film I'd played around with before. If you've ever taken apart an LCD monitor then you probably have run into some shiny colorful plastic material like this before.
&lt;/p&gt;
&lt;p&gt;
    Basically it's just polarizer film, or a film that only let's light through when it's &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_polarization&quot;&gt;linearly polarized&lt;/a&gt; in a particular direction. &lt;a href=&quot;https://physics.stackexchange.com/questions/155391/what-happens-if-you-remove-the-polarization-filter-from-a-computer-monitor&quot;&gt;This Physics StackExchange post&lt;/a&gt; will explain why polarizer film is required for LCDs to work. One cool bonus feature is that this film has the optical effect of generating nifty rainbow colors as you bend it. You can see another effect of that in this cool GIF from the &lt;a href=&quot;https://www.exploratorium.edu/&quot;&gt;exploratorium&lt;/a&gt;.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://www.exploratorium.edu/sites/default/files/PolarizedLightMosiac_DSC_7232.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    I should be able to cut out an identical shape if I wanted to through some technicolor light around the boat. I'll update with the new version once I get a chance to try it.
&lt;/p&gt;
&lt;h4&gt;Sailing&lt;/h4&gt;
&lt;p&gt;
    Unfortunately, the owner hasn't yet let me sail it, but I'm hoping that these cool modifications along with a trial run or two with him this winter will have me sailing that beauty around the Bay by spring. Fingers crossed.
&lt;/p&gt;</description>
        <pubDate>Tue, 02 Jan 2018 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2018/01/sailboat-light-covers/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2018/01/sailboat-light-covers/</guid>
        
        <category>boatwork</category>
        
        
      </item>
    
      <item>
        <title>Making Better Eyes</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: Currently engaging in exploratory experiments to determine validity of hypothesis. 10% confidence of success, but experiment is low risk, which makes it worth pursuing.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        In May 2017, I had an eye exam with my new optometrist. During that visit, my optometrist made a passing remark about a quirk that he noticed in my old glasses. That tiny remark completely changed my perspective on optometry and near-sightedness. And I'm hoping that it might just change my life.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-4ZgtsQLJgpw/WWJq8wDEgAI/AAAAAAAAIpQ/mPvZHgPxLwgQg6owh8Zvxg1qDlSwekfAQCLcBGAs/s1600/IMG_20170709_103715.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Why had I never thought of that before?&lt;/h4&gt;
&lt;p&gt;
        All this started when my new optometrist asked me nonchalantly whether my previous optometrist had ever mentioned putting a prism in my glasses. I'm severely myopic (or near-sighted) with a prescription of around -7.5 diopters in my glasses. This means I need to take my prescriptions pretty seriously because getting the wrong glasses means I can't see much farther than 12 inches in front of me.
    &lt;/p&gt;

    Now, as it just so happened, I had taken my prior prescription to the online eyeglasses retailer, &lt;a href=&quot;https://www.reddit.com/r/malefashionadvice/comments/3yowqq/how_is_the_quality_of_warby_parker_glasses/&quot;&gt;Warby Parker&lt;/a&gt;, so I knew very well that there was no mention of &quot;prism&quot; anywhere on my prescription. Moreover, even though I've been going to the optometrist for more than 20 years, I had never heard about prism before. Since I didn't know what prism was, I asked what it meant for glasses to have prism.
    
&lt;p&gt;
        Essentially, as my doctor explained, prism means that the center of the focus of the lens is not aligned with the center of your eye. In other words, it means the lens of the glasses are offset. This is normally done intentionally when a person has a misaligned eye that needs to be corrected. But since I knew that my old prescription didn't mention prism, I told the optometrist that it must have been a mistake, and that I remember having a really hard time adjusting to my glasses when I got them. And then he responded with a statement that completely took me by surprise.
    &lt;/p&gt;
&lt;blockquote&gt;It must have just been lucky then because you actually need exactly the same amount of prism that is in your glasses.&lt;/blockquote&gt;
&lt;p&gt;
        I could tell by the way that he said it that he wasn't questioning the arrow of causation, but to me, the following painfully obvious question instantly sprung loose in my imagination:
    &lt;/p&gt;
&lt;h6&gt;Could my new-found prism have been caused by my glasses?&lt;/h6&gt;
&lt;p&gt;
        Knowing what little I knew about biology, it seemed more likely to me that my eye would have adapted to an erroneous prism than that the accidental prism and the &lt;strong&gt;never before diagnosed&lt;/strong&gt; prism happened to just perfectly counterbalance. So if I assume that my glasses were able to retrain my eye to adjust for a prism, it isn't too difficult to jump to the next obvious question:
    &lt;/p&gt;
&lt;h6&gt;Could other vision problems be induced by glasses, specifically, my progressive myopia?&lt;/h6&gt;
&lt;p&gt;
        I was floored. How had that thought never occurred to me? I feel pretty stupid for never thinking about it, but once the idea was in my head, I had to get an answer.
    &lt;/p&gt;
&lt;h4&gt;What causes myopia?&lt;/h4&gt;
&lt;p&gt;
        To explain why I'd never thought of this before, we have to understand my previously &lt;i&gt;correct&lt;/i&gt; yet &lt;i&gt;limited&lt;/i&gt; understanding of the cause of myopia. In short, myopia is caused by &lt;a href=&quot;http://www.allaboutvision.com/conditions/myopia.htm&quot;&gt;the lens of the eye being unable to properly focus&lt;/a&gt; a distant image on the retina of the eye. If we look at a picture of light coming into a simple convex lens (like the one in our eye), we would see all the light being redirected to focus down to a single point, called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Focus_(optics)&quot;&gt;focal point&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-PrqqPeldvQ4/WU3hrjtR_1I/AAAAAAAAIhM/3ookaYm6z6wg68djAWn4KDdleOZ_OD4qACLcBGAs/s1600/convex_lens.jpg&quot; title=&quot; How light is redirected through a lens. source  How light is redirected through a lens. source&quot;/&gt;
&lt;p&gt;
        The exact shape of the lens determines how much the light rays are redirected, which sets the &lt;a href=&quot;http://www.nikonusa.com/en/learn-and-explore/a/tips-and-techniques/understanding-focal-length.html&quot;&gt;focal length&lt;/a&gt; or how far away the focal point occurs. This occurs in a camera, a telescope, and most importantly our eyes. In our eyes, this means that light coming from an object will focus down to a little miniature image at the focal point on the other side of our lens. Basically, if you want the mini image to always appear at the same location (your retina), but the real object is at a different location, you will need a different thickness of lens. The eye provides this ability by giving us muscles that quite literally &lt;i&gt;squeeze&lt;/i&gt; our lens to &lt;a href=&quot;https://www.sciencelearn.org.nz/resources/50-how-the-eye-focuses-light&quot;&gt;change its thickness&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-06VX6JEA8sg/WU3hrt50E8I/AAAAAAAAIhQ/TKmxO6zA8eAX7uQxHS_5Mkir-w3Of9IRQCLcBGAs/s1600/Eye-focus-final-3000X2000.jpg&quot; title=&quot;The eye squeezes the lens to adjust focus. source The eye squeezes the lens to adjust focus. source&quot;/&gt;
&lt;p&gt;
        The problem with myopia is just that the lens in your eye can't get thin enough to turn a far away object into an image at the exact location of your retina. Instead, &lt;a href=&quot;https://www.virginiaeyeconsultants.com/procedures/eye-conditions/myopia/&quot;&gt;the image is focused a little bit in front of the back of the retina&lt;/a&gt;, which causes the image at the retina to be fuzzy. The underlying reason can either be due to the lens being too thick or from the eyeball being too elongated.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-9_9840U2Vmk/WU3g_jrIjuI/AAAAAAAAIhE/uyllbGSOBewyMnLMQAeSx7N0U-qc6D6VQCLcBGAs/s1600/myopia.jpg&quot; title=&quot;Distance glasses adjust the accessible focal range of the eye. source Distance glasses adjust the accessible focal range of the eye. source&quot;/&gt;
&lt;p&gt;
        Either way, you should note that &lt;strong&gt; myopia doesn't come from an inability of your muscle to squeeze the lens hard enough, but, rather, a failure of the muscle to release the lens far enough. &lt;/strong&gt; The corrective lens actually is making up for a mismatch between the minimum thickness of your lens and the elongation of the eyeball.
    &lt;/p&gt;
&lt;p&gt;
        Most people with a technical degree will be introduced to this information around their freshmen or junior year of college. Since I felt like I knew a little about optics, I felt like I perfectly understood the problem. However, this still leaves the question of why some eyes are able to stay functional, while others come out of alignment.
    &lt;/p&gt;
&lt;h6&gt;The mechanics of short-sightedness&lt;/h6&gt;
&lt;p&gt;
        The next question one has to ask is &lt;i&gt;Why is a myopic person's eyeball elongated&lt;/i&gt;?
    &lt;/p&gt;
&lt;p&gt;
        I'd heard that the cause for the misalignment was genetic, due to some deficiency in the formation of the eye. The explanation that I remember hearing from my early optometrists only informed me that my eye was somehow too elongated. This is true relative to the minimum thickness of my lens, since my eye is literally too elongated for even my most relaxed focal point to reach it. This means that there is nothing I can do to get that focal point to my retina because any amount that I squish my lens to get thicker only moves the point of focus further toward the center of the eye and away from my retina at the back.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-FuRLCSN9mY4/WU3m_Oq13vI/AAAAAAAAIhg/0z9l1qmYGlITIpvVLOPRNqeOLGycrYMXgCLcBGAs/s1600/Ciliarymuscles.jpg&quot; title=&quot;Closeup on the muscles that are squeezed to adjust focus point. source Closeup on the muscles that are squeezed to adjust focus point. source&quot;/&gt;
&lt;p&gt;
        Although my optometrists accurately explained this immediate cause of my failure to focus, they never went into specifics of how my eye got to be that way, only suggesting that I had a genetic problem. But I can remember thinking how strange it was that so many people could be so blind so suddenly if this was an underlying genetic problem. About 30% of people in the United States are near-sighted today so, logically, then shouldn't approximately 30% of people have needed glasses 200 years ago too? That's just how genetics work. But 200 years ago glasses were a rare luxury for the rich so 30% of the country would have been effectively blind! At the time, I explained it away to myself by saying, &quot;Well my grandparents were all farmers; maybe on the farm no one noticed that they were going blind.&quot;
    &lt;/p&gt;
&lt;h4&gt;The biological case for vision adaptation&lt;/h4&gt;
&lt;p&gt;
        As far as I know, no one can state for sure what is truly the causing the sudden epidemic of progressive myopia. In 2015, the journal Nature posted &lt;a href=&quot;http://www.nature.com/news/the-myopia-boom-1.17120&quot;&gt;this article&lt;/a&gt;, suggesting that the myopia boom was due to children not being exposed to enough sunlight. The evidence they cite (pun intended) is that children who spend more time outside tend to have lower levels of myopia.
    &lt;/p&gt;
&lt;p&gt;
        However, a more parsimonious explanation, and one that is more widely accepted than the outdoor light theory, is simply that being outside means you are spending more time focusing on things that are far away. Being inside probably means you are looking at nearby objects, like books or computers more often. In short, it's possible that myopia is nothing more than the eye trying to adapt to the environment it is put into day after day.
    &lt;/p&gt;
&lt;p&gt;
        There are many hundreds of complex feedback mechanisms that our bodies have in place, tuning our various physiological processes to fall into homoeostasis (&lt;a href=&quot;https://www.albert.io/blog/positive-negative-feedback-loops-biology/&quot;&gt;here's a tiny handful of examples&lt;/a&gt;). From our kidneys nearly instantly setting the osmolarity, pH or ion concentration of our blood, to our muscles slowly adapting to the toll of the labor, to the development of the size of our fingers and toes, the body almost magically tunes itself to function properly. Why should vision be any different?
    &lt;/p&gt;
&lt;p&gt;
        I'm not alone in my belief that myopia is really just an adaptation to keeping the eye focused close up. Many research studies &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0042698998002296&quot;&gt;in animals&lt;/a&gt; and &lt;a href=&quot;http://journals.lww.com/optvissci/Abstract/1969/09000/THE_TRANSMISSION_OF_REFRACTIVE_ERRORS_WITHIN.5.aspx&quot;&gt;on many&lt;/a&gt; &lt;a href=&quot;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0080361&quot;&gt;different populations&lt;/a&gt; suggest that close work is a &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/20592235&quot;&gt;plausible cause of myopia&lt;/a&gt;, and that &lt;a href=&quot;http://www.bmj.com/content/324/7347/1195&quot;&gt;close-up focus along with genetic factors&lt;/a&gt; is what is causing the &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/20008719&quot;&gt;increase in myopia&lt;/a&gt; today. I don't have time to enumerate all the details of these studies, but if you'd like a high level overview of the research, I suggest you listen to the first half of &lt;a href=&quot;myhttps://www.youtube.com/watch?v=x5Efg42-Qn0&quot;&gt;this excellent talk&lt;/a&gt; by &lt;a href=&quot;http://gettingstronger.org/the-author/&quot;&gt;Todd Becker&lt;/a&gt;. &lt;h6&gt;The glasses problem&lt;/h6&gt;
&lt;p&gt;
            Of course, the issue isn't just that there are more myopic people. The issue is really that there are &lt;a href=&quot;https://www.theatlantic.com/health/archive/2016/02/in-2050-half-the-world-will-be-nearsighted/468606/&quot;&gt;so many more people with an advanced level of myopia&lt;/a&gt;. In fact, the levels of severe myopia are measurably &lt;a href=&quot;https://www.theatlantic.com/health/archive/2014/05/nearsightedness-and-the-indoor-life/361169/&quot;&gt;higher among young people&lt;/a&gt; than they are among the elderly. This leads to the question about what could be causing the pandemic worsening degree of myopia, and to one conclusion: that our increased reliance on glasses is making myopia worse.
        &lt;/p&gt;
&lt;p&gt;
            This point is more controversial than the issue of near-work causing myopia. However, it is very clear that myopia can be &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/cxo.12312/abstract;jsessionid=326E7CC5287AF8D06E34055FB9D9D4EC.f03t02&quot;&gt;intentionally induced in animals&lt;/a&gt; through the use of corrective lenses. In these studies, scientists put a pair of glasses onto chickens who presumably have pretty good eyesight.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/--rHz-s1F4p4/WVAR6fHU2zI/AAAAAAAAIiM/wTe-hl-C9RMuWTk7RKV6BXmEf98IUIz6QCLcBGAs/s1600/Chicken%2Beyes.png&quot; title=&quot;source source&quot;/&gt;
&lt;br/&gt;
&lt;p&gt;
            They wait a while and then measure the chicken's eyes and find, lo and behold, that the chicken with glasses have a &lt;strong&gt;much&lt;/strong&gt; longer eyeball. In short, the chicken's that wore glasses are now myopic even thought their peers without glasses are still just fine. Recently, researchers have proposed the &lt;a href=&quot;http://www.computersinbiologyandmedicine.com/article/S0010-4825(06)00192-2/fulltext&quot;&gt;incremental retinal defocus theory&lt;/a&gt; as a way to explain this phenomenon, which basically suggests that defocus releases chemicals that affect eye growth. If the same effect works in humans (and why shouldn't it), this would explain why people with glasses end up needing a higher prescription later on.
        &lt;/p&gt;
&lt;p&gt;
            On the other hand, I find it hard to believe that something this obvious wouldn't have been noticed and addressed a long time ago. If glasses were so obviously making us go blind, why wouldn't we have enacted measures to reduce our dependence on them. In fact, there have been several studies that dissuade me from believing in the validity of this mechanism. For starters, &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0042698902002584&quot;&gt;several&lt;/a&gt; &lt;a href=&quot;http://www.journalofoptometry.org/en/under-correction-human-myopia-is/articulo/S1888429613000885/&quot;&gt;studies&lt;/a&gt; have shown that undercorrection of myopia can lead to &lt;i&gt;worsening&lt;/i&gt; myopia in youth and adolescents (though counteracting the effects of near work with plus lenses &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/10806444&quot;&gt;has been shown to prevent myopia progression&lt;/a&gt;). And it appears that there are probably &lt;a href=&quot;http://newsroom.cumc.columbia.edu/blog/2015/08/31/gene-leads-to-nearsightedness-when-kids-read/&quot;&gt;genetic factors that increase one's susceptibility&lt;/a&gt; to &lt;a href=&quot;https://www.sciencedaily.com/releases/2016/04/160421133905.htm&quot;&gt;near work causing myopia&lt;/a&gt;.
        &lt;/p&gt;
&lt;h5&gt;Is bad vision correctable?&lt;/h5&gt;
&lt;p&gt;
            All of this is well and good if it can be shown that developing eyes are harmed by the introduction of glasses. However, that doesn't do me much good other than showing me that I should keep my kids as far away from the optometrist as possible. The big question I need to answer is if there is anything that I can do today to undo the harm that may have occurred thanks to a misguided public health policy.
        &lt;/p&gt;
&lt;p&gt;
            I still do not know if vision is correctable through training. It's very clear from published research that adult and juvenile eyes will respond adaptively to stimuli. In addition, there are &lt;a href=&quot;http://gettingstronger.org/2010/07/improve-eyesight-and-throw-away-your-glasses/&quot;&gt;many&lt;/a&gt;, &lt;a href=&quot;https://www.facebook.com/endmyopia/&quot;&gt;many groups&lt;/a&gt; and &lt;a href=&quot;https://endmyopia.org/&quot;&gt;blogs&lt;/a&gt; online that swear they have been able to achieve improvements in eyesight through various regimens. However, conventional optometrists don't acknowledge any of this as even borderline legitimate. I admit my ignorance on this subject, but I also admit I'm more than a little optimistic that I'll soon find out.
        &lt;/p&gt;
&lt;h4&gt;An experiment in vision correction&lt;/h4&gt;
&lt;p&gt;
            Before I bought new glasses I decided I wanted to see if I could start to push my vision back in the direction of 20/20. I figure there isn't that much to lose: My vision is already so bad that &lt;a href=&quot;https://www.fda.gov/MedicalDevices/ProductsandMedicalProcedures/SurgeryandLifeSupport/LASIK/ucm061366.htm&quot;&gt;LASIK is a dangerous bet&lt;/a&gt;, &lt;a href=&quot;http://www.allaboutvision.com/contacts/orthok.htm&quot;&gt;Ortho-K&lt;/a&gt; isn't possible, contact lenses will continue to leave me with dry, fatigued eyes by sundown, and my increasingly heavy glasses will forever limit my ability to maintain an active, healthy life. At -7.5 diopters, I'm on the road to blindness if I don't do something.
        &lt;/p&gt;
&lt;h5&gt;Trying to be scientific&lt;/h5&gt;
&lt;p&gt;
            I'm not the best scientist, but that doesn't mean I don't want to try to be as systematic as possible in my approach to improving my eyesight. Towards that goal, I'm writing this blog post for a couple of reasons. First, I want to make sure I had a relatively decent understanding of the basic science that underpins the justification for the possibility of vision correction. Writing a post always makes me double check my research so I don't say something stupid. But beyond this, I want to document in a reasonably reproducible manner the approach I'm taking to improve my vision. I want to make it clear what I'm trying to do up front, and then, after a few years, I can fairly evaluate whether I've seen any improvement and what led to such improvement.
        &lt;/p&gt;
&lt;p&gt;
            Stating &lt;a href=&quot;https://www.nature.com/articles/s41562-016-0021&quot;&gt;the goal and the methods before the study&lt;/a&gt; is a valuable approach in &lt;a href=&quot;https://osf.io/&quot;&gt;Open Science&lt;/a&gt; for two reasons. First, if I am successful, after the fact there can be no accusation that I fudged something or that I misrepresented my approach. On the other hand, if it doesn't work, I will have a record that I tried and failed. If everyone records their failed attempts too, then we'll start to get some grassroots confirmation that this really isn't possible. There's always the possibility that the field of optometry isn't deluding us, and I would like to reveal in an unbiased way what proof my experience can offer.
        &lt;/p&gt;
&lt;h5&gt;My experimental technique&lt;/h5&gt;
&lt;p&gt;
            Although many different forms of vision remedy exist on the internet (and some are &lt;a href=&quot;https://www.youtube.com/watch?v=WEetWYtLCFQ&quot;&gt;just plain quackery&lt;/a&gt;), I've tried to pick a very simple routine.
        &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;When doing all near work (reading or working on the computer) wear weaker glasses (approximately +1.25 diopters relative to my most recent prescription) or reading glasses with contacts.&lt;/li&gt;
&lt;li&gt;Whenever I notice blur, practice focusing on things just &lt;i&gt;a little too far&lt;/i&gt; outside my easily visible range.&lt;/li&gt;
&lt;li&gt;When outside, use regular prescription, but be sure to keep focus on far away objects whenever possible.&lt;/li&gt;
&lt;li&gt;When possible, rest my eyes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
            This is based on the suggested routine from &lt;a href=&quot;http://gettingstronger.org/wp-content/plugins/wordpress-toolbar/toolbar.php?wptbto=http%3A%2F%2Fgettingstronger.org%2Frehabilitation%2F&amp;amp;wptbhash=aHR0cDovL2dldHRpbmdzdHJvbmdlci5vcmcvMjAxMC8wNy9pbXByb3ZlLWV5ZXNpZ2h0LWFuZC10aHJvdy1hd2F5LXlvdXItZ2xhc3Nlcy88d3B0Yj5JbXByb3ZlIGV5ZXNpZ2h0ICYjODIxMTsgYW5kIHRocm93IGF3YXkgeW91ciBnbGFzc2VzPHdwdGI%2BaHR0cDovL2dldHRpbmdzdHJvbmdlci5vcmc8d3B0Yj5HZXR0aW5nIFN0cm9uZ2Vy&quot;&gt;gettingstronger.org&lt;/a&gt;, but I have simplified it so that I can state clearly what methods I am employing. This will enable me to better describe &lt;i&gt;exactly&lt;/i&gt; the patterns of behavior that led to vision improvement (or lack thereof).
        &lt;/p&gt;
&lt;h4&gt;Preliminary data&lt;/h4&gt;
&lt;p&gt;
            As a baseline starting point, I am including my prescription as of May 2017. My goal is to continue just getting annual prescriptions, and using that as my official record. I'm hoping to see about a half diopter improvement per year since that was approximately the rate at which my myopia progressed. Of course, that will mean that it'll take 10 years before I can see without glasses, but better late than never.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Aey91VVwFJg/WVAVEsd6HKI/AAAAAAAAIig/3_YZxmPQFwUcvtR6bfTfVZK7KGoYI-SIACKgBGAs/s1600/IMG_20170616_182411.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            Fortunately, I was able to convince my optometrist to give me a pair of glasses for working on the computer. I had been wearing reading glasses with contacts anyway so we figured I could just get a prescription with +1.25 diopters added and use that so I wouldn't dry my eyes out with the prescription. In theory, I should switch back to my regular prescription any time I walk away from the computer, but I've effectively started wearing these glasses when I was away from the computer too. I now spend about 70% of my day wearing my -6.25 glasses.
        &lt;/p&gt;
&lt;p&gt;
            For the first three days with the computer glasses, I had an intense headache and I couldn't see further than my computer screen. It was truly painful, but I persisted, remembering how painful it was when I originally received my erroneous prescription from Warby Parker. I quickly grew accustomed to the changes, and any eye strain was completely unnoticeable after the first week.
        &lt;/p&gt;
&lt;p&gt;
            I've now been following this program for about a month. As the month has progressed, I have seen an immediate and quite obvious improvement, but I don't want to overstate the results. I feel that this immediate improvement could just be due to my adjustment to this new set of glasses, and my brain getting used to perceiving somewhat fuzzy images better than I was used to before.
        &lt;/p&gt;
&lt;p&gt;
            To get some early quantitative results, I've tried two different online &lt;a href=&quot;http://www.personaleyes.com.au/online-eye-test/index.php&quot;&gt;eye&lt;/a&gt; &lt;a href=&quot;https://www.zeiss.com/vision-care/en_us/better-vision/better-vision-with-zeiss/zeiss-online-vision-screening-check.html&quot;&gt;tests&lt;/a&gt; to estimate my &lt;a href=&quot;https://en.wikipedia.org/wiki/Visual_acuity&quot;&gt;visual acuity&lt;/a&gt; . Both claim that I am 20/20 when wearing my -6.25 lenses. I actually think I'm probably closer to 20/40, based on how well I can see street signs around me (&lt;a href=&quot;https://www.aoa.org/patients-and-public/eye-and-vision-problems/glossary-of-eye-and-vision-conditions/visual-acuity?sso=y&quot;&gt;20/40 is worse than 20/20&lt;/a&gt;). To put that in perspective, &lt;a href=&quot;https://www.reddingmedical.com/documents/Spot%20VS100%20Vision%20Screener,%20Conversion%20Chart%20&amp;amp;%20Instructions.pdf&quot;&gt;this conversion chart&lt;/a&gt; (derived from &lt;a href=&quot;http://www.hicsoap.com/publications/TheRelationshipofVisualAcuity.PDF&quot;&gt;this paper&lt;/a&gt;), suggests that my -1.25 of uncorrected vision should equate to approximately 20/70. Clearly I am seeing better than that even if these tests aren't perfectly accurate. I don't think this is necessarily so dramatic though, and I can't really be sure that this change in visual acuity isn't just a an early effect of my brain getting comfortable with fuzzier images. To really be sure, I will have to wait for my next official eye exam sometime next year. &lt;i&gt;Note, I don't want to measure my vision too often because I believe this could effectively train my eyes to get better at beating Snellen charts, which could bias my results.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
            A conservative interpretation is that my eyes had the ability to adjust to the sensation of wearing a weaker prescription, and I've been able to compensate for the weaker prescription in a short time by focusing better even in the presence of some blur. I do not expect this rapid improvement to persist in the coming months though. Instead, I am hoping that over the next year or so I will slowly adapt to being able to see further and further with my -6.25 lenses.
        &lt;/p&gt;
&lt;p&gt;
            I will check back in with an update on my vision at the 6 month point. If I've improved to the point that my -6.25 glasses are truly 20/20 and I have no difficulty viewing things at moderate distance, I may order an even weaker pair of glasses online for computer work.
        &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;</description>
        <pubDate>Sun, 19 Nov 2017 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2017/11/making-better-eyes/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/11/making-better-eyes/</guid>
        
        <category>science</category>
        
        <category>biology</category>
        
        
      </item>
    
      <item>
        <title>hope you dance (alone)</title>
        <description>&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-8Ztl7NFEjQw/WTo4DMnOYnI/AAAAAAAAIY0/Q_i-Cws8TbwfnkxKB06EBGjm7rAw1aSJQCLcB/s1600/Screenshot%2Bfrom%2B2017-06-08%2B22-52-11.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        For the past couple of months, I've been obsessed with &lt;a href=&quot;http://neilcicierega.com/&quot;&gt;Neil Cicierega&lt;/a&gt;'s amazing &lt;a href=&quot;mashup of marshmello Alone and early 2000s maudlin smash hit i hope you dance&quot;&gt;mashups&lt;/a&gt;. Basically, he does an unbelievably amazing job of squeezing tons of irony and kitsch out of a bunch of 90s and 2000s songs. His work has a very DIY feel, and it very much comes out of the internet culture, but the work is really impeccable and just sooo funny.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://images.genius.com/7748ece5191c0a368b5ea02112649286.800x800x1.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;i&gt;btw, I just looked up the links for Neil Cicierega and ended up spending the last two hours listening to his music again.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        Anyway, &lt;a href=&quot;http://www.phrases.org.uk/meanings/imitation-is-the-sincerest-form-of-flattery.html&quot;&gt;imitation is the sickest form of flattery&lt;/a&gt; so I decided I would play around with mashing up a couple of tunes myself. I've always liked the idea of merging dance music with country music because the only famous example is the &lt;a href=&quot;http://mentalfloss.com/article/82584/long-history-behind-song-cotton-eye-joe&quot;&gt;notably horrible Cotton Eye Joe&lt;/a&gt;. After deciding to do a country tune merged with a dance songe, the obvious choice for me was the classic &lt;a href=&quot;http://www.chicagotribune.com/news/columnists/chi-schmich-sunscreen-column-column.html&quot;&gt;wear your suncreen&lt;/a&gt; of the south: &lt;a href=&quot;http://www.greatamericanthings.net/music/songs-music/song-i-hope-you-dance/&quot;&gt;Hope you dance&lt;/a&gt; by appropriately triple named &lt;a href=&quot;https://en.wikipedia.org/wiki/Lee_Ann_Womack&quot;&gt;Lee Ann Womack&lt;/a&gt;. For the dance track, I decided to just mash it up with an instrumental of Marshmello's Alone for the sole reason that I just think that track is great.
    &lt;/p&gt;
&lt;p&gt;
        Here's my mashup on youtube dubbed over clips from the original music video. It's not great, but I kind of like it in a weird way. Read below for more on how to make a track like this.
    &lt;/p&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/UnhhmN9PJGk&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;h3&gt;The Audacity of Dope&lt;/h3&gt;
&lt;p&gt;
        All the music editing took place using the &lt;a href=&quot;http://www.audacityteam.org/&quot;&gt;Audacity&lt;/a&gt; open source music editor. The community surrounding this software is great and there are already a ton of tutorials to get you started. I'm going to focus primarily on the process for grabbing a bunch of music that you like off of youtube and putting it together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-iWerQHgB8iA/WTo34SWZIUI/AAAAAAAAIYw/pmq0Z4aeKHgPDVMERkuKsa7iqJ-BxOg7QCLcB/s1600/Screenshot%2Bfrom%2B2017-06-08%2B22-51-12.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;downloading some audio&lt;/h6&gt;
&lt;p&gt;
        The first step is to download music. I got all of mine off of youtube using &lt;a href=&quot;https://www.onlinevideoconverter.com/mp3-converter&quot;&gt;this site&lt;/a&gt;. Since this was just a fun project, I didn't fuss too much with getting really good audio. My primary focus was trying to get music with audio and instrumental separated so that I could merge them without having the instruments conflict. I was able to do that for Alone, but old country songs don't have a very wide remixing community so I had to make due on my own.
    &lt;/p&gt;
&lt;h6&gt;removing instrumentals&lt;/h6&gt;
&lt;p&gt;
        I played around with a couple of the examples in &lt;a href=&quot;http://manual.audacityteam.org/man/tutorial_vocal_removal_and_isolation.html&quot;&gt;this tutorial&lt;/a&gt; from Audacity. They worked to a certain degree, but there are still fragments of instruments in the background of the Womack track. I just went with it and tried to incorporate them in a musical way.
    &lt;/p&gt;
&lt;h6&gt;beat matching&lt;/h6&gt;
    Once I had the music and vocals more or less isolated, there was one crucial step called beat matching. basically, the two songs were in very different tempos so I tried to get them close to the same speed so that I could merge them without the two tracks getting out of sync. To do this, I first estimated the bpm of the songs by tapping to the beat on an &lt;a href=&quot;http://www.all8.com/tools/bpm.htm&quot;&gt;online bpm tool&lt;/a&gt;. This gave me a relative difference in tempo, which I could use to adjust one of the tracks using Audacity's &lt;a href=&quot;http://manual.audacityteam.org/man/change_tempo.html&quot;&gt;change tempo feature&lt;/a&gt;. &lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-2KRmZpY6twg/WTowqENdMzI/AAAAAAAAIYg/z_JlyQx7DM8HxsPV9pIHx7WSqdLyypZ3gCLcB/s1600/change_tempo_w10.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;slice and dice&lt;/h6&gt;
&lt;p&gt;
        After this, basically all I did was slice audio clips, and copy and paste them into an Audacity project with the instrumental running in the background. I &lt;a href=&quot;http://manual.audacityteam.org/man/change_pitch.html&quot;&gt;changed the pitch&lt;/a&gt; of the clips in different ways in different places, but I just adjusted the pitch by ear until it sounded sort of OK. Occasionally, I'd just start throwing random effects onto clips, but I never really kept track of what I was doing so I can't really describe what I did there.
    &lt;/p&gt;
&lt;p&gt;
        Long story short, you just have to play around for a long time to massage the clips into the surrounding beat track. This took me about 4 nights of continuous work and then another maybe three or four where I would just poke around for 15 minutes. I suspect that the next time I do this it will take significantly less time, but I will end up with a significantly better project. I didn't have too high of hopes so the product I ended up with was good enough for me to finalize the project and move on.
    &lt;/p&gt;
&lt;h3&gt;Throwing together a video&lt;/h3&gt;
&lt;p&gt;
        Finally, I really wanted to see this weird new song stitched back in with the original music video. So I went about getting a copy of the video from youtube. If you don't know already, all you have to do to download a youtube video is add ss to the url as described &lt;a href=&quot;http://www.nairaland.com/1934159/how-download-youtube-videos-using&quot;&gt;here&lt;/a&gt; (and a moillion other places online.
    &lt;/p&gt;
&lt;p&gt;
        After you download the mp4, you can edit in any video editor. I used this really janky program called &lt;a href=&quot;https://www.shotcut.org/&quot;&gt;ShotCut&lt;/a&gt;, but I would not recommend it. It served its purpose for me, but I'm sure there must be better video editing packages out there.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-8Ztl7NFEjQw/WTo4DMnOYnI/AAAAAAAAIY0/Q_i-Cws8TbwfnkxKB06EBGjm7rAw1aSJQCLcB/s1600/Screenshot%2Bfrom%2B2017-06-08%2B22-52-11.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I won't describe how to slice and dice a video up, but I will give you a few suggestions if you want to upload a copyrighted video to youtube. After you do all the editing, just add a ton of crazy filters so that none of the original video appears in its original condition in your final product. Otherwise youtube will block it automatically.
    &lt;/p&gt;
&lt;p&gt;
        Note: I think this is all legal because it falls under fair use, but then again, I'm not a lawyer so if anybody cease and desists you, just take it down and don't fight them. That probably won't happen if you make something as crappy as the music I made, but keep it in mind.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Fri, 17 Nov 2017 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2017/11/hope-you-dance-alone/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/11/hope-you-dance-alone/</guid>
        
        <category>music</category>
        
        
      </item>
    
      <item>
        <title>Indiana Jones and the Elusive Promo Code</title>
        <description>&lt;p&gt;
        In a lot of ways, my brother and I share a lot of the same opinions, but there are a few subjects where we disagree vehemently. One of the places where our difference of opinion has led to conflict has been on the subject of gift giving. To explain the paradox of our situation, I wrote the following allegory.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;h5&gt;The paradox of the brothers gifts:&lt;/h5&gt;
&lt;p&gt;
            Once there were two brothers who had to buy each other gifts. Brother Will believed that the value of the gift lay in the utility that it brought to the receiver. He believed it was the benefit that counts. As such, he would even go so far as to ask the receiver what it is they wanted, rather than risk a mistake.
        &lt;/p&gt;
&lt;p&gt;
            Brother Andrew believed that the value of the gift lay in the effort the giver exerted in trying to pick the gift. He believed it was the thought that counts. As such, he would be pleased with a gift that the receiver immediately threw away as long as the receiver believed that Andrew had thought long and hard to pick it out.
        &lt;/p&gt;
&lt;p&gt;
            When the brothers came to give each other gifts, they were doomed to fail.
        &lt;/p&gt;
&lt;p&gt;
            If Brother Andrew aimed to search his soul for what Brother Will would truly want, he would inevitably come to the realization that he must give up being thoughtful and directly ask Brother Will, even if it meant that his gift didnt truly represent his feelings.
        &lt;/p&gt;
&lt;p&gt;
            If Brother Will aimed to give a gift that Brother Andrew would value highly, he would have to forgo his philosophy of directly ascertaining the gift of highest value, and instead project his feelings about Andrew into his selection of a gift, even though he might be wrong.
        &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5&gt;&lt;/h5&gt;
&lt;p&gt;
        Long story short, I am the utilitarian, and my brother is the romantic. This dichotomy has been largely fine from my viewpoint for many years: I just ask my brother what he needs and then ship it; my brother gets me gifts I don't need, and I give them away to other people. However, earlier this month my brother actually managed to nail it with his gift and get me something that I really liked that I didn't even know I needed, which made me reconsider my approach. I suddenly found a new respect for the contemplation required in his style, so for his best man's gift, I decided I'd to try something different.
    &lt;/p&gt;
&lt;h3&gt;The Backstory&lt;/h3&gt;
&lt;p&gt;
        Both my brother and I grew up loving &lt;a href=&quot;https://en.wikipedia.org/wiki/Indiana_Jones_(franchise)&quot;&gt;Indiana Jones&lt;/a&gt;, as every kid should. My brother has dressed up as Indiana on many occasions, and our mother even somehow let us buy bullwhips when we were kids.
    &lt;/p&gt;
&lt;p&gt;
        When I got my PhD from the University of Chicago, my brother wanted to commemorate it with something that acknowledged that Dr. Jones and I are &lt;a href=&quot;http://indianajones.wikia.com/wiki/University_of_Chicago&quot;&gt;both alumni of the same institution&lt;/a&gt;. He thought long and hard on the gift, and decided to get me a &lt;a href=&quot;http://indianajones.wikia.com/wiki/Indiana_Jones%27s_Satchel&quot;&gt;WWII gas mask bag&lt;/a&gt; like the one Indiana uses to carry his stolen loot (I mean archaeological findings). Although I didn't realize it at first, this turned out to be a very practical and useful gift. Having this satchel is a great way to carry just a few things while going on hikes without having to lug a whole backpack. Plus it's just inherently really cool to walk around with a piece of Indiana Jones gear on.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-NX_kUpncASg/WagYceTakjI/AAAAAAAAI8I/5-s7ldd5TkE1C_ymfuclkXcAmAjmDERDwCKgBGAs/s800/IMG_20170829_223632.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When I got my brother a gift for being my best man and officiating my wedding, I wanted to make it something practical, but I also wanted to continue the adventurous spirit. Importantly, I wanted to make sure the delivery was part of the gift itself. The best thing I could think of was to get something that would enable my brother to finish a project that he's been wanting to execute on for a while now. He has a good idea for a board game, but he has never gotten around to finishing it and building it. To help him get it made, I got him credits with &lt;a href=&quot;https://www.thegamecrafter.com/&quot;&gt;Game Crafter&lt;/a&gt; to get all the pieces printed and delivered as soon as he finalizes the plans.
    &lt;/p&gt;
&lt;p&gt;
        Traditionally, I would have just emailed him the promo code, but for this delivery, I decided to make a little mystery and see if he could follow the clues to discover his gift...
    &lt;/p&gt;
&lt;h3&gt;The Setup&lt;/h3&gt;
&lt;p&gt;
        I thought it would be too hard to get someone to figure out both a website and complex 16 character promo code so instead I just created a fake Indiana Jones themed email and had the promo code sent there. For the puzzle he has to figure out to check gmail and the username and password from the hints I give. As an added bonus, I'm not going to directly reveal to him that there's a puzzle at all. I'm just going to hint at it with my clues a couple of times during my wedding weekend.
    &lt;/p&gt;
&lt;h4&gt;Clue 1: Map of the West Indies&lt;/h4&gt;
&lt;p&gt;
        For the first clue, I'm trying to be subtle enough that he could still doubt whether there is anything going on at all. To do this, I'm pretending that the first clue was actually hidden in the gift that he gave me. He bought it online so there's some chance that he'll believe that it was an &lt;a href=&quot;http://www.huffingtonpost.com/2012/12/18/uchicago-indiana-jones_n_2322098.html&quot;&gt;easter egg from the person selling it&lt;/a&gt;. I know it's a long shot, but even if he only has the tiniest momentary sensation that I didn't put it there, then that will make it just a little bit mysterious.
    &lt;/p&gt;
&lt;p&gt;
        The clue is a pretty basic map of the Caribbean that I found a few days ago on the sidewalk. To make it look more &quot;authentic,&quot; I stained it with coffee folded it up and ripped one edge. The symbolism of this token is that another name for the Caribbean is the West Indies, and Indy is Dr. Jones' abbreviated nickname.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-2ktRD2ZG9C8/Waj7MWjgbNI/AAAAAAAAI8w/PDn4EYAwgdE7QP2k0gpsAi3DR3US3Tj0ACKgBGAs/s800/IMG_20170830_181342.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        On the back, I'm adding the text:
    &lt;/p&gt;
&lt;blockquote&gt;Summer 1943,&lt;br/&gt;Island two miles south of Terre Rouge, Haiti&lt;/blockquote&gt;
&lt;p&gt;
        I didn't want to make it too obvious so I used a reference from a fairly obscure &lt;a href=&quot;http://indianajones.wikia.com/wiki/Indiana_Jones_and_the_Army_of_the_Dead&quot;&gt;Indiana Jones novel&lt;/a&gt;, &lt;i&gt;Indiana Jones and the Army of the Dead&lt;/i&gt;. The Island that Indiana and crew visit in the book is Called Zile Muri-yo, which is more ore less a transliteration of the French, Isle de Mort, or Island of the Dead. This is essentially the only reference I could find that put Indy somewhere in the West Indies so I kind of had to use it. From this, hopefully my brother can deduce that &lt;i&gt;zilemuriyo@gmail.com&lt;/i&gt; is the email address he'll be looking for. Of course, at this point he doesn't know anything about an email account. That clue comes later.
    &lt;/p&gt;
&lt;p&gt;
        As a premature setup, I also sent him a text mentioning that I found a map at the bottom of the bag he gave me. Of course, his text response shows that he isn't that gullible.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-OnAlmJ6PCIo/Waj7je6yb1I/AAAAAAAAI80/nKRlGHqeFrAPWYDmUfKUSH8WhJQ2Bcj8ACKgBGAs/s1600/Screenshot_20170831-064407.png&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Clue 2: Morse Code Belt&lt;/h4&gt;
&lt;p&gt;
        Next up we have the red herring, specially equipped with a classic coded puzzle. My brother will expect a best man gift so I'm going to need to give him something early on to throw him off the trail.
    &lt;/p&gt;
&lt;p&gt;
        The item I've chosen is an odd leather belt that I got a few years back. It says made in India so I'm going to suggest that it was fashioned in the region of India where &lt;i&gt;Temple of Doom&lt;/i&gt; is set. This is another subtle clue because encoded in the belt is a message that comes from that film.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-C4Xl75W6yzI/Waj7pll6ooI/AAAAAAAAI84/es37Sgl1bnIDIFEgO0c-m8k-GotdoRC9ACKgBGAs/s800/IMG_20170830_181508.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The belt has those weird holes poked through it all along the edge. The secret is that I'm stringing thread in a Morse code pattern between and among the holes. I'm using two types of thread. Presumably, this is hideous enough that my brother will notice there must be something up with the strings randomly strewn across a weird looking belt.
    &lt;/p&gt;
&lt;p&gt;
        The two colors each encode a different word. One is &lt;strong&gt;fortune&lt;/strong&gt;, the other is &lt;strong&gt;glory&lt;/strong&gt;. From this, hopefully my brother will guess that &lt;i&gt;fortuneandglory&lt;/i&gt; is the password. &quot;Fortune and glory&quot; is famously what Indiana (and everyone) is seeking on adventures.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-WAqGdbSdIF4/Waj8JwmnkRI/AAAAAAAAI9A/5LFfljRPgAkaZgYdcv9_0wcRV4wZTka9ACLcBGAs/s800/fortune-and-glory.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Still, he probably won't know at this point that he's looking for an email address, but he and I have both used that trick before so he might see it coming. Anyway, just in case, that is where the last clue comes in.
    &lt;/p&gt;
&lt;h4&gt;Clue 3: Lincoln Log Message&lt;/h4&gt;
&lt;p&gt;
        The last clue is going to be hidden in a gift I give to my brother's daughter, Penny. I got her several boxes worth of Lincoln Logs because she likes building things. I'll be giving her the bulk of the toys on Sunday at her birthday party, but, on Friday night before my wedding, I'm going to give my brother a little teaser of 5 lincoln logs and a figurine that looks a bit like Indiana.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-V_der9_HS9U/Waj6eu3UxPI/AAAAAAAAI8k/BkzSQCuy3KwLd6DLhY30-60UZVzD6MtIACKgBGAs/s800/IMG_20170830_181547.jpg&quot; title=&quot;Note that the thread is the same as used in the belt &quot;/&gt;
&lt;p&gt;
        The trick is that on some of the flat faces of the logs, there are little letters carved in: A, I, L, and M.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-EXomLziaRSo/Waj6PlrVpsI/AAAAAAAAI8g/Ko5qa0FrFuwKCbVuY5yfeo8KczgNoWeNgCKgBGAs/s800/IMG_20170830_203309.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Since each letter appears twice, the puzzle can be solved by constructing them together such that the same letters overlap.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-2zZK9nv6zI8/Waj6KPsrIKI/AAAAAAAAI8c/T1qBJ5AwCW0lIgg9ydMEWGipysW2xiJZQCKgBGAs/s800/IMG_20170830_203346.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When he does that, he should hopefully see that the logs form the shape of a capital G.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-sxMN4thpARY/Waj616VcF4I/AAAAAAAAI8s/kaa9yRPAUm0aQQ1J6IFeK5KK8dkJrDcngCKgBGAs/s800/IMG_20170830_203535.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        That along with the letters MAIL, should presumably help make it clear how to use the other two clues in some combination. Then, if everything goes according to plan, he'll log in and get the &lt;i&gt;Elusive Promo Code&lt;/i&gt;.
    &lt;/p&gt;
&lt;h3&gt;The Delivery&lt;/h3&gt;
&lt;p&gt;
        Overall, the delivery didn't go as well as I expected. The big issue was that I didn't make it obvious enough that there was a puzzle to solve. I went out of my way to make it seem like finding the map was an accident, and that the belt came that way. This led to some confusion. Even after my brother knew, he felt too pressured having to work on the problems while visiting family.
    &lt;/p&gt;
&lt;p&gt;
        There was also a technical problem with the construction of the Morse code belt that hampered the puzzle solving. Many of the threads came untied when transporting the belt around so there was an incomplete message by the time my brother was ready to solve the puzzle. In the end, I had to give that clue away because it was just to hard to solve with some threads missing.
    &lt;/p&gt;
&lt;p&gt;
        But in the end, I think my brother was really happy with the effort I put into both gift selection and delivery. And although it took a lot more work, I had a lot of fun building the puzzle. I think I'll try to keep this up with the next gift I give him, and maybe carry it over to my niece when she's old enough.
    &lt;/p&gt;
&lt;p&gt;
        The best part is that since we're brothers, I know that sooner or later the temptation to one-up each other will kick in. I'm looking forward to my brother coming up with something even more clever for my next gift.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 17 Sep 2017 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2017/09/indiana-jones-and-elusive-promo-code/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/09/indiana-jones-and-elusive-promo-code/</guid>
        
        <category>games</category>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <title>Marshalling at Poplar Creek</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: First hand account, additional reflections on life are purely my own musings. &lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        Throughout the past spring, I have been volunteering as a golf marshal at my local municipal golf course. It's a simple, but highly relaxing job, which has given me a new perspective on how a golf course is run and maintained. I'd like to document just what goes into a typical Saturday morning shift at the golf course in this photographic illustration post.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-HfxqZIkhosQ/WUWpoFsLbwI/AAAAAAAAIc8/srWh-DTh7Bo9P42QsWeWeM-TM7tq7m32QCKgBGAs/s800/VID_20170617_074634.mp4&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        On the particular day when I was taking these pictures, Eddie, our Saturday morning &quot;cart guy,&quot; needed me to drive a broken down gas cart as it was being towed.
    &lt;/p&gt;
&lt;h6&gt;Pushing carts around&lt;/h6&gt;
&lt;p&gt;
        Most of the actual work seems to consist of moving golf carts from one location to another throughout the day, which I find to marvellously fun.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-L418Wl3UlY0/WUWjClRRrWI/AAAAAAAAIcU/sPeXgIPGoXonlDGpKSesTbp7B_4CIGqwwCKgBGAs/s800/IMG_20170617_072156.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I line them up in a neat little row. When we run out, I go to &quot;The Barn&quot; to unplug the charging batteries and tow more to the clubhouse.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Z5M31fAc6tE/WUWnsqkuD8I/AAAAAAAAIcw/FopbAMOpnfk5aPzjk_KQy450ct2LB5lBQCKgBGAs/s1600/IMG_20170617_084526.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-AqK0xrqFncE/WUWnsrrO3WI/AAAAAAAAIcw/Q5jUioYM0bMITZ24Ad9PNXCg3Y1haFkyACKgBGAs/s1600/IMG_20170617_084325.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The rugged and useful look of the batteries inside is so surprising compared to the cheap and toy-like look of the cart itself. It seems like so much power when you see the batteries tethered together, and yet it feels so weak when you hear the little whirring motors as you try to climb a 1% incline. I suppose this will enhance my respect someday when I get to see the inside of somebody's Tesla.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-UQfHsOsucYE/WUWnsgYKAsI/AAAAAAAAIcw/ctv7NZxW2QsKq5FaGs50PBaplbDtzBsigCKgBGAs/s1600/IMG_20170617_084337.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Finally, the tow bars tie the carts together into a dopey little snake that slithers through the course. The tow bar connects straight on to the axle, allowing the cart in front to turn the wheel in whatever direction it is pulled.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-PDDs5CFf2xE/WUWnsujMBEI/AAAAAAAAIcw/Yqw6m-sgooYvKyrxFDvO8L-oyVyWqWKPgCKgBGAs/s1600/IMG_20170617_084402.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        It's quite monotonous, but I like the opportunity to not think so much. To just listen to my podcast or audiobook, with the comforting knowledge that there isn't anything else I could be doing then. I committed to this time, and I am stuck in the slow lane for now. Maybe it's partly the golf course, partly the boredom that remind me of when I was young and there was nothing to do in my boring little run-down steel town. It's nice.
    &lt;/p&gt;
&lt;h6&gt;A fine walk spoiled&lt;/h6&gt;
&lt;p&gt;
        I basically spend the rest of the day sitting under this tree and watching golfers pass. There are a wide range of birds that pop in under there: crows down to hummingbirds. If anybody looks angry, I drive around a bit to act as a reminder that other humans still exist in this world.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-gymTypK1gKo/WUWhbw5ZibI/AAAAAAAAIcI/WJ-CcLKN9Z0c9uKODYCEL1tJR1CTjKRPACKgBGAs/s1600/PANO_20170617_090255.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        As I sat there today, I listened to &lt;a href=&quot;http://www.goodreads.com/author/show/10015.Kate_Atkinson&quot;&gt;Kate Atkinson&lt;/a&gt;'s &lt;a href=&quot;http://www.nytimes.com/2013/04/28/books/review/life-after-life-by-kate-atkinson.html&quot;&gt;Life After Life&lt;/a&gt;. Thanks to this little weekly respite, I had a bit of time to wax poetic, aimlessly scrawling on my coffee cup wrapper.
    &lt;/p&gt;
&lt;blockquote&gt;Memory of my future memory of now,&lt;br/&gt;Do I already remember where I'll be and what I'll do Thursday after next.&lt;br/&gt;And if I can't remember yet three Thursdays past, isn't it just as future-like?&lt;br/&gt;&lt;/blockquote&gt;
&lt;p&gt;
        Sometimes it's nice to do a boring thing. Of course, afterwards I have to go home and write about how special this boring thing is.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sat, 09 Sep 2017 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2017/09/marshalling-at-poplar-creek/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/09/marshalling-at-poplar-creek/</guid>
        
        <category>exploring</category>
        
        
      </item>
    
      <item>
        <title>The Stedden Constitution</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: Strongly convinced of personal utility, haven't fully considered all ramifications of broader adoption.&lt;/i&gt;
&lt;/p&gt;
&lt;blockquote&gt;In order that we might form a more perfect union, we aim to adopt this constitution as a set of guiding principles for our partnership. &lt;br/&gt;--&lt;i&gt;Preamble to the Stedden Consitution&lt;/i&gt;&lt;/blockquote&gt;
&lt;h3&gt;The founding of a partnership&lt;/h3&gt;
&lt;p&gt;
        On September 2nd, 2017, Claire Grace Stevenson and William Michael McFadden are going to enter into formal partnership. Oftentimes, this type of partnership is called a marriage, but Claire and I are trying to think of our marriage differently. We want to look at this tradition with fresh eyes, and commit to using this opportunity to meet our own highest aspirations as companions for each other and as human beings.
    &lt;/p&gt;
&lt;p&gt;
        Toward this goal, we have decided to draft a set of guidelines that we will commit to in order to improve our marriage. Since we're both changing our last names to Stedden when we get married (a combination of our last names) and since this is in many ways the founding document of our partnership, we've nicknamed it the Stedden Constitution.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-S0wDJ8pgbIA/WZkQ5QRKtQI/AAAAAAAAI4Q/UPX824oNWMksuOjYVPyabVJdTE7194eGwCLcBGAs/s1600/Screen%2BShot%2B2017-08-19%2Bat%2B9.32.15%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h3&gt;Motivation&lt;/h3&gt;
&lt;p&gt;
        There have been &lt;a href=&quot;https://www.nytimes.com/2017/06/23/style/modern-love-to-stay-in-love-sign-on-the-dotted-line-36-questions.html&quot;&gt;several&lt;/a&gt; great &lt;a href=&quot;http://www.nytimes.com/2012/09/30/fashion/marriage-seen-through-a-contract-lens.html&quot;&gt;pieces&lt;/a&gt; over the past couple of decades based on the idea of setting up some kind of formal document. The main idea is that by putting something in writing, everyone has to think hard about why they feel the way they do, and they can't arbitrarily change their principles when it suits them.
    &lt;/p&gt;
&lt;p&gt;
        Other &lt;a href=&quot;https://waitbutwhy.com/2014/02/pick-life-partner.html&quot;&gt;things&lt;/a&gt; that Claire and I have been &lt;a href=&quot;http://www.slate.com/articles/arts/everyday_economics/1997/09/the_marriage_contract.html&quot;&gt;reading&lt;/a&gt; lately showcased the value of thinking about marriage as a negotiation for mutual benefit and thinking deeply about the cost-benefit of marriage. Ultimately, we are two people who like thinking about our actions and reaching mutually agreeable decisions so we thought this would be a great exercise for us.
    &lt;/p&gt;
&lt;h5&gt;Formalizing our highest aspirations&lt;/h5&gt;
&lt;p&gt;
        We really liked the idea of taking an opportunity to write out our aspirations for ourselves and each other. One of the main reasons for formalizing our relationship with marriage is to attain shared and individual goals that we really wouldn't be able to accomplish without being able to count on each other. But to accomplish those goals, we decided it was important to describe the goals we think are the most important.
    &lt;/p&gt;
&lt;p&gt;
        Here is a brief list of examples of aspirations that we are hoping to attain with each other's help. The full list is in the document below.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Develop understanding of and exercise faculties in diagnosing and treating patterns of irrational conflict inducing behavior&lt;/li&gt;
&lt;li&gt;Fairly allocate resources, despite living in an unfair world&lt;/li&gt;
&lt;li&gt;Ensure that each member of the partnership has all of the communicative and caring personal support they need&lt;/li&gt;
&lt;li&gt;Generate more value for the universe than is consumed by the members of the partnership as well as the additional activities that come about as a direct result of the partnership &lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;
&lt;h5&gt;A just and equitable relationship is by definition a negotiation&lt;/h5&gt;
&lt;p&gt;
        Claire and I both believe that any decisions in a relationship need to look like fair negotiations, with give and take so that both parties can be happy. I will go further with my own opinion: I believe that freedom to choose is truly the most fundamental human right one can give to another. If I had to pick one principle above all it would be that individual freedom should never be impinged without the consent of the individual. From this, it follows that all compromises and resolutions would need to be free negotiations between empowered individuals.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-DRwiRQzZg3E/WZkPGxu_WTI/AAAAAAAAI4E/aR-x7RC8pRQnW80BnP6r9VeGLs-aD2PXwCLcBGAs/s1600/7.jpg&quot; title=&quot;Note: Claire would never use that nail polish &quot;/&gt;
&lt;p&gt;
        Our agreement is putting in place the first formal ground rules for how we would negotiate our most fundamental decisions as our relationship progresses. We treat each other as equal partners and therefore we should write our founding constitution with that in mind.
    &lt;/p&gt;
&lt;h4&gt;Implementation&lt;/h4&gt;
&lt;p&gt;
        It can be tough to get the details right on an agreement like this. We couldn't find too many physical examples of real written marriage agreements despite many people talking about them, which meant we were largely on our own for how to structure it. Obviously, there are a million different ways that this could be done so the task can seem a little daunting.
    &lt;/p&gt;
&lt;p&gt;
        One thing was for sure, we definitely wanted to write all of this down and not count on our memories to keep our agreement in tact! Documentation tends to make us both feel more accountable. I cannot tell you how much more has gotten done in my life thanks to the existence of the TO-DO list. And beyond that, in terms of polishing things and following through, this blog has resulted in me finishing so many projects that otherwise would have sat at 95% done.
    &lt;/p&gt;
&lt;p&gt;
        We also wanted to keep this a living document since we are quite sure that we haven't perfected it yet. In some ways, just the exercise is valuable for helping us to understand each others needs better. Nevertheless, we did get some insight into what we thought would be best for our writing.
    &lt;/p&gt;
&lt;h5&gt;Avoiding obligations&lt;/h5&gt;
&lt;p&gt;
        We don't want this to be the place where we list our pet peeves and household chores. This document is more of a framework for the big picture items that will help us sort out all the smaller things day-to-day.
    &lt;/p&gt;
&lt;p&gt;
        To make sure we didn't get bogged down in too many small issues, I started by basing the outline around the concept of the &lt;a href=&quot;http://felipecastro.com/en/okr/what-is-okr/&quot;&gt;OKR&lt;/a&gt;. OKR stands for Objective and Key Result, and it's a framework developed at Google and used at my current company to keep us focused on our objectives and the key measurable outcomes that will help us determine if we're meeting our objectives. This methodology doesn't perfectly apply to what we were trying to attain with our constitution, but it did help to set the tone for what we wanted. We wanted to make sure we maintained focus on our top objectives and that we included specific actions that would immediately benefit those goals.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-wKw9CfJcunU/WZkbwSykI0I/AAAAAAAAI4g/Jju5gHTCt4EhAixEC6T4wM4MRyU5COQ2QCLcBGAs/s1600/MBO-and-OKR.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Based on this framework, we set up a short list of goals for five topics. Then we added activities and decisions that we will monitor to make sure we are keeping up with our objectives. So for example, one goal of our constitution was to make sure we fairly share our resources, and one action related to that objective was to maintain separate accounts and utilize a system of shared payments and gifts to formalize redistribution of finances. All of these goals and actions were kept at a high level without implementation details so that we could adapt our methods without having to ignore our constitution's guiding principles.
    &lt;/p&gt;
&lt;h5&gt;A political, legal, and economic microcosm&lt;/h5&gt;
&lt;p&gt;
        I like to think that there is an analogy that our partnership is more like the founding of a state than a contract of two business parties. We tried to ensure that we covered all the most important sections of life, and it was interesting to see that they had some interesting parallels with branches of real governments. The main sections that we focused on were:
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;On the resolution of conflicts in the relationship&lt;/li&gt;
&lt;li&gt;On the division of labor and capital&lt;/li&gt;
&lt;li&gt;On intimacy and emotional support&lt;/li&gt;
&lt;li&gt;On respecting the individuality of the members of the union&lt;/li&gt;
&lt;li&gt;On promoting ethical, engaged, valuable interactions with society&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        The first two can really be likened to our own little legal and economic systems, and the rest form the main different dimensions of the political issues that we've found ourselves trying to navigate already. We may someday find other broad areas that need to be incorporated, but for now, we've defined the scope of what our marriage tries to regulate.
    &lt;/p&gt;
&lt;h5&gt;Is this binding?&lt;/h5&gt;
&lt;p&gt;
        Uhhh, probably not. It seems like the only thing in a normal pre-nup is the money stuff. Our agreement on money stuff is that we will keep separate accounts and keep a careful budget to allow us to share expenses fairly. In the event of a divorce, we'll probably be able to use the budget to show how we managed our money during the marriage.
    &lt;/p&gt;
&lt;h5&gt;Timeframe&lt;/h5&gt;
&lt;p&gt;
        We want to make sure this document stays current as our needs and our understanding changes. Therefore, we've set the specific content of this document to be binding only until our first anniversary with the expectation that we will modify and reinstate next year and (hopefully) every year thereafter.
    &lt;/p&gt;
&lt;p&gt;
        For a bit, we considered designing both our constitution and our marriage to become fully optional for continuation after 30 years. The reason we considered this was so that we could plan our lives together for 30 years without expectations or pressure to stay together after that time. Of course, we both firmly believe today that we'll want to continue our marriage for the rest of our lives, but we want to be able to be able to reevaluate the situation without either of us feeling like it would be a betrayal at that time. I liked the idea of 30 years because that is about how long we've lived up to now so it's kind of more sincere to commit ourselves to each other for as long as our current lifetime. Also, this is just enough time for us to raise our family according to our current plan.
    &lt;/p&gt;
&lt;p&gt;
        I personally think that it would be highly logical to start making marriages intentionally optional after child-rearing is over. I know that divorce already makes this the practical outcome for a lot of marriages, but, to me, it would be better if we just made temporary marriage the default state. One factor to consider is that we now live much, much longer than anyone did back when marriage was first invented, and the need to keep two people pinned together indefinitely seems cumbersome as the populace ages. Plus, this would make it even more special when people actively decide to stay together after all that time.
    &lt;/p&gt;
&lt;p&gt;
        Unfortunately, there isn't really any legal way to make a marriage end after a set time period (though I assume that will become standard soon enough). However, we plan to maintain active communication as we approach September 2nd, 2047, to make sure that we want to keep our marriage on the books.
    &lt;/p&gt;
&lt;p&gt;
        It can be a little uncomfortable to talk about these kinds of things just as we're on the cusp of getting married, but on the other hand, these are the realities of the world we live in. It's sort of similar to my job in that no one wants to think about their risk of getting cancer in 10 years, but to me it seems sensible to address this head on and proactively. Based on &lt;a href=&quot;https://www.bls.gov/opub/mlr/2013/article/marriage-and-divorce-patterns-by-gender-race-and-educational-attainment.htm&quot;&gt;statistics for our demographic&lt;/a&gt;, Claire and I have set ourselves up to have a long and happy marriage, with only a 23% chance of being divorced after 15 years together. It's sad that 23% is surprisingly much better than other populations, but we're hoping that makes it all the more special when we succeed.
    &lt;/p&gt;
&lt;h4&gt;The Stedden Constitution - Year 1&lt;/h4&gt;
&lt;p&gt;
        And now without further ado, here is the document in its entirety.
    &lt;/p&gt;
&lt;iframe height=&quot;400&quot; src=&quot;https://docs.google.com/document/d/1ibN5nGRMWRl8JhEBFDqGGvocRhOYD3wT_R9a-eVIO6U/pub?embedded=true&quot; style=&quot;border:1px solid black&quot; width=&quot;100%&quot;&gt;&lt;/iframe&gt; &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h4&gt;Reflections&lt;/h4&gt;
&lt;p&gt;
        For the most part this document is meant to be a reflection on our personal values and our future goals. It's also a reflection on the state of marriage in this world. I believe that an exercise like this would prevent a large portion of failed marriages and broken homes. A few things stand in the way of a good idea like this from catching on in our culture.
    &lt;/p&gt;
&lt;p&gt;
        First, for some reason we culturally seem to have decided that it's distasteful to carefully think about the principles behind their relationships. Rather we spend vast quantities of time thinking about the shallow details of our wedding ceremony decorations, and who needs to be invited. Theoretically, I guess most people should have thought about the underpinnings of their reason for marriage before it gets to this point, but something tells me that it's rarer than one would think.
    &lt;/p&gt;
&lt;p&gt;
        It was a challenge to get this written with the absurdly onerous minutia involved in planning a wedding ceremony. But I'm so thankful that we took the time to draft this carefully and I firmly hope that we can inspire a few others to do the same.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 27 Aug 2017 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2017/08/the-stedden-constitution/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/08/the-stedden-constitution/</guid>
        
        <category>writing</category>
        
        <category>philosophy</category>
        
        
      </item>
    
      <item>
        <title>Theseus and the Cell (a PhD dissertation story)</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: High confidence in technical validity of model, low confidence in biological applications.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        The main reason I haven't been very active on this blog for the past year is that I've been finishing up my PhD thesis. Since it was a big project, I think it deserves a little real estate on this blog of mine, but I don't want to rehash my whole thesis here since that was the point of publishing the dissertation. What I want to do in this blog post is outline the big idea behind my thesis and a couple of the fun things that I did to illustrate it.
    &lt;/p&gt;
&lt;h4&gt;How does an organism change its shape?&lt;/h4&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-aExL4L6pT8g/WTgYr_JKqhI/AAAAAAAAIXE/Cye57SqPgKIwsrX_-gjW-Dh5ANiFTQtOgCLcB/s800/Embryo.gif&quot; title=&quot;Zebrafish developing from 1 cell into an early embryo &quot;/&gt;
&lt;p&gt;
        Imagine you had a shed filled with the most basic tools that you could use for constructing houses, say it just had a ton of hammers and saws. Now, lets say that every day you deliver more raw materials like lumber and nails to that shed. Would you ever imagine that you could come back nine months later and see that that shed had turned into a one bedroom house with a garage? What if you came back twenty years later and that shed had turned itself into a three story mansion with a pool out back? Would you think that's just impossible?
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-wgY_Pxh54es/WTgZm7Mi0yI/AAAAAAAAIXQ/sErKYz5yIOk6NiarvH0StNFGibaE0nZJACLcB/s1600/animation-full-home-remodel1-1.gif&quot; title=&quot; &quot;/&gt;
&lt;hr/&gt;
&lt;p&gt;
        Well that's basically exactly what happens every time a human embryo develops into a newborn baby and then, later, a fully grown adult. You start just with the basic tools for life in a simple package, and over time that simple embryo gets remodelled piece by piece into the person reading this blog post right now.
    &lt;/p&gt;
&lt;p&gt;
        Now, if you are a tinkerer like me, you might guess that all this would take place kind of the same way humans build stuff. We might start with something simple, but when we want to change something, we'll knock down a wall and put up a newer, better one in its place. Or we'll build a separate free-standing building next to the old one and then connect them together after you have both structures made. There are a lot of ways to build things, but the point is at the human scale of construction, we normally work by building something from the ground up with tools from the outside. Then when we want to revise, we build something new and attach it to the old thing or knock the old thing down when it isn't useful anymore.
    &lt;/p&gt;
&lt;blockquote&gt;Reference: &lt;a href=&quot;https://www.google.com/search?q=Dilbert&amp;amp;tbm=isch&quot;&gt;all of Dilbert&lt;/a&gt;&lt;/blockquote&gt;
&lt;p&gt;
        But what's amazing is that cells don't work this way. In fact, they pretty much can't for a couple of reasons:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There are no &quot;outside tools&quot; or an independent construction crew because the organism &lt;em&gt;is simultaneously&lt;/em&gt; the tools, the builders, and the structure being made.&lt;/li&gt;
&lt;li&gt;An individual cell can never totally knock something down and build a new version all at once because that would compromise its current function.&lt;/li&gt;
&lt;li&gt;When we are talking about individual molecules it is really hard to coordinate building things separate from the current cell. On that scale anything you tried to build would quickly float away from the construction site.&lt;/li&gt;
&lt;/ol&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-1_pVNxp68bQ/WTgZ-7lNjeI/AAAAAAAAIXU/6hd7kuprKSESorvZN0KOuUopoTjCTlhpACLcB/s800/roofon.jpg&quot; title=&quot;No giant construction workers for cells :( &quot;/&gt;
&lt;p&gt;
        So how do organisms overcome these obstacles to grow and change their form? Well, basically they do it by constantly making minimal modifications to their own structure, molecule by molecule, until they wind up with all these incremental changes adding up to large scale development. The analogy with builders is if you would move a wall by taking out one nail at a time, slipping the board as far as you can, and then renailing it before moving on to the next nail.
    &lt;/p&gt;
&lt;p&gt;
        We'll see how this works in a minute, but to understand just how they manage to rearrange their own internal parts without any outside help, we have to take a look at the basic building materials of the cell.
    &lt;/p&gt;
&lt;h4&gt;What's a cell made of?&lt;/h4&gt;
&lt;p&gt;
        The structure of almost all the interesting cells in the human body is a big, disordered cage-like web of tiny, molecular fibers made of a protein called &lt;em&gt;actin&lt;/em&gt;. I like to compare it to a messier version of a Zeppelin frame. In this vizualization I made as part of my dissertation defense, I take you on a little tour inside an egg shaped cell to see the orange actin filaments holding the cell together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-HYLaD555oGk/WTa_kUWEfeI/AAAAAAAAIVQ/l-4Sv8gF_MIM0guWbUZAqJ2Wu_JtJLcEQCLcB/s1600/cell_zoom.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The outside coating of this Zeppelin-like cell is a layer of oily goo, called the plasma membrane. On it's own, this oily layer isn't capable of providing much structure at all. Ultimately, if this was all that was holding cells together, a cell (or a Zeppelin) would just flop over in a little puddle of mushy goo (or a deflated blimp).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-pG4jSe0RScI/WTYu-uJpedI/AAAAAAAAITs/l2ImAcyKjms2apZiYoQ0snCWoXS7BCaWgCLcB/s1600/mn_goodyear.jpg&quot; title=&quot;Not the Best Year Not the Best Year&quot;/&gt;
&lt;p&gt;
        What makes the cell strong and able to hold its shape is the cage of molecular fibers that get stuck together by other small sticky proteins to create something like a disordered version of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Geodesic_dome&quot;&gt;geodesic dome&lt;/a&gt;. Inside this cage of actin filaments, the rest of the cell's machinery, like DNA, ribosomes, and mitochondria are free to do their work, largely protected from outside forces.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-GaatGYC44sk/WTYxDu1P1eI/AAAAAAAAIUA/zisPh0_dXQcFsmU8N_Nk8MJODZJO0k2BQCLcB/s1600/3320963272_93c60d29a7_z.jpg&quot; title=&quot;One of Fuller's Geodesic Dome - A mouse cell with actin fibers in green &quot;/&gt;
&lt;p&gt;
        As you can probably guess, it is by rearranging this web of actin filaments that organisms are able to grow, divide, and generally change their shapes. But before we get to describing how the cell does that, lets take a quick trip into an ancient philosophical discussion that helps to illustrate this basic physical system.
    &lt;/p&gt;
&lt;h4&gt;The Ship Of Theseus&lt;/h4&gt;
&lt;p&gt;
        If you know your ancient Greek mythology, you might remember Theseus as the smarter-than-your average hero of ancient Athens. What made Theseus interesting was that he often had to rely on a little cleverness to make his way through (as compared to that dumb jock Hercules). He was most famous for navigating the &lt;a href=&quot;http://www.creativitypost.com/arts/myth_and_creativity_ariadnes_thread_and_a_path_through_the_labyrinth&quot;&gt;labyrinth at Knossos&lt;/a&gt; and slaying the Minotaur&lt;a href=&quot;https://www.youtube.com/watch?v=2aoIs-5zqoI&quot;&gt;&lt;/a&gt;, and he's generally considered to have set up Athens into the &lt;a href=&quot;http://blog.amaliadillin.com/2011/01/theseus-as-father-of-athenian-democracy.html&quot;&gt;ancient model of democracy&lt;/a&gt;. But anyway, this story isn't so much about Theseus as much as it is about &lt;a href=&quot;https://en.wikipedia.org/wiki/Ship_of_Theseus&quot;&gt;his boat&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-zqjzUEG7zco/WTgbY2eV_PI/AAAAAAAAIXg/WZAoGOKdkD4cCneoRxm1NETf0fCiMmsXgCLcB/s1600/ancient-greek-boat.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You see, since Theseus was such a celebrity around Athens, after he died, people kept up maintenance on his ship and sold tickets to go sailing on it. But as time went on, one or two of the boards would get rotten, and so someone would see that those boards were going to cause the boat to sink and they'd replace them. Then a couple of years later, a few different boards would start to rot and somebody else would go and replace them. And every couple of years, this would continue so that there were always a few old boards being removed and a few fresh boards being added.
    &lt;/p&gt;
&lt;p&gt;
        Now this continued for centuries, until eventually somebody noticed that only one of the boards on the boat was actually original anymore. And what's even worse, they noticed when they looked at some old drawings that the layout of the boat wasn't even the same anymore because each time they brought on new wood they would slightly alter how it fit onto the boat.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-FssfV97-NmI/WTgdxn7ytbI/AAAAAAAAIXs/qoCTOJVxOZw48FhgxNIh3GOvDeo-__iZwCLcB/s1600/KOnQ8x.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Now this was ancient Greece so there were a ton of philosophers around (I'm pretty sure philosophy was, like, a quarter of Athens' GDP). And the philosophers liked to point out that pretty soon nobody should be wasting money to go see that boat because it &lt;em&gt;wouldn't be the same boat anymore&lt;/em&gt;. Now everybody understood that philosophers are generally kind of &lt;a href=&quot;http://www.denisdutton.com/bad_writing.htm&quot;&gt;pretentious&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Ethics&quot;&gt;buzz-kills&lt;/a&gt; anyway, but they also had to admit that they were kind of right.
    &lt;/p&gt;
&lt;p&gt;
        The people selling tickets to sail on the ship of Theseus were bummed because this started to hurt ticket sales so they tried to hatch a plan to get the philosophers to agree that it was still the same boat. Fortunately, they'd taken all the old rotting boards and piled them up in the same place over the centuries. On that spot, the boards had already decomposed back into soil, and a bunch of new trees had sprouted up and grown. So the people selling tickets to ride Theseus' ship took the wood from the trees that grew from the ground where the original boards rotted and started to incorporate those boards back into the modern ship.
    &lt;/p&gt;
&lt;p&gt;
        And so they asked the philosophers, &quot;Now since, it's all the same material*, wouldn't you agree that this is still the same ship?&quot; And some of the philosophers agreed and some didn't and this led to a philosophical conundrum about the nature of being... but that is a problem for another kind of &lt;a href=&quot;http://thoughtcatalog.com/maria-noelle/2015/04/the-meaning-of-life-as-explored-by-a-communications-major/&quot;&gt;blog&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The reason I brought this story up was to illustrate the way in which cells remodel themselves over time. Cells break down their actin fibers one at a time and then use the broken down material to build new fibers which they incorporate in different locations. This leads to a slow remodelling of the whole structure without ever losing the overall integrity.
    &lt;/p&gt;
&lt;h4&gt;My computational model of the actin network&lt;/h4&gt;
&lt;p&gt;
        My whole PhD was basically dedicated to using a computer simulation to recreate the molecular processes that cause cells to morph from one shape to another. Although writing the model itself involved a lot of math and computer code, the basic principles underlying the model are pretty simple to explain.
    &lt;/p&gt;
&lt;h6&gt;The structure&lt;/h6&gt;
&lt;p&gt;
        We already went over how the structure of the cell comes from actin filaments &lt;a href=&quot;https://en.wikipedia.org/wiki/Non-covalent_interactions&quot;&gt;sticking together&lt;/a&gt; with other &lt;a href=&quot;https://www.mechanobio.info/topics/cytoskeleton-dynamics/actin-filament-bundle-assembly/&quot;&gt;smaller, sticky proteins&lt;/a&gt;. To get a clearer view of how this actually looks in a real cell here are a few electron microscopy images.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-xTxi9zzUoSQ/WTa9CQV7CuI/AAAAAAAAIVA/ayUf_RE8e7sWEG2T9743NO7azOo2Saa0QCLcB/s1600/309fbe1e5c14522cfa6d3924dc918ff5.jpg&quot; title=&quot;Actin filament network electron microscope images &quot;/&gt;
&lt;p&gt;
        In reference to our analogy of moving one board around at a time to change the structure, the next question that arises is how would the cell move these structural actin filaments around in the first place.
    &lt;/p&gt;
&lt;h6&gt;The movers&lt;/h6&gt;
&lt;p&gt;
        The way these filaments get moved around is ridiculously amazing. Every cell is teaming with nanoscale molecular motors called myosins. These myosins are tiny clumps of protein that burn chemical energy in the cell to generate little tiny tugs on actin filaments. This GIF shows what it looks like for one motor to pull against an individual actin filament. The colorful thing that is moving around is the myosin.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-6-pmB6QKC1Y/WTbUl-5S7gI/AAAAAAAAIV8/735jSANWAsUgFWyEyS632Yg3__-L0hI-QCLcB/s1600/myosin.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        By adding up hundreds of little tugs in different places around the cell, we end up with cellular scale motions. These motions can pull larger protein complexes around the cell or they can even pull against the surface of the cell to cause the cell to pinch in the center for dividing. In this video you can see the actin filaments in white all get pulled into a central ring, and that ring is pulled by the myosins toward the center to pinch the sides of the cell inward.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-EfEXuJXDafc/WTeA6a1PtyI/AAAAAAAAIWU/bzZKt-ykeFMWY7L-HQkIFIBhLY0oVbCVACLcB/s1600/contract_ring.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        What's even more crazy is that this microscopic system for moving around molecular components in the cell is actually evolutionarily conserved with our larger scale system for moving our muscles. Over time, multi-cellular organisms repurposed the function of actin and myosin to generate specialized muscular tissues. Every time we move, it's thanks to the sum activity of billions of actins and myosins working together to produce the macroscopic contractions in our muscles .
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-l_LRsVEi7W8/WTbVMtObn-I/AAAAAAAAIWA/GzNpCUey9tAcL5ke2fSAYkzgR_lqNHSQACLcB/s1600/muscle-contraction-o.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But back on the molecular scale of the cell, all these tiny tugging motions produce highly localized contractions within the cell. In my thesis research, I simulated the mechanical properties of actin filaments and myosin motors to reproduce local contractions of patches of simulated cellular material. In thee next animation, you can see one of the many thousands of simulations I ran to test the model and make predictions about how these cellular materials might behave with different concentrations of motors and filaments.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-0LRpOdmdbvs/WTbEDcIFxfI/AAAAAAAAIVc/vigPRb90Qmc8Ln1xnqDCN9ksSzePGelogCLcB/s1600/contract.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        So (after proving that the simulation makes sense and works right) the next question I asked was whether this model was enough to explain a significant amount of biological information? Could I predict how the cell would move around its structure just by employing my equations for simulated motors and filaments. Well it turns out it isn't quite that simple. If we just left these motors to their own devices, they would eventually either lock up the structure or tear it apart. To show this some of my colleagues, actually mixed purified myosin and actin together an recorded what happened under the microscope. As you can see in this next movie, the patch starts to deform a little bit, but before long, it winds up ripping itself into little chunks.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-BpT9-v3M3jc/WTbLWIfXV1I/AAAAAAAAIVs/Q3om4VQBsoYEDhoGQWuXiuw2c1urTxRPwCLcB/s1600/tearup.gif&quot; title=&quot;Actin and Myosin reconstitution tearing itself apart from Murrell et al. Actin and Myosin reconstitution tearing itself apart from Murrell et al.&quot;/&gt;
&lt;p&gt;
        To keep the cell alive and able to change shape, we have to introduce one more property that lets the actin network refresh itself as it is being moved around.
    &lt;/p&gt;
&lt;h6&gt;Recycling material&lt;/h6&gt;
&lt;p&gt;
        We find that as the motors move filaments around they end up wearing the filaments out so that they can't be moved around too much before they start to break down. So to solve this problem, just like in the ship of Theseus up above, the cell intentionally removes the old actin filaments and uses the material to rebuild fresh filaments that can be used to reconstruct. And also like in the ship of Theseus, the cell is doing this one filament at a time.
    &lt;/p&gt;
&lt;p&gt;
        To actually see this breakdown occur, my colleagues and I developed a method that allowed us to measure how long these filaments lasted before being broken down. We used single-molecule particle tracking movies like this one to watch individual pieces of actin get incorporated into the actin web, sit in the structure for a little while, and then get broken down and disbursed. In this video, you can see the flickering molecules as they get added and removed from the structure.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-ZE-bZYO0Y_c/WTeFeyg7BdI/AAAAAAAAIWg/AFF2kPkv7EAecWfu-uFD1-PwE0OZGfBYACLcB/s1600/tata.gif&quot; title=&quot;Single molecules of actin from Robin et al. Single molecules of actin from Robin et al.&quot;/&gt;
&lt;p&gt;
        I started calling this phenomenon filament recycling because, to me, it seems like the perfect analogy. The cell is actively breaking down its old structural material into its constituent parts and then reassembling those parts in order to rebuild its structure. The name still hasn't caught on (filament turnover seems to be the more popular jargon), but I'm hopeful that I'll be able to check back in on the field in a couple of years and see that they adopted my name.
    &lt;/p&gt;
&lt;h6&gt;Putting it all together&lt;/h6&gt;
&lt;p&gt;
        One of the most interesting things about doing a PhD is that you get to be the first to try something. For my thesis, I got to be &lt;a href=&quot;https://www.nature.com/articles/ncomms10323&quot;&gt;one of&lt;/a&gt; the first people to incorporate this recently discovered biological process of filament recycling into my mathematical model. This movie shows what my simulations looked like when I added in recycling.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-L5ZG2QM7xhQ/WTgeqtHn4SI/AAAAAAAAIX4/JuQbz61R9oUR2Rd9HSb4T0rvnCmggYQzwCLcB/s1600/act_rec.gif&quot; title=&quot;Wibbly wobbly filaments in simulation &quot;/&gt;
&lt;p&gt;
        This bears a striking resemblance with how the actin and myosin look in real cells.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-9JJjh981rXE/WTgf2RQt3gI/AAAAAAAAIYE/EQLG8l6uVV8ZMfQSoOkwISiKEzG40X92wCLcB/s1600/actin_seq.gif&quot; title=&quot;Wibbly wobbly filaments in living cells &quot;/&gt;
&lt;p&gt;
        The main takeaway of this work was that adding recycling prevented the cell from tearing itself to shreds. Beyond the basic observations, using a mathematical model allowed me to make a ton of predictions about how cells work, and it provided the field with some worthwhile ideas to explore in designing new experiments. You can view the &lt;a href=&quot;https://arxiv.org/abs/1612.07430&quot;&gt;preprint of the paper&lt;/a&gt; I wrote with my colleagues describing this research if you are interested to learn more.
    &lt;/p&gt;
&lt;p&gt;
        But most importantly, that wrapped up the body of work that my thesis committee decided was enough to qualify me for a PhD.
    &lt;/p&gt;
&lt;hr/&gt;
&lt;h4&gt;The Seventh Labor - Writing the thesis&lt;/h4&gt;
&lt;p&gt;
        Like Theseus or any hero, just when you thought it was over, there's always a little more to be done. The final step in getting a PhD is to write a massive document and then stand up and give a talk about the work you have done over the years. The talk wasn't that hard for me, but, man, writing the paper was impossible. For some perspective, writing up this blog post took me about 5 hours split up over two nights. Writing up my dissertation took me over two years and I don't even want to think about the number of hours. It was gruelling and &lt;a href=&quot;https://thesiswhisperer.com/2014/09/17/im-writing-a-book-no-one-will-read-and-other-reasons-the-phd-can-get-you-down/&quot;&gt;arguably not really worth it&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        Fortunately, I version controlled the whole thing &lt;a href=&quot;https://github.com/wmcfadden/theseus&quot;&gt;on GitHub&lt;/a&gt; to keep track of the process. Using the &lt;a href=&quot;https://github.com/lots-of-things/git-pdf-viz&quot;&gt;Git PDF Visualizer code&lt;/a&gt; that I &lt;a href=&quot;http://www.makeloft.org/2016/06/git-versioned-pdf-visualizer.html&quot;&gt;wrote about on this blog&lt;/a&gt; last year, I was able to make a cool little video showing the progress.You can see a couple of big lulls when I worked on &lt;a href=&quot;https://www.usenix.org/node/195133&quot;&gt;analyzing datacenter efficiency&lt;/a&gt; and building an &lt;a href=&quot;http://sexpertise.makeloft.org/&quot;&gt;automated doctor&lt;/a&gt;.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/970OKVFPxQQ&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        The finished document was published on some completely ridiculous &lt;a href=&quot;http://www.proquest.com/&quot;&gt;basically inaccessible website&lt;/a&gt;, but you can get a copy &lt;a href=&quot;https://github.com/wmcfadden/theseus/raw/master/theseus/theseus.pdf&quot;&gt;here&lt;/a&gt; if you're dying to read it. Enjoy.
    &lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;
&lt;i&gt;*I know that most of the material in trees comes from CO2 in the air, and not decomposed material in the soil, but we'll just pretend that ancient Athenians didn't know that so the story still works.&lt;/i&gt;
&lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Mon, 14 Aug 2017 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2017/08/theseus-and-cell-phd-dissertation-story/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/08/theseus-and-cell-phd-dissertation-story/</guid>
        
        <category>science</category>
        
        <category>analysis</category>
        
        <category>modeling</category>
        
        <category>biology</category>
        
        <category>physics</category>
        
        <category>writing</category>
        
        
      </item>
    
      <item>
        <title>Analyzing Edge.org forum data - Experiences with Crowdsourcing Analysis</title>
        <description>&lt;p&gt;
&lt;i&gt;Epistemic status: First foray into this type of analysis, expecting a 33% chance of at least 1 major technical error.&lt;/i&gt;
&lt;/p&gt;
&lt;p&gt;
        I recently signed up to take part in an &lt;a href=&quot;https://docs.google.com/document/d/1fXQBLdWydISskOKhoq8gl5unuwsv7VA3pkKY4IWFS6o/edit&quot;&gt;experiment&lt;/a&gt; on crowdsourcing data analysis run by &lt;a href=&quot;https://www.esmt.org/martin-schweinsberg&quot;&gt;Martin Schweinsberg&lt;/a&gt; out of &lt;a href=&quot;https://www.esmt.org/&quot;&gt;ESMT Berlin&lt;/a&gt;. For this project, a bunch of analysts are going to try to determine independently whether a hypothesis is true using the same data set. Then we'll get back together at the end to see how variable our conclusions were. What we really hope to get out of this is some understanding of whether independent analysts can produce reliable reproducible results or if the many different ways of analyzing any complex data source will inevitably lead to discrepancies in interpretation.
    &lt;/p&gt;
&lt;p&gt;
        I'm very interested to be part of this study to promote reproducible and open scientific practices. After seeing the &lt;a href=&quot;https://osf.io/preprints/psyarxiv/qkwst/&quot;&gt;preprint&lt;/a&gt; of the previous round of crowdsourced analysis and Martin's &lt;a href=&quot;https://osf.io/hj9zr/&quot;&gt;crowdsourcing science course&lt;/a&gt;, I feel like this will be an interesting experience. I'm hoping to learn a lot about social science research and statistical inference techniques.
    &lt;/p&gt;
&lt;p&gt;
        I'll be writing more about the collaboration experience in a followup post once I get feedback on my contribution, but here, I wanted to write up my initial analysis of the data. I should point out that I'm not that experienced with social science research so this just a novice's attempt at using some statistical methods. Hopefully, it doesn't turn out that I've made too many mistakes.
    &lt;/p&gt;
&lt;h3&gt;The Edge.org Data Set&lt;/h3&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Uc2ASFAtzV8/WX00JBh5aqI/AAAAAAAAIu0/LVxu5syh8IoFIAM3FbG0tyjxvEeTRZxCgCLcBGAs/s1600/Screen%2BShot%2B2017-07-29%2Bat%2B6.19.08%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        For this study we are going to be trying to answer a few questions about how scientists and technologists communicate. To do this we're going to be looking at communications from an online forum dedicated to scientific discussions called The Edge. I had never heard of it but from what I can gather, Edge.org is designed facilitate important intellectual discussion about the &quot;edge&quot; of what science has concluded about reality.
    &lt;/p&gt;
&lt;blockquote&gt;To arrive at the edge of the world's knowledge, seek out the most complex and sophisticated minds, put them in a room together, and have them ask each other the questions they are asking themselves. &lt;/blockquote&gt;
&lt;p&gt;
        Importantly, the forum isn't open to anyone and the contributors are selected by Edge based on their creative work. These contributors include Daniel Kahneman, Marissa Meyer, Craig Venter, and many other academics as well as writers, entrepreneurs, business leaders, and more. These individuals are supposed to make up a class called the third culture, which I think is in contrast to the two culture mentality of science &lt;i&gt;vs.&lt;/i&gt; &quot;literary intellectuals.&quot; This is how the website describes the third culture:
    &lt;/p&gt;
&lt;blockquote&gt;The third culture consists of those scientists and other thinkers in the empirical world who, through their work and expository writing, are taking the place of the traditional intellectual in rendering visible the deeper meanings of our lives, redefining who and what we are. &lt;/blockquote&gt;
&lt;p&gt;
        To read more about the background on The Edge, you can read &lt;a href=&quot;https://www.edge.org/about-edgeorg&quot;&gt;this historical account&lt;/a&gt; by the creator. But perhaps the easiest way to get acquainted (and the way I first approached it) was to look at a few sample threads.
    &lt;/p&gt;
&lt;h4&gt;Example forum thread&lt;/h4&gt;
&lt;p&gt;
        As a quick example of what conversational threads really end up looking like, I randomly selected a post titled &lt;strong&gt;&lt;a href=&quot;https://www.edge.org/conversation/mirror-neurons-and-imitation-learning-as-the-driving-force-behind-the-great-leap-forward-in-human-evolution&quot;&gt;Mirror neurons and imitation learning as the driving force behind the great leap forward in human evolution&lt;/a&gt;&lt;/strong&gt;
&lt;/p&gt;
&lt;p&gt;
        From the &lt;a href=&quot;https://www.edge.org/conversation/frank_schirrmacher-wake-up-call-for-europe-tech&quot;&gt;few&lt;/a&gt; &lt;a href=&quot;https://www.edge.org/conversation/paul_davies-time-loops&quot;&gt;other&lt;/a&gt; &lt;a href=&quot;https://www.edge.org/conversation/david_gelernter-the-second-coming-%E2%80%94-a-manifesto&quot;&gt;examples&lt;/a&gt; I looked up, I get the sense that, most of the time, the conversation looks kind of like one person going on a rant about their personal project or promoting a book, and then a bunch of academics debating at length who really deserved credit for that idea.
    &lt;/p&gt;
&lt;p&gt;
        While Edge and the third culture ideal is a cool idea, people are people I guess. Fortunately, the content being stuffy academic jibber-jabber makes it easier to analyze the data without getting caught wasting time reading the articles.
    &lt;/p&gt;
&lt;h4&gt;The Edge.org community&lt;/h4&gt;
&lt;p&gt;
        The data table provided for the analysis consists of about 7975 comments provided by 728 users across 522 threads. About half of these threads are actually live recorded discussions, but I removed those to focus down on just online discussion in 3657 comments from 681 users across 344 threads. Some threads were more popular than others, and some users were more prolific than others. To get a sense of the data and the structure of the community generating the data, I started with some basic preliminary plots.
    &lt;/p&gt;
&lt;p&gt;
        One cool thing about the data set is that they have categorized all the community members based on their job title and academic discipline (if they are academics). This gives a pretty clear insight into what kinds of people are making contributions. There are actually a lot of people with non-academic jobs on the forum, though professors do make up the bulk of the population. For those who have a discipline, there seems to be an overabundance of those who focus on social sciences. Of course, I'm not sure if that is due to there actually being more social scientists in the world or if they just are more drawn to this forum, though I suspect the latter.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-lg2ykXC-BYI/WWKOugW2ZuI/AAAAAAAAIps/X6uffXODC90TF_CphAVymOsxILf19X2VQCLcBGAs/s1600/Discipline%2BCount.png&quot; title=&quot; Counts of Users based on Job Title and Discipline. &quot;/&gt;
&lt;p&gt;
        Next, to get a sense of engagement, I plotted the number of contributions coming from each community member as a function of how many years they had been active in the community. The result showed that there were a few members who had been contributing since the forum began, and those few individuals were very active. However, the vast majority of users only made a small number of contributions during 1 year.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-aaVIk_SHwjk/WWKPnrGjRgI/AAAAAAAAIp0/8kleJpBM1e0lxmSteIS2D5CeX8kTY4ccACLcBGAs/s1600/YearsContrib%2Bvs%2BTotal%2BContribs.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Finally, this last set of figures shows that certain threads were more popular than others, and that the number of threads created has varied by quite a bit over the years.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-M1X5O7CYA0g/WWKPs31_xjI/AAAAAAAAIqE/bkHwg5fr91goze6PQjicOrwWogqs-Z3XQCLcBGAs/s1600/DebateSize%2BCount.png&quot; title=&quot;Thread contribution stats &quot;/&gt;
&lt;p&gt;
        Fortunately, the forum data hasn't offered too many surprises up to now. So I feel a little more comfortable using it to address the hypotheses that I've been tasked with investigating.
    &lt;/p&gt;
&lt;h3&gt;Testing hypotheses&lt;/h3&gt;
&lt;p&gt;
        The aim of this project is to test two hypotheses provided by the project organizers.
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A womans tendency to participate actively in the conversation correlates positively with the number of females in the discussion.&lt;/li&gt;
&lt;li&gt;Higher status participants are more verbose than are lower status participants.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        By the end, I know I'm supposed to provide some type of effect size to display the significance of any finding. I normally don't work in the language of formal effect sizes (folks at the company I work for glaze over when I toss around p-values) so I'm going to try to keep my analysis simple. Hopefully if I just follow the basic guidelines on linear models, I can justify my usage to any reviewers.
    &lt;/p&gt;
&lt;p&gt;
        I'm personally much more interested about the question of female participation in science. From personal experience, I've noticed differences in communication styles between men and women and I thought it would be interesting to see if there were signals of those differences in the online forum data. At the same time I also like the idea of comparing the verbosity of academics, particularly comparing how verbose individuals from different disciplines and job descriptions might be.
    &lt;/p&gt;
&lt;p&gt;
        In the following two sections, I'll go through my analysis of each hypothesis separately.
    &lt;/p&gt;
&lt;h4&gt;Contributions from Women&lt;/h4&gt;
&lt;p&gt;
        I find that a lot of the nuance of which direction I'm going to pursue comes down to how I'm interpreting the hypothesis.
    &lt;/p&gt;
&lt;blockquote&gt;A womans tendency to participate actively in the conversation correlates positively with the number of females in the discussion. &lt;/blockquote&gt;
&lt;p&gt;
        To flesh out the first hypothesis, I needed to specify what participation means. I'm going to interpret the hypothesis as valid if I can detect whether a woman joining in on a conversation depends on how many other women are in the conversation.
    &lt;/p&gt;
&lt;h5&gt;Female contributions across threads&lt;/h5&gt;
&lt;p&gt;
        To begin, I wanted to test the simplest evidence that would point to the hypothesis being true. Can I detect whether women self-segregate into certain threads? In other words, are there some threads with a lot more women than we would guess.
    &lt;/p&gt;
&lt;p&gt;
        The easiest way to see this would be to just visually check if there are lots of crazy outlier threads in terms of female contribution. We can plot the fraction of women in each thread along with a confidence interval to see if there. I used a Wilson confidence interval to determine the significance of the discrepancy from the expected proportion given the sample size in each thread. Because the confidence intervals on very small samples are too large to be meaningful, I've filtered out the threads that have fewer than 5 people.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-pwLX-PJch9c/WWKYJnX3C0I/AAAAAAAAIqQ/a8y7Us9-ZAwPMbB1vDxtp7363QgkqrbFACLcBGAs/s1600/Female%2BFraction%2BDiscrepancy.png&quot; title=&quot;Confidence intervals for each thread shows that most threads have a fair distribution of women. &quot;/&gt;
&lt;p&gt;
        It looks like there are basically only 3 threads that don't overlap with the expected proportion (solid lines). So at the simplest level, it seems that women are participating in all threads about as much as we would expect.
    &lt;/p&gt;
&lt;p&gt;
        We can also perform a statistical test of the female proportion of contributors in each thread using a chi squared test of homogeneity. This can be performed easily with R's prop.test function. The results of my prop test (below) show that the differences between female proportion are not significant enough to conclude that women are segregating into groups and only talking with one another. The p-value on the prop test was 0.12, which is widely accepted as &lt;a href=&quot;http://blog.minitab.com/blog/understanding-statistics/what-can-you-say-when-your-p-value-is-greater-than-005&quot;&gt;not significant&lt;/a&gt;.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;span style=&quot;color:brown&quot;&gt; prop.test(thread_info$UniqueFemaleContributors,thread_info$UniqueContributors) &lt;/span&gt;&lt;br/&gt;&lt;br/&gt; 93-sample test for equality of proportions without&lt;br/&gt; continuity correction&lt;br/&gt;&lt;br/&gt;X-squared = 107.96, df = 92, p-value = 0.1224&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        At this point, I'm thinking that I would feel pretty comfortable concluding that female participation is largely unbiased across threads. However, this is a rich data set so I wanted to continue with some more exploratory analysis.
    &lt;/p&gt;
&lt;h6&gt;Digging deeper: female demographics by discipline and job, effects of time, and total contributions&lt;/h6&gt;
&lt;p&gt;
        There is some concern that different covariates could influence the rates of female participation. Particularly, I was interested in the gender skew among different disciplines and jobs. Plotting the community size as well as the female makeup of each community showed that female job titles and disciplines were not evenly distributed.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-HQZyi6AXKz8/WWKscPWpgbI/AAAAAAAAIqk/0HhH0ltECE4OunmkYSC4NWDDYY2PhzCvwCLcBGAs/s1600/fraction%2Bfemale%2Bdiscipline.png&quot; title=&quot; Line is Female Fraction (apologies for being same color) &quot;/&gt;
&lt;p&gt;
        The result is largely what you'd expect. Natural science and math is underrepresented in their share of women compared to humanities and social sciences. And the more prestigious professions also show a lower proportion of women. However, the effects are not as severe as you might think. The groups all mostly overlap, but you can tell that there are trends that would probably shake out if we had more participants.
    &lt;/p&gt;
&lt;p&gt;
        A much bigger issue is that female participation hasn't been constant over time. In fact, the outlying threads from the previous analysis were all from 2010 onward. Obviously, that will be a potential confounding variable in the analysis. As you can see from the following figure, the fraction of contributions from women grew considerably over the past 20 years.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-IWZyetk5r_E/WWKtyACHlaI/AAAAAAAAIqw/dStR3ZFVBWgonE2SXGg90mrNZznvlbo_QCLcBGAs/s1600/Female%2Bby%2Byear.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Related to this, there is also one other interesting quirk in the number of contributions made by individuals relative to how long they have been in the community. This last plot basically shows that for recent users the number of contributions made by men and women is approximately the same. However, for users who have been involved for more than 10 years or so, the men seem to have been much more active.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-uvFu8rtx51s/WWKvKmw6xVI/AAAAAAAAIrA/EHi-f20G_7ccqnyFfyhINeAYUIyz27JBACLcBGAs/s1600/Rplot01.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This shouldn't really affect our results, but it's interesting, and it might be useful to keep it in mind.
    &lt;/p&gt;
&lt;p&gt;
        Taking all of this into account, I wanted to attempt a slightly more sophisticated methodology for modeling female participation.
    &lt;/p&gt;
&lt;h5&gt;Predicting the gender of the next contributor&lt;/h5&gt;
&lt;p&gt;
        As a final test, I wanted to see whether there was any information about a thread that could be used to predict whether the next person to enter the thread would be a woman. My reasoning behind this was that any variable that would be shown to significantly affect the prediction would meet some definition of significance. Therefore, if the fraction of women participating was predictive, we could conclude that women must be using that information to influence whether they enter the conversation. I believe this is generally how people do &lt;a href=&quot;http://www.pitt.edu/~wahed/teaching/2083/fall10/Lecture610.pdf&quot;&gt;statistical inference&lt;/a&gt; from linear models, but I could be wrong. In the past, I've mostly always used fitting techniques like this to infer &lt;a href=&quot;http://courses.washington.edu/matlab1/ModelFitting.html&quot;&gt;error estimates on parameter values&lt;/a&gt; (I used to be a physicist after all).
    &lt;/p&gt;
&lt;p&gt;
        The way I will operationalize this is to try to predict the gender of each new contributor to a thread given the information about the thread up to the point before this contributor joined. I chose this metric specifically because I didn't want to include any influence from that participant having already joined in the conversation. Therefore, what I'm looking at is the probability that given a new person enters the conversation, what is the probability that that participant is a female.
    &lt;/p&gt;
&lt;p&gt;
        The main variable I want to test to see if it affects this probability is the fraction of previous contributions in a thread that came from women. To test this variable I had to construct it by using a running sum of the number of unique participants and thread responses from both men and women.
    &lt;/p&gt;
&lt;p&gt;
        In addition to this primary metric of interest, I also wanted to include a few covariates that I thought might be of interest. In particular, I wanted to see if the thread year, and the overall thread progress (i.e. what fraction of the total length of the thread has already occurred before the participant under question joins the converstaion.)
    &lt;/p&gt;
&lt;p&gt;
        Without controlling for thread year, I found a very slight effect of the cumulative fraction of comments that came from women.
    &lt;/p&gt;
&lt;p&gt;
        Additionally, I also found an effect from the thread progress. Women seemed to be less inclined to enter a conversation as it was nearing it's end.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-t3fViz9NUdk/WWK8UIzcAzI/AAAAAAAAIrU/imVQj5jm_CMWsohTG5vvgDyFmZ7sMjX6QCLcBGAs/s1600/thread%2Bprogress.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I used the &lt;a href=&quot;https://stat.ethz.ch/R-manual/R-devel/library/stats/html/glm.html&quot;&gt;R glm function&lt;/a&gt; to &lt;a href=&quot;http://www.ssc.wisc.edu/sscc/pubs/RFR/RFR_RegInference.html&quot;&gt;infer the significance&lt;/a&gt; of the two contributions. The code below produces a summary of the model, with the estimated coefficients and the their test statistic (see wikipedia for more details on the &lt;a href=&quot;https://en.wikipedia.org/wiki/Wald_test&quot;&gt;Wald test&lt;/a&gt;).
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;span style=&quot;color:brown&quot;&gt;&amp;gt; model = glm(Female ~ OtherFemale_CumFrac + ThreadProgress, family = 'binomial', data_th1 )&lt;br/&gt;&amp;gt; summary(model)&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Call:&lt;br/&gt;glm(formula = Female ~ OtherFemale_CumFrac + ThreadProgress, &lt;br/&gt;    family = &quot;binomial&quot;, data = data_th1)&lt;br/&gt;&lt;br/&gt;Coefficients:&lt;br/&gt;                    Estimate Std. Error z value Pr(&amp;gt;|z|)    &lt;br/&gt;(Intercept)          -1.9450     0.1233 -15.774  &amp;lt; 2e-16 ***&lt;br/&gt;OtherFemale_CumFrac   1.4296     0.4605   3.104  0.00191 ** &lt;br/&gt;ThreadProgress       -0.4739     0.1946  -2.436  0.01485 *  &lt;br/&gt;---&lt;br/&gt;Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        In the last column, Pr(&amp;gt;|z|), a p-value is computed for that variable given all the information from the rest of the model. Thus both ThreadProgress and OtherFemale_CumFrac show some correlation with the outcome in question even when taking the other variable into account. From this we could conclude that there is some significant correlation between women joining the conversation and the percent of comments thus far that came from women.
    &lt;/p&gt;
&lt;p&gt;
        I submitted the above result because I was in a rush to meet the deadline, BUT the story isn't quite over. Long story short, I missed a BIG issue that basically invalidated my result!
    &lt;/p&gt;
&lt;h5&gt;OOPS! Adding Thread Year as a Covariate&lt;/h5&gt;
&lt;p&gt;
        I mentioned in my analysis abover that female participation varied with thread year. Unfortunately, I forgot to include that as a covariate when performing the regression above. When taking year into account, the significance of the above result evaporated.
    &lt;/p&gt;
&lt;p&gt;
        Basically, all I had to do to fix the problem was add thread year back into the equation for the glm. Had I done that in the beginning I would have found the following result.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;span style=&quot;color:brown&quot;&gt;&amp;gt; model = glm(Female ~ OtherFemale_CumFrac + ThreadProgress + Year, family = 'binomial', data_th1 )&lt;br/&gt;&amp;gt; summary(model)&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;Call:&lt;br/&gt;glm(formula = Female ~ OtherFemale_CumFrac + ThreadProgress + &lt;br/&gt;    Year, family = &quot;binomial&quot;, data = data_th1)&lt;br/&gt;&lt;br/&gt;Coefficients:&lt;br/&gt;                      Estimate Std. Error z value  Pr(&amp;gt;|z|)    &lt;br/&gt;(Intercept)         -101.33251   23.40287  -4.330 0.0000149 ***&lt;br/&gt;OtherFemale_CumFrac    0.60656    0.52847   1.148    0.2511    &lt;br/&gt;ThreadProgress        -0.49821    0.19466  -2.559    0.0105 *  &lt;br/&gt;Year                   0.04958    0.01167   4.248 0.0000216 ***&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        From the last column, Pr(&amp;gt;|z|), we can see the significance p-value is well below 0.05 for the Year variable, whereas the OtherFemale_CumFrac variable is now at 0.25 and thus not significant. Therefore, I have to reject the hypothesis that female participation has been influenced by anything other than time at this point.
    &lt;/p&gt;
&lt;h6&gt;Takeaway: no evidence for the hypothesis &lt;/h6&gt;
&lt;p&gt;
        Although, I did find a slight effect, the confounding variable of thread year appears to be the real predictor. Therefore, we should accept the null hypothesis that women's participation is not influenced by the participation of other women.
    &lt;/p&gt;
&lt;p&gt;
        Unfortunately, I didn't double check my work until I started writing this blog post! That means the answer I submitted has a MUCH higher significance that I really found. Oh well, I suppose these are the growing pains of trying to learn how to use an online collaborative data analysis framework. At least I learned, that I need to write up my analysis BEFORE I submit it to make sure my thinking is clear.
    &lt;/p&gt;
&lt;h4&gt;Verbose Academics?&lt;/h4&gt;
&lt;p&gt;
        There was a second hypothesis to be tested as part of this project.
    &lt;/p&gt;
&lt;blockquote&gt;Higher status participants are more verbose than are lower status participants. &lt;/blockquote&gt;
&lt;p&gt;
        I was significantly less interested in this question so I won't speak to as much detail on this problem as I did above. But there were some interesting points which I'll highlight quickly.
    &lt;/p&gt;
&lt;h5&gt;What specifically should we test&lt;/h5&gt;
&lt;p&gt;
        This problem is kind of hard because there are lots of reasonable ways to operationalize &quot;verbosity,&quot; and answering this hypothesis really requires picking a definition. I actually tested three related measurements before getting to one that had a very weak observable effect. The forum post data included precomputed text analysis of the &lt;a href=&quot;http://liwc.wpengine.com/&quot;&gt;LIWC metrics&lt;/a&gt;. These metrics basically try to boil down complex properties of text into simpler metric(see &lt;a href=&quot;http://liwc.wpengine.com/wp-content/uploads/2015/11/LIWC2015_LanguageManual.pdf&quot;&gt;this manual&lt;/a&gt; for lots of details). I just used three simple metrics that I thought would be good measures of verbosity:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;total word count per post (WC),&lt;/li&gt;
&lt;li&gt;word count per sentence (WPS),&lt;/li&gt;
&lt;li&gt;and the LIWC metric for usage of words that are six letters or longer (Sixltr).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        For the dependent variable I tried a couple of metrics all of which related to the total citations of the user up to the point of their last contribution on the forum. They all showed basically the same thing so, in the interest of brevity, I'll just report results in terms of the total number of citations. Basically my less ambiguous hypothesis ended up being:
    &lt;/p&gt;
&lt;h6&gt;Does a users word usage relate to the number of citations they've had?&lt;/h6&gt;
&lt;p&gt;
        I figured the main confounding variables for this study would be the discipline and job title of the contributor so I decided to do a little exploration to see how those related.
    &lt;/p&gt;
&lt;h5&gt;How discipline and job affected verbosity&lt;/h5&gt;
&lt;p&gt;
        This was one of the things I wanted to know the most. After having lived with three anthropologists for about 6 months, I had a pretty solid preconceived notion about how verbose people in the humanities were. Just plotting the WPS and Sixltr metrics showed that there was some pretty noticeable discrepancies between the disciplines, with social science and humanities coming in at the high end for word length, and social science and natural science coming in at the high end for the Sixltr score.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-OUO5bWa1eIw/WWLffONo6nI/AAAAAAAAIr0/a4YFQnvUKcUnMJSIX5Ifw1RiCDifcP6AQCLcBGAs/s1600/Sixltr%2BDiscipline.png&quot; title=&quot;  Different disciplines write differently (not that surprizing) &quot;/&gt;
&lt;p&gt;
        Likewise, when looking at the effect of job title on word count (WC), it seemed pretty clear that the academic job titles were more inclined to writing longer posts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Wvw15DFVC1Y/WWLhm-rufUI/AAAAAAAAIr8/Iot7L_sES-Yv9uSf5nWPDDGMl1B2YX3qACLcBGAs/s800/job%2Btitle%2BWC.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Clearly, with the large, significant effects that these variable imparted, I figured it might be hard to pick up much signal from the impact of citations.
    &lt;/p&gt;
&lt;h5&gt;Impact of citations on verbosity&lt;/h5&gt;
&lt;p&gt;
        Interestingly, any effect of citations on verbosity seemed to be at best discipline and job specific. As an example, we can look at the effect of citations on a user's mean Sixltr score, while comparing only members of the same discipline. In the following figure, I group and color users by discipline so that you can follow a colored line to see what the average effect citations had on the Sixltr score.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-BhuPN7abqok/WWLbdSiYtTI/AAAAAAAAIrk/gq_ubjJg94UBbG0XFnUeH1lc22CZhTacACLcBGAs/s1600/citation%2Bsixltr%2Bdiscipline.png&quot; title=&quot;Effect of citation count varies across disciplines &quot;/&gt;
&lt;p&gt;
        As you can see most of the disciplines actually have a negative correlation between citations and number of six letter words used. However, the natural sciences seems to show a positive correlation. Likewise, we can look at the same measurement while comparing among members of the same academic hierarchy (1 being assistant professor and 6 being chaired professor).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-yQQhouV2BZ0/WWLcBRolc9I/AAAAAAAAIro/gOi2q1yys7cdk7A9Kv3wInBaNAXBeQRhwCLcBGAs/s1600/citation%2Bsixltr%2Bhierarchy.png&quot; title=&quot;Effect of citation count varies across echelons of academia &quot;/&gt;
&lt;p&gt;
        Again, the results are all over the place, with higher academic rank showing a positive correlation while a lower academic rank has a negative correlation. However, the folks with a low academic rank and few citations appear to be just as verbose as those with a high academic rank and many citations. It almost looks like there is a &lt;strong&gt;valley of verbosity&lt;/strong&gt; among the middle of the pack.
    &lt;/p&gt;
&lt;p&gt;
        To make a long story short, this is the kind of data where you can slice any story out of it that you want. I chose to keep my tests simple and linear so I had a pretty good feeling that I wasn't going to find any strong effect in this data set.
    &lt;/p&gt;
&lt;h6&gt;Results of the modeling&lt;/h6&gt;
&lt;p&gt;
        Finally, I tested the hypothesis using the same glm formula as before, though this time I was predicting a &lt;a href=&quot;https://en.wikipedia.org/wiki/Normal_distribution&quot;&gt;gaussian&lt;/a&gt; variable rather than a &lt;a href=&quot;https://onlinecourses.science.psu.edu/stat200/node/37&quot;&gt;binomial&lt;/a&gt;. It turned out that WC and WPS had almost no effect so I will just show the results for Sixltr since that was more interesting.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;Call:&lt;br/&gt;glm(formula = Sixltr ~ Total_Citations, family = &quot;gaussian&quot;, &lt;br/&gt;    data = user_wc)&lt;br/&gt;&lt;br/&gt;Coefficients:&lt;br/&gt;                    Estimate   Std. Error t value Pr(&amp;gt;|t|)    &lt;br/&gt;(Intercept)     28.492929260  0.510552842  55.808   &amp;lt;2e-16 ***&lt;br/&gt;Total_Citations -0.000008705  0.000014841  -0.587    0.559    &lt;br/&gt;---&lt;br/&gt;Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        Again, if we analyze the printout, we can see that the p-value for Total_Citations is well above the minimum for significance of 0.05. Thus we would reject that Total_Citations has much of an impact on Sixltr. I repeated this modeling exercise for a bunch of different citation related variables and seeing if they had an impact on WC, WPS and Sixltr. None of them showed significant results. I also tried a few &lt;a href=&quot;http://www.public.iastate.edu/~alicia/stat328/Multiple%20regression%20-%20higher%20order.pdf&quot;&gt;second order models&lt;/a&gt;, where I looked at whether citations could have a different impact given combinations of other variables (e.g. did citations matter if we controlled for tenured professors in the social sciences). I started to see a few significant results (p &amp;lt; 0.05), but by that time I had been testing so many hypotheses that I was going to need some serious effect sizes to believe anything. &lt;/p&gt; &lt;h6&gt;Takeaway: basically no evidence for the hypothesis. &lt;/h6&gt;
&lt;p&gt;
                I had to conclude that citations as a measure of academic status wouldn't map directly to usage of six letter words. But at this point in the project, I was running low on time, and every code rerun correlated with me uttering four letter word. Eventually, I had to give up even though I wasn't totally satisfied with my results.
            &lt;/p&gt;
&lt;p&gt;
                As usual, all my code is on the lots-of-things Github for you to tear into should you so desire. Best of luck, and hope you can get further on it than I did.
            &lt;/p&gt;
&lt;i&gt;
&lt;h6&gt;* A note on dataexplained.org&lt;/h6&gt;
&lt;p&gt;
                    As part of this project, we were initially supposed to do all of our analysis using the website &lt;a href=&quot;http://dataexplained.org&quot;&gt;dataexplained.org&lt;/a&gt;. This site had an &lt;a href=&quot;https://www.rstudio.com/&quot;&gt;RStudio&lt;/a&gt; console that recorded every line of code that was executed. Based on &lt;a href=&quot;https://www.youtube.com/watch?v=Do3bQ7TvDcM&quot;&gt;the video instructions&lt;/a&gt;, the analysts were then supposed to group their code into logical blocks and document why they chose that line of reasoning. Initially, I thought this was an awesome idea, and I was excited to try to use it to record and document my analysis process. Unfortunately, the website was poorly designed and I quickly started to experience performance problems that made it impossible to use it. The IT team eventually fixed the issues but by then I had already started doing a fair bit of work locally. I manually reproduced the majority of the work in the interface, but I'm disappointed that the interface wasn't really built well enough to make it useful. In particular a lot of the questions they ask are poorly worded, which just leads skipping the question. Hopefully in future rounds, there will be a better method to record every step of the process.
                &lt;/p&gt;
&lt;/i&gt;&lt;br/&gt;
</description>
        <pubDate>Sat, 29 Jul 2017 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2017/07/experiences-with-crowdsourcing-analysis/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/07/experiences-with-crowdsourcing-analysis/</guid>
        
        <category>data science</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>Engagement Ring from Found Smoky Quartz</title>
        <description>&lt;img border=&quot;0&quot; height=&quot;480&quot; src=&quot;https://1.bp.blogspot.com/-FEZWAlMmtRk/WPGKsWYHewI/AAAAAAAAH9g/037ZKdxEiSUOLBbK6dS8No0WEsk6O1dQgCLcB/s640/IMG_4928.jpeg&quot; style=&quot;display:none&quot; width=&quot;640&quot;/&gt;
&lt;p&gt;
        Sometimes you try something that you're just sure will never work, yet somehow, even though you almost can't believe it, things work out just perfectly. When my fiancee, Claire, and I talked about getting engaged, we dreamed about how cool it would be to make the engagement ring from scratch from a gem we found ourselves. We never really thought that it was possible, but for some crazy reason, Claire let me plan a trip to &lt;a href=&quot;http://academic.emporia.edu/aberjame/student/rice1/CMB.htm&quot;&gt;Colorado's mineral belt&lt;/a&gt; to see what we could find. This is the story of how we just got plain old lucky despite not knowing what the heck we were doing.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-CMwyQbs4kWg/WM7msXQA_KI/AAAAAAAAHpc/Er2v5B6ajBcnbqpJuYfwlmHQakkBuitkQCKgB/s1600/Image.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In a lot of ways it's a perfect way to sum up just how lucky we've been to have found each other too, even though we never could have believed it would happen.
    &lt;/p&gt;
&lt;h4&gt;Finding our treasure&lt;/h4&gt;
&lt;p&gt;
        Believe it or not, there's still an abundance of gemstones just waiting to be found out there. As an example, just the other day I found this beauty while I was out on my run on a trail around Burlingame, CA.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-coxKnXgMAvk/WM84r2-sp9I/AAAAAAAAHqU/bxBW9285HyAs6aK42ykq4zsFei5F38ZTQCLcB/s1600/IMG_20161202_092350.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;strong&gt;Just kidding.&lt;/strong&gt; That &quot;gem&quot; was plastic, and truth be told it's a heck of a lot harder to find a gem than going for a jog in a crowded suburb. But then again, that's kind of the point: rockhounding is a great way to get into the less travelled parts of the great outdoors.
    &lt;/p&gt;
&lt;h5&gt;Rockhounders are we.&lt;/h5&gt;
&lt;p&gt;
        Rockhounding is another word for &lt;a href=&quot;https://en.wikipedia.org/wiki/Amateur_geology&quot;&gt;amateur geology&lt;/a&gt;. Yes that's right, regular people are capable of finding interesting rocks and gems. Toward the middle of the 20th century, there was a surge in the popularity of recreational rock and gem collecting in the US. There are still &lt;a href=&quot;https://www.gemsociety.org/article/mined-in-america/&quot;&gt;many areas&lt;/a&gt; in the US where amateurs will try their luck, but the widespread popularity of gem collecting seems to have ebbed substantially since its heyday.
    &lt;/p&gt;
&lt;p&gt;
        Because minerals are a fundamentally limited resource, it can be tough to find the best spots. Most material on the internet is fairly sparse and tough to interpret, but the Bob Loeffler's &lt;a href=&quot;http://www.peaktopeak.com/&quot;&gt;peaktopeak website&lt;/a&gt; has done a really great job of collecting and mapping many &lt;a href=&quot;http://www.peaktopeak.com/colorado/index.php3&quot;&gt;mine sites around Colorado&lt;/a&gt;. Another great resource for rockhounding sites was the &lt;a href=&quot;https://books.google.com/books/about/Colorado_Rockhounding.html?id=7EJavgAACAAJ&amp;amp;source=kp_cover&amp;amp;hl=en&quot;&gt;Colorado Rockhounding&lt;/a&gt; by Stephen M. Voynick. In addition to ultimately leading us to the sites where we had the most luck, this book also gave us some context to understand the history of Colorado's mineral belt.
    &lt;/p&gt;
&lt;h5&gt;Treasure Falls&lt;/h5&gt;
&lt;p&gt;
        Yes, it sounds too good to be true, but we found the gem that I proposed with at Treasure Falls. We were up in the clouds looking in the rock piles below this area where road crews had blasted through the side of the mountain. Our rockhounding book suggested that these were really great places because they offered freshly exposed rock that hadn't been picked through already.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-HscuaQ0wUwQ/WNnIrC3jneI/AAAAAAAAH4E/wHwB2ApZGqo9h1rtvb3RWg2zMKOgpwYyACLcB/s1600/IMG_4190.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This was basically the first site that we spent a lot of time investigating. From the beginning, we found many pretty rock in the rock piles where the rubble was collected, but none of them really seemed to be gemstones at all. Claire stayed in the rock piles while I ventured out closer to the exposed side of the mountain nearer the road. As I was looking through that region a lot of small rocks kept falling down towards where I was searching, which was a little nerve racking. Eventually, I found what looked like a black meteor, broken into three parts, with a little purplish-clear nugget right in the center.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-gN1h151CD_M/WNnKyM_TceI/AAAAAAAAH4g/RvzfhSlTA-QpF_x1Koab_aXuzFy9h1yEACLcB/s1600/IMG_4205.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-opKDiuwtH7o/WNnK12JQKqI/AAAAAAAAH4k/ilhD3_KRLPQRJjyBk5OGFwafn7MIkw-lACLcB/s1600/IMG_4212.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I rushed back over to Claire carrying the rock. I knelt down in the mud around the rock piles she was searching in and presented her with 15 lbs. of rock with a golf ball-sized smoky quartz in the center. Then I asked her to marry me, and she said yes!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-tx46PfwBXe4/WM9HHG6qw0I/AAAAAAAAHrE/AE84mFi5DLkIs7_naaukoarZkzLtHFXGgCLcB/s1600/IMG_2977.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        She was blown away that I'd found something. To tell the truth, she had kind of been doubting that this little adventure would turn up anything. I thought we'd find something, but I never thought we'd find something quite that large and beautiful. After spending the whole rest of trip trying to find any more interesting rocks and gems, we never topped that first find.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-sNTRQ4CnYrg/WNnJpT0pKzI/AAAAAAAAH4Q/iKlYLRUHcTg_Pr7M339zsNLvrMm2SyUFACLcB/s800/IMG_4188.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Claire and I have decided we're hooked on rockhounding. Searching for something really focuses your senses and helps you to take in the details of your surroundings to a level that you sometimes lose during a long day of hiking. Collecting rocks (or plants for that matter) can be a great way to motivate you to keep going that next little stretch of trail. I'll never forget one of our best hikes at high elevation surrounded by these old abandoned mine shafts. We didn't find much other than a little silver, but we kept going up and up the mountain in a chilly rain, carrying heavy chunks of rock until we just couldn't make it another step... and then we had to get back before dark. Rockhounding is really an adventure, and I suggest it if you're into hiking off-the-beaten-path kinds of places.
    &lt;/p&gt;
&lt;h5&gt;Learning what we had&lt;/h5&gt;
&lt;p&gt;
        To be honest, when collecting, Claire and I really just looked for shiny things and carried back anything that looked pretty and interesting. To learn what we had, we brought our haul into the &lt;a href=&quot;http://www.mines.edu/Geology_Museum&quot;&gt;Colorado School of Mines Geology Museum&lt;/a&gt; in Golden, CO. The museum curator was nice enough to go through our minerals and gems with us. This was where we learned that the geode I'd proposed with had been an &lt;a href=&quot;https://en.wikipedia.org/wiki/Agate&quot;&gt;agate&lt;/a&gt; or a &lt;a href=&quot;http://www.quartzpage.de/gen_types.html#CQ&quot;&gt;cryptocrystalline quartz&lt;/a&gt;. Being a quartz means that it is composed of silicon and oxygen. Cryptocrystalline refers to the fact that the silicon oxide doesn't form a perfectly repetitive crystal, but instead there are many mini-crystals that aren't quite perfectly aligned. It's relatively common and not normally considered a precious gemstone, but that doesn't diminish it in our hearts any.
    &lt;/p&gt;
&lt;h4&gt;Cutting the Stone&lt;/h4&gt;
&lt;p&gt;
        At first, I was pretty sure that I could shape a part of the geode into the faceted stone for Claire's ring myself. We found a smallish section with some oblong agate-like rings that we chiselled away from the darker stone to make the ring.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-RalG2WbInrg/WNnM8mhwIlI/AAAAAAAAH5E/pU_tKifu6j4oz6R8TumW3r7SK7FpmuPPACLcB/s800/IMG_4309.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        With the chunk that came out ther was still a lot of work to do to remove the excess debris and shape it into a decent chunk for faceting and polishing. I spent a whole weekend with a diamond edged Dremel slowly carving down the piece to get it close to the right size.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Pl0K_mqPglk/WNnM7oNDM4I/AAAAAAAAH5A/aRO38-GIP_8O1UeEqNfdxvlIKFHoCgM4wCLcB/s1600/IMG_4321.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Based on a few &lt;a href=&quot;http://www.thriftyfun.com/tf49873458.tip.html&quot;&gt;mediocre&lt;/a&gt; &lt;a href=&quot;http://www.howtodothings.com/fashion-personal-care/how-to-cut-quartz-crystal&quot;&gt;references&lt;/a&gt; I could find online, I held the stone in place just with a pliers and cut into the gem surface at right angles to keep it from slipping. I used mineral oil for the lubricant to keep the dust down and make the cuts cleaner. I was a little bit over-the-top paranoid about silicosis. In general, exposing yourself to quartz dust is a bad idea, but in all honesty for a project this size, it really wasn't any big deal.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/CJZNXaxTUaI&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-zq55A9NA8JA/WNnNCY1yvXI/AAAAAAAAH5M/CyO15172PVEQjDU39QKXhdXtbWmSOZGSwCLcB/s1600/IMG_4331.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        With the main chunks off, I started carving off the last bits of black rock with the edge. This also worked well for getting a roughly rounded circumference at the size we wanted.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/DZOU0egc-wc&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        At this stage, we spent a bit wondering whether we wanted to keep the stone in this sort of natural state. We liked how the stone had naturally broken to produce that interesting little peak, but ultimately, we decided we'd want to get the glossiness that could only come with a polish. And that just wouldn't be possible without getting the surface faceted.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-YkrVnoE7cBE/WNnNHXHIPnI/AAAAAAAAH5c/hKKF8swOvoQgrdvYkpmssjLw8xbR0kywQCLcB/s1600/IMG_4339.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Just for fun, I tried cutting a flat little piece of the excess off as an experiment to see what the material looked like in thin segments. I smoothed it down as much as possible. It ended up looking like a little glass (which it is) with some interesting swirling imperfections in it.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-GxpQBJkOM0Y/WNnMrtwuZaI/AAAAAAAAH44/RDMp0bClIg4IASSC5JY7oq53DuxDm0uNACLcB/s1600/IMG_20160905_105308.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-PAPBByfM_8g/WNnMqPAYa8I/AAAAAAAAH40/sLUXjgqKCJER7HyJi0uM61at-jKzvrTQQCLcB/s800/IMG_20160905_112111.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6&gt;Bringing in the Professional&lt;/h6&gt;
&lt;p&gt;
        Ultimately, I wasn't able to get a good enough polish on the stone surface to really make the stone shine. Claire also wanted a rose-cut facet, which is generally considered to be a fairly difficult cut. I was nervous that my faceting wouldn't be quite good enough since I'd never had any practice before. Ultimately, we decided it would be better to let a professional do the final cut and polish.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-Glx90c1rvKg/WNH42c4_swI/AAAAAAAAHr4/g2YBArFwumsZCbwjlWNapldVzdezgNf5QCLcB/s800/Apr-2015-f1-e1480986144969-225x300.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        There aren't that many lapidaries who will take custom jobs from individuals anymore. Fortunately, we were able to track down a nice gentleman from Kentucky named &lt;a href=&quot;https://gemsbyjohn.com/&quot;&gt;John Wright&lt;/a&gt;. We sent the part of the stone that I had shaped down to a rough cut, and John sent back a polished rose-faceted gem just a little over a week later.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-itfYyJjq9d8/WNnZAB1lZTI/AAAAAAAAH6A/fN2IYwEK8bUkbuHwdPt1dAxqQghmhgnqACLcB/s800/IMG_4463.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Mounting the Ring&lt;/h4&gt;
&lt;p&gt;
        Claire had found some inspiration from &lt;a href=&quot;http://www.mineralogydesign.com/&quot;&gt;Mineralogy Studios&lt;/a&gt; in Chicago's Ravenswood neighborhood. We went and met with the owner and jeweller, Theresa Cowan, there to find out what kind of mounting we could do.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://assets.dnainfo.com/generated/chicago_photo/2015/07/mineralogydoorway-1436320075.jpg/extralarge.jpg&quot; title=&quot; &quot;/&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;338&quot; mozallowfullscreen=&quot;&quot; src=&quot;https://player.vimeo.com/video/144520365?title=0&amp;amp;byline=0&amp;amp;portrait=0&quot; webkitallowfullscreen=&quot;&quot; width=&quot;640&quot;&gt;&lt;/iframe&gt;&lt;a href=&quot;https://vimeo.com/144520365&quot;&gt;Mineralogy&lt;/a&gt;
&lt;p&gt;
        Theresa was wonderful to work with. She was very knowledgeable about gemstones and totally game to work with us on our unusual project. Claire liked the look of some of Theresas rings, so she gave us the exact measurements of the stones in them (length, width, height etc) to make sure we could tell the lapidary exactly what we wanted.
    &lt;/p&gt;
&lt;p&gt;
        Then Claire brought in the final stone and Theresa worked her magic to produce the perfect ring. Claire was thrilled with the final product. It was the classy without being over-the-top.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-PnGQ_QLR1so/WPGK1hjm4QI/AAAAAAAAH9o/iIbcTvwJG9IC0AwKZoWniQkk1Cb12-y_wCLcB/s800/IMG_4920.jpeg&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;The finishing touches &lt;/h6&gt;
&lt;p&gt;
        We also asked Theresa to make Claires wedding band with diamonds from her Great Aunt. We cant wait to make it official this fall!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-FEZWAlMmtRk/WPGKsWYHewI/AAAAAAAAH9g/037ZKdxEiSUOLBbK6dS8No0WEsk6O1dQgCLcB/s1600/IMG_4928.jpeg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Bonus: Earrings&lt;/h4&gt;
&lt;p&gt;
        Collected some fragments from the original stone and turned them into earrings for Claire's mom.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-jlI1cNWnLy0/WM8zZM1BKuI/AAAAAAAAHp8/11hZ4GfF83gCqvRT6vvglGWhNCdN68UVwCLcB/s800/earrings2.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Fri, 14 Apr 2017 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2017/04/engagement-ring-from-found-smoky-quartz/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2017/04/engagement-ring-from-found-smoky-quartz/</guid>
        
        <category>design</category>
        
        <category>craft</category>
        
        
      </item>
    
      <item>
        <title>Text Mining and Natural Language Processing on Health Forums</title>
        <description>&lt;p&gt;
        As part of the &lt;a href=&quot;http://insighthealthdata.com/&quot;&gt;Insight Health Data Science Fellowship&lt;/a&gt;, I just got to spend the last 3 weeks working on a pretty fun project applying natural language processing to medical health forums. The goal is to curate health forums so that people can get instant advice on sexual health problems and then see the most relevant forum posts on those issues.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-eDtnSA_LrOk/V_6IY2EOMLI/AAAAAAAAHDE/cqVsQMqK4PQT5H720zmOrH-3aw-R6Tw8wCLcB/s1600/png%253Bbase64de1231217d364075.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The web app is up and running. To try it out, hop on over to &lt;a href=&quot;sexpertise.makeloft.org&quot;&gt;sexpertise.makeloft.org&lt;/a&gt; (maybe use an incognito tab if you're skiddish about your search history). I'll eventually do another post all about the AWS backend API and the D3 frontend stuff, but for this post I want to focus in just on the text mining and analysis that went into building the condition suggester. To jump straight to the code you can check out &lt;a href=&quot;&quot;&gt;my Github repo&lt;/a&gt;.
    &lt;/p&gt;
&lt;h3&gt;Health Forum Datasets&lt;/h3&gt;
&lt;p&gt;
        At least &lt;a href=&quot;http://www.pewinternet.org/fact-sheets/health-fact-sheet/&quot;&gt;4 out of 5 internet users&lt;/a&gt; ask health related questions online and google says &lt;a href=&quot;https://googleblog.blogspot.com/2015/02/health-info-knowledge-graph.html&quot;&gt;1 in 20 searches are for medical info&lt;/a&gt;. Clearly, online information is an integral part of the healthcare pipeline in this day and age. Providing better information to users up front can change their whole medical experience downstream.
    &lt;/p&gt;
&lt;p&gt;
        Nowhere is this more important than in sexual health information because social taboos can prevent people from feeling comfortable seeking medical help. As many as &lt;a href=&quot;http://healthdecide.orcahealth.com/2012/11/20/survey-finds-people-turn-to-internet-over-doctor-for-health-questions/#.V_5u_7Uy3qM&quot;&gt;63% of people who go online for medical advice&lt;/a&gt; say they turn to the internet to talk about sensitive issues like sex and STDs. Fortunately, the internet is helping to alleviate some of these constraints.
    &lt;/p&gt;
&lt;p&gt;
        To get advice on these issues many users turn to online &quot;Ask a Doctor&quot; forums found on &lt;a href=&quot;http://exchanges.webmd.com/default.htm&quot;&gt;WebMD&lt;/a&gt;, &lt;a href=&quot;http://www.doctorslounge.com/forums/&quot;&gt;DoctorsLounge&lt;/a&gt; or &lt;a href=&quot;http://ehealthforum.com/&quot;&gt;eHealthForum&lt;/a&gt;. All of these sites offer free anonymous questions with medical professionals. On these sites, typically an &quot;Asker&quot; poses a question in a public forum, which can then be answered by a doctor.
    &lt;/p&gt;
&lt;p&gt;
        As an example let's look at the following interaction between an asker and a doctor, which can be found at &lt;a href=&quot;http://www.doctorslounge.com/forums/viewtopic.php?f=61&amp;amp;t=43266&quot;&gt;this doctorslounge.com post&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-Yeold6n9Mbs/V_5qqMS5OCI/AAAAAAAAHCM/Tx31LffyQpEE31jUZfhvqZNcD2wXNUO8QCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B09-53-25.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The asker normally talks about symptoms that he or she is experiencing (blue), while the doctor responds with suggestions and, importantly, mentions different likely conditions (green). Unfortunately, it can take as much as a week for a doctor to respond, and this can cause the asker to wait unnecessarily rather than seeking medical help at a clinic.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-z9yFUe9O8Hc/V_5xx2cUQPI/AAAAAAAAHCc/SWd4whSfyPYoCn3rdYktAkb1vVFcYFq0wCLcB/s1600/waittime.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        It would be great to be able to mine the text so that we could map those symptoms to conditions automatically. At the same time, it's clear that there's a lot of extra information in the posts. Without any further analysis, it's basically impossible to tell what's important in these messages and how to extract meaning from them. But fortunately, there is a process for working with textual data known as NLP that will help us make sense of this.
    &lt;/p&gt;
&lt;h6&gt;Scraping forum data&lt;/h6&gt;
&lt;p&gt;
        In order to analyze these forums I needed to download many forum conversations from multiple websites. To do this I used BeautifulSoup to crawl the webforus and store the text from the asker, the doctor, and any other respoonders. I ended up getting data from WebMD, eHealthForum, DoctorsLounge, and ScarletTeen sexual health forums. Others that I could add would be reddit and stackexchange as well as medhelp.
    &lt;/p&gt;
&lt;p&gt;
        I downloaded 150,000 posts in 60,000 threads and about half of them had a response from a medical professional (either a doctor or a registered nurse). Identifying medical professionals was always specific to each forum, and the best one can do is get a sense of the heuristics each site uses to identify their &quot;official&quot; responses. To view the scrapers that I used to download the data check out my &lt;a href=&quot;https://github.com/lots-of-things/insight-health-scraper&quot;&gt;insight-health-scraper&lt;/a&gt; repo on GitHub.
    &lt;/p&gt;
&lt;h4&gt;Filtering on writing style&lt;/h4&gt;
&lt;p&gt;
        One of the first things I noticed when perusing my dataset was the wide disparity in the quality of Asker questions and their writing style. I also noticed that the doctors tended to sound a lot smarter than the askers as you might expect. This led me to wonder whether I could detect the quality of the writing style. To do this I calculated the Flesch-Kincaid Grade Level of each post in my corpus using &lt;a href=&quot;https://github.com/mmautner&quot;&gt;mmauter&lt;/a&gt;'s &lt;a href=&quot;https://github.com/mmautner/readability&quot;&gt;readability package&lt;/a&gt; for python. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests&quot;&gt;Flesh-Kinkaid readability tests&lt;/a&gt; are a system to estimate the reading ease of paragraphs. The Grade Level tries to map someone's writing onto the equivalent educational Grade Level in the American school system. I applied it to my corpus and was able to get a nice plot of the frequency of reading levels for both the asker and doctor texts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/--JWKUmh_ekM/V_5yhhrh7-I/AAAAAAAAHCk/26dMNj4-wzsZgwhNl9OAhYmrIW_FEWXXQCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B10-27-19.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        As you can see, using this metric, doctor texts score significantly higher than asker texts. Flesch-Kincaid mainly takes into account the number of syllables in words and the number of words in sentences. Ernest Hemingway would probably disagree that those are good metrics for the quality of writing, but it's a fair proxy short of any other information about the text. For example, one asker posed the following thought provoking health question:
    &lt;/p&gt;
&lt;blockquote&gt;Should I have sex with some random guy?&lt;/blockquote&gt;
&lt;p&gt;
        This sentence actually scores negative on the Flesch-Kinkaid grade level. To me it seems like it should score negative on pretty much every level.
    &lt;/p&gt;
&lt;p&gt;
        At any rate, the Flesch-Kincaid metric gave me a method to establish which asker questions were just unfit to be displayed. At the end of the project, this helped in filtering the responses that I showed to end users. However, I still left that data in during the modelling part.
    &lt;/p&gt;
&lt;h3&gt;Finding Conditions in Doctor Responses&lt;/h3&gt;
&lt;p&gt;
        After the dataset is downloaded and tidied, you have to ask what you are going to do with the dataset. At the moment, the whole dataset just consists of pairs of unstructured text, one for asker and one for doctor. You could try to map from asker text to doctor text (see below for that problem), but first it would be better to get a simpler set of labels to map to. In the end, what I really wanted was just a list of all the recognizable conditions that the doctor mentions.
    &lt;/p&gt;
&lt;p&gt;
        So to turn this into a more cleanly labelled dataset, I needed to generate a list of condition labels directly from the doctor text. This turns out to be not a trivial task with lots of ways to tweak the final result. I can't offer a perfect answer, but I can offer the solution I used to detect conditions in doctor text.
    &lt;/p&gt;
&lt;h4&gt;Generating condition synonym list from CDC and Mayo clinic websites&lt;/h4&gt;
&lt;p&gt;
        To get recognizable conditions to label, I needed to build a list of text strings that could be construed to represent &quot;diseases&quot;. Fortunately, both the &lt;a href=&quot;http://www.cdc.gov/diseasesconditions/&quot;&gt;CDC&lt;/a&gt; and &lt;a href=&quot;http://www.mayoclinic.org/diseases-conditions&quot;&gt;Mayo Clinic&lt;/a&gt; have lists of diseases and conditions which were easy enough to scrape using my &lt;a href=&quot;https://github.com/lots-of-things/insight-health-scraper&quot;&gt;insight-health-scraper package&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        After I had the raw list, I realized that there were lots of conditions that were pretty similar to each other. I decided I needed to collapse this list down to a shorter list of truly unique entries for two reasons: 1) I didn't want an overwhelming array of conditions to display at the end, and 2) I wanted to enhance the predictive ability of my model by increasing the number of occurrences of each condition I was trying to model. To do this I used a technique called &lt;a href=&quot;https://en.wikipedia.org/wiki/Approximate_string_matching&quot;&gt;fuzzy matching&lt;/a&gt; to see which strings were more than 90ish% similar to each other.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://autoaudit.com/wp-content/uploads/2013/10/services-fuzzy-matching-logic.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I relied on a cute python package called &lt;a href=&quot;https://github.com/seatgeek/fuzzywuzzy&quot;&gt;fuzzywuzzy&lt;/a&gt;, which worked great for identifying close partial matches of strings. Specifically, I could just use the extractOne() method to find the closest match out of the diseases I've already seen. If the match was better than 90%, just add it as a synonym to the original disease, creating a way to map all of the similar strings to one term.
    &lt;/p&gt;
&lt;h4&gt;The many ways to match a string&lt;/h4&gt;
&lt;p&gt;
        Once I had the disease synonyms, I needed to look into the doctor text to see when they were mentioned. There were a number of different ways to do this, and I explored several permutations of the following techniques.
    &lt;/p&gt;
&lt;h6&gt;Multiple &quot;synonyms&quot;&lt;/h6&gt;
&lt;p&gt;
        I already had multiple different terms that mapped to the same disease so I had a long list of somewhat similar terms that could be compared against (e.g. 'ehrlichiosis' and 'human ehrlichiosis' both map to the same disease).
    &lt;/p&gt;
&lt;h6&gt;Spelling correction&lt;/h6&gt;
&lt;p&gt;
        Another cool package called &lt;a href=&quot;https://pypi.python.org/pypi/pyenchant/&quot;&gt;PyEnchant&lt;/a&gt; can make spelling corrections. It is slow so I didn't use it on the whole dataset, but it could offer another way to correct spelling errors for diseases.
    &lt;/p&gt;
&lt;h6&gt;Fuzzy matching&lt;/h6&gt;
&lt;p&gt;
        As I mentioned above, fuzzy matching allows similar strings that are not exact matches to be compared. Again, this technique is much slower than a simple string comparison, but I decided to use it anyway in this case to make sure I didn't miss any similar text.
    &lt;/p&gt;
&lt;h6&gt;Marking negation&lt;/h6&gt;
&lt;p&gt;
        Finally, it's possible that a mention doesn't necessarily mean the text is relevant. In particular, a doctor could be saying that she &lt;i&gt;doesn't&lt;/i&gt; think you have a condition (e.g. &quot;You probably don't have an STD&quot;). Using negation marking in nltk.util allows you to mark every word in a sentence that comes after a negation (i.e. not, no, etc). I stored the results of this, but it only reduced the number of identified conditions by 1% so I didn't bother using it for simplicity of explanation. Nevertheless, it can be a good idea if you're trying this on a different dataset.
    &lt;/p&gt;
&lt;h4&gt;Disease labelling results&lt;/h4&gt;
&lt;p&gt;
        I searched for 200 diseases across the 30,000 doctor texts. Of those, only 80 occurred more than 100 times so I decided to just focus on those. The following diagram shows some of the most and least frequently mentioned diseases./p&amp;gt; &lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-dcoWntZNXq4/V_6GaYj5Q2I/AAAAAAAAHC4/cBM40kOXEZEpm-BAGH8cBUQQXwMHVPwUwCLcB/s1600/occurence.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            I also repeated this with the asker comments to see which conditions were mentioned by them. In addition I queried the top disease-related wikipedia articles to see how many times they were viewed and I compiled some CDC data to see which diseases occurred the most. Combining these, it was interesting to see what the most commonly mentioned issues were from these disparate datasets
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-px90z-NSk6c/V_6F39Js8bI/AAAAAAAAHC0/z7JJtUIrdM4KK9iPtOHoShgmU4lY-i2XgCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B11-46-58.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            Clearly different things are on different people's minds.
        &lt;/p&gt;
&lt;h3&gt;Predicting Conditions from Questions&lt;/h3&gt;
&lt;p&gt;
            With a labelled dataset, I could generate a model that predicted conditions using input text. However, the asker text was still just an unprocessed string, which isn't really easy to model without to measure the occurrence of important words. Unfortunately, there is no obvious way to extract the most important words from the text &lt;i&gt;a priori&lt;/i&gt;. Instead, I had to use some natural language processing techniques to extract the features of the text into a numerical form that could be fit with a model.
        &lt;/p&gt;
&lt;h4&gt;Term Frequency Inverse Document Frequency (TFIDF)&lt;/h4&gt;
&lt;p&gt;
            The most traditional way to convert text into a vector of features is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bag-of-words_model&quot;&gt;&quot;bag of words&quot; model&lt;/a&gt;. In this model, you lose all information about the ordering of the words and you basically just end up with counts of occurrences of each word. I used a slight adaptation of this called &lt;a href=&quot;https://en.wikipedia.org/wiki/Tf%E2%80%93idf&quot;&gt;TFIDF&lt;/a&gt;, where you normalize the word counts by the frequency of those words across all the documents in your corpus. This has the effect of making it so that your representation has values much larger than 1 whenever a word is over-represented compared to the average document.
        &lt;/p&gt;
&lt;p&gt;
            You can find a lot of information about &lt;a href=&quot;http://aimotion.blogspot.com/2011/12/machine-learning-with-python-meeting-tf.html&quot;&gt;TFIDF on the web&lt;/a&gt;. It is the standard and most obvious way to deal with this problem. Just to briefly make it clear what we got out of this. Basically after converting your text into TFIDF form, you'll have a vector of numbers where each element in the vector represents how over-represented a certain word is in that text. One consequence is that two identical documents will have identical vector representations. Similarly documents with similar word frequencies will have simimilar vector representations.
        &lt;/p&gt;
&lt;h6&gt;Stop Words, Stemming, and Ngrams&lt;/h6&gt;
&lt;p&gt;
            There are three additional techniques that extend the usefulness of TFIDF. First, removing &lt;strong&gt;stop words&lt;/strong&gt; filters out the most common English words that don't really convey meaning. Words like 'I', 'in' and 'the' get dropped so they aren't wasting space in your vectorized representation. Second, &lt;strong&gt;stemming&lt;/strong&gt; drops inferred suffixes off of words. Thus, 'running,' 'runs,' and 'run' will all map to 'run,' which further reduces your feature space. Finally, generating &lt;strong&gt;ngrams&lt;/strong&gt; creates new words out of continuous segments of words. So for example, without ngrams you would have a count of 'bus' and a count of 'driver' in your document, but you wouldn't know if the term 'driver' was ever associated with 'bus.' If you use a bigram (or 2-gram) then you would also have the count of 'bus driver' in your text. This can give you more meaning if t turns out to be an important feature.
        &lt;/p&gt;
&lt;h6&gt;Restricting feature frequency&lt;/h6&gt;
&lt;p&gt;
            I also filtered out words and phrases that were too common and too rare. To do this I clipped out the least frequent 1% and the most frequent 40% of words. This was something where I really wanted to explore the effect on my model systematically, but due to time constraints I had to move on after finding a &quot;good enough&quot; restricting condition.
        &lt;/p&gt;
&lt;h6&gt;Experiments with Doc2Vec&lt;/h6&gt;
&lt;p&gt;
            In addition to the classic TF-IDF, I also experimented with the state of the art &lt;a href=&quot;https://radimrehurek.com/gensim/models/doc2vec.html&quot;&gt;gensim Doc2Vec&lt;/a&gt; for extracting features from my text. Doc2Vec (and its basis &lt;a href=&quot;https://en.wikipedia.org/wiki/Word2vec&quot;&gt;Word2Vec&lt;/a&gt;) is a complicated algorithm that &lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/3wu7di/how_does_doc2vec_work/&quot;&gt;many&lt;/a&gt; other people have attempted &lt;a href=&quot;https://www.quora.com/How-does-word2vec-work&quot;&gt;to explain&lt;/a&gt; better than me. In a nutshell, it attempts to look at the context.
        &lt;/p&gt;
&lt;p&gt;
            One great thing about it is that it maps different words into a &quot;meaning&quot; space. This means that you can map synonymous words to the same feature space with lower dimensionality. As such different words can be have their nearby regions inspected and you can see which words are the most similar in meaning. Here I display 3 different Doc2Vec implementations, and which words they find closest in meaning to ovulation.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-o1SvnRhJKt4/V_6Ih_SLo7I/AAAAAAAAHDI/udZY11Dvr2AOS_ho95Lx4mWIT7FyHfTkwCLcB/s1600/png%253Bbase649f9c19b5fbaf1495.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            In truth, Doc2Vec is a family of algorithms, each with its own pluses and minuses. As you can see the one on the left looks to be the most informative. That one uses the &lt;a href=&quot;https://www.quora.com/What-are-the-continuous-bag-of-words-and-skip-gram-architectures-in-laymans-terms&quot;&gt;skip-gram model&lt;/a&gt;, which you can look into if you are interested in the details. All in all, I'm impressed with Doc2Vec, and with a little more fiddling I'm sure I could change my implementation to include this more elegant vectorization procedure. However, the current Doc2Vec implementations do not enable you to directly map a text to a unique vector representation. Instead, they infer a &quot;good enough&quot; representation with some random noise, which is not guaranteed to be the same every time you query. I didn't have time to fix this issue so I left the TFIDF in production.
        &lt;/p&gt;
&lt;h6&gt;Results of the vectorization&lt;/h6&gt;
&lt;p&gt;
            To get a better idea of what comes out of the vectorization process take a look at this text from the example above.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/--wqIFOHhBrc/V_6jvlAKvhI/AAAAAAAAHEM/mqgqtM2H8F0oDEqFrP23saOTJB91XPIKwCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-57-14.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            As you can see, many of the words have been truncated by the stemming. Also, even though there are many possible ngrams in this example, none of them are in the final vectorization. That just means that they were either too frequent or not frequent enough to make the cut. All in all, a lot of information has been lost, but we don't know if we've kept enough until we've tried to make a model.
        &lt;/p&gt;
&lt;h4&gt;Modelling sparse data with multiple labels&lt;/h4&gt;
&lt;p&gt;
            For this model, I didn't have a lot of data, but I had a lot I had to predict. In the end, I was trying to predict 80 diseases, and many of those diseases didn't even have many more than 100 examples in the dataset. That leaves a lot of room to get things wrong.
        &lt;/p&gt;
&lt;p&gt;
            For example, using the &lt;a href=&quot;https://en.wikipedia.org/wiki/F1_score&quot;&gt;F1 score&lt;/a&gt; I only had actual predictive power over a handful of conditions. This was universally true with any model that I used (random forests, SVM, logistic regression, and naive bayes) which is a good indication that I just didn't have enough samples to get a predictive model.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/--9fAgxwLBsg/V_6UeACyzxI/AAAAAAAAHDc/tUVFFjy39vkFvdp48LvXlwNmIJ_-3MGngCLcB/s1600/png%253Bbase64a41082f67ebe75a4.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            Fortunately, after a little while I realized that my problem was actually way easier than trying to predict the diseases. Really, all I needed was to identify the 10-or-so most probable diseases associated with a given disease. Doing that with some fidelity isn't anywhere near as hard, and I found that I could be pretty successful even with my small dataset. The resulting conditions definitely passed the gut test and matched with pretty good fidelity to my expectations.
        &lt;/p&gt;
&lt;p&gt;
            To be more systematic, I used an ROC area under the curve to score my models and found that I could get 0.85 (1 being the best) using a moderately sized random forest. So that was the model that ended up going into production.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-Svlsu3cCewo/V_6WszpbtQI/AAAAAAAAHDo/l8AUaY5kKpoHYFLPaN2aZjitP9oyUmG_wCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-01-44.png&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Viewing the most predictive words for each condition&lt;/h4&gt;
&lt;p&gt;
            One interesting thing that falls out of this modelling is the ability to see which words are most important for predicting a given condition. I built an &lt;a href=&quot;http://sexpertise.makeloft.org/analysis&quot;&gt;interactive analysis tool&lt;/a&gt; to visualize the words that are best at predicting a given condition. One of the coolest predictions is for appendicitis.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-W_i-MCj1eE4/V_6ZSE__ZvI/AAAAAAAAHD4/SgBpIUBzpwsjHnN3H-PkKHL8OmfGqzK0QCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-06-24.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            As you can see, two of the most closely related phrases are 'right' and 'abdominal pain.' To me it's absolutely incredible that this ended up working so perfectly. Feel free to explore the &lt;a href=&quot;http://sexpertise.makeloft.org/analysis&quot;&gt;analysis tool&lt;/a&gt; to find more cool patterns like this.
        &lt;/p&gt;
&lt;h3&gt;Bonus: Disease Connectivity Map&lt;/h3&gt;
&lt;p&gt;
            As a cool little additional analysis, I also found that I could infer the connections between diseases based on their co-occurrence in doctor responses. Using this connection map I was able to build a little &lt;a href=&quot;https://bl.ocks.org/mbostock/4062045&quot;&gt;D3 force graph&lt;/a&gt; to visualize the connectivity.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-AK0lHBPssqU/V_6ZNh_v26I/AAAAAAAAHD0/KDvyLCfs-kcyjdic01CtTF6dYA4olW4cgCLcB/s1600/Screenshot%2Bfrom%2B2016-10-12%2B13-09-22.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            You can definitely see clusters amongst some obviously related conditions. Women's health issues like pregnancy, breastfeeding, and back pain; flu, sore throat, and cold; and all the stds clump together. Some things are less explainable. If you want to explore first hand you can go to the &lt;a href=&quot;http://sexpertise.makeloft.org/analysis&quot;&gt;analysis page&lt;/a&gt;. Have fun and be safe.
        &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;</description>
        <pubDate>Wed, 12 Oct 2016 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2016/10/text-mining-and-natural-language/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2016/10/text-mining-and-natural-language/</guid>
        
        <category>data science</category>
        
        <category>machine learning</category>
        
        <category>code</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <title>Git Versioned PDF Visualizer</title>
        <description>&lt;a href=&quot;https://github.com/lots-of-things/git-pdf-viz&quot;&gt;jump to the code&lt;/a&gt;
&lt;p&gt;
    I've been writing a &lt;a href=&quot;https://github.com/wmcfadden/theseus&quot; title=&quot;my PhD thesis&quot;&gt;very long document&lt;/a&gt; over the past couple of years. Because I love tracking my own behavior and &lt;a href=&quot;https://en.wikipedia.org/wiki/Open_science&quot;&gt;Open science&lt;/a&gt;, I decided to version control the whole editing process of my thesis on GitHub. Because I've been keeping track of all my updates with git, that means I can monitor all the changes that have gone into my thesis over time. This can also be useful for &lt;a href=&quot;http://danaernst.com/using-github-to-coauthor-papers/&quot;&gt;collaborating on writing papers&lt;/a&gt; too (though my prototypical Luddite advisor would rather do things by emailing &lt;a href=&quot;http://www.apple.com/mac/pages/&quot;&gt;Mac Pages&lt;/a&gt; documents).
&lt;/p&gt;
&lt;h4&gt;Git PDF movie maker&lt;/h4&gt;
&lt;p&gt;
    As a cool way to visualize all the changes, I wrote a series of a couple of scripts that checkout each version and make a movie out of all the .pdfs in the repo over time. Here's the current state (note that the thesis isn't even close to finished yet; I'll update when I get more on it.)
&lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/mWvQ1Y5uaGc&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
    If you think you'd like to use this, you can bounce over to the &lt;a href=&quot;https://github.com/lots-of-things/git-pdf-viz&quot;&gt;git-pdf-viz GitHub repo&lt;/a&gt; and download it now. Read on below for more info on how it works, how to modify it, and to see the results of running git-pdf-viz on my thesis.
&lt;/p&gt;
&lt;h4&gt;A Real Bash!&lt;/h4&gt;
&lt;p&gt;
    Writing bash scripts is a party, I know. This entire project is comprised of just a few bash scripts that are meant to be run sequentially (with some editing maybe).
&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;save_all_pdfs&lt;/li&gt;
&lt;li&gt;pdfs_to_ims&lt;/li&gt;
&lt;li&gt;ims_to_montage&lt;/li&gt;
&lt;li&gt;montage_to_frame&lt;/li&gt;
&lt;li&gt;frame_to_movie&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Save All PDFs&lt;/h4&gt;
&lt;p&gt;
    The first script really takes care of the core of this program. There's lots of extra details but the key piece of save_all_pdfs.sh is &quot;git rev-list master,&quot; which gives you all the commit ids for your repo. This pseudo-bash shows the general idea:
&lt;/p&gt;
&lt;pre&gt;
for commit in $(git rev-list master)
do
    git checkout $commit
    ...copy all pdfs to somewhere safe...
done
&lt;/pre&gt;
&lt;p&gt;
    &quot;git checkout&quot; updates all the files that are sitting in the project directory locally. So with the list of revisions from &quot;git rev-list master&quot; I can reset the state of my file system to reflect the state at each committed phase of the project. After that, I just need to copy all the files I need (in this case my pdfs) somewhere safe for use later. (&lt;strong&gt;Caveat:&lt;/strong&gt; I'm currently only copying pdfs if they have a corresponding latex file because I wanted to ignore any figures that weren't included. You can modify the script accordingly if you need all your pdfs copied.)
&lt;/p&gt;
&lt;h4&gt;Playing with pdfs and images&lt;/h4&gt;
&lt;p&gt;
    The next three scripts rely on &lt;a href=&quot;http://ghostscript.com/doc/current/Devices.htm&quot;&gt;GhostScript&lt;/a&gt; and &lt;a href=&quot;http://www.imagemagick.org/script/index.php&quot;&gt;ImageMagick suite&lt;/a&gt; to jockey our pdfs into a composite image that will eventually be turned into movie frames. You can view the scripts themselves for more details about implementation, but I'll explain the idea behind each script for reference.
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=merged.pdf *.pdf &lt;/strong&gt; uses ghostscript to merge all the saved pdfs together&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;convert merged.pdf im/i_%03d.png&lt;/strong&gt; converts the merged pdf to a sequence of individual pngs&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;montage -mode concatenate -tile 10x i_* ../final.png&lt;/strong&gt; stitches all the individual png &quot;pages&quot; into a &quot;montage&quot; panel with 10 columns&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;convert &quot;${now}/final.png&quot; -resize 1000x -gravity northwest -background white -extent 1000x700 -colorspace RGB &quot;PNG32:bydate/${now}.png&quot;&lt;/strong&gt; rescales each montage and ensures that all images are the same size and colorspace&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;mogrify -gravity southeast -pointsize 26 -annotate +10+10 %t *.png&lt;/strong&gt; adds a little timestamp (based on the title) in the southeast corner&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
    At the end of this process there will be a folder named bydate/ with an image for every frame of a movie that's about to get made.
&lt;/p&gt;
&lt;h4&gt;Lights, Camera, Action&lt;/h4&gt;
&lt;p&gt;
    As the final step we use &lt;a href=&quot;https://ffmpeg.org/&quot;&gt;ffmpeg&lt;/a&gt; to convert all of the images into an mp4 movie. This requires two lines because ffmpeg is made to work with numerically sequential files, and my files are named based on their date.
&lt;/p&gt;
&lt;pre&gt;
ls *.png | sort -V | xargs -I {} echo &quot;file '{}'&quot; &amp;gt; list.txt
ffmpeg -r 2 -f concat -i list.txt -r 30 -c:v libx264 -pix_fmt yuv420p ../git_pdf_viz.mp4
&lt;/pre&gt;
&lt;p&gt;
    This is a good example of how compicated ghostscript, ImageMagick, and ffmpeg can be to use. Through all of this there are about 20 extra parameters that have to get passed to each of these programs to make them work properly. I can't explain all of them in detail, so I recommend the individual software's documentation if you find you need to modify these extensively. These are &lt;strong&gt;amazingly&lt;/strong&gt; powerful programs that make life so much easier for any kind of batch audiovisual project so I highly encourage getting acquainted with them at some point in your life.
&lt;/p&gt;
&lt;p&gt;
    Have fun, and I hope that this encourages you to use open source version control whenever you write/edit any large document project.
&lt;/p&gt;</description>
        <pubDate>Mon, 20 Jun 2016 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2016/06/git-versioned-pdf-visualizer/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2016/06/git-versioned-pdf-visualizer/</guid>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>Parallel IPython with Jupyter Notebooks on a SLURM cluster</title>
        <description>&lt;p&gt;
        I figured it would be such a piece of cake to get my Jupyter IPython notebooks to run parallel on my work cluster, but in the end, I had so much trouble trying to find the simple steps for setting it up. After much fiddling, I offer you an explanation of what is sort of working.
    &lt;/p&gt;

&lt;h4&gt;Running a remote ipython notebook server&lt;/h4&gt;
&lt;p&gt;
        The first part of this is actually incredibly simple: you need to connect your local browser to a remote Jupyter notebook server. Essentially, all you need is some port forwarding or ssh &quot;tunnelling&quot; to connect your local web browser to an ipython notebook server that is being run through a batch system on the cluster. Sound simple enough? Well unfortunately, I couldn't find any single tutorial that clearly stated the necessary steps outright. I did manage to find two similar examples where the &lt;a href=&quot;https://wiki.scinet.utoronto.ca/wiki/index.php/IPython_Notebook_on_GPC&quot;&gt;first&lt;/a&gt; works correctly but looks overly complicated while the &lt;a href=&quot;https://github.com/tnarihi/wiki/wiki/Jupyter-notebook-on-TTIC-clusters&quot;&gt;second&lt;/a&gt; looks like it should work, but for some reason doesn't.
    &lt;/p&gt;
&lt;p&gt;
        To make it work I created an sbatch job named ipy_srv.sbatch which launched the server somewhere on a machine in the cluster and then printed the serving machine's ip and port number to the log file. I could then use those values with the ssh tunnel.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;#!/bin/sh&lt;br/&gt;#SBATCH --part=westmere&lt;br/&gt;#SBATCH --reservation=energy&lt;br/&gt;#SBATCH --ntasks=1&lt;br/&gt;#SBATCH -t 04:00:00             # max runtime is 4 hours&lt;br/&gt;#SBATCH -J  ipy_server    # name&lt;br/&gt;#SBATCH -o log/ipy-%J.out&lt;br/&gt;&lt;br/&gt;let ipnport=($UID-6025)%65274&lt;br/&gt;echo ipnport=$ipnport&lt;br/&gt;&lt;br/&gt;ipnip=$(hostname -i)&lt;br/&gt;echo ipnip=$ipnip&lt;br/&gt;&lt;br/&gt;module load python&lt;br/&gt;ipython notebook --ip=$ipnip --port=$ipnport --no-browser&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I don't know where &quot;($UID-6025)%65274&quot; came from, but it seems to get the job done so I just left it. After launching this with &lt;strong&gt;sbatch ipy_srv.sbatch&lt;/strong&gt;, I can check in the most recent file under log/ipy-* to get the ip and port number at the top of the file.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-rxiSDUa7Kbw/VzOXXp8duQI/AAAAAAAAGNI/HfqjnmTc6_YsaUGx2TXiY8PrsrW-uOsPACLcB/s1600/Screenshot%2Bfrom%2B2016-05-11%2B15%253A13%253A34.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Next simply ssh into the cluster of your choice while using the tunnelling flag -L. You'll probably need to add your credentials
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;ssh -N username@midway.rcc.uchicago.edu -L &amp;lt;local port&amp;gt;:&amp;lt;server ip&amp;gt;:&amp;lt;server port&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I just used &amp;lt;local port&amp;gt;=8888 so that I could connect to http://localhost:8888/tree like I normally do when serving the notebook on my local machine. And voila... the ipython notebook interface pops up when you navigate your web browser to that address.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-BhI3eAPd-dY/VzOU7TTJy_I/AAAAAAAAGM8/EpuLq7IIaI8ptUZjMOO8qkN81mQ1b-hkACLcB/s1600/Screenshot%2Bfrom%2B2016-05-11%2B15%253A23%253A47.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You can stop here if you only want to host your notebooks on a cluster as a server, but of course using a cluster means you can do so much more because you can run things in parallel. Keep going to see how that works.
    &lt;/p&gt;
&lt;h4&gt;Running the cluster with parallel jobs&lt;/h4&gt;
&lt;p&gt;
        To make things slightly more confusing, but also much more useful, I wanted to run a parallel cluster for my ipython notebooks. This really broke down to two steps:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;#ipcluster&quot;&gt;Setting up an ipcluster to run on a set of nodes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#connections&quot;&gt;Getting ipython notebook server to send jobs to the ipcluster&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;ipcluster&quot;&gt;Setting up an ipcluster&lt;/h4&gt;
&lt;p&gt;
        This part can theoretically be carried out in a number of ways, but in practice I found that only one way actually works with SLURM as your backend. In particular, I found it very troublesome to use any of the &quot;automatic&quot; setup systems, like ipcluster or ipython_cluster_helper. They didn't play nicely with the SLURM configurations that I was working with so I wrote a script that directly launched the underlying tools, ipcontroller and ipengine.
    &lt;/p&gt;
&lt;p&gt;
        The script I used based largely on examples I found from &lt;a href=&quot;http://k-d-w.org/node/96&quot;&gt;Sebastian Plsterl&lt;/a&gt;, &lt;a href=&quot;http://twiecki.github.io/blog/2014/02/24/ipython-nb-cluster/&quot;&gt;twiecki&lt;/a&gt; and &lt;a href=&quot;https://rcc.fsu.edu/docs/parallel-ipython-programming-hpc-and-spear&quot;&gt;FSU's RCC&lt;/a&gt;. After the SBATCH setup info, it accomplishes three things:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Delete all old ipython profiles and create a new one for this ipcluster &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;rm -r ~/.ipython/profile_job*&lt;br/&gt;profile=job_${SLURM_JOB_ID}&lt;br/&gt;&lt;br/&gt;echo &quot;Creating profile ${profile}&quot;&lt;br/&gt;ipython profile create ${profile}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Launch an ipcontroller that can connect to any IP using this profile &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;ipcontroller --ip=&quot;*&quot; --profile=${profile} &amp;amp;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Launch as many ipengines as needed (60) that will connect to the ipcontroller at $(hostname) &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;srun ipengine --profile=${profile} --location=$(hostname)&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        After you run this script using &lt;strong&gt;sbatch run_ipcluster.sbatch&lt;/strong&gt;, SLURM will return a job number that you will need to use later. To see what this is doing behind the scenes you can view the output in the appropriate log/ipc-* file. You'll essentially see the ipcontroller come online and then you'll see a bunch of updates as each ipengine makes contact with the ipcontroller. However, at this point we really haven't accomplished anything because all those ipengines are still waiting for work to do.
    &lt;/p&gt;
&lt;h4 id=&quot;connections&quot;&gt;Connecting to your parallel ipcluster&lt;/h4&gt;
&lt;p&gt;
        To actually use the ipengines we set up, we have to use the special parallel programming utilities housed in IPython.parallel. Technically, we're supposed to use &lt;a href=&quot;https://github.com/ipython/ipyparallel&quot;&gt;ipyparallel&lt;/a&gt; now, and I recommend using that if you know how. At the time of writing this though, ipyparallel needs to be installed separately and most of the examples I've found used IPython.parallel so I didn't feel like crossing those hurdles for my set up.
    &lt;/p&gt;
&lt;p&gt;
        IPython.parallel doesn't have to be used with Jupyter notebooks, and, in my opinion, combining the two makes things a little difficult to understand at first. To make things easier, I'll introduce the script based method first and then show the tricks for using it in a notebook.
    &lt;/p&gt;
&lt;h6&gt;Running a standalone script&lt;/h6&gt;
&lt;p&gt;
        For a quick test to make sure that the cluster is actually functioning at all, you can run the &lt;a href=&quot;https://github.com/lots-of-things/ipynb-par-slurm/blob/master/pypar.py&quot;&gt;pypar.py&lt;/a&gt; test. This code generates an estimate of  from a &lt;a href=&quot;http://interactivepython.org/runestone/static/thinkcspy/Labs/montepi.html&quot;&gt;large &quot;dartboard&quot; simulation&lt;/a&gt; so the accuracy should increase with more machines being used.
    &lt;/p&gt;
&lt;p&gt;
        To run this using the parallel cluster, pass the profile name to the script.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;$ module load python&lt;br/&gt;$ python pypar.py -p job_&amp;lt;jobn&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        &amp;lt;jobn&amp;gt; is the job number returned by SLURM when you submitted run_ipcluster.sbatch earlier. When the script finishes there should be a file called result-job.txt, which will include a pretty OK estimate of . I'm not going to get too deep into how how to actually do parallel programming in Ipython, but here are some tutorials and examples to get you started working with that.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;https://ipython.org/ipython-doc/3/parallel/parallel_demos.html&lt;/li&gt;
&lt;li&gt;http://nbviewer.jupyter.org/github/minrk/IPython-parallel-tutorial/blob/master/examples/Parallel%20image%20processing.ipynb&lt;/li&gt;
&lt;li&gt;http://minrk.github.io/scipy-tutorial-2011/basic_remote.html&lt;/li&gt;
&lt;/ul&gt;
&lt;h6&gt;Connecting your notebooks to the cluster&lt;/h6&gt;
&lt;p&gt;
        Using IPython.parallel inside the Jupyter notebook isn't that much trickier than in a python script. There are a few tricks that are covered in &lt;a href=&quot;http://twiecki.github.io/blog/2014/02/24/ipython-nb-cluster/&quot;&gt;twieki's post&lt;/a&gt;, but I'm not sure if that's exhaustive. Just as an example, I've included the somewhat useless dummie_notebook.py to get you started. It performs some calculations and outputs to the file to simpleoutput.txt. To make it work, you'll have to update the profile referenced when setting up the parallel.Client() so that it matches the job name of returned when you launched run_ipcluster.sbatch.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-IP2Dr2Tqd8c/VzuMv7lD59I/AAAAAAAAGNw/u1r8hWqeKx4pexG-dLyuDH3OfJL9CKrGACLcB/s1600/Screenshot%2Bfrom%2B2016-05-17%2B16%253A27%253A04.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        If everything is set up correctly you should just get the range of numbers from 1 to 10,000 in the simpleoutput.txt file. You can make sure that the job actually ran in parallel by checking the corresponding log/ipc-* file to make sure that a ton of communications started getting printed to file.
    &lt;/p&gt;
&lt;h4&gt;Future directions and get the code&lt;/h4&gt;
&lt;p&gt;
        This setup should prove to be very useful to me and I hope it will be to you too. You can get all the code from my &lt;a href=&quot;https://github.com/lots-of-things/ipynb-par-slurm&quot;&gt;ipynb-par-slurm&lt;/a&gt; repo on Github. In the future, I think it should be possible to extend this method to work with other libraries that support parallelism, but I'm just scratching the surface of those challenges right now. I may update the github repo to include other examples that work with more packages if that turns out to be possible. Happy parallelizing,
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 11 May 2016 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2016/05/work-in-progress-parallel-ipython-from/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2016/05/work-in-progress-parallel-ipython-from/</guid>
        
        <category>data science</category>
        
        <category>infra</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>Bluetooth controlled Redbot construction</title>
        <description>&lt;p&gt;
        For part of the Ray elementary after school electronics and robotics club (R-ASER), I'm prototyping a robot that can be remotely controlled via a serial connection through bluetooth. The following is the rough draft of the classroom instructions. (PS, volunteering with kids is fun so go out and do it.)
    &lt;/p&gt;
&lt;h4&gt;Adding the Bluetooth module&lt;/h4&gt;
&lt;p&gt;
        This lesson starts with a fully assembled and functional Redbot chassis. You can find more info abut the robot kit and instructions on &lt;a href=&quot;https://learn.sparkfun.com/tutorials/redbot-assembly-guide&quot;&gt;sparkfun's tutorial website&lt;/a&gt;, and you can see more of our Redbot based projects once we have them online. This is what our original Redbot looks like before we start construction.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-XWaEhvNkWMI/VxUDQrKEcpI/AAAAAAAAGBE/v_GPtW_YD3g0D00sVyaHbNwniVz8uzkHQCKgB/s1600/IMG_20160418_103145.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We'll be modifying this basic robot with an a bluetooth module that doesn't come from sparkfun so we'll get all the excitement of working with non-kit electronics. We're going to be adding an HC-05 BT module like the one pictured below.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-ureRUngkG68/VxUooNgWmiI/AAAAAAAAGCY/tzU378CqnooU82_6p3AxYYe7BadBnQaLgCKgB/s1600/IMG_20160418_103201.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This device contains a fully functional bluetooth transmitter and receiver so we don't have to worry about building the parts that transmit data through the air. That means all we will have to do is listen to the serial data coming from the device as if it were coming from the USB cable.
    &lt;/p&gt;
&lt;h4&gt;Connecting through a voltage divider&lt;/h4&gt;
&lt;p&gt;
        The big trick with this device is that it communicates using only 3.3 V while the Arduino usually uses 5 V. This means that if we send information to the using 5V we will overload the circuit and burn the chip up. This cause us to need to use a &lt;a href=&quot;https://en.wikipedia.org/wiki/Voltage_divider&quot;&gt;voltage divider&lt;/a&gt; to decrease the voltage going to the bluetooth module. We'll put together a circuit based on &lt;a href=&quot;http://www.instructables.com/id/Cheap-2-Way-Bluetooth-Connection-Between-Arduino-a/?ALLSTEPS&quot;&gt;this excellent Instructable&lt;/a&gt; from techbitar
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FSK/AI30/HMMFE6UO/FSKAI30HMMFE6UO.MEDIUM.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To start we'll connect black, red, yellow, and green wires to the bluetooth module like in the image.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-hhOEchGO0dA/VxUDQj-omjI/AAAAAAAAGBE/xxBRx0Vtbdkz7S9jJoVkJ7H-68FcbE5pgCKgB/s1600/IMG_20160418_103759.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The black and red wires will just connect the bluetooth module to the power and ground of the Arduino microcontroller. The yellow and green wires will connect to analog ports on the Arduino in order to transmit and receive signals. Serial signals work by having each connected device transmit information from a port labeled TXD and receive signal from a port labeled RXD. So we're going to use the green wires to receive signals from the Arduino (RXD) to the bluetooth module, and we're going to use the yellow wires to transmit signals to the Arduino (TXD).
    &lt;/p&gt;
&lt;h6&gt;The voltage divider&lt;/h6&gt;
&lt;p&gt;
        The signal that is going into the bluetooth module needs to be at 3.3v so we will need to connect that wire through a voltage divider. A voltage divider just causes some voltage to be lost directly to ground without going through another part of the circuit.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Impedance_voltage_divider.svg/220px-Impedance_voltage_divider.svg.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In our circuit that means we need to add two resistors connected to the yellow lead coming out of the RXD pin.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-k974hT3hAmg/VxUobvFKDLI/AAAAAAAAGCQ/5i4xEP3xI0s1mbOsX6FluNJQnAHOaGcGQCKgB/s1600/IMG_20160418_103846.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We'll use a 1 kOhm resistor on the line to the Arduino input and a 2 kOhm resistor on the line to the ground. This will cause most of the voltage to be on the Arduino input with only a little being divided away. What would happen if we had used 2kOhm on both?
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-pe5KXXeO_ws/VxUDQqvwcYI/AAAAAAAAGBE/MVdcat5kge8MoqArk7USNjhoY5q5iOZYACKgB/s1600/IMG_20160418_103858.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To make things more clear I used a black wire coming off the 2 kOhm resistor (going to ground) and a white wire off the 1 kOhm resistor (going to the inputs).
    &lt;/p&gt;
&lt;h4&gt;Connecting to the board&lt;/h4&gt;
&lt;p&gt;
        The final step for connecting the module is to plug it into the board itself. You can figure out how to connect our wires from the diagram above and using your logic. The important thing to know is that A0 is going to be doing the receiving from the bluetooth module while A1 is going to be doing the sending to the module. Can you figure out which color wires should connect even without looking? &lt;strong&gt;IMPORTANT: Two of the wires in the next image are reversed so you have to figure out which color goes where!&lt;/strong&gt;
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-TNl0oI6tGK0/VxUDQvqxLJI/AAAAAAAAGBE/vf7lQGaqlu4Y-HKWiHVZ3chg0KrvXDLgwCKgB/s1600/IMG_20160418_104051.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The board has a switch that you'll have to change too. This switch changes the Arduino circuitry so that now analog ports A0 and A1 will work just like the Serial USB works. This is called SoftwareSerial and we'll talk more about it next time, but for now just make sure that the switch points to &quot;XBEE SW SERIAL&quot;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-Wykpn_3f1eE/VxUMhB-KZMI/AAAAAAAAGB0/texGL8Nz6uAy-my0T-wHH_lsC-6b4WxyQCKgB/s1600/IMG_20160418_113003.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Renaming the Bluetooth Module&lt;/h4&gt;
&lt;p&gt;
        If you are working with more than one bluetooth module in the same area, you will need to rename your module so that you don't get it confused with any of the other ones in the area. To do this you will need to upload some special code to your Arduino that'll let you write from your USB serial to the modules serial line.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;#include &amp;lt;RedBot.h&amp;gt;&lt;br/&gt;#include &amp;lt;RedBotSoftwareSerial.h&amp;gt;&lt;br/&gt;&lt;br/&gt;RedBotSoftwareSerial swsp;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  Serial.println(&quot;Arduino is ready&quot;);&lt;br/&gt;  swsp.begin(9600);&lt;br/&gt;  Serial.println(&quot;BTserial started at 9600&quot;);&lt;br/&gt;  delay(50);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  if (swsp.available())&lt;br/&gt;    Serial.write(swsp.read());&lt;br/&gt;&lt;br/&gt;  // Keep reading from Arduino Serial Monitor and send to HC-05&lt;br/&gt;  if (Serial.available()){&lt;br/&gt;    char c = Serial.read();&lt;br/&gt;    Serial.write(c);&lt;br/&gt;    swsp.write(c);&lt;br/&gt;  }&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        After this code is uploaded you should power on the bluetooth module. Next open the Serial Monitor and you should see the text &quot;Arduino is ready&quot; and &quot;BTSerial started at 9600&quot;. At this point, if you type in the Serial Monitor nothing special should happen. You need to activate the module's AT mode, which will allow you to change internal programming of the module. To do this you need to press and hold the tiny button sitting next to the EN line on the module.
    &lt;/p&gt;
&lt;p&gt;
        IMPORTANT: In the bottom right of the Serial Monitor, you need to make sure you have selected &quot;Both NL and CR&quot; and &quot;9600&quot;. This ensures that every time you press enter, the message is sent with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Newline&quot;&gt;New Line&lt;/a&gt; character. The Bluetooth module requires new lines at the end of every command.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-CTsSPHDBE9Y/Vz5g3mMsFaI/AAAAAAAAGOI/T2-ydewCf7Q_Mjc_KV-oRSONoZXkVcrlwCLcB/s1600/serial_nlcr.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        While holding down that button you can type &quot;AT&quot; and the serial monitor should respond &quot;OK.&quot; Next type &quot;AT+NAME&quot; to see the current name of the module(which should be &quot;HC-05&quot;). Finally type &quot;AT+NAME=####&quot; where you should put a unique name in place of #### so that you can identify your module when you try to pair with it. After you've done that, simply turn the Arduino back off and back on to reset the Bluetooth module.
    &lt;/p&gt;
&lt;h4&gt;Connect bluetooth device&lt;/h4&gt;
&lt;p&gt;
        Again connecting will be different on every machine, but we'll show the steps for Windows.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-fMqFoxy7M0I/VxUyXB7QHfI/AAAAAAAAGCw/wDy8YmUnWz8uM_XuRyIF4NiOGVYBllwXwCLcB/s1600/icon-bluetooth.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You'll start by making sure that the bluetooth module is powered on and blinking. Next, right click on the little bluetooth icon in the corner and select &quot;Connect Devices&quot; or something similar. This will open a dialog that let's you search for the bluetooth module. There's no guarantee on the name but it might say HC-05 if you're lucky.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/F4D/GW1B/H1JUIZBK/F4DGW1BH1JUIZBK.MEDIUM.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You'll have to move through a few more steps until you need to add a pairing code to make the devices talk to each other. This is just how bluetooth makes sure that you aren't accidentally connecting to the wrong device. For me the pairing code was 1234, but this is not guaranteed to be correct.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FHS/ORJ6/H1JUIZBJ/FHSORJ6H1JUIZBJ.LARGE.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You'll have to figure out which serial port the device is talking to. That can be found in the device properties.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FWZ/8AGB/H1JU5CJD/FWZ8AGBH1JU5CJD.LARGE.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Write to Serial Bluetooth with Tera Term&lt;/h4&gt;
&lt;p&gt;
        Next, we have to set up Tera Term to talk to that port. Tera Term is pretty much the same thing as the Serial Monitor, but it works slightly better. Importantly, we can use it with the COM port that the Bluetooth is talking to.
    &lt;/p&gt;
&lt;h6&gt;Install Tera Term&lt;/h6&gt;
&lt;p&gt;
        The first thing we're going to do is get Tera Term onto our machines. Installing Tera Term will be different on every system, but for Windows machines, you can simply download the latest .exe file from their website.
    &lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://en.osdn.jp/projects/ttssh2/releases/&quot;&gt;https://en.osdn.jp/projects/ttssh2/releases/&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
        Once Tera Term is installed, open it. After you open Tera Term you just have to select he same COM Port connected to the Bluetooth. The trick here is that our Bluetooth modules actually connect to two COM Ports, but only one of them works. It appears to be totally random which COM port is selected so you have to guess. If you guess correctly, the blinking pattern on the Bluetooth chip will change to two short flashes. If you guess wrong, you just have to reopen Tera Term and select the other port.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://cdn.instructables.com/FSH/QADB/H1JU5CJC/FSHQADBH1JU5CJC.LARGE.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Once you think you're connected you need to get some code on your Arduino to really see if it's working.
    &lt;/p&gt;
&lt;h4&gt;Checking for connectivity&lt;/h4&gt;
&lt;p&gt;
        As a simple test case we can use the following code from techbitar to blink code over the serial port once we have the computer connected to the Arduino.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;#include &amp;lt;RedBot.h&amp;gt;&lt;br/&gt;#include &amp;lt;RedBotSoftwareSerial.h&amp;gt;&lt;br/&gt;&lt;br/&gt;int counter =0;&lt;br/&gt;RedBotSoftwareSerial swsp;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  swsp.begin(9600);&lt;br/&gt;  delay(50);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  counter++;&lt;br/&gt;  swsp.print(&quot;Arduino counter: &quot;);&lt;br/&gt;  swsp.println(counter);&lt;br/&gt;  delay(500); // wait half a sec&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The part where we define swsp relies on using Software serial to make a &quot;software&quot; version of the regular serial port (i.e. the one we use when we write Serial.println()). We don't have to worry about how this works under the hood (unless something doesn't work).
    &lt;/p&gt;
&lt;h4&gt;Challenge: Drive the car&lt;/h4&gt;
&lt;p&gt;
        You now have swsp working just like a regular USB serial port. So use it just like you would to control the Redbot! If you can't figure it out, you can cheat and click in the box to see the code to drive the car.
    &lt;/p&gt;
&lt;input name=&quot;answer&quot; onclick=&quot;showDiv()&quot; type=&quot;button&quot; value=&quot;Click to Cheat&quot;/&gt;

&lt;br/&gt;

&lt;script&gt;
function showDiv() { document.getElementById('welcomeDiv').style.display = &quot;block&quot;; }
&lt;/script&gt;</description>
        <pubDate>Mon, 18 Apr 2016 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2016/04/bluetooth-controlled-redbot-construction/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2016/04/bluetooth-controlled-redbot-construction/</guid>
        
        <category>electronics</category>
        
        <category>robots</category>
        
        
      </item>
    
      <item>
        <title>Connecting the Artifice Center with a Shared NAS Drive</title>
        <description>&lt;p&gt;
        These are some quick instructions for anybody interested in connecting a NAS to Linux computers on a closed local network. In particular, this guide will help to reconnect the NAS drive to the computers at the &lt;a href=&quot;www.artificechicago.org&quot;&gt;Artifice Tech Center&lt;/a&gt; in Woodlawn.
    &lt;/p&gt;
&lt;h4&gt;The NAS drive&lt;/h4&gt;
&lt;p&gt;
        A NAS (&lt;a href=&quot;https://en.wikipedia.org/wiki/Network-attached_storage&quot;&gt;Network attached storage&lt;/a&gt;) device allows you to essentially connect hard drives directly to your network without needing them to be associated with a &quot;real&quot; computer. If you have a wireless router, you can just plug the device straight into the router.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-uz-UeIv9vhc/Vz54Bh5sTtI/AAAAAAAAGOo/UIHzIL2AglwfrH_ks9BnkDmK5ohzc7vxACKgB/s1600/CAM00041.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        From the hardware end there isn't really much more to it than that. The device should have it's own IP address that you can communicate with from any other device on the network.
    &lt;/p&gt;
&lt;h4&gt;Making a Shared folder on the NAS&lt;/h4&gt;
&lt;p&gt;
        To let other computers modify the disk drives in the NAS, you need to set up a shared folder on it. The machine case itself should have it's access point IP address printed somewhere on it. If for some reason it doesn't, you'll need to use other information printed on it to search the web or the address.
    &lt;/p&gt;
&lt;p&gt;
        Once you have the IP, you can connect to the NAS simply by typing that address into the browser on any computer in your local the network. To connect to mine, I navigated to &lt;a href=&quot;http://192.168.1.32&quot;&gt;http://192.168.1.32&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        You can find the specific instructions for making network shares on &lt;a href=&quot;http://www.dlink.com/uk/en/support/faq/network-storage-and-backup/nas/dns-series/dns-320l/uk_create-users_groups-and-folder-sharing-in-dns-320l&quot;&gt;dlink's help site&lt;/a&gt;. The process is mostly self-explanatory. I made a directory called Artifice_Share, and set the permissions so that anybody could read or write anything.
    &lt;/p&gt;
&lt;h4&gt;Mounting a drive to a Linux machine (Mint)&lt;/h4&gt;
&lt;p&gt;
        The more mysterious step is how to get a machine to automatically connect to the shared drive. Fortunately, the instructions that I got from &lt;a href=&quot;http://forums.dlink.com/index.php?topic=7848.0&quot;&gt;this post on the dlink forums&lt;/a&gt; are actually quite easy. In the technical jargon we are setting up our &quot;fstab&quot; file to &quot;mount&quot; the directory. In practice that just looks like adding a line to our &quot;/etc/fstab&quot; file:
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;.... a bunch of other junk ....&lt;br/&gt;&lt;br/&gt;//&lt;span style=&quot;color:red&quot;&gt;192.168.1.32&lt;/span&gt;/Volume_1/Artifice_Share /home/artifice/Desktop/Artifice_Share cifs guest,rw,uid=1000,gid=1000,nounix,iocharset=utf8,file_mode=0777,dir_mode=0777 0 0&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        You'll have to adjust the IP (in red) to match with the device ID for your particular NAS. After you restart the computer there should be 2 folders on the Desktop both named Artifice_Share. I don't know why two show up, but it doesn't seem like it's causing any harm.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 30 Mar 2016 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2016/03/connecting-artifice-center-with-shared/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2016/03/connecting-artifice-center-with-shared/</guid>
        
        <category>infra</category>
        
        
      </item>
    
      <item>
        <title>Star Wars Themed Settlers of Catan</title>
        <description>&lt;p&gt;
        I have been wanting to get a Settlers of Catan game for ourselves ever since I played it for the first time a few months ago. It looked like an incredibly simple game setup so my girlfriend and I figured it would easy enough to build the game ourselves.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-63w9Rl8tGLI/Vrgh8uWuEjI/AAAAAAAAF4o/dKeaPCS_mOQ/s1600/IMG_20160207_225952.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Of course, since we were making it ourselves this was a prefect opportunity to make the game theme just the way we wanted. Amid the hype surrounding &lt;a href=&quot;http://www.imdb.com/title/tt2488496/&quot;&gt;The Force Awakens&lt;/a&gt;, we decided to go for a Star Wars theme. Prepare for the nerdy, folks.
    &lt;/p&gt;
&lt;p&gt;
        There are &lt;a href=&quot;http://www.starwars.com/databank&quot;&gt;nearly infinite possibilities&lt;/a&gt; provided by the &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_Star_Wars_books&quot;&gt;thousands of stories&lt;/a&gt; set in the &lt;a href=&quot;http://starwars.wikia.com/wiki/List_of_planets&quot;&gt;many planetary systems&lt;/a&gt; of the &lt;a href=&quot;http://www.swgalaxymap.com/&quot;&gt;Star Wars Galaxy&lt;/a&gt;. Not to mention that you can choose from any period in the galaxy's &lt;a href=&quot;http://starwars.wikia.com/wiki/Timeline_of_galactic_history/Legends&quot;&gt;roughly 1 billion year history&lt;/a&gt; as your setting&lt;a href=&quot;#/footnote&quot;&gt;*&lt;/a&gt;. Needless to say, this leaves you with a lot of choices to make in designing a game's backdrop.
    &lt;/p&gt;
&lt;p&gt;
        Other people have made Star Wars Settlers games before. The two that we could find were Settlers of the Old Republic and Settlers of the Empire. Both of them look great, especially Settlers of the Empire, so we wanted to make sure we approached it differently so that we could have our own
    &lt;/p&gt;
&lt;h4&gt;Settlers of the Outer Rim&lt;/h4&gt;
&lt;p&gt;
        Ultimately, we decided on a theme based on the time period around Episode VII. The game is set in the most distant reaches of the galaxy, known as the Outer Rim. The basic premise is that after the fall of the Empire and the rise of the New Republic, new traders and settlers will try to expand the influence of the Republic to systems in the so called Outer Rim. I think this is a fairly reasonable concept, and it steers the game's focus away from more established periods of &lt;a href=&quot;https://en.wikipedia.org/wiki/Star_Wars_canon&quot;&gt;Star Wars Canon&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The gameplay is still exactly identical to the original Settlers of Catan. Only the names and faces of the cards have been changed to reflect the new storyline. When we play it, I like to kind of pretend we're really in this storyline with its grand theme of galactic economics.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-r4KSiXOMmNA/VrgjXxxAQAI/AAAAAAAAF5A/7ruINkl9ArE/s1600/building_panel.png&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;
&lt;h6&gt;The Story&lt;/h6&gt;
&lt;p&gt;
        You're a galactic pioneer of the New Republic, looking to find new resources in the Outer Rim of the galaxy. The main hurdle for trade in this sector is the establishment of new and secure hyperspace routes, landing pads, and space stations. Of course, for such a lucrative opportunity there's obviously a lot of competition. Your challenge is to reach economic dominance of the Outer Rim before any of your opponents.
    &lt;/p&gt;
&lt;p&gt;
        To build your hyperspace routes and resupply stations you'll need to extract resources from the star systems in this region. You can also trade with the Bank of the New Republic or you can look for better deals with smugglers at the edges of the galaxy.
    &lt;/p&gt;
&lt;p&gt;
        In addition, to help you control more territory, you can also invest in development of your trade network. These investments can pay off with exclusive Republic contracts, captured smugglers, free hyperspace routes, or any of a number of valuable ships and droids. Finally, you can also attain abandoned lightsabers, which help you gain influence over a confederation of Outer Rim bounty hunters.
    &lt;/p&gt;
&lt;p&gt;
        At each turn, you roll a dice to find out which systems have resources ready for extraction. Then you proceed to trade, or to purchase equipment and development cards.
    &lt;/p&gt;
&lt;p&gt;
        For every space port or space station you will receive 1 or 2 Victory Points, respectively. The Republic will reward you with extra points if you provide the longest hyperspace route, or if you recover the largest number of lost lightsabers. The game ends when one player attains 10 Victory Points.
    &lt;/p&gt;
&lt;h4&gt;Game Components&lt;/h4&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Outer Rim Gameboard&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://3.bp.blogspot.com/-cwRdoN-GzMs/VrgcWi35s0I/AAAAAAAAF3U/ROnufWxP2V4/s1600/IMG_20160207_222522.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Game Pieces&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://1.bp.blogspot.com/-dKfqIIngOWg/Vrgcla728UI/AAAAAAAAF3k/Iq218v-WSwQ/s1600/IMG_20160207_222135.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Galactic Resources&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-NnlWcNx0amE/VrgcpSaV4-I/AAAAAAAAF3s/BSpvJLTxnBk/s1600/IMG_20160207_221604.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Development Cards&lt;/h6&gt;
&lt;img border=&quot;0&quot; src=&quot;https://2.bp.blogspot.com/-YK3EwaQSays/VrgiBPdo0hI/AAAAAAAAF4w/hVCKIcw6l7E/s1600/IMG_20160207_224717.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Gameplay&lt;/h6&gt;
&lt;p&gt;
        As mentioned above, the gameplay follows the original &lt;a href=&quot;http://www.catan.com/service/game-rules&quot;&gt;Settlers of Catan rules&lt;/a&gt;. If you've played Settlers before, you'll see the parallels immediately. Otherwise I suggest &lt;a href=&quot;https://www.youtube.com/watch?v=mco5SL4-y-c&quot;&gt;this video&lt;/a&gt; to get you more acquainted with how to set up and play.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h6 style=&quot;text-align:center&quot;&gt;Graphics for Download&lt;/h6&gt;
&lt;p&gt;
        If you like the idea of the game and would like to recreate it for yourself, we've put the &lt;a href=&quot;https://github.com/lots-of-things/settlers-outer-rim&quot;&gt;svg files&lt;/a&gt; on the &lt;a href=&quot;https://github.com/lots-of-things/&quot;&gt;MakeLofT Github&lt;/a&gt;. I've just embedded all the images directly and I haven't rerasterized or compressed anything so some of the files are a little big. Hope you have fun if you put it together, and may the Force be with you.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://4.bp.blogspot.com/-xR4w_yMiK2k/VrglVD3UOBI/AAAAAAAAF5M/xCLD7ReUn7E/s1600/bacta.png&quot; title=&quot; &quot;/&gt;
&lt;p id=&quot;footnote&quot;&gt;*&lt;sub&gt;I know that the possibilities have technically been drastically slashed by Disney's &lt;a href=&quot;http://www.dailydot.com/geek/star-wars-expanded-universe-not-canon/&quot;&gt;decanonization of the Expanded Universe&lt;/a&gt;, but I still believe that the Legends are real.&lt;/sub&gt;
&lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 07 Feb 2016 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2016/02/star-wars-themed-settlers-of-catan/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2016/02/star-wars-themed-settlers-of-catan/</guid>
        
        <category>games</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <title>The Plexi+Rock Boot Tray Accident</title>
        <description>&lt;p&gt;
        Over the holidays, I always end up with new projects to make for gifts for my friends and family. This time for Christmas my gf's mom asked me to make a boot tray for her new apartment. She specifically said, &quot;use any materials you want,&quot; so I took her up on that by combining left-over plexiglass and tumbled gravel to make a classic, &lt;a href=&quot;https://www.google.com/search?q=rock+shoe+tray&amp;amp;source=lnms&amp;amp;tbm=isch&amp;amp;sa=X&amp;amp;ved=0ahUKEwjIvvu4t-7JAhXDKx4KHWlQANoQ_AUICCgC&amp;amp;biw=1319&amp;amp;bih=671&quot;&gt;rock boot tray&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-f-a5ltIGHv0/Vni1dxc9W0I/AAAAAAAAFpI/svbf1BgmCaA/s1600/IMG_20151218_172725.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This projecct was quite funny because really nothing went expected, but the result still looks pretty impressive in my opinion At the very least this is another example that muddling through will &lt;strong&gt;almost always&lt;/strong&gt; get you what you want. That should probably be the official slogan of this blog.
    &lt;/p&gt;
&lt;h5&gt;The plexiglass tray&lt;/h5&gt;
&lt;p&gt;
        The tray is the main endeavor in this project. Once you have a tray, the rest is just cleaning up some rocks. But there are so many ways to make a tray, I didn't know what I wanted to do. I thought originally I'd go with simple bent sheet metal, but that was too much like what I made for Claire's &lt;a href=&quot;http://www.makeloft.org/2014/12/introducing-daves-grill-it-all.html&quot;&gt;dad last year&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        Instead, I stumbled on some simple clear plastic that was left over from an experiment at work. Most people would probably call this plexiglass, but it's actually technically Lexan (polycarbonate), not plexiglass (acrylic).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-o1cdCP3oWhU/Vni4FamMBvI/AAAAAAAAFpU/JBQp0MHz7gc/s1600/IMG_20151216_194043.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To mold polycarbonate, you only need to heat it to &lt;a href=&quot;http://www.instructables.com/answers/Is-it-safe-to-melt-polycarbonate/&quot;&gt;somewhere just above 150&lt;/a&gt;. So I threw a test piece into the oven to see what it would do. I slowly heated to 200 but it was still stiff. Then I went to 250 and finally, 300 before it started to bend.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-9yAsrKMm1hY/Vni5HkazydI/AAAAAAAAFpg/gLatHIYxtd4/s1600/IMG_20151216_194104.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The results weren't amazing, but the edge was moldable so I figured I'd toss in the main piece and see what I could make of it. However, for this piece the oven was already warmed up to 300 and this had some pretty crazy (but pretty) results!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-R_TpCiU7ak4/Vni6KrSPOZI/AAAAAAAAFps/g8WtrRPRyww/s1600/IMG_20151216_213301.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;a href=&quot;http://bbs.homeshopmachinist.net/archive/index.php/t-30224.html&quot;&gt;As it turns out&lt;/a&gt;, polycarbonate has a high water content in the plastic so if you rapidly ramp the temperature up past the boiling point, the water inside the material starts to boil out. In this case, this caused the plastic to turn white with tiny bubbles and for the edges to turn up.
    &lt;/p&gt;
&lt;p&gt;
        But amazingly that was exactly what I wanted anyway! So... I just decided to keep it like that (not that I had much choice at that point). The edge wasn't perfectly symmetric along the back side, but I figured that part could go against the wall.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-NvGgUGT2eaI/Vni6-6bDNYI/AAAAAAAAFp0/FoemmhWj8C0/s1600/IMG_20151216_213326.jpg&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Cleaning rocks&lt;/h5&gt;
&lt;p&gt;
        For rocks I just gathered pebbles from vacant lots and trails around my neighborhood. I tried to pick prettier sets, but once I realized how many I need I just started grabbing handfuls.&lt;p&gt;
&lt;p&gt;
                I did want them to shine a little though. After I cleaned them, I tried to &quot;cure&quot; them (or something) by putting them through an oil bath followed by a soap bath.
            &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-P9v_iJDZItw/Vni7a7NSRHI/AAAAAAAAFp8/_qFXUh60b6E/s1600/CAM00440.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                This led to a significant improvement in shininess (at least temporarily).
            &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-M91SKhxlvVQ/Vni8Rcqv_sI/AAAAAAAAFqI/bwDGgCC1Sjw/s1600/IMG_20151218_172628.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                After, piling the rocks on the tray, all that was left was to add shoes. And I think it made for a cute and practical little outdoorsy themed home furnishing.
            &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-gjf0sss2iE8/Vni8j3TsVuI/AAAAAAAAFqQ/sI2nGfewNmc/s1600/IMG_20151218_172705.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                I almost wanted to keep it for our house.
            &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;&lt;/p&gt;</description>
        <pubDate>Tue, 22 Dec 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/12/the-plexirock-boot-tray-accident/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/12/the-plexirock-boot-tray-accident/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <title>Q&amp;amp;A on the Route Crime Calculator</title>
        <description>&lt;p&gt;
        I've recently built a cool little web app that helps evaluate the number of crimes occurring along a person's travel route in the City of Chicago. To elaborate a little on the rationale and methodology, I've written this blog post where I answer some plausible questions.
    &lt;/p&gt;
&lt;h6&gt;How safe is travelling around in Chicago?&lt;/h6&gt;
&lt;p&gt;
        That's hard to say, but hopefully I've made it a little easier to evaluate that. Obviously both native Chicagoans and visitors to the city have often find themselves travelling on public transit through neighborhoods that can make them feel unsafe. I wanted to explore this question and give some way to compare different routes and parts of the city so I started analyzing some of the city's open crime data for answers. This led to some interesting results so I decided to try to open that data up to the public in some reasonable way by making a little webapp.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-vLP4HuiJA6A/Vm95iCkSAKI/AAAAAAAAFcY/cMtPnk43kQg/s1600/routecrime.png&quot; title=&quot; &quot;/&gt;
&lt;h6&gt;So what can it do?&lt;/h6&gt;
&lt;p&gt;
        To help prevent exposure to crime and to make everybody feel more safe, this tool evaluates the likelihood of criminal activity based on your transit route. It shows a few options and let's you see whichever one is the &quot;safest.&quot;
    &lt;/p&gt;
&lt;h6&gt;So it's like minority report or something?&lt;/h6&gt;
&lt;p&gt;
        The problem of predicting crime has been tackled before in &lt;a href=&quot;http://www.theverge.com/2014/2/19/5419854/the-minority-report-this-computer-predicts-crime-but-is-it-racist&quot;&gt;Chicago&lt;/a&gt; and &lt;a href=&quot;http://thinkprogress.org/justice/2015/02/12/3622235/police-departments-use-big-data-predict-crime-will-hit-next/&quot;&gt;elsewhere&lt;/a&gt;. However, it seems like most of the focus I've seen on this matter focused on its relation to policing strategies rather than public awareness. I don't intend to predict crimes, and I certainly don't want to build a tool that could be used to unfairly target citizens. I'd prefer that everybody just be aware of the real dangers (or lack of dangers) presented to them. I wanted to make something that helps the average person better evaluate exactly what they are facing when they take to the street every day.
    &lt;/p&gt;
&lt;h6&gt;So then what exactly does it do?&lt;/h6&gt;
&lt;p&gt;
        This tool is really just a fancy database query that looks up the past crimes that have occurred at any block in the city. I break the data up based on time of day, day of the week, and month of the year to make the prediction as accurate as possible. With that data, I can compute the average number of crimes that occur at that time and place over the past couple of years, which gives me a rate for crime occurrence.
    &lt;/p&gt;
&lt;p&gt;
        Now from good old &lt;a href=&quot;https://developers.google.com/maps/documentation/directions/?hl=en&quot;&gt;Google Directions API&lt;/a&gt;, I can find out for each route how long you're going to spending in a given region. And from that I can simply add up the total number of crimes that will happen in an area during the time that you will be there. I repeat that for all the areas that you will pass through on your route and that's the total number of crimes that will happen in your vicinity during your trip.
    &lt;/p&gt;
&lt;h6&gt;So you present some big number of crimes?&lt;/h6&gt;
&lt;p&gt;
        Surprisingly no. The number of crimes is actually pretty darn small, so I present a relatively tiny &lt;a href=&quot;https://en.wikipedia.org/wiki/Probability&quot;&gt;probability&lt;/a&gt; of a crime occurring, in the form of classic &lt;a href=&quot;https://en.wikipedia.org/wiki/Odds&quot;&gt;betting odds&lt;/a&gt;. &lt;h6&gt;And you're satisfied with that?&lt;/h6&gt;
&lt;p&gt;
            Actually I'm pretty disappointed with the final result because there's a huge half of the story missing. To really present how likely a crime is to happen to &lt;strong&gt;you&lt;/strong&gt;, I need to know how many people are on the street when a crime occurs. That means I need to have some idea about street traffic, which is harder to find than you'd think. This is my quiet plea for somebody to make that data available somewhere.
        &lt;/p&gt;
&lt;h6&gt;Where did you get that data?&lt;/h6&gt;
&lt;p&gt;
            Since 2000, the city of Chicago has been tracking all of their criminal activity using their &lt;a href=&quot;https://portal.chicagopolice.org/portal/page/portal/ClearPath/Online%20Services/ICLEAR&quot;&gt;CLEAR database&lt;/a&gt;. The majority of the data on crime type and location has been &lt;a href=&quot;https://data.cityofchicago.org/Public-Safety/Crimes-2001-to-present/ijzp-q8t2&quot;&gt;put online&lt;/a&gt; to allow the public to have open access to it. This has been used in &lt;a href=&quot;http://blog.spotcrime.com/2015/07/impacts-of-open-crime-data.html&quot;&gt;other projects&lt;/a&gt; to &lt;a href=&quot;http://chicagocrimeviewer.roosdesignconsulting.com/&quot;&gt;visualize local crime maps&lt;/a&gt;, &lt;a href=&quot;http://&quot;&gt;report recent crimes&lt;/a&gt;, and &lt;a href=&quot;http://www.crimeinchicago.org/&quot;&gt;display other trends&lt;/a&gt;.
        &lt;/p&gt;
&lt;h6&gt;So is that it?&lt;/h6&gt;
&lt;p&gt;
            I hope not. I really want other people to pick this up and work on it so I've put it all up in a &lt;a href=&quot;https://github.com/lots-of-things/route-crime-calculator/blob/master/analysis/crime_maps_viz.ipynb&quot;&gt;GitHub project&lt;/a&gt; for someone else to run with. Anyone is free to modify it any way they want, and I'll push their mods to the original if they work. So please help and have fun.
        &lt;/p&gt;
&lt;/p&gt;</description>
        <pubDate>Mon, 14 Dec 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/12/route-crime-calculator/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/12/route-crime-calculator/</guid>
        
        <category>data science</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>ARFI: A Robotic Dog</title>
        <description>&lt;p&gt;
        Over the past couple of months, me and my friends at &lt;a href=&quot;http://blog.artificechicago.org/&quot;&gt;Artifice Tech Education&lt;/a&gt; have been building our very own robot dog mascot, &lt;a href=&quot;http://blog.artificechicago.org/p/arfi-robotic-dog.html&quot;&gt;ARFI&lt;/a&gt;. He's been a lot of fun to build, and although we really don't have much in the way of &lt;a href=&quot;https://github.com/lots-of-things/arfi-the-kionoid&quot;&gt;plans&lt;/a&gt; or intricate design specs, I thought I'd share some of the production experience here. Hope you enjoy...
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-YHdCwZrollQ/Vm-K1o3JEjI/AAAAAAAAFc8/QF2LTMuCzmk/s1600/CNrF-7aWsAAqvLM.jpg%253Alarge.jpeg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Preliminary Construction&lt;/h4&gt;
&lt;p&gt;
        My friends from &lt;a href=&quot;http://blog.artificechicago.org/&quot;&gt;Artifice&lt;/a&gt; went into the machine shop with me to try to piece together the basic aluminum frame to assemble. Eventually we settled on a pretty simple design equipped with rolly chair wheels that we had lying around.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-WqTeBOAwJeU/Vm-E2LPokEI/AAAAAAAAFco/UQn7GAucpjk/s1600/CAM00224.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We brought it down to the center where Jeice had a fun time putting it together for us. He got it looking pretty slick for us.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-QIU3ijVL0BU/Vm-E2OiTHZI/AAAAAAAAFco/q_hOpUKRYzI/s1600/CAM00233.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-tnOv_k1oSuE/Vm-E2JqkGpI/AAAAAAAAFco/-vD-juIwgJQ/s1600/CAM00234.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But unfortunately, our design skills were not so clean and our little puppy ran amok and hurt himself.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/nMDIItKs4bw&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        So it was back to the workbench to figure out the next step.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The trouble with the switch&lt;/h4&gt;
&lt;p&gt;
        We quickly reworked the battery mount and made little corrections to the way the wheels worked, but our big problem was wiring up a significantly non-resistant switch to drive the motor.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-N7FfTH4S6dY/Vm-E2DPcowI/AAAAAAAAFco/cYhQeb5Wm30/s1600/CAM00251.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We finally landed on a home made (read SPARKING) relay that did the trick. Basically, we set up a motor to move a wire back and forth to touch another wire and complete the circuit. The power went straight from battery into the motor to drive it, which I'm pretty sure not how these things normally work.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-Pst_MTRrzv0/Vm-E2ELM-vI/AAAAAAAAFco/J2Y_SyxEqYY/s1600/CAM00271.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But it was functional enough to drive out to the parade the very next day.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/qdMcYOVm-uo&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;h4&gt;The final touches&lt;/h4&gt;
&lt;p&gt;
        Now that he was running, I decided to bring him in for other people to help us make a little more... dog-like. I'll admit that the kids were teasing me for thinking that this robot was anything like a dog.
    &lt;/p&gt;
&lt;p&gt;
        I brought him into the Science Hack Day at the Adler planetarium to see who would help me out. Fortunately, quite a few people came around and helped me throw together an exterior for the boy. I thought he looked quite cute by the end.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-c-3T0Nyr8Ow/Vm-E2PnJE0I/AAAAAAAAFco/Un-Rx84FKuM/s1600/CAM00296.jpg&quot; title=&quot; &quot;/&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-DKXzUk3slyE/Vm-E2FSTokI/AAAAAAAAFco/YCIzkQr1_uA/s1600/CAM00298.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And of course, the most fun is always getting to drive him around!
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/jEU99vibnBg&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
</description>
        <pubDate>Mon, 14 Dec 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/12/arfi-robotic-dog/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/12/arfi-robotic-dog/</guid>
        
        <category>electronics</category>
        
        <category>robots</category>
        
        
      </item>
    
      <item>
        <title>Paper Chess Set</title>
        <description>&lt;p&gt;
        I've recently started playing chess with the students at the &lt;a href=&quot;http://blog.artificechicago.org/&quot;&gt;after-school program&lt;/a&gt; where I volunteer. It's fun, but we only have one chess set so only two students get to play at a time. Since our program is being run on such a shoestring budget, I decided I'd try to build a super economical chess set out just four pieces of paper and some hot glue.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-mroh4I9gYU0/Vlv0H3wzd-I/AAAAAAAAFZI/h4MVdNrbpOQ/s1600/IMG_20151128_123019.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I found an &lt;a href=&quot;http://www.josephwu.com/Files/PDF/chess.pdf&quot;&gt;origami chess set&lt;/a&gt; online, but decided that it just didn't look like the actual chess pieces. After a little exploring, I came up with this set, which I think more closely resembles the &quot;classic&quot; chess look-and-feel. It's not exactly origami, but below I've described the step-by-step instructions for each piece. Enjoy.
    &lt;/p&gt;
&lt;h4&gt;Cutting the paper&lt;/h4&gt;
&lt;p&gt;
        The 16 pieces all start from square slips of paper of varying sizes that are all cut from basic 8&quot; x 11&quot;. To make the king and queen you use a square with sides equal to half the width of a sheet of paper. The pawns are made from 1/4 page width and all the other pieces come from 1/3 page width squares.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-IaXydEjCz2w/VlvmF3eo2JI/AAAAAAAAFXg/TQjpp_Dcykg/s1600/IMG_20151123_222958.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Pawn&lt;/h4&gt;
&lt;p&gt;
        We'll start with the easiest one. All the pieces start by being rolled into a cone and fixed with hot glue. For the pawns we'll use the smallest squares.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-wRl_-9joldQ/Vlvmey0tk8I/AAAAAAAAFXk/Nw8I0dU-zck/s1600/IMG_20151123_223103.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Next the open end is folded inside to make the base even. You can try different methods with this and keep going until you have the desired flatness and height.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-jVVKdZB1y8Q/Vlvme54KnUI/AAAAAAAAFXk/kXvp1U54lrg/s1600/IMG_20151123_223300.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And finally, for the pawn, I just crush the pointy tip down using a pen.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-IpVy-YfAG2I/Vlvme4ACgoI/AAAAAAAAFXk/qd2sjJK8d08/s1600/IMG_20151123_223213.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;

&lt;p&gt;
    This leaves a simple rounded cone piece perfect for the boring army of pawns.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-Qwi-hppiYGc/VlvoET24_aI/AAAAAAAAFX4/HET5a5bM76o/s1600/IMG_20151123_224637.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Bishop&lt;/h4&gt;
&lt;p&gt;
    The next simplest piece is probably the bishop. You start by making a curved cut along the corner of the paper that will become the tip of the cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-NicIR13ECOU/VlvqMLi6lYI/AAAAAAAAFYI/gIqYdlvT84g/s1600/IMG_20151123_225738.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Then you roll the lower part into a cone with a narrow diameter and then the top part into a cone with a slightly wider diameter.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-pWAW9CjNRfc/VlvqMFi6ytI/AAAAAAAAFYI/GLIoStX-nfk/s1600/IMG_20151123_230054.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Then I crush down the upper cone with the pen like before and cut a little upward facing slit.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-un6rnJtRU7w/VlvqMMJjJBI/AAAAAAAAFYI/6izmauyDq-k/s1600/IMG_20151123_230225.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    And now you have a little bishop to watch over the army of pawns.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-4XEhGOChZJM/VlvqMPUTVcI/AAAAAAAAFYI/uuDsp4fmInU/s1600/IMG_20151123_230455.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Rook&lt;/h4&gt;
&lt;p&gt;
    The rook is a little harder and I'm still not sure how to dimension it right. I start by snipping the square into two rectangles with one a bit wider than the other.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-oTwUMaX7GzA/VlvsgRVXtZI/AAAAAAAAFYU/z2VQOtf6jIo/s1600/IMG_20151124_224331.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The wider one is twisted into a cone with hole in the top and glued together. The base has the long parts tucked under just like for the pawn and bishop.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-gn2oz4Wd3AU/VlvsgeEADnI/AAAAAAAAFYU/Lwyl1eEC5Dc/s1600/IMG_20151124_224358.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The narrower one has the edges folded over and then it gets glued into a little ring.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-qN4e8RJo5eA/VlvsgVajWEI/AAAAAAAAFYU/aBWpgH8snsI/s1600/IMG_20151124_224641.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    You glue the ring onto the cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-TOE_oYF-DaE/VlvsgXW0sYI/AAAAAAAAFYU/9U59hysUzuM/s1600/IMG_20151124_224801.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    And after cutting little notches along the top side of the ring, we have a little outpost.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-l_Kyf8bAwSE/VlvsmCrG9GI/AAAAAAAAFYc/M_CknM8-syQ/s1600/IMG_20151124_224857.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Knight&lt;/h4&gt;
&lt;p&gt;
    The knight was a tough one to figure, but I'm glad it turned out pretty cute. You start by making basically a larger version of the pawn, and then you cut halfway through the top part of the cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-glYc3T7dU5c/VlvvQVOyVGI/AAAAAAAAFYw/VJ8InoAZb8s/s1600/IMG_20151127_205558.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Next, my girlfriend came up with the idea to cut the little ears out like this.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-p1mTZMNuBQs/VlvuuD_56rI/AAAAAAAAFYo/uGZraIeMpp8/s1600/IMG_20151127_210049.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    Finally you glue the hole in the base back together, and there's a cute little horsey.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-50jYVAjfIZM/VlvuuCva5vI/AAAAAAAAFYo/cmWxWd2OW_U/s1600/IMG_20151127_210227.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Queen and King&lt;/h4&gt;
&lt;p&gt;
    The queen and king are very similar except for the piece you put on top. They both start with the largest squares of paper. Again they are rolled into cones, but now the long part at the bottom is cut off to be used for the top.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-0Wb2kIhqPHw/Vlvw3gu7wvI/AAAAAAAAFY8/dnI6-82wlv8/s1600/IMG_20151128_121019.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The top of the cone is also cut off, inverted and stuck back into the top hole. I also changed the diameter of that part of the cone, but I'm not sure that's necessary.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-9A0CL64eHMY/Vlvw3nP1qcI/AAAAAAAAFY8/yYy4vtMUI1k/s1600/IMG_20151128_121132.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    For the queen, the extra piece is turned into a tiny little yamuka that gets inserted into the top cone.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-l9Ra67p5WEU/Vlvw3gJ3zaI/AAAAAAAAFY8/_5b1mzC7oR4/s1600/IMG_20151128_121350.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
    The king's topper has a little cross cut into it and then it's rolled into a cone. You have to trim the cone so that it fits on the top right without too much overhang.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-T37ILCsa1FE/Vlvw3gQNdRI/AAAAAAAAFY8/VSAPilRXIbk/s1600/IMG_20151128_122403.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Next steps&lt;/h4&gt;
&lt;p&gt;
    This is a fun way to make the pieces, but I still need a chessboard. I'm thinking that with the leftover paper I should be able to make the black and white squares to mount onto something else.
&lt;/p&gt;
&lt;p&gt;
    I can't wait to make the other half and start using this. With a cheap chess set like this, I'll never be without the game again!
&lt;/p&gt;</description>
        <pubDate>Sun, 29 Nov 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/11/paper-chess-set/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/11/paper-chess-set/</guid>
        
        <category>art</category>
        
        <category>games</category>
        
        
      </item>
    
      <item>
        <title>Power Analysis of an Indoor Water Fountain</title>
        <description>&lt;p&gt;
        Craving tranquil water splashing in your tiny apartment? You can have a relaxing fountain for under $10 if you have an old phone charger lying around.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-sCw0KnIFbjc/Vc07qYWEjxI/AAAAAAAAEWU/ALv1aEL2tsM/s1600/CAM00277.jpg&quot; title=&quot; &quot;/&gt;
&lt;h4&gt;Simple setup&lt;/h4&gt;
&lt;p&gt;
        The majority of the work is done by this cheap little &lt;a href=&quot;http://www.amazon.com/Andoer-Ultra-quiet-DC12V-Brushless-Submersible/dp/B00LUL3F5K&quot;&gt;$6 pump&lt;/a&gt; that I got from Amazon. I just barely submerged the input under the water's surface and left the output facing up out of the water.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-7w6vyFkv1GI/Vc06CQHr12I/AAAAAAAAEVw/jjFs7svqQmE/s1600/CAM00275.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Powering it was incredibly easy. I just stripped and connected the red and black wires from my power supply to those on the pump. I had a spare switch too so I added it, but that isn't necessary if you're willing to plug it in when you want it on.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-aDcqIxhVBho/Vc06k_TapCI/AAAAAAAAEWA/MexiFx3U8r8/s1600/CAM00282.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I added an assortment of rocks and a friend's ceramic frog to a $2 flower pot base and filled it with water. I tilted the fountain a bit so that it would fling the water over the rocks in a little arc and the fountain was finished.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe align=&quot;middle&quot; allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/V5ysWrSF9xg&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;h4&gt;Power comparison&lt;/h4&gt;
&lt;p&gt;
        The fountain is lovely and cute and all, but as a quick side note, I was curious just how much that little guy was really going to cost me in power. Specifically, I wanted to compare the power consumption of natural noise generation to that of synthetic noise from a speaker. My back-of-the-envelope analysis is a little sloppy so please correct me in the comments if you see a mistake.
    &lt;/p&gt;
&lt;p&gt;
        At 5 Volts, that motor was pulling 2 Watts of power. Since electricity costs about $0.08/kWh, I'm estimating that it'll cost me one penny in electricity every 2.5 days or about $1.50 per year. Meanwhile my radio pulls about 5 Watts so that'll cost me roughly $3.75 per year.
    &lt;/p&gt;
&lt;p&gt;
        Both numbers are pretty small when you think about it, but I'm glad that the natural sound appears to be a better deal. Additionally, this will become less of a concern eventually because I'm hoping to replace the power supply with a solar cell. But then, I'll have to factor in the solar panel cost as well. (Not to mention that the fountain will only run in the daytime.)
    &lt;/p&gt;
&lt;h4&gt;Pump Lifetime&lt;/h4&gt;
&lt;p&gt;
        When the pump finally breaks down, I'll update this post with approximate usage statistics to let you all know the life cycle cost of this guy. Of course, the pump will almost certainly break down before an audio speaker would, but then again, that means I get to build something even better next time!
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Thu, 13 Aug 2015 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2015/08/power-analysis-of-indoor-water-fountain/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/08/power-analysis-of-indoor-water-fountain/</guid>
        
        <category>misc</category>
        
        <category>energy</category>
        
        <category>analysis</category>
        
        
      </item>
    
      <item>
        <title>The Barbie Hadoop Cluster (Multi-Node Cluster)</title>
        <description>&lt;p&gt;
        I've finally finished the Barbie Hadoop Cluster! It's been several months since I &lt;a href=&quot;/2015/01/the-barbie-hadoop-cluster-stage-1.html&quot;&gt;started the project&lt;/a&gt;, but after the hiatus I was ready to come back and get it finished.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-XGwAxKreBtw/VbWKR9SptdI/AAAAAAAAEHU/FgdjpgyQkKM/s1600/CAM00240.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Due to space limitations in our apartment, the stack of 9 Dell PCs is also being used as a TV/monitor stand. They're connected through a switch and all the extra ports on my roouter at the moment. Hopefully at &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;her permanent home&lt;/a&gt;, Barbie will look a little more at ease.
    &lt;/p&gt;
&lt;h4&gt;Setting Barbie Up&lt;/h4&gt;
&lt;p&gt;
        The beginning of the procedure for the setup is basically exactly the same as I described in my &lt;a href=&quot;http://www.makeloft.org/2015/01/the-barbie-hadoop-cluster-stage-1.html&quot;&gt;previous post&lt;/a&gt;, except for a change in the configuration files in the &lt;a href=&quot;https://github.com/lots-of-things/hadoop-compiled&quot;&gt;associated github project&lt;/a&gt;. Pretty much the entirety of the hadoop setup on each computer was accomplished simply with the folowing command.&lt;p&gt;
&lt;pre&gt;&lt;br/&gt;sudo git clone https://github.com/lots-of-things/hadoop-compiled.git /usr/local/hadoop&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                This is followed by changing permissions and adding a few directories to the $PATH by modifiying .bashrc.&lt;p&gt;
&lt;pre&gt;&lt;br/&gt;sudo chown -R doopy:hadoop /usr/local/hadoop&lt;br/&gt;cat /usr/local/addToBash &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                        This had to be done on each of the seven working machines. They each had different RAM and hard disk amounts, with skipper and stacie being the best and barbie and ken being the worst.
                    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-qNgeAOJanSY/VbWUclEdoeI/AAAAAAAAEHw/WLnnP2yBb70/s1600/CAM00241.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
                        I changed the /etc/hosts on every machine so that each machine could recognize each other by name.
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;10.0.0.9        barbie&lt;br/&gt;10.0.0.10       kelly&lt;br/&gt;10.0.0.13       skipper&lt;br/&gt;10.0.0.14       stacie&lt;br/&gt;10.0.0.16       ken&lt;br/&gt;10.0.0.17       christie&lt;br/&gt;10.0.0.18       midge&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                        I decided to make skipper the master, Each machine needs to let the master connect by ssh without a password so I copied Skipper's rsa key made in the initial setup using
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;ssh-copy-id -i ~/.ssh/id_rsa.pub remote-host&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
                        Where remote-host had to be changed to every machine I wanted to connect to. Finally, skipper's slaves file (etc/hadoop/slaves) needed to have each machine added to it (including herself so she would do some work too instead of just running as the NameNode).
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;barbie&lt;br/&gt;kelly&lt;br/&gt;skipper&lt;br/&gt;stacie&lt;br/&gt;ken&lt;br/&gt;christie&lt;br/&gt;midge&lt;br/&gt;&lt;/pre&gt;
&lt;h4&gt;In all honesty...&lt;/h4&gt;
&lt;p&gt;
                        I screwed this up about a dozen times before getting it to work, but every mistake was something well-documented with solutions on the web. The best trick I learned was to delete the datanode temporary file on each machine whenever I screwed things up. In my setup that would be done like this.
                    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;rm -r /usr/local/hadoop/datanode&lt;br/&gt;&lt;/pre&gt;
&lt;h4&gt;And Finally&lt;/h4&gt;
&lt;p&gt;
                        I was finally able to load a few documents into the hdfs and run the wordcount on them across all machines. Overall, I feel extremely satisfied getting this done finally (though I've got a much more &lt;a href=&quot;http://spark.apache.org/&quot;&gt;sophisticated system&lt;/a&gt; at my disposal at the cluster &lt;a href=&quot;https://rcc.uchicago.edu/&quot;&gt;where I work&lt;/a&gt;). Now I'm just getting ready to try it out on one of my pet projects!
                    &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;</description>
        <pubDate>Sun, 26 Jul 2015 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2015/07/the-barbie-hadoop-cluster-multi-node/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/07/the-barbie-hadoop-cluster-multi-node/</guid>
        
        <category>data science</category>
        
        <category>infra</category>
        
        
      </item>
    
      <item>
        <title>Artifice Slideshow</title>
        <description>&lt;meta content=&quot;250&quot; http-equiv=&quot;refresh&quot;/&gt;
&lt;a href=&quot;http://3.bp.blogspot.com/-O-XIJtZFxaw/VZw8tBrXSgI/AAAAAAAAD_Q/eJzGSVL5xk4/s1600/CAM00081.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-O-XIJtZFxaw/VZw8tBrXSgI/AAAAAAAAD_Q/eJzGSVL5xk4/s200/CAM00081.jpg&quot; style=&quot;visibility:hidden&quot;/&gt;&lt;/a&gt; &lt;embed flashvars=&quot;host=picasaweb.google.com&amp;amp;hl=en_US&amp;amp;feat=flashalbum&amp;amp;RGB=0x000000&amp;amp;feed=https%3A%2F%2Fpicasaweb.google.com%2Fdata%2Ffeed%2Fapi%2Fuser%2F103585488893025173441%2Falbumid%2F6168872337058837057%3Falt%3Drss%26kind%3Dphoto%26hl%3Den_US&quot; height=&quot;400&quot; pluginspage=&quot;http://www.macromedia.com/go/getflashplayer&quot; src=&quot;https://photos.gstatic.com/media/slideshow.swf&quot; type=&quot;application/x-shockwave-flash&quot; width=&quot;600&quot;/&gt;
&lt;p&gt;
        A slideshow of the things we've done at &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;Artifice&lt;/a&gt; so far this year./
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Tue, 07 Jul 2015 00:00:00 -0700</pubDate>
        <link>https://bonkerfield.org/2015/07/artifice-slideshow/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/07/artifice-slideshow/</guid>
        
        <category>artifice</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 9: Laser activated trip wire</title>
        <description>&lt;p&gt;
        After last week's success with the physical trip wires, it's time to move on to some serious spy trip wire technology: LASERS!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.geeky-gadgets.com/wp-content/uploads/2014/09/Laser-Tripwire.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This project combines some of the tricks we've already learned as well as introducing a new concept called &lt;a href=&quot;http://arduino.cc/en/Tutorial/AnalogInput&quot;&gt;analog input&lt;/a&gt;. Check out the finished product in action in this video. Warning: the buzzer is a little loud and annoying so maybe turn your sound down before you play it.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/7lXQL_aAJZs?rel=0&quot; width=&quot;640&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;h4&gt;Connecting the light sensor&lt;/h4&gt;
&lt;p&gt;
        The first step is to hook up the light sensor so we can see how analog voltage works. The circuit takes electricity from the 5V pin and runs it through the light sensor into pin A0. There's also another resistor between pin A0 and GND. This basic circuit is called a voltage divider, and the schematic looks like this.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://learn.adafruit.com/system/assets/assets/000/000/458/medium800/light_cdsanasch.gif?1396763210&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We''l learn more about how the voltage divider is working later, but for now just try to hook it up like in this picture.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-rlKS01_B5YU/VP0vC2TV4UI/AAAAAAAAC08/xppnNLcbguo/s1600/CAM00051.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Upload the &lt;a href=&quot;http://arduino.cc/en/Tutorial/ReadAnalogVoltage&quot;&gt;ReadAnalogVoltage&lt;/a&gt; code to the Arduino and open the Serial Monitor to see what voltage is being read on pin A0.
    &lt;/p&gt;
&lt;p&gt;
        Now, wave your hand above the sensor. Do you notice the voltage value changing on the Serial Monitor? The analog input pins let you measure how much light is shining on the sensor.
    &lt;/p&gt;
&lt;h4&gt;Understanding Analog Input&lt;/h4&gt;
&lt;p&gt;
        In the past weeks, we've focused solely on digital inputs. Digital inputs tell you whether there is at least a certain amount voltage on the pin. The cutoff is normally somewhere around 2 volts. If you hook up any voltage higher than that, the Arduino will view the pin as ON (or HIGH).
    &lt;/p&gt;
&lt;p&gt;
        Analog works differently. With analog input, the value of the voltage is read into the Arduino. So if you hook up 2 volts, the Arduino will read 2 volts. And if you hook up 1.67 volts, the Arduino will read 1.67.
    &lt;/p&gt;
&lt;p&gt;
        This is really useful when you have a sensor like the one we're using. The analog input lets us measure continuous changes in the reading on the sensor. So when the light level changes a little bit, the voltage also changes by a little bit. Therefore, we can use the Arduino to measure subtler changes than we could with digital input.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h5&gt;The Voltage Divider Circuit&lt;/h5&gt;
&lt;p&gt;
        Here's a little conundrum: The Arduino pins measure voltages, but our sensor doesn't actually produce any voltage itself. Instead the sensor changes its resistance when light shines on it.
    &lt;/p&gt;
&lt;p&gt;
        To convert this change in resistance into a change in voltage, we use a simple circuit called a &lt;a href=&quot;http://en.wikipedia.org/wiki/Voltage_divider&quot;&gt;voltage divider&lt;/a&gt;. This circuit is specially designed to cause a change in resistance to trigger a change in the voltage at the midpoint of the circuit. We'll use this circuit repeatedly whenever we need a sensor so it's important to remember how it works.
    &lt;/p&gt;
&lt;h4&gt;Blinking LED Trip Wire&lt;/h4&gt;
&lt;p&gt;
        Now we have the sensor controlling the voltage on pin A0. Next, we want to use the voltage input to control whether an LED will go off. Start by hooking up an LED to pin 13 just like we did for the old physical trip wire.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-SFKge6VMBLk/VP0vZiUdd3I/AAAAAAAAC1I/c5znRWrGcXc/s1600/CAM00055.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We'll use almost the same code that we used in the physical trip wire from last week. We'll need to modify it so that instead of asking whether there is any voltage on the digital pin, we're going to ask HOW MUCH voltage is coming in on the analog pin..
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int sensorValue = analogRead(A0);&lt;br/&gt;  float voltage = sensorValue * (5.0 / 1023.0);&lt;br/&gt;  Serial.println(voltage);&lt;br/&gt;&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;if(voltage &amp;lt; _______)&lt;/strong&gt;{&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;  }&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Above is the code we'll need to make it work. BUT, I've left one spot blank. That's the place where we have to decide what the threshold voltage should be. To figure out what the value should be, point the laser at the light sensor and look at the numbers being printed in the Serial Monitor. You want the threshold to be somewhere between the voltage when the laser is shining and the voltage when the laser is off.
    &lt;/p&gt;
&lt;p&gt;
        After you upload the code, the LED should blink until you point a laser pointer at it. Then if at any point someone steps in the way, the voltage will change so that the blinking LED loop will get triggered. And that's a trip wire!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-xr_aqwD2wF4/VP0vjAz_T5I/AAAAAAAAC1Q/de3UPEWnqzA/s1600/CAM00060.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Bonus round! Adding the buzzer&lt;/h4&gt;
&lt;p&gt;
        What we have now is called a silent alarm. It activates a light but doesn't sound an alarm to catch your attention.
    &lt;/p&gt;
&lt;p&gt;
        To bring the alarm to the next level, I also added a buzzer that goes off when the LED goes off. You can use this code and &lt;a href=&quot;http://arduino.cc/en/Tutorial/Tone&quot;&gt;hook up a speaker&lt;/a&gt; to make it work. I've just added a single line that controls a tone emitted on pin 8.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;    &lt;strong style=&quot;color:red&quot;&gt;tone(8,600,3000);&lt;/strong&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        See if you can figure out where to put this line of code to make the buzzer go off when the LED blinks
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-srwecgVc4Jw/VP0vqm05P4I/AAAAAAAAC1c/UDnOd0jvvSY/s1600/CAM00059.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        In the end, the completed laser trip wire will look like this. Now have some fun catching intruders!
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 08 Mar 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/03/week-9-laser-activated-trip-wire/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/03/week-9-laser-activated-trip-wire/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 8: Arduino trip wire</title>
        <description>&lt;p&gt;
        Today's project is a challenge to build a trip wire. The challenge builds on the Arduino input and output skills we put into practice last week. All we have to do is slightly adapt last weeks PushButton project.
    &lt;/p&gt;
&lt;h4&gt;Installing the tripwire&lt;/h4&gt;
&lt;p&gt;
        The trip wire is nothing more than a long wire that acts just like a button. Remember that a button is just a part of the circuit that can either be connected or not.
    &lt;/p&gt;
&lt;p&gt;
        So when we build our trip wire all we have to do is replace the button with the long loop of wire. The trip wire goes into the circuit exactly where the button went before.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Adapting the pushbutton code&lt;/h4&gt;
&lt;p&gt;
        The only major difference between our push button and the trip wire is that the trip wire should activate when the circuit isn't complete. So the logic that made the LEDs blink is backwards from what it was before.
    &lt;/p&gt;
&lt;p&gt;
        To fix the code we just have to make one change so that &lt;strong&gt;if&lt;/strong&gt; statement only activates when the circuit voltage is 0. If you change the code like this, the if statement will be off until the digitalRead on pin 2 says 0.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;// digital pin 2 has a pushbutton attached to it. Give it a name:&lt;br/&gt;int pushButton = 2;&lt;br/&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  // make the pushbutton's pin an input:&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  //if the buttonState is 1, make the LEDs blink 4 times&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;if(buttonState==0)&lt;/strong&gt;{&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;  }&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Now the trip wire should work how we want it.
    &lt;/p&gt;
&lt;h4&gt;Obstacle course&lt;/h4&gt;
&lt;br/&gt;

&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sat, 07 Mar 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/03/raser-week-8-arduino-trip-wire/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/03/raser-week-8-arduino-trip-wire/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>Procrastinating with a Time Optimization Game</title>
        <description>&lt;p&gt;
    I've got to admit, I'm majorly busy at this time of year. But today, I'm deciding to procrastinate by writing a post onironically enougha game about &lt;a href=&quot;http://xkcd.com/1205/&quot;&gt;optimizing your use of time&lt;/a&gt;!
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.explainxkcd.com/wiki/images/e/e5/is_it_worth_the_time.png&quot; title=&quot; &quot; /&gt;
&lt;br /&gt;
&lt;h4&gt;The Background&lt;/h4&gt;
&lt;p&gt;
    If you've ever participated in an &lt;a href=&quot;http://en.wikipedia.org/wiki/Behavioral_economics&quot;&gt;economics research study&lt;/a&gt;, you've probably had the pleasure of participating in a &quot;computerized experiment.&quot; These are pretty much just silly games that you play for a little while so the researchers can &quot;measure&quot; your behavior.
&lt;/p&gt;
&lt;p&gt;
    Recently, I played a game that asked me to choose between two tasks in order to maximize the payoff (I'll give more details below). I did pretty well at making a gut decision on which one to choose during the game, but I knew that there had to be some way to figure out the optimum choice. So afterwards, I decided to analyze the game a little more and find out how to explain it mathematically.
&lt;/p&gt;
&lt;br /&gt;
&lt;h4&gt;The Game Premise&lt;/h4&gt;
&lt;p&gt;
    Imagine you spend your work dividing your time between two tasks. One of them is an easy task that takes 1 minute, and the other is a hard task that takes 2 minutes.
&lt;/p&gt;
&lt;p&gt;
    For the easy task, you're always offered $1, while for the hard task you get offered a different amount between $1 and $5.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, whether you pick the easy task or the hard one, you aren't guaranteed to get paid every time. You're told the probability that you'll get paid before you decide which task to take. For simplicity we'll just say the chances of getting paid are 33%, 66%, or 100%.
&lt;/p&gt;
&lt;p&gt;
    So the challenge is to decide whether you want to waste your time on the hard task given the offered payout and the probability of getting payed.
&lt;/p&gt;
&lt;h4&gt;Sample Game&lt;/h4&gt;
&lt;p&gt;
    To make the game more clear, I built a &lt;a href=&quot;http://codepen.io/wmcfadd2/full/Joppjg/&quot;&gt;sample game&lt;/a&gt; in javascript on CodePen. The objective is to make the most money you can before you use up all your time.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/--uoEYazVJfg/VN-hM5Q3_5I/AAAAAAAACnE/BUaxRFWnzVM/s1600/Screen%2BShot%2B2015-02-14%2Bat%2B1.24.08%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    Before we look at the answer you should give the game a shot. &lt;a href=&quot;http://codepen.io/wmcfadd2/full/Joppjg/&quot;&gt;Try it out&lt;/a&gt;.
&lt;/p&gt;
&lt;h4&gt;Trying to find a general solution&lt;/h4&gt;
&lt;p&gt;
    After playing around for a few minutes you'll probably get the idea of how best to win. It makes sense to only take the hard task when you have a chance of getting more than $2. The real trick though is that sometimes, even though you might make more, the odds that you'll win are so low that you shouldn't waste your time on the hard task.
&lt;/p&gt;
&lt;p&gt;
    My original rule of thumb was to take the hard task only when the expected value of the hard task (i.e. offered payout * chance of winning) was higher than $2. My logic was just that I should only waste my time when I have a reasonable chance of getting the higher payout.
&lt;/p&gt;
&lt;p&gt;
    But I was pretty sure there must be a more solid way to figure out what the cutoff offer should be. And I wasn't going to rest until I found it.
&lt;/p&gt;
&lt;h4&gt;Simulate it!&lt;/h4&gt;
&lt;p&gt;
    I needed to get a better understanding of what would happen given a cutoff dollar value above which I'd take the hard task. Of course, I didn't want to have to play the game over and over again just to find out the outcome. Instead, I wrote a &lt;a href=&quot;http://en.wikipedia.org/wiki/Computer_simulation&quot;&gt;simulation&lt;/a&gt; of the game in &lt;a href=&quot;http://www.mathworks.com/products/matlab/&quot;&gt;MATLAB&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    I've got the functional &lt;a href=&quot;https://github.com/lots-of-things/task-game/blob/master/taskgame_sim.m&quot;&gt;simulation code&lt;/a&gt; on GitHub. It looks complicated, but it's basically just a loop that picks one probability (33%, 66%, or 100%) and then picks the corresponding &quot;choice&quot; threshold. Then it just simulates the game by offering a random value and letting the &quot;choice&quot; decide whether the offer is accepted. It adds up winnings and time according to the choice and the outcome.
&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
    
winnings = 0;
i = 1;
t = 0;
while (t&amp;lt;totaltime)
  index = unidrnd(length(probabilities));
  p = probabilities(index);
  c = choices(index);
  offer = unifrnd(minval, maxval);
  if(unifrnd(0, 1)&amp;lt;p)
    if(offer&amp;gt;c)
      winnings = winnings+offer;
      t = t+hardT;
    else
      winnings = winnings+minval;
      t = t+easyT;
    end
  else
    if(offer&amp;gt;c)
      t = t+hardT;
    else
      t = t+easyT;
    end
  end
end


&lt;/pre&gt;
&lt;p&gt;
    With this simulation I was able to graph the winnings as a function of each choice threshold. It's tough to visualize all three dimensions at once, but here I've plotted the winnings as a function of two of the choice thresholds.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-bgJF7Tjvk4M/VOJI8HRV3JI/AAAAAAAACtg/t3J2aM1ArZM/s1600/payoff_sim.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    You can kind of see that the maximum return takes place with these two thresholds set somewhere around $2 and $3. But still, there should be a way to describe this mathematically so that I can get a nice clean number to set as the threshold.
&lt;/p&gt;
&lt;h4&gt;Deriving a solution&lt;/h4&gt;
&lt;p&gt;
    Using the intuition I got from the simulation, I wanted to work out a mathematical formula that would predict the average payout for a given set of choice thresholds.
&lt;/p&gt;
&lt;p&gt;
    The outcome is just the product of the number of rounds you play times the average winnings for each round. The average winnings is obviously a function of the choice thresholds because that's what determines whether you take the easy or hard task.
&lt;/p&gt;
&lt;p&gt;
    What makes it more interesting is that the number of rounds you play is also a function of your choice thresholds. The lower your choice threshold, the more hard tasks you'll try, meaning you'll get fewer rounds before the time runs up.
&lt;/p&gt;
&lt;p&gt;
    So I basically needed a formula that would take those two things into account. I can't go through all of my reasoning because it would be sooooo tedious, but I'll break it down in a few math steps.
&lt;/p&gt;
&lt;p&gt;
    To get started we know that the total winnings is just going to be the sum of the winnings from the easy rounds and the winnings from the hard rounds.
&lt;/p&gt;
&lt;p lang=&quot;latex&quot; &gt;W_{tot} = f_e\frac{T}{t_e}w_e + f_h\frac{T}{t_h}w_h &lt;/p&gt;
&lt;p&gt;
    We know the total time, &lt;span lang=&quot;latex&quot;&gt;T&lt;/span&gt;, and the time it takes for the hard and easy tasks, &lt;span lang=&quot;latex&quot;&gt;t_e, t_h&lt;/span&gt;. So we just need to figure out the fraction of the time spent on the hard and easy tasks (&lt;span lang=&quot;latex&quot;&gt;f_e,f_h&lt;/span&gt;) and the average amount you'd win for both (&lt;span lang=&quot;latex&quot;&gt;w_e,w_h&lt;/span&gt;).
&lt;/p&gt;
&lt;p&gt;
    I'm going to leave that part up as an exercise for the reader, but after a little head scratching I was able to figure it out. The solution looks like this
&lt;/p&gt;
&lt;p lang=&quot;latex&quot; style=&quot;text-align:center;&quot;&gt;W_{tot} = \frac{T}{t_e}\left ( 1 - \frac{1}{1+\tfrac{O_{max}-O_{min}}{O_{max}-\bar c}\tfrac{t_e}{t_h-t_e}}\right )w_{avg} &lt;/p&gt;
&lt;p&gt;
    For the new variables, &lt;span lang=&quot;latex&quot;&gt;O_{max}&lt;/span&gt;and&lt;span lang=&quot;latex&quot;&gt;O_{min}&lt;/span&gt; are the max and min offers, &lt;span lang=&quot;latex&quot;&gt;\bar c&lt;/span&gt; is the average value of your three choice thresholds, and &lt;span lang=&quot;latex&quot;&gt;w_{avg}&lt;/span&gt; is the average payoff for an individual turn.
&lt;/p&gt;
&lt;p lang=&quot;latex&quot; style=&quot;text-align:center;&quot;&gt;w_{avg} = \sum p_i((O_{max}-c_i)(c_i+O_{max})/2 + O_{min}(c_i-O_{min}))/(O_{max}-O_{min}) &lt;/p&gt;
&lt;p&gt;
    This ended up being really ugly by the end. To ensure that I was calculating this solution correctly, I wrote another &lt;a href=&quot;https://github.com/lots-of-things/task-game/blob/master/taskgame_estimate.m&quot;&gt;MATLAB function&lt;/a&gt; to print my predicted value just like above. To me, this is a great way to prove whether you carried out the math right. The similarity between my analytical solution and the simulated results makes me confident that I didn't make any mistakes along the way.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-TQkyDZ0Mmoo/VOJI8G_asqI/AAAAAAAACtk/Zq3vqA5kb7g/s1600/payoff_est.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    It isn't perfectly easy to see using a point cloud so I binned the data to make it more clear. From this graph, it's pretty clear that the cutoff thresholds are $2.25 for the 100% chance and $2.90 for the 66% chance.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-1Z2kuD7legs/VOJI8JewFOI/AAAAAAAACtc/PovqlwgP58k/s1600/payoff_est_max.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    We could do a little more math to write out the optimum solution, but most of the challenge is over at this point. I think I'm going to call it a night.
&lt;/p&gt;
&lt;h4&gt;What did we learn&lt;/h4&gt;
&lt;p&gt;
    Looking at simplified decision-making games is a fun way to think about how we make choices in our everyday life. Every choice offers us some risk that we've wasted our time on an uncertain reward. Maybe this blog post was just such a waste of time. But you know what, I had fun. Can you really &lt;a href=&quot;https://uk.finance.yahoo.com/news/can-you-put-a-price-on-fun-yes-310-346.html&quot;&gt;put a price&lt;/a&gt; on that?
&lt;/p&gt;
&lt;p&gt;
    By the way, if you're a social psychologist or an economist, please leave a comment. I would love to know what this game is called. There has to be some cool history behind it that I'd like to learn about.
&lt;/p&gt;
&lt;p&gt;
    As usual you can find all the code for this project on the &lt;a href=&quot;https://github.com/lots-of-things/task-game&quot;&gt;make_loft GitHub account&lt;/a&gt;, and you can find the online game on &lt;a href=&quot;http://codepen.io/wmcfadd2/pen/KwQxxy&quot;&gt;my CodePen account&lt;/a&gt;.
&lt;/p&gt;
&lt;br /&gt;
&lt;script src=&quot;https://latex.codecogs.com/latexit.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Mon, 16 Feb 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/02/procrastinating-with-time-optimization/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/02/procrastinating-with-time-optimization/</guid>
        
        <category>games</category>
        
        <category>design</category>
        
        <category>code</category>
        
        <category>analysis</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 5 - Review Game</title>
        <description>&lt;p&gt;
        We've learned a lot so far in the RASER program by now. So to remind us about all of the things we've learned, we want to have a competition and see who remembers the most.
    &lt;/p&gt;

&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-NRtijp0yDJc/VLxzRqKl1lI/AAAAAAAACZY/2c44kU1cRQc/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;Lightning Review Game&lt;/h4&gt;
&lt;p&gt;
        Below we have 6 challenges from the previous 4 weeks. The challenges are each given different numbers of points based on how tough we think they are.
    &lt;/p&gt;
&lt;p&gt;
        See if you can remember how to build each of the following:
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10 pts - Battery powered LED with resistor &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#circuit&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;25 pts - 2 Battery powered LEDs in parallel &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#twoLEDs&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;33 pts - Battery powered LED with variable resistor &lt;a href=&quot;/2015/01/raser-week-2-led-dimmers-and-switches.html#varresist&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;47 pts - Arduino powered LED &lt;a href=&quot;/2015/01/raser-week-3-arduino-led-blinker.html#ArdBat&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;53 pts - Arduino powered blinking LED &lt;a href=&quot;/2015/01/raser-week-3-arduino-led-blinker.html#blink&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;61 pts - Read Arduino Serial Input &lt;a href=&quot;/2015/01/raser-week-4-arduino-led-passcode-pad.html#justinput&quot;&gt;(Answer)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        How did you do? Can you explain how each of the circuits worked? Would you be able to explain how much current was flowing through the circuits?
    &lt;/p&gt;
&lt;p&gt;
        Hopefully, that review was helpful.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;RASER students in action!&lt;/h4&gt;
&lt;p&gt;
        The results are in for the first competition of the season. We had a strong showing from all teams, but in the end, the winners were The Chicken Nuggets and The Guys Who Are Really Good At Making Circuits And Arduinos And Stuff. (I'm sorry if I got that name wrong. It's a tough one to remember.)
    &lt;/p&gt;
&lt;p&gt;
        Here are some pictures of the students working on their projects during the competition.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-sclBEFVmQKQ/VNI515dlmPI/AAAAAAAAClc/oN1eODMkf6U/s1600/CAM00012.jpg&quot; style=&quot;max-width: 100%;&quot; title=&quot;
   
 &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Fri, 06 Feb 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/02/raser-week-5-review-game/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/02/raser-week-5-review-game/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 6: Arduino LED Passcode Pad - Part 2</title>
        <description>&lt;p&gt;
        Two weeks ago, we started learning about one of the most important things Arduinos can do: read input voltages. We want to continue working on reading input this week and connect our input back to output LEDs.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Feeling Voltage with a Van de Graaff Generator&lt;/h4&gt;
&lt;p&gt;
        To get started on today's lesson, we want to make the point of what a voltage actually is. A great way to that is to literally feel the voltage using a Van de Graaff generator.
    &lt;/p&gt;
&lt;p&gt;
        A Van de Graaff generator is a device that builds up large amount of static electricity that can be transmitted to another person when she touches it. The build up of electricity produces a voltage difference between the person becoming charged and the rest of the Earth (called the ground).
    &lt;/p&gt;
&lt;p&gt;
        Now even if the person lets go of the generator, she still has that voltage potential built up in her. We can even measure the voltage difference using a multimeter if the voltage isn't too high.
    &lt;/p&gt;
&lt;p&gt;
        When the person then touches the ground, the voltage difference produces a current that generates a spark. The voltage is dissipated very quickly so the shock only lasts an instant. After that, the person has returned to the same voltage as ground.
    &lt;/p&gt;
&lt;p&gt;
        This is something important to learn about circuits: just because a circuit element isn't directly connected to the plus end of the battery, doesn't mean that it might not have a voltage built up on it. In order to make sure a part of the circuit is at 0 voltage, you have to connect that part of the circuit back to ground.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Using a Button To Turn on an LED&lt;/h4&gt;
&lt;p&gt;
        Next we want to continue our work with Arduino Serial Input from last week. Start by rebuilding the &lt;a href=&quot;/2015/01/raser-week-4-arduino-led-passcode-pad.html#button&quot;&gt;basic input button&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-V1PPucOh9sM/VdaBCotvrgI/AAAAAAAAEg0/_hIhIfwt6Hk/s1600/photo%2B3jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When that's done we can start adding to the code to use the input voltage on pin 2 to control the output voltage on pin 13. Try modifying the code to look like this:
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;int pushButton = 2;&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;int led = 13;&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;pinMode(led, OUTPUT);&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;digitalWrite(led1,buttonState);&lt;/strong&gt;&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        &lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The red lines in this code are used to control the LED. The first two parts are just like from the LED Blink program. The last line performs a &lt;strong&gt;digitalWrite&lt;/strong&gt; using the state of the button that we read in from &lt;strong&gt;digitalRead&lt;/strong&gt;. This makes it so that the LED will only light up when the button is pushed.
    &lt;/p&gt;
&lt;p&gt;
        To make this work, we just need to add an LED to pin 13 like we did back in the LED Blink Program from Week 3.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-V6dZ6bjO-s0/VdaCUUS7NjI/AAAAAAAAEhE/iftc9x4kFNQ/s1600/photojan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And whenevever we push the button down we should see the LED light up. Give it a try. Remember that we aren't controlling the LED's voltage directly. We're controlling the Arduino, and the Arduino is controlling the LED.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Hooking up multiple LED Buttons&lt;/h4&gt;
&lt;p&gt;
        To really take advantage of the Arduino's inputs, we can hook up multiple LEDs and have them interact with our button in different ways.
    &lt;/p&gt;
&lt;p&gt;
        As a simple example, try making the following changes to your code.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;// digital pin 2 has a pushbutton attached to it. Give it a name:&lt;br/&gt;int pushButton = 2;&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;/strong&gt;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  // make the pushbutton's pin an input:&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;/strong&gt;&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  // print out the state of the button:&lt;br/&gt;&lt;strong style=&quot;color:red&quot;&gt;  digitalWrite(led1,buttonState);&lt;br/&gt;  digitalWrite(led2,1-buttonState);&lt;/strong&gt;&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        This will cause the two buttons to perform the opposite actions. The line &lt;blockquote&gt;&lt;strong style=&quot;color:red&quot;&gt;digitalWrite(led2,1-buttonState);&lt;/strong&gt;&lt;/blockquote&gt; will print the opposite of the buttonState (1-buttonState) to led2.
    &lt;/p&gt;
&lt;p&gt;
        Next we just have to hook up another LED to pin 12. If you use red and green LEDs, this will result in a red light-green light, like a traffic signal.
    &lt;/p&gt;
&lt;p&gt;
        You can also try messing around with delays to change how each LEDs are controlled. Experiment a little to see what you can do to control the LEDs differently.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The button triggered blink attack!&lt;/h4&gt;
&lt;p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;// digital pin 2 has a pushbutton attached to it. Give it a name:&lt;br/&gt;int pushButton = 2;&lt;br/&gt;int led1 = 13;&lt;br/&gt;int led2 = 12;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {&lt;br/&gt;  // initialize serial communication at 9600 bits per second:&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  // make the pushbutton's pin an input:&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;  pinMode(led1, OUTPUT);&lt;br/&gt;  pinMode(led2, OUTPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  // read the input pin:&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  //if the buttonState is 1, make the LEDs blink 4 times&lt;br/&gt;  &lt;strong style=&quot;color:red&quot;&gt;if(buttonState==1){&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,HIGH);&lt;br/&gt;    digitalWrite(led2,HIGH);&lt;br/&gt;    delay(500);&lt;br/&gt;    digitalWrite(led1,LOW);&lt;br/&gt;    digitalWrite(led2,LOW);&lt;br/&gt;    delay(500);&lt;br/&gt;  }&lt;br/&gt;  &lt;/strong&gt;&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);        // delay in between reads for stability&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
            This block of code introduces the IF statement. The if statement asks a question, &lt;strong style=&quot;color:red&quot;&gt;if(buttonState==1)&lt;/strong&gt;. IF the answer is true, the Arduino runs the code inside the brackets { ...}. If the answer to the question isn't true, the Arduino skips that code.
        &lt;/p&gt;
&lt;p&gt;
            So when the button is pushed, we know that the buttonState==1 (buttonState is equal to 1). This means that the LEDs will then toggle from low to high over and over again, like it says to in the code.
        &lt;/p&gt;
&lt;p&gt;
            At this point the LED is starting to listen to us and perform different tasks based on our input. This is really the first step towards unlocking all the amazing things an Arduino can do!
        &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Challenge: Build the Passcode Game&lt;/h4&gt;
&lt;p&gt;
            I used combinations of input and output skills to build the Passcode Game that I showed last week. Now I challenge you to make one work! If you want a little help trying to put it together, you can look up the code and a schematic for the game on &lt;a href=&quot;https://github.com/lots-of-things/passcode-pad&quot;&gt;my GitHub page&lt;/a&gt;. If you're feeling up for a challenge try to build it yourself from scratch using some of the tools we learned about today.
        &lt;/p&gt;
&lt;br/&gt;
&lt;/p&gt;
&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sun, 01 Feb 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/02/raser-week-5-arduino-led-passcode-pad/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/02/raser-week-5-arduino-led-passcode-pad/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 4: Arduino LED Passcode Pad - Part 1</title>
        <description>&lt;p&gt;
        This will be the first lesson where we really get into programming the Arduino to do something cool. The Arduino is an amazing tool for making devices that react to external inputs. In this lesson, we'll learn about how to work with both input and output by connecting buttons that can toggle LEDs on and off.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The Passcode Game&lt;/h4&gt;
&lt;p&gt;
        To see an example of what you can do with input and output on the Arduino, check out this game I built. The point is to push the buttons that make the LEDs light up in the right combination. When you push the right combination all the LEDs start blinking.
    &lt;/p&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;360&quot; src=&quot;//www.youtube.com/embed/LSY8wUgjRD8?rel=0&quot; width=&quot;640&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;
        Making this game work is a little complex, but it's doable just from the skills we'll learn today. In today's lesson, I'm going to try to explain how to use a button, and how to use the button input to turn on LEDs. At the end, I challenge you to build your own and post the results in the comments!
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4 id=&quot;justinput&quot;&gt;Measuring voltages with the Arduino&lt;/h4&gt;
&lt;p&gt;
        In this project, the important thing we're trying to get the Arduino to do is measure the voltage that's coming into a pin. To do that, we have to program the Arduino to do two things:
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pay attention to a particular pin&lt;/li&gt;
&lt;li&gt;show us the whether there is a voltage on the pin&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        The Arduino comes with an example program called DigitalReadSerial that is set up to measure the voltage on pin number 2. The important part of the code looks like this.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&lt;br/&gt;int pushButton = 2;&lt;br/&gt;&lt;br/&gt;void setup() {&lt;br/&gt;  Serial.begin(9600);&lt;br/&gt;  pinMode(pushButton, INPUT);&lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;void loop() {&lt;br/&gt;  int buttonState = digitalRead(pushButton);&lt;br/&gt;  Serial.println(buttonState);&lt;br/&gt;  delay(1);       &lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The part at the top sets up pin number 2 to be an INPUT pin instead of an OUTPUT pin. We won't talk to much about that now, but you can read more in Arduino's &lt;a href=&quot;http://arduino.cc/en/Tutorial/DigitalReadSerial&quot;&gt;DigitalReadSerial tutorial&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        The &quot;loop&quot; part at the bottom does two things.
    &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;blockquote&gt;int buttonState = digitalRead(pushButton)&lt;/blockquote&gt; reads what voltage is on pin 2
        &lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;Serial.println(buttonState);&lt;/blockquote&gt; prints out the value on pin 2
        &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
        To see the value that pin 2 is measuring, we have to click on the Arduino Serial Monitor button in the top right.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://learning.codasign.com/images/f/f9/Arduino_serial.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When we open the Serial Monitor, we'll see a bunch of 0s or 1s printing on the screen. If we connect a wire from pin 2 to the 5 V pin, the Serial Monitor will show us 1s. If we connect a wire from pin 2 to the GND pin, the Serial Monitor will show 0. The Serial Monitor gives us a way to see if a circuit is open or closed by checking what the voltage is on any pin.
    &lt;/p&gt;
&lt;p&gt;
        (Ideally, we'd always keep a resistor on the wire between 5V and pin 2, but if we're just testing for a few seconds this will be OK.)
    &lt;/p&gt;

&lt;h4 id=&quot;button&quot;&gt;Building a Simple Button&lt;/h4&gt;
&lt;p&gt;
        The easiest way to change the voltage from 0 to 5 V is by using a button. A button is really just a switch that closes an electrical circuit. My friends Pete and Joe built these awesome paper cup buttons that keep the button at the top steady so you can connect it to the Arduino more easily.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-8r_doGqIYdY/VdaAvPVyZVI/AAAAAAAAEgk/K25Dsc_D6oM/s1600/photo%2B2jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We want to set up the circuit so that the button will connect pin 2 to the 5 V. That will cause the Serial Monitor to display 1. When the button isn't pressed, we want pin 2 to be connected to ground. To get started, we'll connect the 5 V pin to the &lt;span style=&quot;color:red&quot;&gt;plus (+)&lt;/span&gt; holes on our breadboard and connect the GND pin to the &lt;span style=&quot;color:red&quot;&gt;minus (-)&lt;/span&gt; holes.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-BkPd5RsdUoY/VdaBDcPUGfI/AAAAAAAAEg8/Wl01Zgzmr68/s1600/photo%2B1jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        After we have the 5V and the GND connected to the breadboard, we just need to set up the button to toggle between each of them. To do this we're going to set up the button. We want one lead to connect to the 5V (the plus terminals on our breadboard) and the other connects to pin 2. However, there really should be a small resistor between the button and pin 2. (I accidentally missed this in the photo. It worked, but that practice could damage the Arduino eventually.) Finally, we're going to add a resistor between pin 2 and GND as well to prevent a short circuit there too.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-V1PPucOh9sM/VdaBCotvrgI/AAAAAAAAEg0/_hIhIfwt6Hk/s1600/photo%2B3jan26.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This might seem confusing, but we need this kind of setup to make the voltage on pin 2 to go back to GND whenever the button isn't pressed.
    &lt;/p&gt;
&lt;p&gt;
        We can draw the circuit up to show how the resistor prevents a total short circuit when the button is pressed.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.codeproject.com/KB/boards-embedded-devices/Interfacing_Arduino_LCDs/PushButtonSchematic.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We're using a more advanced kind of circuit diagram than we have before, but you should be able to study it to figure out how the electricity runs from the voltage to either pin 2 or GND.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h5&gt;Next week, we'll continue this project to show how to program the Arduino to use the input from pin 2 to make an LED light up on pin 13!&lt;/h5&gt;

&lt;br/&gt;

&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sun, 25 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/raser-week-4-arduino-led-passcode-pad/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/raser-week-4-arduino-led-passcode-pad/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>tweet_note: An unfakeable timestamp notebook</title>
        <description>&lt;img border=&quot;0&quot; src=&quot;http://graphics8.nytimes.com/images/2012/05/17/technology/bits-Twittermask/bits-Twittermask-tmagArticle.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I have a confession. I don't like tweeting that much. I always feel like I sound like an idiot. And with tweets, I run into the possibility of sounding like an idiot at a much higher rate.
    &lt;/p&gt;
&lt;p&gt;
        But... I do love the idea of keeping timestamped notes for/about myself and what I'm working on.
    &lt;/p&gt;
&lt;p&gt;
        This led me to build a twitter account that &lt;strong&gt;no one else can read&lt;/strong&gt;.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h5 style=&quot;text-align:center&quot;&gt;What did you say?&lt;/h5&gt;
&lt;br/&gt;
&lt;p&gt;
        Yes I know it seems like the exact opposite of what Twitter is about (trying to get everyone's attention, everywhere). But instead of having a separate notes app, now I can just store all my dumb thoughts right next to my public ones.
    &lt;/p&gt;
&lt;h4&gt;tweet_note.py&lt;/h4&gt;
&lt;p&gt;
        The only drawback comes from an inability to easily digest my notes in chronological order. So to fix this I built myself a little program to read in my recent tweets and turn them into a pretty little document.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-O4KLW4_G3vo/VMFpPlZp_BI/AAAAAAAACdg/2WUFNozDQSA/s1600/Screen%2BShot%2B2015-01-22%2Bat%2B3.18.23%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When I run tweet_note.py, it builds an html table to display all the tweets in the last day, reversed so the first one is at the top. I took the elegant table style from &lt;a href=&quot;http://johnsardine.com/freebies/dl-html-css/simple-little-tab/&quot;&gt;John Sardine&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        As always, &lt;a href=&quot;https://github.com/lots-of-things/tweet_note&quot;&gt;the code&lt;/a&gt; is available and free to use from my GitHub. I'd love it if somebody could hook it up to work on Google App Engine, but at the moment that's too much work for me.
    &lt;/p&gt;
&lt;h4&gt;how it works&lt;/h4&gt;
&lt;p&gt;
        It's set up similarly to my earlier &lt;a href=&quot;http://makeloft.blogspot.com/2015/01/actsofsuperness-twitter-game.html&quot;&gt;#ActsOfSuperness game&lt;/a&gt;, except that it runs using the user_timeline function of the Twitter API. And instead of writing to Google DataStore, it just has to write a local html file. All in all, it's much simpler.
    &lt;/p&gt;
&lt;p&gt;
        Check out the &lt;a href=&quot;https://github.com/lots-of-things/tweet_note/blob/master/README.md&quot;&gt;readme&lt;/a&gt; on github for more info
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Thu, 22 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/tweetnote-unfakeable-timestamp-notebook/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/tweetnote-unfakeable-timestamp-notebook/</guid>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>The Barbie Hadoop Cluster - Stage 1</title>
        <description>&lt;p&gt;
        Ever since I took Coursera's &lt;a href=&quot;https://www.coursera.org/course/datasci&quot;&gt;Intro to Data Science&lt;/a&gt; course, I've been dreaming of getting my own &lt;a href=&quot;http://www-01.ibm.com/software/data/infosphere/hadoop/mapreduce/&quot;&gt;MapReduce&lt;/a&gt; system up and running. It just seems so much more rewarding to have my own data framework right in front of me rather than paying for &lt;a href=&quot;http://aws.amazon.com/&quot;&gt;Amazon AWS&lt;/a&gt; or &lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google Cloud&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        Recently the &lt;a href=&quot;http://www.artificechicago.org/&quot;&gt;non-profit I volunteer for&lt;/a&gt; handed me 9 left-over recycled computers and a lot of left-over hard drives that they needed to find a home for. So while they were sitting in my house, I decided to put them to use in my dream &lt;a href=&quot;http://searchbusinessanalytics.techtarget.com/definition/Hadoop-cluster&quot;&gt;Hadoop Cluster&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        So here is my step-by-step protocol for setting up the cluster from scratch. In this post I'm going from Ubuntu install CD to Hadoop &quot;pseudo-distributed&quot; mode. In &lt;a href=&quot;#&quot;&gt;Stage 2&lt;/a&gt;, I move to a four node distributed cluster, and in &lt;a href=&quot;#&quot;&gt;Stage 3&lt;/a&gt;, I'm going to launch my own MapReduce job.
    &lt;/p&gt;
&lt;h4&gt;The Barbie Cluster&lt;/h4&gt;
&lt;p&gt;
        First off, the most important thing in sysadmin is the honor of naming computers. In shock/disapproval/sarcastic honor of &lt;a href=&quot;http://www.npr.org/2014/11/22/365968465/after-backlash-computer-engineer-barbie-gets-new-set-of-skills&quot;&gt;Mattel's failed attempt&lt;/a&gt; to update their outdated views about women, I decided to name all of my computers after Barbie characters.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-DUzTPSAiKi0/VMB1J3XGqMI/AAAAAAAACbI/Cogjyj_ttfw/s1600/barbie.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        As of right now I have four computers set up,
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Barbie&lt;/li&gt;
&lt;li&gt;Ken&lt;/li&gt;
&lt;li&gt;Skipper&lt;/li&gt;
&lt;li&gt;Kelly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        And fortunately, &lt;a href=&quot;http://en.wikipedia.org/wiki/List_of_Barbie%27s_friends_and_family&quot;&gt;mass toy consumerism&lt;/a&gt; will allow me to expand my cluster to effectively any size.
    &lt;/p&gt;
&lt;h4&gt;The operating system&lt;/h4&gt;
&lt;p&gt;
        I originally tried to get the &quot;Barbie Cluster&quot; up and running with Puppy Linux. I chose Puppy initially because most of the machines lacked a DVD drives or USB booting, which ruled out more of the &quot;filled out&quot; Linux distributions. Puppy did install pretty easily and I would recommend it for someone who needs a lightweight, functional OS. But eventually, I, like many before me, decided that Puppy was just too much of an undocumented burden to run Hadoop, and I scrapped it for an Ubuntu command line install. (You can't get a lower memory OS than command line, I say)
    &lt;/p&gt;
&lt;p&gt;
        To get Ubuntu installed I downloaded the &lt;a href=&quot;http://archive.ubuntu.com/ubuntu/dists/trusty/main/installer-i386/current/images/netboot/mini.iso&quot;&gt;Ubuntu 14.04 Minimal Install CD&lt;/a&gt;, which I found &lt;a href=&quot;https://help.ubuntu.com/community/Lubuntu/Documentation/MinimalInstall&quot;&gt;here&lt;/a&gt;. I &lt;a href=&quot;http://lifehacker.com/251758/mac-tip--how-to-burn-an-iso-or-dmg-file-to-disc&quot;&gt;burnt the .iso&lt;/a&gt; file to a CD, and popped the CD into the CD drives of my hungrily waiting Dells.
    &lt;/p&gt;
&lt;p&gt;
        After &lt;a href=&quot;http://pcsupport.about.com/od/tipstricks/ht/bootcddvd.htm&quot;&gt;she boots to the CD&lt;/a&gt;, select Command Line Install. The setup is pretty straightforward and I didn't need any special choices except naming the computers and users. I partitioned the disk with &quot;Guided, Use Entire Disk and LVM,&quot; but I'm not sure if that was necessary. No reason not to do that though since that's what most Linux systems work on.
    &lt;/p&gt;
&lt;h4&gt;Before Getting to Hadoop&lt;/h4&gt;
&lt;p&gt;
        There's been a suggestion that you should create a dedicated user for Hadoop on your machine. Since this system doesn't have any other user, that seems unnecessary. I didn't bother with that, but I did create a hadoop group and add my doopy user to that group for consistency.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;  $ addgroup hadoop&lt;br/&gt;  $ usermod -g hadoop doopy&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I set up and auto-login for myself based on a suggestion I found &lt;a href=&quot;http://askubuntu.com/questions/175248/how-to-autologin-without-entering-username-and-passwordin-text-mode&quot;&gt;here&lt;/a&gt;. This isn't necessary, but I'm not going to have monitors and it's possible I might want things to run automatically in the background without having to ssh in. To have the machines log on automatically, edit the file '/etc/init/tty1.conf' so that the last line reads
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;exec /sbin/getty -8 38400 tty1 -a doopy&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Finally, the most important thing is to get the prerequisite software installed. To do that just type
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;  $ sudo apt-get install openjdk-7-jdk ssh git &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        This should get your java and ssh set up. I also included git because everyone eventually needs it anyway.
    &lt;/p&gt;
&lt;p&gt;
        Finally, you need to set up ssh to allow this machine to ssh itself without a password. (I know, it's the weirdest thing ever, but this is how Hadoop works. I suppose it's probably genius on a level that I don't even understand.)
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;  $ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa&lt;br/&gt;  $ cat ~/.ssh/id_rsa.pub &amp;gt;&amp;gt; ~/.ssh/authorized_keys&lt;br/&gt;  $ ssh localhost&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Make it yourself&lt;/h4&gt;
&lt;p&gt;
        After apt-getting java and ssh, the only other thing you need is the Hadoop package itself. Unfortunately, the binary distribution that I got from Apache started throwing errors after I installed it. I hunted down the errors and found that the problems arose from a 32-bit vs 64-bit conflict.
    &lt;/p&gt;
&lt;p&gt;
        To solve the problem I recompiled it myself based on the ideas I found &lt;a href=&quot;https://github.com/y12studio/y12hadoop/blob/master/install-hadoop-2.4.0.md&quot;&gt;here&lt;/a&gt;. The Hadoop Github had &lt;a href=&quot;https://github.com/apache/hadoop/blob/trunk/BUILDING.txt&quot;&gt;slightly better instructions&lt;/a&gt;, that nailed down the steps that I had to take. I put &lt;a href=&quot;https://github.com/lots-of-things/hadoop-compiled&quot;&gt;my own compiled distribution&lt;/a&gt; up on the MakeLofT GitHub.
    &lt;/p&gt;
&lt;p&gt;
        So if you want to skip all the hard work you can get the whole thing set up with this line...
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;&lt;strike&gt;sudo git clone https://github.com/lots-of-things/hadoop-compiled.git /usr/local/hadoop&lt;/strike&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        EDIT: Nevermind, I edited that file so that settings now work for my current production setup.
    &lt;/p&gt;
&lt;p&gt;
        You also may need to change the ownership of the /usr/local/hadoop file you just added.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;sudo chown -R doopy:hadoop /usr/local/hadoop&lt;br/&gt;&lt;/pre&gt;
&lt;p&gt;
        Finally, you need to add some of these files to your .bash file. You can do this by appending the included file called addToBash to the end of your .bash file.
    &lt;/p&gt;
&lt;pre&gt;&lt;br/&gt;cat addToBash &amp;gt;&amp;gt; ~/.bashrc&lt;br/&gt;&lt;/pre&gt;
&lt;h4&gt;Modifying Hadoop's setup&lt;/h4&gt;
&lt;p&gt;
        I picked and chose the setup protocol from these three tutorials to tease out exactly what I needed to do. It's so odd that they can all be telling you to do the same thing, and yet still disagree on so much. Importantly, I found that all the information I could find on the YARN setup was pretty much totally off. I had to activate an additional JobHistoryServer that nobody mentioned.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/&quot;&gt;Michael Noll's tutorial was kind of out of date&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://eycheu.blogspot.com/2014/04/hadoop-240-on-ubuntu-1310.html&quot;&gt;This one seemed to have you doing extra unnecessary things&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/SingleCluster.html&quot;&gt;Apache's setup instructions were the shortest and least filled out&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
        It was totally unclear to me why each tutorial asked you to modify the files in slightly different ways. Hopefully, I'll come back and edit this to explain all those knobs to other beginners.
    &lt;/p&gt;
&lt;p&gt;
        For now, &lt;a href=&quot;https://github.com/lots-of-things/hadoop-compiled.git&quot;&gt;my distribution&lt;/a&gt; comes preset to work with Hadoop YARN in pseudo-distributed way. You can look at the other tutorials to see the different things they did, but all I did was edit the following four files to fill out their configuration tag as shown.
    &lt;/p&gt;
    etc/hadoop/core-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;etc/hadoop/hdfs-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt; etc/hadoop/mapred-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;etc/hadoop/yarn-site.xml: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&amp;lt;configuration&amp;gt;&lt;br/&gt;    &amp;lt;property&amp;gt;&lt;br/&gt;        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&amp;lt;/name&amp;gt;&lt;br/&gt;        &amp;lt;value&amp;gt;org.apache.hadoop.mapred.ShuffleHandler&amp;lt;/value&amp;gt;&lt;br/&gt;    &amp;lt;/property&amp;gt;&lt;br/&gt;&amp;lt;/configuration&amp;gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        Youhave to make the next to files if you want to run YARN.
    &lt;/p&gt;
    sbin/start-jobhist.sh: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;bin=`dirname &quot;${BASH_SOURCE-$0}&quot;`&lt;br/&gt;&quot;$bin&quot;/mr-jobhistory-daemon.sh start historyserver&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt; sbin/stop-jobhist.sh: &lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;bin=`dirname &quot;${BASH_SOURCE-$0}&quot;`&lt;br/&gt;&quot;$bin&quot;/mr-jobhistory-daemon.sh stop historyserver&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;h4&gt;Running the example&lt;/h4&gt;
&lt;p&gt;
        To test that this was working I simply ran the example task that all three of those tutorials suggested. You can find it on any of those sites but here I've reproduced it for you.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;The following instructions are to run a MapReduce job locally. If you want to execute a job on YARN, see YARN on Single Node.&lt;br/&gt;&lt;br/&gt;    1) Format the filesystem:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs namenode -format&lt;br/&gt;&lt;br/&gt;    2) Start NameNode daemon and DataNode daemon:&lt;br/&gt;&lt;br/&gt;      $ sbin/start-dfs.sh&lt;br/&gt;&lt;br/&gt;    3) Start YARN daemon:&lt;br/&gt;&lt;br/&gt;      $ sbin/start-yarn.sh&lt;br/&gt;&lt;br/&gt;    EXTRA) Start JobHistoryServer:&lt;br/&gt;&lt;br/&gt;      $ sbin/start-jobhist.sh&lt;br/&gt;&lt;br/&gt;    4) Make the HDFS directories required to execute MapReduce jobs:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs dfs -mkdir /user&lt;br/&gt;      $ bin/hdfs dfs -mkdir /user/&amp;lt;username&amp;gt;&lt;br/&gt;&lt;br/&gt;    5) Copy the input files into the distributed filesystem:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs dfs -put etc/hadoop input&lt;br/&gt;&lt;br/&gt;    6) Run some of the examples provided:&lt;br/&gt;&lt;br/&gt;      $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output 'dfs[a-z.]+'&lt;br/&gt;&lt;br/&gt;    7) View the output files on the distributed filesystem:&lt;br/&gt;&lt;br/&gt;      $ bin/hdfs dfs -cat output/*&lt;br/&gt;&lt;br/&gt;    8) Stop YARN:&lt;br/&gt;&lt;br/&gt;      $ sbin/stop-yarn.sh&lt;br/&gt;&lt;br/&gt;    9) Stop dfs:&lt;br/&gt;&lt;br/&gt;      $ sbin/stop-dfs.sh&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        I was able to monitor the jobs from my laptop over my network by going to &lt;a href=&quot;http://10.0.0.1:8088&quot;&gt;http://10.0.0.1:8088&lt;/a&gt;. Of course, I replaced 10.0.0.1 with the local IP address for that machine.
    &lt;/p&gt;
&lt;h4&gt;Troubleshooting&lt;/h4&gt;
&lt;p&gt;
        Something in this tutorial is going to become outdated in the next six months. My best advice is simply to keep searching, my friend. Someone else has debugged it before you.
    &lt;/p&gt;
&lt;p&gt;
        And now, after just a week, I have four individual machines running Hadoop by themselves. Next week, I'm hoping to get them talking to each other and running another example problem across a distributed file system... Well, I can dream can't I?
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Wed, 21 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/the-barbie-hadoop-cluster-stage-1/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/the-barbie-hadoop-cluster-stage-1/</guid>
        
        <category>infra</category>
        
        <category>data science</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 3: Arduino LED blinker</title>
        <description>&lt;p&gt;
        Electronics engineers can build really complicated devices by controlling when and where simple circuits turn on and off. For example, check out this flat screen monitor that I've opened up to see the inside. The monitor uses signals from the computer to turn on tiny spots on the screen, called pixels. By turning the correct pixels on and off at the right time, we perceive a moving image.
    &lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/Re3s62cd1WE?rel=0&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        In the &lt;a href=&quot;/2014/12/raser-curriculum.html&quot;&gt;past lessons&lt;/a&gt;, we've started getting a sense about how electronic circuits work. But now it's time to start connecting them up to make something functional. Today, we're going to be using a programmable &lt;a href=&quot;http://en.wikipedia.org/wiki/Microcontroller&quot;&gt;microcontroller&lt;/a&gt; called an &lt;a href=&quot;http://www.arduino.cc/&quot;&gt;Arduino&lt;/a&gt; to make our LEDs blink in patterns.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-pS_t0Y86OK0/VdZ_KF0pbGI/AAAAAAAAEgE/V8Mq7jX19Z8/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h4&gt;The Arduino &lt;/h4&gt;
&lt;p&gt;
        An Arduino is like a tiny computer that let's you measure signals and turn things on and off. To make it work you write a program which is uploaded to the device. The program tells the microcontroller to send and receive signals on pins. Then you connect the pins to sensors, lights, motors, and other parts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/6/6c/Arduino316.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The Arduino is capable of &lt;a href=&quot;http://playground.arduino.cc/Projects/ArduinoUsers&quot;&gt;many things&lt;/a&gt;. To get started today, we're going to use it to power an LED light show.
    &lt;/p&gt;
&lt;h4 id=&quot;ArdBat&quot;&gt;Connecting an LED to the Arduino&lt;/h4&gt;
&lt;p&gt;
        First, we'll remake the &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#circuit&quot;&gt;LED circuit that we made earlier&lt;/a&gt; using a battery pack, a resistor, and a single LED.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-i9dF1aglhMc/VKi-4ipoxAI/AAAAAAAACLk/7z70tCT0MAA/s1600/LED-CIRCUIT2.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Once that's working, we're simply going to replace the battery with power from the Arduino. We remove the battery pack and replace it with two wires connected to the Arduino. The plus should connect with the Arduino pin that says 3.3V, and the minus should connect with any of the Arduino pins that say GND.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-21Rv8tRUNK0/VdZ_oSrCLYI/AAAAAAAAEgQ/pRRzBylkTbI/s1600/photo%2B3%25282%2529.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The LED should light up because the 3.3V pin on the Arduino also produces a voltage. Next we'll make the LED blink by connecting it to a pin that turns its voltage on and off.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4 id=&quot;blink&quot;&gt;Arduino Blinking LED&lt;/h4&gt;
&lt;p&gt;
        These Arduinos have been pre-programmed with a program that makes pin 13 blink on and off. We'll see how this programming works in a minute, but first, we'll test to see if we have our setup working.
    &lt;/p&gt;
&lt;p&gt;
        To make the LED blink, remove the wire from the pin marked 3.3V and move it to the pin labeled 13. Wait a few seconds, to see if the LED starts blinking.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-fXXLjqKURKY/VdZ_nx87w2I/AAAAAAAAEgM/J0XWj_U2D84/s1600/photo%2B2.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This is pretty cool, but right now, it's just one LED blinking on and off. Next we'll start programming the Arduino ourselves to see how to make it light up in cooler ways.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Programming the Arduino&lt;/h4&gt;
&lt;p&gt;
        We program the Arduino by writing code on the computer and uploading it to the microcontroller through a USB connection. We do this in the Arduino IDE software.
    &lt;/p&gt;
&lt;p&gt;
        Let's view the code that made the LED blink. First we have to launch the Arduino IDE by finding it on the desktop(if it isn't there we'll need to &lt;a href=&quot;http://arduino.cc/en/main/software&quot;&gt;download it&lt;/a&gt;). Next, click the Open File button and then find the program labeled &quot;Blink.&quot; This is the program currently loaded onto our Arduinos.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;&lt;br/&gt;&lt;br/&gt;// Pin 13 has an LED connected on most Arduino boards.&lt;br/&gt;// give it a name:&lt;br/&gt;int led = 13;&lt;br/&gt;&lt;br/&gt;// the setup routine runs once when you press reset:&lt;br/&gt;void setup() {                &lt;br/&gt;  // initialize the digital pin as an output.&lt;br/&gt;  pinMode(led, OUTPUT);     &lt;br/&gt;}&lt;br/&gt;&lt;br/&gt;// the loop routine runs over and over again forever:&lt;br/&gt;void loop() {&lt;br/&gt;  digitalWrite(led, HIGH);   // turn the LED on (HIGH is the voltage level)&lt;br/&gt;  delay(1000);               // wait for a second&lt;br/&gt;  digitalWrite(led, LOW);    // turn the LED off by making the voltage LOW&lt;br/&gt;  delay(1000);               // wait for a second&lt;br/&gt;}&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        The program repeatedly toggles the voltage on pin 13 from HIGH (on) to LOW (off). To upload the program we push the upload button on the Arduino program.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.chicoree.fr/w/images/8/85/Arduino_Upload_(button).png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        If you want to know everything about this program you can look at the Arduino's &lt;a href=&quot;http://arduino.cc/en/tutorial/blink&quot;&gt;Blink Tutorial&lt;/a&gt; on their website. For right now, we just want to focus on changing how frequently the LED lights up. Right now the delay between events is set to 1000 milliseconds (that's equal to 1 second). Can you figure out how to change the blinking interval to be much faster or much slower? Try it out.
    &lt;/p&gt;
&lt;p&gt;
        Finally, the only reason pin 13 blinks is because the program specifies pin 13 to blink. We can add more code to the program that causes another pin to do the same thing. Try to change the code so that another pin also can run a blinking LED.
    &lt;/p&gt;
&lt;h4&gt;The LED array&lt;/h4&gt;
&lt;p&gt;
        As the final challenge, try to to make a blinking LED array like this one.
    &lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/xW_o4bGGoZ4?rel=0&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;br/&gt;
&lt;p&gt;
        If we set up enough of these, we could turn them into something like this!
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/e/e2/NYC_-_Times_Square_-_0420.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But maybe that's a little ambitious for right now.
    &lt;/p&gt;

&lt;script src=&quot;https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js&quot;&gt;&lt;/script&gt;</description>
        <pubDate>Sun, 18 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/raser-week-3-arduino-led-blinker/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/raser-week-3-arduino-led-blinker/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 2: LED dimmers and switches</title>
        <description>&lt;p&gt;
        This lesson will extend our knowledge of electricity and resistance by adding variable resistors and switches.
    &lt;/p&gt;
&lt;p&gt;
        To start I want to show a Variac autotransformer. The dial controls the amount of electricity getting to the light bulb. The light bulb lets us see the electric current running through it by going dimmer when the current is decreased.
    &lt;/p&gt;
&lt;div class=&quot;separator&quot; style=&quot;clear: both; text-align: center;&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-Ws3vCbgsCQk/VMLe5La_Y-I/AAAAAAAAC78/MTL-uDu9EiQ/s320/photo%2B2.JPG&quot; style=&quot;width:180px;&quot;/&gt;&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-iYr8uE1EFlE/VMLe5Pia6lI/AAAAAAAAC8A/g2P1XpSjtqc/s320/photo%2B3.JPG&quot; style=&quot;width:180px;&quot;/&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-MgjNoNtWj-Q/VMLe5NU_FZI/AAAAAAAAC8E/Cuh-CvUWKEw/s320/photo%2B4.JPG&quot; style=&quot;width:180px;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;
        In today's lesson we're going to learn about the &lt;a href=&quot;https://en.wikipedia.org/wiki/Resistor&quot;&gt;resistor&lt;/a&gt;, a basic electronic component that can decrease the current in a circuit.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/b/b9/Resistors_color_code.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But before we get started learning more about resistors, let's review some basic facts about electricity
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Understanding voltage, current, and resistance.&lt;/h4&gt;
&lt;p&gt;
        To start this lesson, we'd like to elaborate on some of the electrical concepts we introduced last week. We learned that electricity flows out of the battery from the plus end to the minus end. We also learned that along the way, the electricity can be used to light an LED or it can be burned up in a resistor.
    &lt;/p&gt;
&lt;p&gt;
        The reason that the electricity flows out of the battery is that there is a difference in the number of electrons on one side of the battery compared to the other. The difference in energy between one side of the battery and the other is called a &lt;a href=&quot;https://en.wikipedia.org/wiki/Voltage&quot;&gt;voltage&lt;/a&gt;. For electricity to flow there has to be a voltage difference because otherwise the electrons don't have any reason to flow through the wires. Voltage is measured in Volts.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://regentsprep.org/Regents/physics/phys03/apotdif/battery.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The rate at which the electrons flow is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Electric_current&quot;&gt;electrical current&lt;/a&gt;. If you have a higher voltage, the current will be higher because the electrons are being pushed more strongly. Current is measured in Amps.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.talkingelectronics.com/pay/BEC/flow_thru_res-complete.gif&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The work done in the LED or the resistor is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Electrical_load&quot;&gt;load&lt;/a&gt; or the &lt;a href=&quot;https://en.wikipedia.org/wiki/Electrical_resistance_and_conductance&quot;&gt;resistance&lt;/a&gt;. Loads and resistors act to slow the electrons down. So as you increase the resistance you decrease the current through the circuit. Resistance is measured in Ohms.
    &lt;/p&gt;
&lt;p&gt;
        To get more practice with these concepts, we'll build a few new circuits.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Rebuilding the LED circuit&lt;/h4&gt;
&lt;p&gt;
        First, let's rebuild our &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html#circuit&quot;&gt;single LED circuit&lt;/a&gt; with a single resistor.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-wml8t5WW1DI/VKjHvbpGBvI/AAAAAAAACMc/lwqJLnbwuZE/s1600/photo%2B4.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We can redraw the circuit like we did before, only now let's write in the voltages and resistances of the batteries and resistors.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-fzAUUbcktDo/VLMXeof11wI/AAAAAAAACRQ/ly9FkjrMDwg/s1600/LED-CIRCUIT_nums.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To find the resistor value we look at the pattern of colored bands on its side. We can input them into an &lt;a href=&quot;http://www.digikey.com/en/resources/conversion-calculators/conversion-calculator-resistor-color-code-5-band&quot;&gt;online calculator&lt;/a&gt; or use a table like this one.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.digikey.com/~/media/Images/Marketing/Resources/Calculators/resistor-color-chart.jpg?la=en-US&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        There's also some resistance that comes from the LED, but you can't tell how much just by looking at it. Later we'll learn how to find out the resistance from the LED using a mathematical formula.
    &lt;/p&gt;
&lt;p&gt;
        Finally, we can measure the current through the circuit to see how fast the electrons are flowing. Hook up the multimeter into the circuit like in the picture. If the multimeter is set to read amps, you can see how many amps are flowing through the circuit. The higher the amps the faster the electrons are flowing.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-TDVfOUEqY0k/VLTFQYz0wtI/AAAAAAAAC5E/x0YuGd5foj8/s1600/photo%2B2.JPG&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Quick Quiz&lt;/h5&gt;
&lt;p&gt;
        If we replace our resistor with one that has a higher resistance, would the current get higher or lower? Check it by replacing the resistor and remeasuring the current with the multimeter.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4 id=&quot;varresist&quot;&gt;Adding a variable resistor&lt;/h4&gt;
&lt;p&gt;
        The resistor provides a fixed resistance that can't be changed without switching that part out of the circuit. Next, we'll use a small &lt;a href=&quot;https://www.st-andrews.ac.uk/~www_pa/Scots_Guide/info/comp/passive/resistor/pots/var_res/var_res.htm&quot;&gt;variable resistor&lt;/a&gt; to change the resistance in our circuit with a dial.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-eaG8OfqNj7s/VLTFQc5XoQI/AAAAAAAAC5I/bhe06BqKW9Y/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We can remove the old resistor from the circuit and put the variable resistor in its place. Hook the circuit up to one inside pin and one outside pin on the variable resistor like in the picture. Now turning the dial changes the amount of resistance, which should change the brightness of the LED.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The mathematical relationship between voltage, resistance, and current&lt;/h4&gt;
&lt;p&gt;
        It turns out that for any electrical load, (like across the resistor or the LED) we can always find the current using &lt;a href=&quot;https://en.wikipedia.org/wiki/Ohm%27s_law&quot;&gt;Ohm's law&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://ecigarettereviewed.com/wp-content/uploads/2013/10/ohms-law-equation.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        By rearranging this formula we can also get the resistance if we know the current. We can use this equation to calculate the resistance across the LED in the circuit we drew out above.
    &lt;/p&gt;
&lt;p&gt;
        Finally, try using measurements of the current through the variable resistor to find out the resistance at different dial positions.
    &lt;/p&gt;
&lt;h4&gt;LED lightning game with switches and variable resistors&lt;/h4&gt;
&lt;p&gt;
        To end the lesson, we're going to replay the game from &lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html&quot;&gt;last lesson&lt;/a&gt;. This time we'll incorporate switches and dimmers to help us light up the right number of lights. And to make the game more challenging we can modify the game so you have to get the right voltage as measured on a multimeter.
    &lt;/p&gt;
&lt;p&gt;
        As you go, try making the circuits more modular so you can modify them quicker. Try to incorporate switches or dimmers to make changes at the flip of a dial.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Mon, 12 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/raser-week-2-led-dimmers-and-switches/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/raser-week-2-led-dimmers-and-switches/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>Four Humours Collage</title>
        <description>&lt;p&gt;
        Claire and I had these fairly cheesy Monet reprints from the Art Institute that I didn't like.
    &lt;/p&gt;

&lt;img border=&quot;0&quot; src=&quot;http://ecx.images-amazon.com/images/I/51AeXLQEh5L._SY355_.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But they had nice stainless steel frames that I wanted to use to fill in our kitchen wall.
    &lt;/p&gt;
&lt;p&gt;
        At first I figured, I'd just print out pretty images from internet or cut things out of magazines and stick them up. But since there were four similar frames, I decided it'd be cool to try to make an interconnected piece some related set of themes.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The Four Humors&lt;/h4&gt;
&lt;p&gt;
        I've always had an interest in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Humorism&quot;&gt;four humors&lt;/a&gt; and their relationship with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Four_temperaments&quot;&gt;four temperaments&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/6/6e/Charles_Le_Brun-Grande_Commande-Les_Quatre_temperaments.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        First, I think it's pretty hilarious to think of ancient &quot;scientists&quot; trying to categorize all matter, medicine and psychology using a universal classification of four things. That being said, a grand unifying worldview of such symmetry would make for an appealing and fairly beautiful ideal if it were possible.
    &lt;/p&gt;
&lt;p&gt;
        So, I decided to put together a big image collection of all the different meanings of the four humors. I tried to pull from the biology, chemistry, philosophy and personality that the humors were supposed to represent. And I tried to be more-or-less true to the color schemes associated with each.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-HHMUs9Bx4BE/VLNDfcvN_yI/AAAAAAAACWk/lpdanglex7k/s1600/image_gallery.png&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Sanguine&lt;/h5&gt;
&lt;p&gt;
        I think Sanguine was my favorite. I basically made this panel to represent the party-people. Dancing, jokes, heat maps, blood cells, and sangria (get it).
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-3z4RanS6SUQ/VLM0n06C9YI/AAAAAAAACUY/I2m0oILZ0PU/s1600/IMG_1393.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h5&gt;Choleric&lt;/h5&gt;
&lt;p&gt;
        This is porbably my least favorite. Cholera is for the users. The haters. The money-men focused on taking stuff from others and pushing everyone around. I focused on gold, business, oil, and war. The biology images are parasites.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-8qq3hZkgcQg/VLM0n_ylG0I/AAAAAAAACUY/m-2GJ0WNNk0/s1600/IMG_1404.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h5&gt;Melancholic&lt;/h5&gt;
&lt;p&gt;
        I was a little stumped about how to do this one because I didn't want to be &quot;melancholic.&quot; I tried to focus on the earthy-utilitarian type. The organisms were little bugs who could break down plastic. There's some muscle tissue and the architecture from an engineering school.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-cNEBQisQXic/VLM0n9H6yfI/AAAAAAAACUY/kSyPF0oIqC4/s1600/IMG_1408.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;h5&gt;Phlegmatic&lt;/h5&gt;
&lt;p&gt;
        I enjoyed this one too. Tranquil water to reflect the contemplative philosopher. Neurons, Buddha-like faces, whales, fractals, and cosmic radiation.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-A9RbzPIt_kM/VLM0n0t-WJI/AAAAAAAACUY/LvlhfPj9ExA/s1600/IMG_1389.jpg&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
&lt;p&gt;
        There were a couple of items that I repeated in each of their characteristic flavors throughout the panels: architecture, potent potables, animals, nudes, and microscopic life. It's fun to compare what got picked for each type.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;putting it together&lt;/h4&gt;
&lt;p&gt;
        I basically just popped them into their frames and hung them up with slightly staggered corners. Here it is hanging in the kitchen above our breakfast table.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-W3Mx9CJDHWg/VLM0n1EyaRI/AAAAAAAACUY/60HR1SqBE4Y/s1600/IMG_1417.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        It's kind of cool having something with so many little side-stories to look at in the mornings when you're getting ready for work. It reminds me about all the diversity in the worldall the different colors, and how it's so hard to classify the world neatly.
    &lt;/p&gt;
&lt;p&gt;
        To see some of the images that I pulled from the web you can check out &lt;a href=&quot;http://wmcfadd2.tumblr.com/&quot;&gt;my tumblr&lt;/a&gt;.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 11 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/four-humours-collage/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/four-humours-collage/</guid>
        
        <category>art</category>
        
        
      </item>
    
      <item>
        <title>#ActsOfSuperness Twitter Game</title>
        <description>&lt;p&gt;
        Three days ago at about 3 a.m. I woke up with an idea to make people be nicer to each other. I know it might sound kind of corny, but I wanted to build a Twitter game to encourage people to do (and tweet) good things.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-E3BGaAk6Jp8/VK7_R2F0ORI/AAAAAAAACQA/fz-tKxVcE8c/s1600/Screen%2BShot%2B2015-01-08%2Bat%2B4.05.34%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The game is called &lt;a href=&quot;http://actsofsuperness.appspot.com/&quot;&gt;#ActsOfSuperness&lt;/a&gt;, and it centers around getting people to retweet the nice things they do for others. The more an action is retweeted the more points they get.
    &lt;/p&gt;
&lt;p&gt;
        As players get higher scores they get moved up in the superhero rankings. Eventually they become Batman, and &lt;a href=&quot;http://io9.com/5928043/everyone-wants-to-be-batman-in-this-i-am-batman-supercut&quot;&gt;everyone wants to be Batman&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.blastr.com/sites/blastr/files/styles/blog_post_media/public/Adam%20West%20Batman.jpg?itok=FLOGEqD-&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        But really, the payout is more about having this fun little excuse to be nice to other people. Maybe I'm horribly naive, but that sounds like enough reward to me.
    &lt;/p&gt;
&lt;p&gt;
        If you want to play all you have to do is add &lt;a href=&quot;https://twitter.com/search?q=%23ActsOfSuperness&amp;amp;src=typd&quot;&gt;#ActsOfSuperness&lt;/a&gt; to your tweets. Then the twitter account &lt;a href=&quot;https://twitter.com/SuperActs&quot;&gt;@SuperActs&lt;/a&gt; will update you with your score and what superhero you are.
    &lt;/p&gt;
&lt;h4&gt;Building the game&lt;/h4&gt;
&lt;p&gt;
        I want to write up how I made this project, and how others can reproduce it. As usual, I've put &lt;a href=&quot;https://github.com/wmcfadden/acts-of-superness&quot;&gt;the source code&lt;/a&gt; on github. I really would like other people to clone this and build it out or duplicate it. You could imagine making clones with any kind of positive (or negative) message as the hashtag. #ActsOfFreshness, #ActsOfMerriness (for Christmas) You get the idea.
    &lt;/p&gt;
&lt;p&gt;
        The project can be broken into two partsa twitter-facing &quot;pseudo-backend&quot; that trawls Twitter and a web-facing frontend that displays the leaderboard.
    &lt;/p&gt;
&lt;h4&gt;The Twitter facing &quot;backend&quot;&lt;/h4&gt;
&lt;p&gt;
        The actual game-play really just boils down to a string of tweets. &lt;a href=&quot;http://meta-guide.com/software-meta-guide/100-best-googlecode-twitter-bot/&quot;&gt;Many people&lt;/a&gt; have built tweetbots, but I thought it would be a good idea (read free) to host it on &lt;a href=&quot;https://cloud.google.com/appengine/docs&quot;&gt;Google App Engine&lt;/a&gt; so I looked for people who had done that before.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-FwUgriHOWDY/VK8DJdEvkJI/AAAAAAAACQM/EAZ1Rcs0J-A/s1600/Screen%2BShot%2B2015-01-08%2Bat%2B4.21.52%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To get started, I borrowed heavily from &lt;a href=&quot;http://www.billthelizard.com/2013/12/creating-twitter-bot-on-google-app.html&quot;&gt;this Twitter Bot example&lt;/a&gt; by BillTheLizard. It leverages &lt;a href=&quot;http://www.tweepy.org/&quot;&gt;tweepy&lt;/a&gt; to automatically update a twitter account's status. With just a few modifications &lt;a href=&quot;https://github.com/BillCruise/BountyBot&quot;&gt;Bill's code&lt;/a&gt; formed the backbone of my project.
    &lt;/p&gt;
&lt;h4&gt;Sending Tweets with Tweepy&lt;/h4&gt;
&lt;p&gt;
        To connect to the Twitter API, you'll first have to set up an &lt;a href=&quot;https://twittercommunity.com/t/how-to-get-my-api-key/7033&quot;&gt;API authentication key&lt;/a&gt;, which is explained &lt;a href=&quot;https://themepacific.com/how-to-generate-api-key-consumer-token-access-key-for-twitter-oauth/994/&quot;&gt;nicely in this tutorial&lt;/a&gt;. I put the keys into a config file like BillTheLizard did, and then I load them in.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;config = ConfigParser.RawConfigParser()&lt;br/&gt;config.read('settings.cfg')&lt;br/&gt;    &lt;br/&gt;CONSUMER_KEY = config.get('Twitter OAuth', 'CONSUMER_KEY')&lt;br/&gt;CONSUMER_SECRET = config.get('Twitter OAuth', 'CONSUMER_SECRET')&lt;br/&gt;ACCESS_TOKEN_KEY = config.get('Twitter OAuth', 'ACCESS_TOKEN_KEY')&lt;br/&gt;ACCESS_TOKEN_SECRET = config.get('Twitter OAuth', 'ACCESS_TOKEN_SECRET')&lt;br/&gt;&lt;br/&gt;auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)&lt;br/&gt;auth.set_access_token(ACCESS_TOKEN_KEY, ACCESS_TOKEN_SECRET)&lt;br/&gt;api = tweepy.API(auth)      &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        After authenticating the twitter, all of the tweeting work is performed in a single line.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;api.update_status(&quot;@%s Congrats! You've moved up to #%s.&quot; % (name,namesake),f.id)&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        To actually set up the Google App Engine part, I only had to adjust Bill's app.yaml file to point to different programs on the frontend and &quot;backend&quot;. I'd used GAE before so this was no problem.
    &lt;/p&gt;
&lt;div&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;application: actsofsuperness&lt;br/&gt;version: 1&lt;br/&gt;runtime: python27&lt;br/&gt;api_version: 1&lt;br/&gt;threadsafe: yes&lt;br/&gt;&lt;br/&gt;handlers:&lt;br/&gt;- url: /favicon\.ico&lt;br/&gt;  static_files: favicon.ico&lt;br/&gt;  upload: favicon\.ico&lt;br/&gt;&lt;br/&gt;- url: /tweet_super&lt;br/&gt;  script: tweet_super.app&lt;br/&gt;  login: admin&lt;br/&gt;&lt;br/&gt;- url: /js&lt;br/&gt;  static_dir: js&lt;br/&gt;  &lt;br/&gt;- url: /im&lt;br/&gt;  static_dir: im&lt;br/&gt;  &lt;br/&gt;- url: /css&lt;br/&gt;  static_dir: css&lt;br/&gt;    &lt;br/&gt;- url: .*&lt;br/&gt;  script: main.app&lt;br/&gt;&lt;br/&gt;libraries:&lt;br/&gt;- name: webapp2&lt;br/&gt;  version: &quot;2.5.2&quot;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;h4&gt;The searching for tweets part&lt;/h4&gt;
&lt;p&gt;
        My backend app was going to need to take in twitter info in order to process tweets and find people to tweet back.
    &lt;/p&gt;
&lt;p&gt;
        I found the &lt;a href=&quot;http://docs.tweepy.org/en/latest/api.html&quot;&gt;tweepy.search since_id parameter&lt;/a&gt;, and the &lt;a href=&quot;https://dev.twitter.com/rest/public/search&quot;&gt;Twitter Search API &lt;/a&gt; could be used to pull in tweets with a given keyword.
    &lt;/p&gt;
&lt;p&gt;
        To keep things recent, I save the last tweet I read in sid and use the &lt;strong&gt;since_id&lt;/strong&gt; parameter in tweepy.search.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;found = api.search('%23ActsOfSuperness',since_id=sid)&lt;br/&gt;for f in found:&lt;br/&gt;    name = f.user.screen_name&lt;br/&gt;    id = f.user.id&lt;br/&gt;    # do something with name and id &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;storing user scores&lt;/h4&gt;
&lt;p&gt;
        The hard part is that I need to keep track of twitter @users and their scores. Now I could do this every time the page loads by searching all the tweets with #ActsOfSuperness and recalculating the totals. But, of course, that would be very slow if there are many tweets to process. Since I want to at least pretend that other people will use this someday, I had to find another way of retaining score over time.
    &lt;/p&gt;
&lt;p&gt;
        If I'm only periodically reading a recent chunk of tweets, I need to update a persistent database of scores.
    &lt;/p&gt;
&lt;h5&gt;Behold the Cloud!&lt;/h5&gt;
&lt;p&gt;
        Fortunately, since I'm running this on Google App Engine, I get to use 1GB of free space on the &lt;a href=&quot;https://cloud.google.com/datastore/&quot;&gt;Google Datastore&lt;/a&gt;. I'm betting that not too many people will be playing so my GAE Datastore Account won't &lt;a href=&quot;https://cloud.google.com/appengine/docs/quotas&quot;&gt;fill up&lt;/a&gt;. But even if I start to get a lot of users playing, GAE will let me expand easily. That would be a good thing, and I could throw AdSense up there to pay for the increased storage space.
    &lt;/p&gt;
&lt;p&gt;
        I referred to Google's &lt;a href=&quot;https://cloud.google.com/appengine/docs/python/gettingstartedpython27/usingdatastore&quot;&gt;Datastore Python Guestbook Demo&lt;/a&gt; to get started. The one issue with the datastore and &lt;a href=&quot;http://en.wikipedia.org/wiki/Eventual_consistency&quot;&gt;eventual consistency&lt;/a&gt; is that you aren't guaranteed that the Datastore is up to date when you access it. That meant that if the user had tweeted more than once, the following code could run multiple times accidentally, producing multiple copies of the same user.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;hero = Hero.all().filter('id =', id).fetch(10)&lt;br/&gt;if len(hero)&amp;gt;0:&lt;br/&gt;   ... Do stuff &lt;br/&gt;else:&lt;br/&gt;   hero = Hero()&lt;br/&gt;   hero.id = id&lt;br/&gt;   hero.handle = name&lt;br/&gt;   hero.score = 1.0&lt;br/&gt;   hero.put()&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        To fix those kinds of duplication problems I decided on the (slightly hacky) fix that would eventually kick out the duplicates if there were any. I now that you can do this somehow with ancestory in GAE, but that apparently limits the number of Datastore calls you can make in a given time window so I didn't want to do that.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;hero = Hero.all().filter('id =', id2).fetch(10)&lt;br/&gt;if(len(hero)&amp;gt;1):&lt;br/&gt;    for i in range(1,len(hero)):&lt;br/&gt;        hero[0].score=hero[0].score+hero[i].score&lt;br/&gt;    db.delete(hero[1:])&lt;br/&gt;hero = hero[0]&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        At this point we just have to update user scores every time we see a new user. This code increments the score and puts it back in the datastore. And if the user has &quot;leveled up&quot; I send them a tweet.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;points = 10.0/(ff.user.followers+1.0)&lt;br/&gt;if(floor(hero.score/10)!=floor((hero.score+points)/10)):&lt;br/&gt;   sup = floor((hero.score+points)/10)&lt;br/&gt;   if(sup&amp;gt;len(HERO_LIST)):&lt;br/&gt;      namesake = HERO_LIST[0]&lt;br/&gt;   else:&lt;br/&gt;      namesake = HERO_LIST[-1-val]&lt;br/&gt;   api.update_status(&quot;@%s Congrats! You've moved up to #%s. &quot; % (name,namesake),f.id)&lt;br/&gt;hero.score = hero.score+points&lt;br/&gt;hero.put()&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Cron for updates&lt;/h4&gt;
&lt;p&gt;
        I'm polling Twitter every half hour to get new tweets to score. Automation like this is accomplished really simply by setting up a &lt;a href=&quot;https://cloud.google.com/appengine/docs/python/config/cron&quot;&gt;cron.yaml file&lt;/a&gt; in app engine.
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;cron:&lt;br/&gt;- description: repeated tweet test&lt;br/&gt;  url: /tweet_super&lt;br/&gt;  schedule: every 30 mins&lt;br/&gt;  timezone: America/Chicago&lt;br/&gt;&lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h4&gt;The web-facing site&lt;/h4&gt;
&lt;p&gt;
        I built the site around a neat &lt;a href=&quot;http://www.bootply.com/ToV8Bzv4GQ&quot;&gt;bootply theme&lt;/a&gt;. My main.py just fills in one dynamic section in the middle, creating a list of @users by sorting the datastore
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;br/&gt;hero = Hero.all().order('-score').fetch(100)&lt;br/&gt;MID_HTML=''&lt;br/&gt;for h in hero:&lt;br/&gt;    MID_HTML = MID_HTML + h.handle&lt;br/&gt;        &lt;br/&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;
        It's simple and neat looking and gets the job done. I also embedded a copy of the &lt;a href=&quot;http://www.ranker.com/crowdranked-list/best-superheroes-all-time&quot;&gt;online list&lt;/a&gt; that I'm using to decide the superhero order. (Thank God Batman was number 1)
    &lt;/p&gt;
&lt;p&gt;
        Eventually, I'm hoping to build something for people to look up any users score eventually, but I might not get to that. It really depends if anyone ever starts using this thing.
    &lt;/p&gt;
&lt;h4&gt;So Go Play Now&lt;/h4&gt;
&lt;p&gt;
        I really had fun making &lt;a href=&quot;http://actsofsuperness.appspot.com/&quot;&gt;#ActsOfSuperness&lt;/a&gt;, and I'm excited for people to try it out.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-HpjubsAZFOg/VK8KKR49EvI/AAAAAAAACQk/xEzo4DF5Awc/s1600/Screen%2BShot%2B2015-01-08%2Bat%2B4.50.59%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I really hope that this game can inspire a few people to go and do some nice things for others. We have so many silly incentives in this day-and-age that promote everyone being &quot;interesting.&quot; Hopefully this app will inspire some people to do actual good.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Thu, 08 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/actsofsuperness-twitter-game/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/actsofsuperness-twitter-game/</guid>
        
        <category>games</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>RASER Week 1: LED circuits</title>
        <description>&lt;p&gt;
        In this lesson we'll learn how the electricity lighting up our gadgets flows through wires from batteries.
    &lt;/p&gt;
&lt;p&gt;
        My friend Pete built this amazing &lt;a href=&quot;http://en.wikipedia.org/wiki/Spark_gap#Visual_entertainment&quot;&gt;Jacob's ladder&lt;/a&gt; that we'll use to start off the lesson. The arc of light traveling up the Jacob's ladder is ionized air, just like in a &lt;a href=&quot;http://en.wikipedia.org/wiki/Lightning&quot;&gt;lightning bolt&lt;/a&gt;. Electricity flowing from one wire to the other causes the air itself to emit light.
    &lt;/p&gt;
&lt;div style=&quot;text-align:center&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/5TBJ-HeRvlk?rel=0&quot; width=&quot;420&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;
&lt;p&gt;
        The students will grapple with the flow of electricity hands on by making an LED light up. Here's the battery connected to the LED to make it glow.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-RtArN_4bKd4/VKjGxZlx9RI/AAAAAAAACL0/0njBoguVdjI/s1600/photo%2B2.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Electricity flows out of the battery and into the material in the LED. That material is specially designed so that when electricity tries to pass through it, the material glows. This is kind of like the air in the Jacob's ladder lighting up
    &lt;/p&gt;
&lt;h4&gt;Getting started with circuits&lt;/h4&gt;
&lt;p&gt;
        Next, we move on to building our own simple circuits that light up. The first component, the &lt;a href=&quot;http://en.wikipedia.org/wiki/Breadboard&quot;&gt;breadboard&lt;/a&gt;, is where all of the electronics construction takes place. You use the breadboard to connect circuit components together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-93-dt3gwaUA/VKjG4WKcxcI/AAAAAAAACL8/pJ9kHneWOtM/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        This breadboard has the back removed so you can see the way all of the holes are connected on the reverse side. On the outsides, the &lt;span style=&quot;color:red&quot;&gt;plus&lt;/span&gt; and &lt;span style=&quot;color:blue&quot;&gt;minus&lt;/span&gt; holes are all connected. In the center, the numbered rows are connected. Plugging into a connected hole is just like touching those to wires together directly.
    &lt;/p&gt;
&lt;h4&gt;The LED circuit&lt;/h4&gt;
&lt;p&gt;
        Now that we're acquainted with the breadboard we're going to build the &lt;a href=&quot;http://en.wikipedia.org/wiki/LED_circuit&quot;&gt;basic LED circuit&lt;/a&gt;. First, start by connecting the plus and minus end of the battery to the plus and minus rows of the breadboard.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-1XmvEXES984/VKjHtztsVVI/AAAAAAAACMI/TuJYYRu8plo/s1600/photo%2B3.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Next, insert the long wire of a clear LED into the plus terminal, and insert the short wire into the minus terminal. The LED should light up. If it doesn't try reversing the ends. Remember that the longer wire should stick into the plus side. This is because the LED only lets the electricity &lt;a href=&quot;http://www.technologystudent.com/elec1/diode1.htm&quot;&gt;flow in one direction&lt;/a&gt;.
    &lt;/p&gt;
&lt;h4&gt;Drawing the circuit&lt;/h4&gt;
&lt;p&gt;
        We can draw the flow of electricity from the battery into the LED and then back into the other end of the battery. This is called a &lt;a href=&quot;http://en.wikipedia.org/wiki/Circuit_diagram&quot;&gt;circuit diagram&lt;/a&gt;, and it helps us to picture how the circuit works and how to modify it to make new things.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-TfJLN8moT0w/VKi5lX-HAZI/AAAAAAAACLM/dDcqioGTq6M/s1600/LED-CIRCUIT.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Electricity leaves one end of the battery and tries to get back to the other end. On its way around, the electricity flows out of the battery on the left and into the LED on the right. Then it leaves the LED and continues around the rest of the loop.
    &lt;/p&gt;
&lt;h4 id=&quot;circuit&quot;&gt;Using different colors&lt;/h4&gt;
&lt;p&gt;
        The blue LED could be hooked up directly to the battery because the LED requires the same amount of electricity that the battery supplies. The yellow, green, and red LEDs need less power so we have to reduce the amount of electricity getting to them from the battery. To do this, we need to add a resistor, which burns up some of the electricity inside of it.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-wml8t5WW1DI/VKjHvbpGBvI/AAAAAAAACMU/88CbI3Key2I/s1600/photo%2B4.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The green LED will still work without the resistor, but it will be lit more brightly than it should. Without the resistor, the green LED will burn out after a while. The resistor protects the LED from getting too much power at once. To learn more, see &lt;a href=&quot;http://www.instructables.com/id/Choosing-The-Resistor-To-Use-With-LEDs/&quot;&gt;this article&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-i9dF1aglhMc/VKi-4ipoxAI/AAAAAAAACLc/SAG8mFiSNXs/s1600/LED-CIRCUIT2.png&quot; title=&quot; &quot;/&gt;
&lt;h4 id=&quot;twoLEDs&quot;&gt;Two LEDs side by side&lt;/h4&gt;
&lt;p&gt;
        If we want to power multiple LEDs at once, we can put them both into the circuit next to each other. Make sure that the long ends are both connected to the resistor and that the short ends are connected to the minus end of the battery. This is called putting the LEDs in parallel. You can try putting one LED after the next (in series), but that keeps the battery from being able to light them.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-1sQAgOhqNhE/VKjHvR5eKdI/AAAAAAAACMQ/ayjIaEoMLkk/s1600/photo%2B5.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Now we can redraw this circuit just like before.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-7V44vjWsjeE/VKi-4j6hvZI/AAAAAAAACLg/Y9WvE0eeIsI/s1600/LED-CIRCUIT3.png&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Quick Quiz&lt;/h5&gt;
&lt;p&gt;
        As a quick test, let's ask what would happen if we unplugged one LED from the two LED circuit. Will the other LED still work? If we go back to the circuit diagram we see that electricity can still flow through the other LED even if the first one is removed. Try it out to see what happens.
    &lt;/p&gt;
&lt;h4&gt;LED lightning game&lt;/h4&gt;
&lt;p&gt;
        To end the lesson, let's try to play a game. This game will give us practice building LED circuits.
    &lt;/p&gt;
&lt;p&gt;
        Since we know how to put multiple LEDs together, try to light the right number to answer a question. Ask a simple math problem and then build a circuit with that number of LEDs lit up. Then ask a new math problem and modify the circuit to get the right number of LEDs again.
    &lt;/p&gt;
&lt;p&gt;
        As you go, try making the circuits more modular so you can modify them quicker. Try to incorporate simple switches so that you can change the setup faster too.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Tue, 06 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/raser-week-1-led-circuits/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/raser-week-1-led-circuits/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>A Better LinkedIn</title>
        <description>&lt;br/&gt;

&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-fv1k4PG_wYI/VKsFCIiAfhI/AAAAAAAACPA/LAjpvnTWtPU/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B3.28.02%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I've been wanting to fix my &lt;a href=&quot;http://www.businessinsider.com/why-the-paper-resume-isnt-dying-any-2013-9&quot;&gt;old paper resum's&lt;/a&gt; abhorrent &lt;a href=&quot;http://viz.wtf/&quot;&gt;lack of data visualization&lt;/a&gt; with an interactive web version. And since I'm about to hit the job market anyway, I figured now is the perfect time to introduce my own &lt;a href=&quot;http://hellowillmcfadden.appspot.com/&quot;&gt;Online Visual Resum&lt;/a&gt;.
    &lt;/p&gt;
&lt;p&gt;
        I've built &lt;a href=&quot;http://hellowillmcfadden.appspot.com/&quot;&gt;the site up&lt;/a&gt; and launched it on Google App Engine. I also &lt;a href=&quot;https://github.com/wmcfadden/visual-resume&quot;&gt;posted the source&lt;/a&gt; for anyone else to fork and play with. The following blog post is my attempt to explain the moving parts and why I thought they were useful improvements on the traditional approach.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;The human factor&lt;/h4&gt;
&lt;p&gt;
        First off, a resum is supposed to be about people so I wanted to leave a constant reminder that all of this data is related to a person. That led me to use a neat &lt;a href=&quot;http://www.bootply.com/templates&quot;&gt;bootstrap sidebar template&lt;/a&gt; from &lt;a href=&quot;http://www.bootply.com/&quot;&gt;bootply&lt;/a&gt; to keep the &quot;person badge thingy&quot; on the left. That keeps the face and details visible while scrolling through the content on the right.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-48QMQyqCrzE/VKr_mjpvhxI/AAAAAAAACOM/PjE3VB42EdI/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B3.17.57%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        And let's not forget the &lt;i&gt;plethora&lt;/i&gt; of social media links one needs to show off. Keeping all of this on the side made it constantly accessible no matter where you go on the page.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;People, projects, and skills are the focus.&lt;/h4&gt;
&lt;p&gt;
        The traditional resum seemed to put a lot of faith in the name of your institution. To me, it seems that that is becoming increasingly less important. This may be because individuals are becoming &lt;a href=&quot;http://www.economist.com/news/leaders/21605906-cost-crisis-changing-labour-markets-and-new-technology-will-turn-old-institution-its&quot;&gt;increasingly self-empowered&lt;/a&gt; through the web, or it might just be the result of a &lt;a href=&quot;http://www.gallup.com/poll/1597/confidence-institutions.aspx&quot;&gt;steady degradation of our trust&lt;/a&gt; in faulty institutions. Whatever the reason, a vanilla bachelor's degree and a few nondescript company names doesn't look like it's going to cut it in the future.
    &lt;/p&gt;
&lt;h5&gt;Focusing on Projects and Direct Collaborators&lt;/h5&gt;
&lt;p&gt;
        Instead of broadly classifying my work by the firm's name, on my site, I have every project and collaborator summarized in a &lt;a href=&quot;http://hellowillmcfadden.appspot.com#demo_1&quot;&gt;Hive Connection Plot&lt;/a&gt;. I also include links to the publications of projects and to the public profiles of the people I worked with when possible.
    &lt;/p&gt;
&lt;p&gt;
        All of this sends the message of interactivity and teamwork that is so important today. There's no room to hide behind your company's credentials if all your work involved repeatedly handing the same form to the same boss.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-85gsYQsqI_o/VKr_4Bc8X0I/AAAAAAAACOU/IyG_61ixbdc/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B2.55.43%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;h5&gt;Including Skills&lt;/h5&gt;
&lt;p&gt;
        Although the main focus of this section was the projects and collaborations, I thought it would be interesting to include the skills I brought to each project too. The great advantage of the Hive plot was the ability to add the skills on a separate branch without cluttering things too much.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Skill Lists should be scored&lt;/h4&gt;
&lt;p&gt;
        One thing that was lacking in the People-Projects-Skills graphic is any quantitative assessment of ability. A list of skills doesn't tell you how well you know them so I built &lt;a href=&quot;http://hellowillmcfadden.appspot.com#skillbubbles&quot;&gt;this zoomable pack hierarchy&lt;/a&gt; to make it obvious how well I know something based on its size.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-OusFwqjYgBE/VKr6v-b4h2I/AAAAAAAACNQ/O-bxCpzHFyg/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B2.57.06%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        When I put down my list of &quot;known languages,&quot; I'm not saying that I know how to do everything with an Arduino or python. In a linear text resume it's impossible to express how well you know a given skill. So most kid's today have technical skill lists that bloat with a thousand things they've tried once or just vaguely understand.
    &lt;/p&gt;
&lt;p&gt;
        It's clear that if this sort of hierarchy of skills were formalized better it would become a heck of a lot more useful. Also publicly accessible scores for various tangible skills would convert this from a subjective assessment into an objective one.
    &lt;/p&gt;
&lt;h5&gt;Adding Education&lt;/h5&gt;
&lt;p&gt;
        Modern degrees are increasingly becoming more and more flexible. We give students the opportunity to learn diverse things, but unfortunately, we don't try to accurately inform employers about what their employees were actually taught. That makes a 21st century degree meaningless in terms of subject matter.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;https://media.licdn.com/mpr/mpr/jc/p/8/005/0a5/3ca/08ba6bd.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;I recently saw &lt;a href=&quot;https://www.linkedin.com/pulse/big-idea-2015-lets-rethink-jeff-selingo&quot;&gt;an article by Jeff Selingo&lt;/a&gt; (ironically the article was on LinkedIn) where he mentioned this idea of a &quot;digital backpack,&quot; that follow you through life, documenting your accrual of skills. The main problem I see with that is the ability to parse who knows what and how they learned it in such a disordered system.
    &lt;/p&gt;
&lt;p style=&quot;display:none&quot;&gt;In the future I want to work out a modified Sankey diagram as a way to fix that problem. It would basically plot how every bit of info you understand was developed from high school on. And it could track your performance along the way so you could understand what's important for learning certain skills. Maybe if you don't understand something right now, it would be obvious that you're struggling just because you didn't &lt;i&gt;really&lt;/i&gt; understand this other subtopic three years ago.
    &lt;/p&gt;
&lt;p&gt;
        This interconnection between skills and education would be fun to work out in the future if I ever get a chance.
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Interest graph&lt;/h4&gt;
&lt;p&gt;
        I'll admit that &lt;a href=&quot;http://hellowillmcfadden.appspot.com#forcegraph&quot;&gt;this one&lt;/a&gt; was mostly just for fun. I thought it would be nice to see the way all the things I like might be related.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/--brk9tzyW9I/VKsAhP7p5iI/AAAAAAAACOg/MAj7w5JnRi0/s1600/Screen%2BShot%2B2015-01-05%2Bat%2B3.03.54%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
&lt;a href=&quot;http://bl.ocks.org/mbostock/4062045&quot;&gt;D3's force plots&lt;/a&gt; are just a fun way to draw connection matrices. They tend to look OK as long as the connectivity of the graph isn't too high. Maybe that's a good way to judge whether you're interested in too many things!
    &lt;/p&gt;
&lt;br/&gt;
&lt;h4&gt;Death to the Old-Fashioned CV&lt;/h4&gt;
&lt;p&gt;
        I did succumb to the peer pressure and include &lt;a href=&quot;http://hellowillmcfadden.appspot.com#boringpage&quot;&gt;a link to my paper CV&lt;/a&gt; too at the end. Hopefully someday there will be a better way, but for now I think it's worthwhile to show off my not-too-shabby credentials in the classic style.
    &lt;/p&gt;

</description>
        <pubDate>Mon, 05 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/a-better-linkedin/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/a-better-linkedin/</guid>
        
        <category>data science</category>
        
        <category>visualization</category>
        
        <category>design</category>
        
        <category>code</category>
        
        
      </item>
    
      <item>
        <title>Wire Network</title>
        <description>&lt;p&gt;
        For the past 10 years or so, I've been saving up my broken metal guitar strings. (For the record, I know I'm a packrat.) A couple of weeks ago, I finally put them to use on this Wire Netowrk Sculpture.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-IQmsl15IlaU/VKYaFC0cbhI/AAAAAAAACJ0/DCs_acosnj0/s1600/photo%2B1.JPG&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The inspiration comes from my job studying &lt;a href=&quot;http://en.wikipedia.org/wiki/Biopolymer&quot;&gt;biopolymer&lt;/a&gt; networks in the &lt;a href=&quot;en.wikipedia.org/wiki/Cytoskeleton&quot;&gt;cellular cytoskeleton&lt;/a&gt;.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://scienceblogs.com/transcript/wp-content/blogs.dir/365/files/2012/04/i-3b17600bb332ac6fd1410b4161368c74-emfig2.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        It sounds complicated, but basically it's just a bunch of microscopic wires that are all stuck together. I'm more-or-less studying how cell's change shape when you push on them.
    &lt;/p&gt;
&lt;p&gt;
        Hopefully, the sculpture makes it a little easier to imagine what I'm working on. I'm hoping to submit it in a Science/Art Competition coming up this spring at my school.
    &lt;/p&gt;
&lt;a href=&quot;http://3.bp.blogspot.com/-PSVVtIvd6Ek/VKb0ctyIVPI/AAAAAAAACKo/nc98n1nJIuY/s1600/3595809_b.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-PSVVtIvd6Ek/VKb0ctyIVPI/AAAAAAAACKo/nc98n1nJIuY/s1600/3595809_b.png&quot; style=&quot;display:none&quot;/&gt;&lt;/a&gt; &lt;br/&gt;
</description>
        <pubDate>Sat, 03 Jan 2015 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2015/01/wire-network/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2015/01/wire-network/</guid>
        
        <category>art</category>
        
        
      </item>
    
      <item>
        <title>Graph Theory of Wall Decor</title>
        <description>&lt;p&gt;
        This is just a short post about a hallway wall decoration I made over the weekend. It's supposed to resemble a &lt;a href=&quot;http://en.wikipedia.org/wiki/Network_theory&quot;&gt;network graph&lt;/a&gt;, linking the different pieces together.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-vkLL0Xgx53M/VKwsofqeMAI/AAAAAAAACPQ/yuGHlTiJTSI/s1600/wallgraph_front.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        Basically I had a lot of unrelated stuff to put on our last empty wall and I needed a clever way to get it all on there. I hope you find it as amusing as I do.
    &lt;/p&gt;
&lt;p&gt;
        For closeups of the individual items that I stitched together, you can check &lt;a href=&quot;https://plus.google.com/photos/103585488893025173441/albums/6101303480819525617&quot;&gt;this photo album&lt;/a&gt; on Google+. &lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-MUXg3Mc6wO8/VKrBNbktU0I/AAAAAAAACM4/GXUA-wYINEk/s1600/wallgraph_front.png&quot; style=&quot;display:none&quot;/&gt;&lt;br/&gt;
&lt;/p&gt;</description>
        <pubDate>Wed, 31 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/graph-theory-of-wall-decor/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/graph-theory-of-wall-decor/</guid>
        
        <category>art</category>
        
        <category>design</category>
        
        
      </item>
    
      <item>
        <title>RASER Curriculum</title>
        <description>&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-flG2HLm3sdw/VKMlSnwVzKI/AAAAAAAABQA/jjtWOSHlH5Y/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B4.20.32%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        I'm running the Ray After School Electronics and Robotics (RASER) Program at Ray Elementary this Winter. The program is going to culminate with a competition on building an Arduino based security system. And each week before that will have a session on one of the sub-components of the project.
    &lt;/p&gt;
&lt;p&gt;
        Here are the project titles, and I'll update with links to descriptions as I build them.
    &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-1-led-circuits.html&quot;&gt;Week 1: LED circuits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-2-led-dimmers-and-switches.html&quot;&gt;Week 2: LED dimmers and switches&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-3-arduino-led-blinker.html&quot;&gt;Week 3: Arduino LED blinker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/01/raser-week-4-arduino-led-passcode-pad.html&quot;&gt;Week 4: Arduino LED Passcode Pad - Part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/02/raser-week-5-review-game.html&quot;&gt;Week 5: Review Game&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/02/raser-week-5-arduino-led-passcode-pad.html&quot;&gt;Week 6: Arduino LED Passcode Pad - Part 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week 7: Review LED Passcode pad &lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/03/raser-week-8-arduino-trip-wire.html&quot;&gt;Week 8: Arduino trip wire&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/03/week-9-laser-activated-trip-wire.html&quot;&gt;Week 9: Laser activated trip switch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Week 10: Arduino Body heat detector &lt;/li&gt;
&lt;li&gt;Week 11: Arduino security competition &lt;/li&gt;
&lt;li&gt;Week 12: Arduino security competition &lt;/li&gt;
&lt;li&gt;Week 13: Arduino security competition &lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;
</description>
        <pubDate>Tue, 30 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/raser-curriculum/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/raser-curriculum/</guid>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>Quantum Gambling Game</title>
        <description>&lt;style&gt;
#markdown img.quantum_im {
    width:8%;
    margin:1%;
    margin-bottom:0;
    display:inline;
}
#markdown input.quantum_input {
    width:8%;
    margin:1%;
    font-size:12px;
    display:inline;
}
&lt;/style&gt;
&lt;p&gt;
    Have you ever heard of quantum computing? Know what makes it so special? Well, many scientists (and their funding agencies) are hoping that quantum computing's secrets just might help &lt;a href=&quot;http://www.inc.com/will-bourne/d-waves-dream-machine.html&quot;&gt;get them rich&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    I can't promise you that. But I can share this quantum gambling game I made with you. Although it looks simple enough on the surface, this betting game actually reveals an interesting application of &lt;a href=&quot;http://en.wikipedia.org/wiki/Quantum_computing&quot;&gt;quantum computing&lt;/a&gt;, the science turning &quot;spooky&quot; physics into solving real problems.
&lt;/p&gt;
&lt;p&gt;
    I'll explain more about strategy and its relation to quantum algorithms below, but for now, try the game out! Read below for more instructions.
&lt;/p&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;div style=&quot;border:1px solid #AAA;border-radius:5px;width:500px;margin:auto;text-align:center&quot;&gt;
    &lt;h4 style=&quot;text-align:center&quot;&gt; Guess the Quantum Card! &lt;/h4&gt;
    &lt;br /&gt;
    &lt;div&gt;&lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card1&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card2&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card3&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card4&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card5&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card6&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card7&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt;
        &lt;img class=&quot;quantum_im&quot; border=&quot;0&quot; id=&quot;card8&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot; /&gt; 
    &lt;/div&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet1&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet2&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet3&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet4&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet5&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet6&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet7&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;input class=&quot;quantum_input&quot; id=&quot;bet8&quot; max=&quot;9&quot; min=&quot;0&quot; type=&quot;number&quot; value=&quot;0&quot; /&gt;
    &lt;div id=&quot;results&quot; style=&quot;display:none&quot;&gt;
  
    &lt;/div&gt;
    &lt;div&gt;
        &lt;button id=&quot;paybut&quot; onclick=&quot;payup()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Trade Bets&lt;/button&gt; 
        &lt;button id=&quot;rebut&quot; onclick=&quot;regame()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Restart&lt;/button&gt; 
        &lt;button id=&quot;startbut&quot; onclick=&quot;startgame()&quot; style=&quot;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Place Bets&lt;/button&gt;
        &lt;button id=&quot;swapbut&quot; onclick=&quot;swap()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;Redistribute&lt;/button&gt;
        &lt;button id=&quot;endbut&quot; onclick=&quot;endgame()&quot; style=&quot;display:none;font-size:1.2em;border-radius:5px&quot; type=&quot;button&quot;&gt;End Game&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;h4&gt;Instructions&lt;/h4&gt;
&lt;p&gt;
    The goal is to get the biggest bet you can onto the Ace of Spades, and to keep your bet off of the decoy cards. But the trick is that during the game none of the cards are ever revealed to you.
&lt;/p&gt;
&lt;p&gt;
    You start the game by placing your initial bets on whatever cards you want.
&lt;/p&gt;
&lt;p&gt;
    After that, you have your choice of two moves, which you get to repeat until you decide you're done.
&lt;/p&gt;
&lt;ol&gt;
    &lt;li&gt;&lt;b&gt;Trade Bets&lt;/b&gt;, meaning any money on the losing cards goes to the dealer, while the money on the winning card stays the same. &lt;/li&gt;
    &lt;li&gt;&lt;b&gt;Redistribute&lt;/b&gt;, meaning you reverse all the bets around the average bet value. So the dealer's money comes back to your side of the average, and vice versa. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
    The redistribute move might seem confusing, so here's what it does graphically.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-QihHMwqvsF8/VKLpaC0D5uI/AAAAAAAABL4/dbQ1ZZBLngk/s1600/mean_invert_grover.gif&quot; title=&quot;
How the Redistribute Move Works

 &quot; /&gt;
&lt;p&gt;
    During the redistribution, the dealer basically just moves the money around so that places where the money is on the dealer's side shift back to places where you still have money. The math can get really complicated based on how many different bets there are going, but it boils down to just flipping the bets like in the graphic.
&lt;/p&gt;
&lt;p&gt;
    Throughout the game, all the money stays on the table. But unfortunately for you, even though the money is changing hands, the dealer never tells you whether a given bet is yours or his on the table.
&lt;/p&gt;
&lt;p&gt;
    Whenever you want, you can end the game. At that point, the dealer checks how much money there is on the winning card and gives you back two times that amount. He takes everything else.
&lt;/p&gt;
&lt;h5 style=&quot;text-align:center;font-size:1.5em&quot;&gt;So can you play?&lt;/h5&gt;
&lt;h5 style=&quot;text-align:center;font-size:1.2em&quot;&gt;And can you figure out how to win... every time?&lt;/h5&gt;
&lt;br /&gt; &lt;br /&gt;&lt;br /&gt;
&lt;h4&gt;Some Quantum Hints&lt;/h4&gt;
&lt;p&gt;
    OK, so you're stumped. Here are some hints.
&lt;/p&gt;
&lt;p&gt;
    I mentioned that it's possible to win &lt;i&gt;every&lt;/i&gt; timenot just &lt;i&gt;most&lt;/i&gt; of the time. That should be a clue that the game doesn't rely on guessing.
&lt;/p&gt;
&lt;p&gt;
    A second clue to point out is that the Trade Bets operation &quot;undoes itself.&quot; That means that if you Trade Bets twice in a row, that's the same thing as not trading bets at all. Take a minute to understand why that's true.
&lt;/p&gt;
&lt;p&gt;
    Finally, I'll just tell you that repeating the Redistribute operation twice in a row isn't necessary to solve the problem.
&lt;/p&gt;
&lt;p&gt;
    If you really don't have any idea what I'm talking about, check out &lt;a href=&quot;#expa&quot; onclick=&quot;expa()&quot;&gt;this appendix&lt;/a&gt; at the bottom of the page for more info.
&lt;/p&gt;
&lt;p style=&quot;text-align:center&quot;&gt;Now give it another try.
&lt;/p&gt;
&lt;h4&gt;Time out: how is quantum computing supposed to help me? &lt;/h4&gt;
&lt;p&gt;
    For quantum computing, it's all about using fewer iterations to get the same job done. A quantum algorithm aims to take a problem that would take billions of calculations on a classical computer and turn it into just hundreds of quantum calculations.
&lt;/p&gt;
&lt;p&gt;
    For example, how long could it take you to find the card by guessing in the classical world? If there are 8 cards you could have to guess 8 times. But for the quantum algorithm on which this game is based, you would be guaranteed to find the card with just 2 guesses. How does it do that? Well, you'll have to read on to find out.
&lt;/p&gt;
&lt;p&gt;
    But with the 2 repetitions in mind, try the game out again.
&lt;/p&gt;
&lt;h4 id=&quot;howtowin&quot;&gt;How to win the Game&lt;/h4&gt;
&lt;p&gt;
    The way to win every time starts with eliminating all guessing. What I mean by &quot;no guessing&quot; is that the initial configuration of bets must be the same for every card. For example, you can just bet 1 on each card.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-00cL8az7VaQ/VKMHxaKokFI/AAAAAAAABMI/VZN_gyUSRps/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B2.13.20%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    After this we just start trying operations. Because Redistributing on all 1s doesn't change the bet values, we know that we start by Trading Bets with the dealer and then we Redistribute. We could redistribute over and over, but it turns out that won't help (although I don't know why. If you know, put it in the comments). At this point, we just have to toggle back and forth between Trading and Redistributing operations.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-pMJqB4nRif8/VKMHxSB8B6I/AAAAAAAABMM/e8VE4AhdiYs/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B2.13.53%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    If we repeat those operations just the right number of times, our initial bets will work their way onto the winning card. Now we just need to figure out how many times to repeat those moves.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-WvR0IUoXD1Y/VKMHxZ7UxbI/AAAAAAAABMQ/_kAvN5N_chs/s1600/Screen%2BShot%2B2014-12-30%2Bat%2B2.14.01%2BPM.png&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    It turns out that the right number of repetitions is two. There's a reason that you have to repeat the pair of operations exactly twice, but I have to wait until after I explain the quantum mechanics to get to that. For now, just try playing it again and show yourself that it actually does work.
&lt;/p&gt;
&lt;br /&gt;
&lt;h4&gt;Quantum Information and Grover's Algorithm&lt;/h4&gt;
&lt;p&gt;
    The two moves in the game are really just classical ways to describe more &lt;a href=&quot;http://www.technologyreview.com/view/427174/einsteins-spooky-action-at-a-distance-paradox-older-than-thought/&quot;&gt;&quot;spooky&quot;&lt;/a&gt; operators from quantum computing. And the money gained at the end of the game is analogous to your probability of finding a solution to the problem using a &lt;a href=&quot;http://en.wikipedia.org/wiki/Brute-force_search&quot;&gt;search algorithm&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
    The Trading Bets operation would be called a Quantum Oracle, which by itself doesn't tell you which solution is right, but will confirm if you have the right answer at the end (by giving you money or taking it). And the Redistribute move is a Grover Diffusion Operator, which essentially lets information about the correct answer &quot;diffuse&quot; from wrong answers. (Note that this is way more complicated than I can explain, and to understand it for real you might need to do &lt;a href=&quot;http://en.wikipedia.org/wiki/Quantum_computing&quot;&gt;more reading&lt;/a&gt; (or even &lt;a href=&quot;https://www.edx.org/course/quantum-mechanics-quantum-computation-uc-berkeleyx-cs-191x#.VKL7kAJBvQ&quot;&gt;take a class&lt;/a&gt;) on the subject.)
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://upload.wikimedia.org/wikipedia/commons/a/ae/Grovers_algorithm.svg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    When you repeat these two operations back to back, you end up performing &lt;a href=&quot;http://en.wikipedia.org/wiki/Grover%27s_algorithm&quot;&gt;Grover's Algorithm&lt;/a&gt;, a technique proven to find the right information in a database (i.e. the cards). Lov Grover (not &lt;a href=&quot;http://muppet.wikia.com/wiki/Grover,_Messenger_of_Love&quot;&gt;Love, Grover&lt;/a&gt;) discovered this way of finding information back in the 90s. He was working on a method to compute inverses by letting a quantum function (i.e. the dealer) perform operations (i.e. Trading Bets) that we couldn't see in the classical world (i.e. on our side of the betting table). What was amazing about it was that it allowed you to perform the calculation many fewer times than you would using a classical (asking &quot;Hey, is it that card?&quot;) approach.
&lt;/p&gt;
&lt;p&gt;
    In the above game, you only need to repeat the procedure 2 times. Whereas to find the card by guessing, you might have to try 8 times. If you want to learn more about why it's exactly 2, I recommend &lt;a href=&quot;http://arxiv.org/pdf/quant-ph/0504012.pdf&quot;&gt;this in depth article&lt;/a&gt; on the subject.
&lt;/p&gt;
&lt;p&gt;
    (And to learn more about Grover's algorithm with cool visualizations, check out &lt;a href=&quot;http://twistedoakstudios.com/blog/Post2644_grovers-quantum-search-algorithm&quot;&gt;this tutorial&lt;/a&gt; from &lt;a href=&quot;http://twistedoakstudios.com/index.php&quot;&gt;Twisted Oak Studios&lt;/a&gt;.
&lt;/p&gt;
&lt;br /&gt;
&lt;h4&gt;So what's the big deal?&lt;/h4&gt;
&lt;p&gt;
    In the end, what's really important about Grover's algorithm is that this isn't just a mathematical artifact. The crazy laws of quantum mechanics somehow make it possible to perform these operation on real materials. This means that it can be used to find real answers to questions that we can't solve fast enough with current computers.
&lt;/p&gt;
&lt;p&gt;
    Unfortunately, building quantum computers is turning out to be &lt;a href=&quot;http://gizmodo.com/why-programming-a-quantum-computer-is-so-damn-hard-1188316086&quot;&gt;insanely hard&lt;/a&gt; so currently we can still do better with classical computers. But hopefully &lt;a href=&quot;http://www.wired.com/2014/10/quantum-computing-close/&quot;&gt;someday soon&lt;/a&gt;, a big breakthrough will make this technology possible. &lt;p&gt;
        I hope this whetted your appetite to learn more about quantum computing. Or at the least, it's a fun little puzzle to show your friends.
    &lt;/p&gt;
    &lt;br /&gt;
    &lt;h4&gt;Playing more with quantum computers&lt;/h4&gt;
    &lt;p&gt;
        If you want to work more on this, feel free to check out my code. For starters, you can find the javascript for the game on CodePen &lt;a href=&quot;http://codepen.io/wmcfadd2/details/YPpqBr/&quot;&gt;here&lt;/a&gt;. If you're more interested about the quantum details, you can also check out &lt;a href=&quot;https://github.com/lots-of-things/quantum-comp&quot;&gt;this project&lt;/a&gt; on Github that implements quantum computing gates as MATLAB matrix operations.
    &lt;/p&gt;
    .&lt;br /&gt;.&lt;br /&gt;.&lt;br /&gt;
    &lt;div id=&quot;expa&quot; onclick=&quot;expa()&quot; style=&quot;cursor:pointer&quot;&gt;
        &lt;h4&gt;Appendix: Basic Primer on the Quantum Betting Game&lt;/h4&gt;
        &lt;p&gt;
            In case you need a little background about betting and guessing games, &lt;a href=&quot;#expa&quot;&gt;here's&lt;/a&gt; a little Appendix that will help fill you in.
        &lt;/p&gt;
    &lt;/div&gt;
    &lt;br /&gt;
&lt;/p&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
function expa() { if (document.getElementById(&quot;appendix&quot;).style.display == &quot;inline&quot;) { document.getElementById(&quot;appendix&quot;).style.display = &quot;none&quot; } else { document.getElementById(&quot;appendix&quot;).style.display = &quot;inline&quot;; } }
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var total = 0;
var bets = [];
var index;
var nrm;
var tog;

function startgame() {
    document.getElementById(&quot;startbut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;paybut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;swapbut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;endbut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;bet1&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet2&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet3&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet4&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet5&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet6&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet7&quot;).readOnly = &quot;true&quot;;
    document.getElementById(&quot;bet8&quot;).readOnly = &quot;true&quot;;
    bets[0] = document.getElementById(&quot;bet1&quot;).value;
    bets[1] = document.getElementById(&quot;bet2&quot;).value;
    bets[2] = document.getElementById(&quot;bet3&quot;).value;
    bets[3] = document.getElementById(&quot;bet4&quot;).value;
    bets[4] = document.getElementById(&quot;bet5&quot;).value;
    bets[5] = document.getElementById(&quot;bet6&quot;).value;
    bets[6] = document.getElementById(&quot;bet7&quot;).value;
    bets[7] = document.getElementById(&quot;bet8&quot;).value;
    index = Math.floor((Math.random() * 8));
    nrm = 0;
    tog = 0;
    for (i = 0; i &lt; bets.length; i++) {
        nrm = nrm + Math.pow(bets[i], 2);
        tog = tog + Math.abs(bets[i]);
    }
    nrm = Math.sqrt(nrm);
    for (i = 0; i &lt; bets.length; i++) { bets[i] = bets[i] / nrm; }
}

function payup() { 
    for (i = 0; i &lt; bets.length; i++) 
        { 
            if (i != index) bets[i] = -bets[i]; }
            refresh();
        }

function swap() { avg = 0; for (i = 0; i &lt; bets.length; i++) { avg = avg + 1 * bets[i]; } avg = avg / 8; for (i = 0; i &lt; bets.length; i++) { bets[i] = 2 * avg - bets[i]; } refresh(); }

function refresh() {
    sm = 0;
    for (i = 0; i &lt; bets.length; i++) { 
        sm = sm + Math.abs(bets[i]); 
    }
    if (sm &gt; 0) { 
        scl = tog / sm; 
    } else { 
        scl = 1; 
    } 
    document.getElementById(&quot;bet1&quot;).value = Math.abs(scl * bets[0]);
    document.getElementById(&quot;bet2&quot;).value = Math.abs(scl * bets[1]);
    document.getElementById(&quot;bet3&quot;).value = Math.abs(scl * bets[2]);
    document.getElementById(&quot;bet4&quot;).value = Math.abs(scl * bets[3]);
    document.getElementById(&quot;bet5&quot;).value = Math.abs(scl * bets[4]);
    document.getElementById(&quot;bet6&quot;).value = Math.abs(scl * bets[5]);
    document.getElementById(&quot;bet7&quot;).value = Math.abs(scl * bets[6]);
    document.getElementById(&quot;bet8&quot;).value = Math.abs(scl * bets[7]);
}

function endgame() {
    val = 0;
    for (i = 0; i &lt; bets.length; i++) { if (i != index) { val = val - Math.abs(bets[i]); } else { val = val + 2 * Math.abs(bets[i]); } } sm = 0;
    for (i = 0; i &lt; bets.length; i++) { 
        sm = sm + Math.abs(bets[i]); 
    } 
    scl = tog / sm;
    val = val * scl;
    total = total + val;
    if (val &gt; 0) { 
        document.getElementById(&quot;results&quot;).innerHTML = &quot;Game over.  You won $&quot; + val.toFixed(2); 
    } else { 
        document.getElementById(&quot;results&quot;).innerHTML = &quot;Game over.  You lost $&quot; + (-val).toFixed(2); 
    }
    if (total &gt; 0) { 
        document.getElementById(&quot;results&quot;).innerHTML = document.getElementById(&quot;results&quot;).innerHTML + &quot;. &lt;br /&gt; Total Winnings= $&quot; + total.toFixed(2); 
    } else { 
        document.getElementById(&quot;results&quot;).innerHTML = document.getElementById(&quot;results&quot;).innerHTML + &quot;. &lt;br /&gt; Total Winnings= -$&quot; + -total.toFixed(2); 
    } 
    document.getElementById(&quot;results&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;rebut&quot;).style.display = &quot;inline&quot;;
    document.getElementById(&quot;paybut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;swapbut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;endbut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;card&quot; + (index + 1)).src = &quot;http://upload.wikimedia.org/wikipedia/commons/e/e2/Aceofspades.png&quot;;
}

function regame() {
    document.getElementById(&quot;card&quot; + (index + 1)).src = &quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Bicyclebackside.jpg/153px-Bicyclebackside.jpg&quot;;
    document.getElementById(&quot;rebut&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;results&quot;).style.display = &quot;none&quot;;
    document.getElementById(&quot;startbut&quot;).style.display = &quot;inline&quot;;
    bets = [0, 0, 0, 0, 0, 0, 0, 0];
    refresh();
    document.getElementById(&quot;bet1&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet2&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet3&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet4&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet5&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet6&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet7&quot;).readOnly = &quot;&quot;;
    document.getElementById(&quot;bet8&quot;).readOnly = &quot;&quot;;
}
&lt;/script&gt;</description>
        <pubDate>Mon, 29 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/quantum-gambling-game/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/quantum-gambling-game/</guid>
        
        <category>games</category>
        
        <category>quantum</category>
        
        
      </item>
    
      <item>
        <title>PVC Easel</title>
        <description>&lt;p&gt;
        One of my gifts to my girlfriend this year was a set of paints and brushes that I found on &lt;a href=&quot;http://www.craigslist.org/about/sites&quot;&gt;craigslist&lt;/a&gt;. She'd been holding on to some canvases, but it didn't look like she'd ever do anything with them unless somebody went out and got the paints for her.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-KcNroociJ_4/VKBYiGSAwQI/AAAAAAAABDA/x11ijF3jW0o/s1600/14%2B-%2B1&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To make the gift all the more special, I decided to build her an easel too. I've had lots of left over fragments of PVC in my closet for a good two years now. And I'm finally just using up the last of them on this project.
    &lt;/p&gt;
&lt;p&gt;
        The easel design is extremely simple. For every connection, I just used a big hole on one side and a screw hole on the other. Everything locks into place and it stands upright.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-3rYj4HP8JCM/VKBQBuKeABI/AAAAAAAABBw/cv8zuwcastM/s1600/2014-12-28%2B11.41.30.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        One cool feature that we knew we needed for our little apartment was the ability to collapse it and store it away. Just removing one screw from the top corner lets the whole thing fold up like this.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-0bTMyyJfE8Y/VKBQBtCT8QI/AAAAAAAABBw/ZhtamwCuAmU/s1600/2014-12-28%2B11.46.54.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The last step is going to be cutting this piece of wood down and coating it to make a little painter's pallet.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-SQVIe-V9Vtk/VKBQBtqHQ6I/AAAAAAAABBw/wfVGJUU0F6o/s1600/2014-12-28%2B11.39.41.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The gift went over great and Claire's really exited to try it out. So hopefully soon, I'll start putting up paintings that she makes.
    &lt;/p&gt;
&lt;br/&gt;
</description>
        <pubDate>Sun, 28 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/pvc-easel/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/pvc-easel/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <title>Solar battery charger &amp;amp; flower pot (first try)</title>
        <description>This is my first attempt at attaching a solar battery charger like &lt;a href=&quot;http://lifehacker.com/5752731/built-a-4-diy-solar-battery-charger&quot;&gt;this one&lt;/a&gt; to a flower pot.  The style of the pot isn't exactly what I was looking for.  I was hoping to have the top at an angle that faced the sun better, but my friend who made the pots couldn't get them to stay flat during baking.  The next edition will have a better pot and hopefully will work to charge cell phones as well. &lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-0cAr7rofgBk/VJ9Aml-NqBI/AAAAAAAAA_Y/5fi1jvpwTxA/s1600/IMG_0154.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Sat, 27 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/solar-battery-charger-flower-pot-first/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/solar-battery-charger-flower-pot-first/</guid>
        
        <category>misc</category>
        
        <category>energy</category>
        
        <category>electronics</category>
        
        
      </item>
    
      <item>
        <title>Mo's Tool Pouch</title>
        <description>So in keeping with the holiday spirit I'm now showing off the little bag I made for my girlfriend's mom. She's an avid &lt;a href=&quot;http://lillstreet.com/department/ceramics-sculpture&quot;&gt;ceramicist&lt;/a&gt; so I made this bag to keep her tools. &lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-NHNTr6jR-Zo/VJi2B-i4GwI/AAAAAAAAA9Q/5s2a-6kX5w4/s1600/2014-12-21%2B14.58.36.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    Over the summer she got me a golf bag to replace my old rundown broken one. (Oh how I wish I had a picture of the old one. It was kind of embarrassing. It looked a little something like this except with a gaping 2 foot hole in the side from which clubs would occasionally fall out.) &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-1TtLY0oCtww/VJH9M2rbiZI/AAAAAAAAA8s/opY6twDVm7E/s1600/m18uBHjUbHQ4tsfQuGPeI6g.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    I figured she'd really like it if I reused the leather to make her a gift. I was originally thinking about just a leather belt until my girlfriend actually came up with the idea for a tool pouch for her ceramics equipment.
&lt;/p&gt;
&lt;h4&gt;How I made it&lt;/h4&gt;
&lt;p&gt;
    The exterior comes from three 4 by 17ish swaths of faux leather/canvas pulled from different intact parts of the bag. I sewed them together lengthwise and rounded the edges for the zipper to go around smoothly.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-u3gnN1f3Vvo/VJi2CGdtMWI/AAAAAAAAA9U/k-ZnGNPgLwk/s1600/2014-12-21%2B14.59.10.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    The zipper came from a mid 90s computer case that I condensed to create a 2010s computer case. In that project, I had removed a section which left over a small ribbon of zipper that I could reuse. This didn't leave too much edge for the zipper so my stitching had to be pretty precise to hold.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://4.bp.blogspot.com/-WoB5YewGNNk/VJi2C8LY1qI/AAAAAAAAA9k/XZ54E9JKauA/s1600/2014-12-21%2B14.59.50.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    On the inside I wanted to have little tool holder straps for ceramics tools to fit in. I didn't know the exact sizing because I couldn't find a casual way to bring up the dimensions of her ceramics tools without arousing suspicion. So I guessed that I could put strips in two orientations and most things would fit somehow.
&lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-RZ2jN5W141c/VJi2B1_kfaI/AAAAAAAAA9c/IjHiJPDWpdA/s1600/2014-12-21%2B14.58.54.jpg&quot; title=&quot; &quot; /&gt;
&lt;p&gt;
    Interestingly I learned that I would have to add decorative stitching on the outside to continue my lines because otherwise it just looked really bad.
&lt;/p&gt;
&lt;p&gt;
    I'm really pleased with the result. Sewing is a new skill to me, but it's worth it to learn. &lt;br /&gt;
&lt;/p&gt;</description>
        <pubDate>Sat, 27 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/mos-tool-pouch/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/mos-tool-pouch/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <title>Modernizing my computer case</title>
        <description> I had an old laptop case from the 90s that I wanted to update for use.  Mostly I just wanted to shrink it down to a reasonable size for a modern laptop. Here's the result. &lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-ZOlGCYGGU-E/VJi9pRYu9VI/AAAAAAAAA90/V-jiITbZhJE/s1600/2014-12-21%2B15.02.04.jpg&quot; title=&quot; &quot;/&gt;
 This is what the old case looked like.  Big and clunky. &lt;img border=&quot;0&quot; src=&quot;http://1.bp.blogspot.com/-xHT7ZbYyI-Q/VJi-Wt0ki5I/AAAAAAAAA98/nwnBz_pJB84/s1600/computer%2Bcases%2Bsamsonite%2B001.JPG&quot; title=&quot; &quot;/&gt;
&lt;br/&gt;
</description>
        <pubDate>Sat, 27 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/modernizing-my-computer-case/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/modernizing-my-computer-case/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <title>Introducing Dave's Grill-It-All</title>
        <description>&lt;p&gt;
        My girlfriend's dad (Dave) is really into grilling (&lt;a href=&quot;http://www.bonappetit.com/entertaining-style/pop-culture/article/tv-dads-kitchen-skills&quot;&gt;as are all dads&lt;/a&gt;). So for Christmas we figured we'd go in together to get him one of these grill attachments that he had been talking about.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://www.kettlepizza.com/v/vspfiles/assets/images/home_tailgate_image_2.jpg&quot; style=&quot;width:200px&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        We looked into a &lt;a href=&quot;http://store.weber.com/accessories/category/cook/cookware/1100&quot;&gt;Kettle Rotisserie&lt;/a&gt; that cost $160 and a &lt;a href=&quot;http://www.kettlepizza.com/KettlePizza-Basic-KPB-22-p/kpb-22.htm&quot;&gt;Kettle Pizza&lt;/a&gt; that came in at $150 (&lt;a href=&quot;http://www.kettlepizza.com/Serious-Eats-KettlePizza-Special-Edition-Kit-p/kpse-22.htm&quot;&gt;or more&lt;/a&gt;).
    &lt;/p&gt;
&lt;p&gt;
        Now me being a man of limited means and boundless ambition, I decided to save a buck and build one myself.
    &lt;/p&gt;
&lt;p&gt;
        And then, I figured, while I'm at it, why not make a grill attachment that does both?
    &lt;/p&gt;
&lt;p&gt;
        After some troubleshooting and plan modifications (see below), I eventually arrived at Dave's Grill-It-All.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-NtbKNswnEzk/VKBarFAaBdI/AAAAAAAABCw/HOfF0GmGxlI/s1600/Screen%2BShot%2B2014-12-28%2Bat%2B1.31.22%2BPM.png&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        You can see the store-bought chicken that we were using to test it. This video shows the rotisserie in action, with commentary and camerawork from my girlfriend Claire.
    &lt;/p&gt;
&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;315&quot; src=&quot;//www.youtube.com/embed/VPnCM2lucXg?rel=0&quot; width=&quot;560&quot;&gt;&lt;/iframe&gt;
&lt;h4&gt;Putting it Together&lt;/h4&gt;
&lt;p&gt;
        The plans (&lt;a href=&quot;https://github.com/lots-of-things/grill-it-all&quot;&gt;on github&lt;/a&gt;) show the sheet metal parts, all made by simply cutting, bending, drilling, and bolting (no welding or fancy stuff). Although the pizza oven could be made with just sheet metal, the rotisserie also required a motor and skewers, which is where the real difficulty came in.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-C9h4bXn3Gjo/VJjcJqFrS3I/AAAAAAAAA-Q/0AylvFG1XZo/s1600/2014-12-22%2B16.40.24.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        The whole body and a few parts of the skewer were all constructed from two sheets of stainless steel sheet metal that I got from Home Depot for $10. Working sheet metal is really easy if you have a big shears at your disposal (&lt;a href=&quot;https://chemistry.uchicago.edu/page/facilities.html#machine&quot;&gt;thanks UChicago!&lt;/a&gt;). Other fancy stuff is nice, but you can do most stuff by hand. I'll do a post someday on hacking sheet metal without the proper equipment, but if you can't wait, check out &lt;a href=&quot;http://www.tractorsupply.com/know-how_Metalworking_working-with-sheet-metal-safety-tools-and-sheetmetal-projects&quot;&gt;these tips and techniques&lt;/a&gt;. Remember that sheet metal can be razor sharp so make sure to blunt corners and sharp edges as best you can.
    &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-LJVJObaTKi8/VJjccD3eRfI/AAAAAAAAA-Y/iUFX8Ka01to/s1600/2014-12-22%2B16.41.48.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
        To make the rotisserie spin, I decided to use an old electric drill that had broken out of its case a few years back. I wasn't using it for anything else and I figured that would make inserting and removing the skewer easy. I hooked it up to one of my left over 12V DC power supplies with a switch.
    &lt;/p&gt;
&lt;p&gt;
        Getting the motor to stay put was a little bit of a trick because it didn't have any mounting points. I basically had to strap it in with a few left-over strips of sheet metal. I also added a layer of towel around it, to try to insulate some of the heat.
    &lt;/p&gt;
&lt;p&gt;
        The real engineering came in when I was building the skewer though. I had several problems: &lt;ol&gt;
&lt;li&gt;Get the skewers to attach to the grill and stay put. &lt;/li&gt;
&lt;li&gt;Get the skewers to hold the bird steady and rotate it. &lt;/li&gt;
&lt;li&gt;Get the skewers to connect up on the other side. &lt;/li&gt;
&lt;li&gt;Make it easy enough to get the bird on and mount the damn thing without burning the operator. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;
            Ultimately, to solve these problems, I came up with the &quot;chopsticks&quot; model.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-hCjskui96Mg/VJjc8wW2IGI/AAAAAAAAA-c/HJrmpFhxT2A/s1600/2014-12-22%2B16.42.58.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            It basically works by skewering the bird at an inward angle from both sides so the skewers meet each other as they pass through. This secures the bird and gets the skewers to meet up on the other side. Unfortunately I still don't know how easy it is to work with compared to other rotisserie setups.
        &lt;/p&gt;
&lt;p&gt;
            Finally, I was able to get the skewers attached by rigging up this contraption.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://2.bp.blogspot.com/-wGVDjdSyqjU/VJjdS4hfJOI/AAAAAAAAA-o/j9RSSCSXZqU/s1600/2014-12-22%2B16.43.16.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            It wound up being quite a trick to get the skewers to stay well connected to the motor. It involved rigging some odd attachments with these old gear parts from a broken sewing machine.
        &lt;/p&gt;
&lt;img border=&quot;0&quot; src=&quot;http://3.bp.blogspot.com/-yWmJ8LtzGh4/VJjdrrUD9YI/AAAAAAAAA-s/I8hBOjL82so/s1600/2014-12-22%2B16.44.00.jpg&quot; title=&quot; &quot;/&gt;
&lt;p&gt;
            I screwed those parts on tight to the skewers and to the shaft coming out of the drill motor. Then I joined them together by screwing two plates around them on both sides.
        &lt;/p&gt;
&lt;p&gt;
            Overall, the project took about a week. Now I'll just have to wait to try it out.
        &lt;/p&gt;
&lt;/p&gt;</description>
        <pubDate>Tue, 16 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/introducing-daves-grill-it-all/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/introducing-daves-grill-it-all/</guid>
        
        <category>misc</category>
        
        
      </item>
    
      <item>
        <title>Predicting Bike Share Usage</title>
        <description>&lt;p&gt;
    I recently worked on a &lt;a href=&quot;https://www.kaggle.com/&quot;&gt;Kaggle&lt;/a&gt; competition while I was taking Coursera's &lt;a href=&quot;https://www.coursera.org/course/datasci&quot;&gt;Introduction to Data Science&lt;/a&gt;. Here's a quick summary of what I came up with.
&lt;/p&gt;
&lt;img alt=&quot;Hangzhou bike sharing station&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Hangzhou_bike_sharing_station.jpg/512px-Hangzhou_bike_sharing_station.jpg&quot; title=&quot;Payton Chung [CC BY (https://creativecommons.org/licenses/by/2.0)]&quot; width=&quot;512&quot;/&gt;
&lt;p&gt;
    The goal of this project was to come up with a system to predict how many bikes will be used during a given hour.
&lt;/p&gt;
&lt;p&gt;
    The bike share company provided us with historical data for two years, including hourly weather and weekend/holiday information as well as the number of bikes in use each hour. I tested my predictions against the hourly bike usage for the last week of every month.
&lt;/p&gt;
&lt;p&gt;
    Because there were slowly-varying trends in bike share popularity over this time, I decided that the most important factor was the average for a given hour over the past 5-10 days. I therefore, generated this statistic from the underlying dataset by performing a moving average. I then supplied the weather and holiday statistics along with the moving average as training data to implementations of a neural network and a random forest. The random forest performed better on my cross-validation set so I used it in my submission.
&lt;/p&gt;
&lt;p&gt;
    The data set was surprisingly small so I simply imported it into the memory of a MATLAB runtime environment. From there, I used a custom script to generate moving averages for every hourly timeslot and added that to the original dataset. These datasets could be fed directly to existing neural network and random forest packages contained in MATLAB. The data munging to create the moving average presented a slight difficulty.
&lt;/p&gt;
&lt;p&gt;
    The approach was simple but still allowed me to improve greatly over the baseline benchmark, reducing the mean error from 1.5 to 0.75. You can check out the &lt;a href=&quot;https://github.com/lots-of-things/biker-predict&quot;&gt;biker-predict&lt;/a&gt; code on github.
&lt;/p&gt;</description>
        <pubDate>Mon, 08 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/predicting-bike-share-usage/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/predicting-bike-share-usage/</guid>
        
        <category>data science</category>
        
        
      </item>
    
      <item>
        <title>A Simple Anagrammer</title>
        <description>&lt;div&gt;
A while back, I wrote a little python code that takes in a word and spits out a list of anagram words.  It kind of takes the fun out of generating anagrams, but it puts the fun back in by letting you figure out how I made them.  Could you do it a better way?  You can look at my &lt;a href=&quot;https://github.com/lots-of-things/simple-anagrammer&quot;&gt; simple-anagrammer &lt;/a&gt; code on github.
&lt;/div&gt;</description>
        <pubDate>Mon, 08 Dec 2014 00:00:00 -0800</pubDate>
        <link>https://bonkerfield.org/2014/12/a-simple-anagrammer/</link>
        <guid isPermaLink="true">https://bonkerfield.org/2014/12/a-simple-anagrammer/</guid>
        
        <category>games</category>
        
        
      </item>
    
  </channel>
</rss>
